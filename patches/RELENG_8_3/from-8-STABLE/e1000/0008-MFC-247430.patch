commit b0757380d7906d9f96d38960d697184afc134e42
Author: jfv <jfv@FreeBSD.org>
Date:   Thu Feb 28 00:22:04 2013 +0000

    MFC of the E1000 drivers to STABLE/8, this includes the follow revisions
    plus a few tweaks:
     196969,196970,211516,214646,215781,215789,215808,215910,223350,
     223482,223831,228281,228393,229939,231796,232238,234665,235256,
     236406,238148,238151,238214,238765,238770,238953,238981,239105,
     239109,239304,240518,240693,240968,241037,241856,241885,243570,
     243857,245334,246128,246482,247064

diff --git a/sys/conf/files b/sys/conf/files
index 94c5a5f..d49138c 100644
--- a/sys/conf/files
+++ b/sys/conf/files
@@ -920,6 +920,8 @@ dev/e1000/e1000_82575.c		optional em | igb \
 	compile-with "${NORMAL_C} -I$S/dev/e1000"
 dev/e1000/e1000_ich8lan.c	optional em | igb \
 	compile-with "${NORMAL_C} -I$S/dev/e1000"
+dev/e1000/e1000_i210.c		optional em | igb \
+	compile-with "${NORMAL_C} -I$S/dev/e1000"
 dev/e1000/e1000_api.c		optional em | igb \
 	compile-with "${NORMAL_C} -I$S/dev/e1000"
 dev/e1000/e1000_mac.c		optional em | igb \
diff --git a/sys/dev/e1000/e1000_82541.c b/sys/dev/e1000/e1000_82541.c
index d13611e..781aa93 100644
--- a/sys/dev/e1000/e1000_82541.c
+++ b/sys/dev/e1000/e1000_82541.c
@@ -642,7 +642,7 @@ static s32 e1000_check_for_link_82541(struct e1000_hw *hw)
 	 * of MAC speed/duplex configuration.  So we only need to
 	 * configure Collision Distance in the MAC.
 	 */
-	e1000_config_collision_dist_generic(hw);
+	mac->ops.config_collision_dist(hw);
 
 	/*
 	 * Configure Flow Control now that Auto-Neg has completed.
diff --git a/sys/dev/e1000/e1000_82543.c b/sys/dev/e1000/e1000_82543.c
index 1507da5..1c01658 100644
--- a/sys/dev/e1000/e1000_82543.c
+++ b/sys/dev/e1000/e1000_82543.c
@@ -1126,7 +1126,7 @@ static s32 e1000_setup_copper_link_82543(struct e1000_hw *hw)
 		DEBUGOUT("Valid link established!!!\n");
 		/* Config the MAC and PHY after link is up */
 		if (hw->mac.type == e1000_82544) {
-			e1000_config_collision_dist_generic(hw);
+			hw->mac.ops.config_collision_dist(hw);
 		} else {
 			ret_val = e1000_config_mac_to_phy_82543(hw);
 			if (ret_val)
@@ -1160,7 +1160,7 @@ static s32 e1000_setup_fiber_link_82543(struct e1000_hw *hw)
 	/* Take the link out of reset */
 	ctrl &= ~E1000_CTRL_LRST;
 
-	e1000_config_collision_dist_generic(hw);
+	hw->mac.ops.config_collision_dist(hw);
 
 	ret_val = e1000_commit_fc_settings_generic(hw);
 	if (ret_val)
@@ -1259,7 +1259,7 @@ static s32 e1000_check_for_copper_link_82543(struct e1000_hw *hw)
 	 * settings.
 	 */
 	if (mac->type == e1000_82544)
-		e1000_config_collision_dist_generic(hw);
+		hw->mac.ops.config_collision_dist(hw);
 	else {
 		ret_val = e1000_config_mac_to_phy_82543(hw);
 		if (ret_val) {
@@ -1433,7 +1433,7 @@ static s32 e1000_config_mac_to_phy_82543(struct e1000_hw *hw)
 	if (phy_data & M88E1000_PSSR_DPLX)
 		ctrl |= E1000_CTRL_FD;
 
-	e1000_config_collision_dist_generic(hw);
+	hw->mac.ops.config_collision_dist(hw);
 
 	/*
 	 * Set up speed in the Device Control register depending on
diff --git a/sys/dev/e1000/e1000_82571.c b/sys/dev/e1000/e1000_82571.c
index a2982b9..ca7a1d0 100644
--- a/sys/dev/e1000/e1000_82571.c
+++ b/sys/dev/e1000/e1000_82571.c
@@ -1,6 +1,6 @@
 /******************************************************************************
 
-  Copyright (c) 2001-2011, Intel Corporation 
+  Copyright (c) 2001-2013, Intel Corporation 
   All rights reserved.
   
   Redistribution and use in source and binary forms, with or without 
@@ -32,8 +32,7 @@
 ******************************************************************************/
 /*$FreeBSD$*/
 
-/*
- * 82571EB Gigabit Ethernet Controller
+/* 82571EB Gigabit Ethernet Controller
  * 82571EB Gigabit Ethernet Controller (Copper)
  * 82571EB Gigabit Ethernet Controller (Fiber)
  * 82571EB Dual Port Gigabit Mezzanine Adapter
@@ -51,9 +50,6 @@
 
 #include "e1000_api.h"
 
-static s32  e1000_init_phy_params_82571(struct e1000_hw *hw);
-static s32  e1000_init_nvm_params_82571(struct e1000_hw *hw);
-static s32  e1000_init_mac_params_82571(struct e1000_hw *hw);
 static s32  e1000_acquire_nvm_82571(struct e1000_hw *hw);
 static void e1000_release_nvm_82571(struct e1000_hw *hw);
 static s32  e1000_write_nvm_82571(struct e1000_hw *hw, u16 offset,
@@ -78,7 +74,6 @@ static s32  e1000_get_hw_semaphore_82571(struct e1000_hw *hw);
 static s32  e1000_fix_nvm_checksum_82571(struct e1000_hw *hw);
 static s32  e1000_get_phy_id_82571(struct e1000_hw *hw);
 static void e1000_put_hw_semaphore_82571(struct e1000_hw *hw);
-static s32  e1000_get_hw_semaphore_82573(struct e1000_hw *hw);
 static void e1000_put_hw_semaphore_82573(struct e1000_hw *hw);
 static s32  e1000_get_hw_semaphore_82574(struct e1000_hw *hw);
 static void e1000_put_hw_semaphore_82574(struct e1000_hw *hw);
@@ -99,13 +94,13 @@ static void e1000_power_down_phy_copper_82571(struct e1000_hw *hw);
 static s32 e1000_init_phy_params_82571(struct e1000_hw *hw)
 {
 	struct e1000_phy_info *phy = &hw->phy;
-	s32 ret_val = E1000_SUCCESS;
+	s32 ret_val;
 
 	DEBUGFUNC("e1000_init_phy_params_82571");
 
 	if (hw->phy.media_type != e1000_media_type_copper) {
 		phy->type = e1000_phy_none;
-		goto out;
+		return E1000_SUCCESS;
 	}
 
 	phy->addr			= 1;
@@ -165,8 +160,7 @@ static s32 e1000_init_phy_params_82571(struct e1000_hw *hw)
 		phy->ops.set_d3_lplu_state = e1000_set_d3_lplu_state_82574;
 		break;
 	default:
-		ret_val = -E1000_ERR_PHY;
-		goto out;
+		return -E1000_ERR_PHY;
 		break;
 	}
 
@@ -174,7 +168,7 @@ static s32 e1000_init_phy_params_82571(struct e1000_hw *hw)
 	ret_val = e1000_get_phy_id_82571(hw);
 	if (ret_val) {
 		DEBUGOUT("Error getting PHY ID\n");
-		goto out;
+		return ret_val;
 	}
 
 	/* Verify phy id */
@@ -201,7 +195,6 @@ static s32 e1000_init_phy_params_82571(struct e1000_hw *hw)
 	if (ret_val)
 		DEBUGOUT1("PHY ID unknown: type = 0x%08x\n", phy->id);
 
-out:
 	return ret_val;
 }
 
@@ -241,8 +234,7 @@ static s32 e1000_init_nvm_params_82571(struct e1000_hw *hw)
 		if (((eecd >> 15) & 0x3) == 0x3) {
 			nvm->type = e1000_nvm_flash_hw;
 			nvm->word_size = 2048;
-			/*
-			 * Autonomous Flash update bit must be cleared due
+			/* Autonomous Flash update bit must be cleared due
 			 * to Flash update issue.
 			 */
 			eecd &= ~E1000_EECD_AUPDEN;
@@ -254,8 +246,7 @@ static s32 e1000_init_nvm_params_82571(struct e1000_hw *hw)
 		nvm->type = e1000_nvm_eeprom_spi;
 		size = (u16)((eecd & E1000_EECD_SIZE_EX_MASK) >>
 			     E1000_EECD_SIZE_EX_SHIFT);
-		/*
-		 * Added to a constant, "size" becomes the left-shift value
+		/* Added to a constant, "size" becomes the left-shift value
 		 * for setting word_size.
 		 */
 		size += NVM_WORD_SIZE_BASE_SHIFT;
@@ -382,12 +373,11 @@ static s32 e1000_init_mac_params_82571(struct e1000_hw *hw)
 
 		/* FWSM register */
 		mac->has_fwsm = TRUE;
-		/*
-		 * ARC supported; valid only if manageability features are
+		/* ARC supported; valid only if manageability features are
 		 * enabled.
 		 */
-		mac->arc_subsystem_valid = (E1000_READ_REG(hw, E1000_FWSM) &
-					   E1000_FWSM_MODE_MASK) ? TRUE : FALSE;
+		mac->arc_subsystem_valid = !!(E1000_READ_REG(hw, E1000_FWSM) &
+					      E1000_FWSM_MODE_MASK);
 		break;
 	case e1000_82574:
 	case e1000_82583:
@@ -405,8 +395,7 @@ static s32 e1000_init_mac_params_82571(struct e1000_hw *hw)
 		break;
 	}
 
-	/*
-	 * Ensure that the inter-port SWSM.SMBI lock bit is clear before
+	/* Ensure that the inter-port SWSM.SMBI lock bit is clear before
 	 * first NVM or PHY acess. This should be done for single-port
 	 * devices, and for one port only on dual-port devices so that
 	 * for those devices we can still use the SMBI lock to synchronize
@@ -422,8 +411,9 @@ static s32 e1000_init_mac_params_82571(struct e1000_hw *hw)
 			E1000_WRITE_REG(hw, E1000_SWSM2, swsm2 |
 					E1000_SWSM2_LOCK);
 			force_clear_smbi = TRUE;
-		} else
+		} else {
 			force_clear_smbi = FALSE;
+		}
 		break;
 	default:
 		force_clear_smbi = TRUE;
@@ -443,10 +433,7 @@ static s32 e1000_init_mac_params_82571(struct e1000_hw *hw)
 		E1000_WRITE_REG(hw, E1000_SWSM, swsm & ~E1000_SWSM_SMBI);
 	}
 
-	/*
-	 * Initialze device specific counter of SMBI acquisition
-	 * timeouts.
-	 */
+	/* Initialze device specific counter of SMBI acquisition timeouts. */
 	 hw->dev_spec._82571.smb_counter = 0;
 
 	return E1000_SUCCESS;
@@ -477,7 +464,7 @@ void e1000_init_function_pointers_82571(struct e1000_hw *hw)
 static s32 e1000_get_phy_id_82571(struct e1000_hw *hw)
 {
 	struct e1000_phy_info *phy = &hw->phy;
-	s32 ret_val = E1000_SUCCESS;
+	s32 ret_val;
 	u16 phy_id = 0;
 
 	DEBUGFUNC("e1000_get_phy_id_82571");
@@ -485,8 +472,7 @@ static s32 e1000_get_phy_id_82571(struct e1000_hw *hw)
 	switch (hw->mac.type) {
 	case e1000_82571:
 	case e1000_82572:
-		/*
-		 * The 82571 firmware may still be configuring the PHY.
+		/* The 82571 firmware may still be configuring the PHY.
 		 * In this case, we cannot access the PHY until the
 		 * configuration is done.  So we explicitly set the
 		 * PHY ID.
@@ -494,29 +480,29 @@ static s32 e1000_get_phy_id_82571(struct e1000_hw *hw)
 		phy->id = IGP01E1000_I_PHY_ID;
 		break;
 	case e1000_82573:
-		ret_val = e1000_get_phy_id(hw);
+		return e1000_get_phy_id(hw);
 		break;
 	case e1000_82574:
 	case e1000_82583:
 		ret_val = phy->ops.read_reg(hw, PHY_ID1, &phy_id);
 		if (ret_val)
-			goto out;
+			return ret_val;
 
 		phy->id = (u32)(phy_id << 16);
 		usec_delay(20);
 		ret_val = phy->ops.read_reg(hw, PHY_ID2, &phy_id);
 		if (ret_val)
-			goto out;
+			return ret_val;
 
 		phy->id |= (u32)(phy_id);
 		phy->revision = (u32)(phy_id & ~PHY_REVISION_MASK);
 		break;
 	default:
-		ret_val = -E1000_ERR_PHY;
+		return -E1000_ERR_PHY;
 		break;
 	}
-out:
-	return ret_val;
+
+	return E1000_SUCCESS;
 }
 
 /**
@@ -528,15 +514,13 @@ out:
 static s32 e1000_get_hw_semaphore_82571(struct e1000_hw *hw)
 {
 	u32 swsm;
-	s32 ret_val = E1000_SUCCESS;
 	s32 sw_timeout = hw->nvm.word_size + 1;
 	s32 fw_timeout = hw->nvm.word_size + 1;
 	s32 i = 0;
 
 	DEBUGFUNC("e1000_get_hw_semaphore_82571");
 
-	/*
-	 * If we have timedout 3 times on trying to acquire
+	/* If we have timedout 3 times on trying to acquire
 	 * the inter-port SMBI semaphore, there is old code
 	 * operating on the other port, and it is not
 	 * releasing SMBI. Modify the number of times that
@@ -576,12 +560,10 @@ static s32 e1000_get_hw_semaphore_82571(struct e1000_hw *hw)
 		/* Release semaphores */
 		e1000_put_hw_semaphore_82571(hw);
 		DEBUGOUT("Driver can't access the NVM\n");
-		ret_val = -E1000_ERR_NVM;
-		goto out;
+		return -E1000_ERR_NVM;
 	}
 
-out:
-	return ret_val;
+	return E1000_SUCCESS;
 }
 
 /**
@@ -613,22 +595,19 @@ static void e1000_put_hw_semaphore_82571(struct e1000_hw *hw)
 static s32 e1000_get_hw_semaphore_82573(struct e1000_hw *hw)
 {
 	u32 extcnf_ctrl;
-	s32 ret_val = E1000_SUCCESS;
 	s32 i = 0;
 
 	DEBUGFUNC("e1000_get_hw_semaphore_82573");
 
 	extcnf_ctrl = E1000_READ_REG(hw, E1000_EXTCNF_CTRL);
-	extcnf_ctrl |= E1000_EXTCNF_CTRL_MDIO_SW_OWNERSHIP;
 	do {
+		extcnf_ctrl |= E1000_EXTCNF_CTRL_MDIO_SW_OWNERSHIP;
 		E1000_WRITE_REG(hw, E1000_EXTCNF_CTRL, extcnf_ctrl);
 		extcnf_ctrl = E1000_READ_REG(hw, E1000_EXTCNF_CTRL);
 
 		if (extcnf_ctrl & E1000_EXTCNF_CTRL_MDIO_SW_OWNERSHIP)
 			break;
 
-		extcnf_ctrl |= E1000_EXTCNF_CTRL_MDIO_SW_OWNERSHIP;
-
 		msec_delay(2);
 		i++;
 	} while (i < MDIO_OWNERSHIP_TIMEOUT);
@@ -637,12 +616,10 @@ static s32 e1000_get_hw_semaphore_82573(struct e1000_hw *hw)
 		/* Release semaphores */
 		e1000_put_hw_semaphore_82573(hw);
 		DEBUGOUT("Driver can't access the PHY\n");
-		ret_val = -E1000_ERR_PHY;
-		goto out;
+		return -E1000_ERR_PHY;
 	}
 
-out:
-	return ret_val;
+	return E1000_SUCCESS;
 }
 
 /**
@@ -712,7 +689,7 @@ static void e1000_put_hw_semaphore_82574(struct e1000_hw *hw)
  **/
 static s32 e1000_set_d0_lplu_state_82574(struct e1000_hw *hw, bool active)
 {
-	u16 data = E1000_READ_REG(hw, E1000_POEMB);
+	u32 data = E1000_READ_REG(hw, E1000_POEMB);
 
 	DEBUGFUNC("e1000_set_d0_lplu_state_82574");
 
@@ -738,7 +715,7 @@ static s32 e1000_set_d0_lplu_state_82574(struct e1000_hw *hw, bool active)
  **/
 static s32 e1000_set_d3_lplu_state_82574(struct e1000_hw *hw, bool active)
 {
-	u16 data = E1000_READ_REG(hw, E1000_POEMB);
+	u32 data = E1000_READ_REG(hw, E1000_POEMB);
 
 	DEBUGFUNC("e1000_set_d3_lplu_state_82574");
 
@@ -771,7 +748,7 @@ static s32 e1000_acquire_nvm_82571(struct e1000_hw *hw)
 
 	ret_val = e1000_get_hw_semaphore_82571(hw);
 	if (ret_val)
-		goto out;
+		return ret_val;
 
 	switch (hw->mac.type) {
 	case e1000_82573:
@@ -784,7 +761,6 @@ static s32 e1000_acquire_nvm_82571(struct e1000_hw *hw)
 	if (ret_val)
 		e1000_put_hw_semaphore_82571(hw);
 
-out:
 	return ret_val;
 }
 
@@ -817,7 +793,7 @@ static void e1000_release_nvm_82571(struct e1000_hw *hw)
 static s32 e1000_write_nvm_82571(struct e1000_hw *hw, u16 offset, u16 words,
 				 u16 *data)
 {
-	s32 ret_val = E1000_SUCCESS;
+	s32 ret_val;
 
 	DEBUGFUNC("e1000_write_nvm_82571");
 
@@ -857,31 +833,27 @@ static s32 e1000_update_nvm_checksum_82571(struct e1000_hw *hw)
 
 	ret_val = e1000_update_nvm_checksum_generic(hw);
 	if (ret_val)
-		goto out;
+		return ret_val;
 
-	/*
-	 * If our nvm is an EEPROM, then we're done
+	/* If our nvm is an EEPROM, then we're done
 	 * otherwise, commit the checksum to the flash NVM.
 	 */
 	if (hw->nvm.type != e1000_nvm_flash_hw)
-		goto out;
+		return E1000_SUCCESS;
 
 	/* Check for pending operations. */
 	for (i = 0; i < E1000_FLASH_UPDATES; i++) {
 		msec_delay(1);
-		if ((E1000_READ_REG(hw, E1000_EECD) & E1000_EECD_FLUPD) == 0)
+		if (!(E1000_READ_REG(hw, E1000_EECD) & E1000_EECD_FLUPD))
 			break;
 	}
 
-	if (i == E1000_FLASH_UPDATES) {
-		ret_val = -E1000_ERR_NVM;
-		goto out;
-	}
+	if (i == E1000_FLASH_UPDATES)
+		return -E1000_ERR_NVM;
 
 	/* Reset the firmware if using STM opcode. */
 	if ((E1000_READ_REG(hw, E1000_FLOP) & 0xFF00) == E1000_STM_OPCODE) {
-		/*
-		 * The enabling of and the actual reset must be done
+		/* The enabling of and the actual reset must be done
 		 * in two write cycles.
 		 */
 		E1000_WRITE_REG(hw, E1000_HICR, E1000_HICR_FW_RESET_ENABLE);
@@ -895,17 +867,14 @@ static s32 e1000_update_nvm_checksum_82571(struct e1000_hw *hw)
 
 	for (i = 0; i < E1000_FLASH_UPDATES; i++) {
 		msec_delay(1);
-		if ((E1000_READ_REG(hw, E1000_EECD) & E1000_EECD_FLUPD) == 0)
+		if (!(E1000_READ_REG(hw, E1000_EECD) & E1000_EECD_FLUPD))
 			break;
 	}
 
-	if (i == E1000_FLASH_UPDATES) {
-		ret_val = -E1000_ERR_NVM;
-		goto out;
-	}
+	if (i == E1000_FLASH_UPDATES)
+		return -E1000_ERR_NVM;
 
-out:
-	return ret_val;
+	return E1000_SUCCESS;
 }
 
 /**
@@ -944,19 +913,17 @@ static s32 e1000_write_nvm_eewr_82571(struct e1000_hw *hw, u16 offset,
 {
 	struct e1000_nvm_info *nvm = &hw->nvm;
 	u32 i, eewr = 0;
-	s32 ret_val = 0;
+	s32 ret_val = E1000_SUCCESS;
 
 	DEBUGFUNC("e1000_write_nvm_eewr_82571");
 
-	/*
-	 * A check for invalid values:  offset too large, too many words,
+	/* A check for invalid values:  offset too large, too many words,
 	 * and not enough words.
 	 */
 	if ((offset >= nvm->word_size) || (words > (nvm->word_size - offset)) ||
 	    (words == 0)) {
 		DEBUGOUT("nvm parameter(s) out of bounds\n");
-		ret_val = -E1000_ERR_NVM;
-		goto out;
+		return -E1000_ERR_NVM;
 	}
 
 	for (i = 0; i < words; i++) {
@@ -975,7 +942,6 @@ static s32 e1000_write_nvm_eewr_82571(struct e1000_hw *hw, u16 offset,
 			break;
 	}
 
-out:
 	return ret_val;
 }
 
@@ -988,7 +954,6 @@ out:
 static s32 e1000_get_cfg_done_82571(struct e1000_hw *hw)
 {
 	s32 timeout = PHY_CFG_TIMEOUT;
-	s32 ret_val = E1000_SUCCESS;
 
 	DEBUGFUNC("e1000_get_cfg_done_82571");
 
@@ -1001,12 +966,10 @@ static s32 e1000_get_cfg_done_82571(struct e1000_hw *hw)
 	}
 	if (!timeout) {
 		DEBUGOUT("MNG configuration cycle has not completed.\n");
-		ret_val = -E1000_ERR_RESET;
-		goto out;
+		return -E1000_ERR_RESET;
 	}
 
-out:
-	return ret_val;
+	return E1000_SUCCESS;
 }
 
 /**
@@ -1023,39 +986,40 @@ out:
 static s32 e1000_set_d0_lplu_state_82571(struct e1000_hw *hw, bool active)
 {
 	struct e1000_phy_info *phy = &hw->phy;
-	s32 ret_val = E1000_SUCCESS;
+	s32 ret_val;
 	u16 data;
 
 	DEBUGFUNC("e1000_set_d0_lplu_state_82571");
 
 	if (!(phy->ops.read_reg))
-		goto out;
+		return E1000_SUCCESS;
 
 	ret_val = phy->ops.read_reg(hw, IGP02E1000_PHY_POWER_MGMT, &data);
 	if (ret_val)
-		goto out;
+		return ret_val;
 
 	if (active) {
 		data |= IGP02E1000_PM_D0_LPLU;
 		ret_val = phy->ops.write_reg(hw, IGP02E1000_PHY_POWER_MGMT,
 					     data);
 		if (ret_val)
-			goto out;
+			return ret_val;
 
 		/* When LPLU is enabled, we should disable SmartSpeed */
 		ret_val = phy->ops.read_reg(hw, IGP01E1000_PHY_PORT_CONFIG,
 					    &data);
+		if (ret_val)
+			return ret_val;
 		data &= ~IGP01E1000_PSCFR_SMART_SPEED;
 		ret_val = phy->ops.write_reg(hw, IGP01E1000_PHY_PORT_CONFIG,
 					     data);
 		if (ret_val)
-			goto out;
+			return ret_val;
 	} else {
 		data &= ~IGP02E1000_PM_D0_LPLU;
 		ret_val = phy->ops.write_reg(hw, IGP02E1000_PHY_POWER_MGMT,
 					     data);
-		/*
-		 * LPLU and SmartSpeed are mutually exclusive.  LPLU is used
+		/* LPLU and SmartSpeed are mutually exclusive.  LPLU is used
 		 * during Dx states where the power conservation is most
 		 * important.  During driver activity we should enable
 		 * SmartSpeed, so performance is maintained.
@@ -1065,32 +1029,31 @@ static s32 e1000_set_d0_lplu_state_82571(struct e1000_hw *hw, bool active)
 						    IGP01E1000_PHY_PORT_CONFIG,
 						    &data);
 			if (ret_val)
-				goto out;
+				return ret_val;
 
 			data |= IGP01E1000_PSCFR_SMART_SPEED;
 			ret_val = phy->ops.write_reg(hw,
 						     IGP01E1000_PHY_PORT_CONFIG,
 						     data);
 			if (ret_val)
-				goto out;
+				return ret_val;
 		} else if (phy->smart_speed == e1000_smart_speed_off) {
 			ret_val = phy->ops.read_reg(hw,
 						    IGP01E1000_PHY_PORT_CONFIG,
 						    &data);
 			if (ret_val)
-				goto out;
+				return ret_val;
 
 			data &= ~IGP01E1000_PSCFR_SMART_SPEED;
 			ret_val = phy->ops.write_reg(hw,
 						     IGP01E1000_PHY_PORT_CONFIG,
 						     data);
 			if (ret_val)
-				goto out;
+				return ret_val;
 		}
 	}
 
-out:
-	return ret_val;
+	return E1000_SUCCESS;
 }
 
 /**
@@ -1101,13 +1064,12 @@ out:
  **/
 static s32 e1000_reset_hw_82571(struct e1000_hw *hw)
 {
-	u32 ctrl, ctrl_ext;
+	u32 ctrl, ctrl_ext, eecd, tctl;
 	s32 ret_val;
 
 	DEBUGFUNC("e1000_reset_hw_82571");
 
-	/*
-	 * Prevent the PCI-E bus from sticking if there is no TLP connection
+	/* Prevent the PCI-E bus from sticking if there is no TLP connection
 	 * on the last TLP read/write transaction when MAC is reset.
 	 */
 	ret_val = e1000_disable_pcie_master_generic(hw);
@@ -1118,13 +1080,14 @@ static s32 e1000_reset_hw_82571(struct e1000_hw *hw)
 	E1000_WRITE_REG(hw, E1000_IMC, 0xffffffff);
 
 	E1000_WRITE_REG(hw, E1000_RCTL, 0);
-	E1000_WRITE_REG(hw, E1000_TCTL, E1000_TCTL_PSP);
+	tctl = E1000_READ_REG(hw, E1000_TCTL);
+	tctl &= ~E1000_TCTL_EN;
+	E1000_WRITE_REG(hw, E1000_TCTL, tctl);
 	E1000_WRITE_FLUSH(hw);
 
 	msec_delay(10);
 
-	/*
-	 * Must acquire the MDIO ownership before MAC reset.
+	/* Must acquire the MDIO ownership before MAC reset.
 	 * Ownership defaults to firmware after a reset.
 	 */
 	switch (hw->mac.type) {
@@ -1167,15 +1130,23 @@ static s32 e1000_reset_hw_82571(struct e1000_hw *hw)
 	ret_val = e1000_get_auto_rd_done_generic(hw);
 	if (ret_val)
 		/* We don't want to continue accessing MAC registers. */
-		goto out;
+		return ret_val;
 
-	/*
-	 * Phy configuration from NVM just starts after EECD_AUTO_RD is set.
+	/* Phy configuration from NVM just starts after EECD_AUTO_RD is set.
 	 * Need to wait for Phy configuration completion before accessing
 	 * NVM and Phy.
 	 */
 
 	switch (hw->mac.type) {
+	case e1000_82571:
+	case e1000_82572:
+		/* REQ and GNT bits need to be cleared when using AUTO_RD
+		 * to access the EEPROM.
+		 */
+		eecd = E1000_READ_REG(hw, E1000_EECD);
+		eecd &= ~(E1000_EECD_REQ | E1000_EECD_GNT);
+		E1000_WRITE_REG(hw, E1000_EECD, eecd);
+		break;
 	case e1000_82573:
 	case e1000_82574:
 	case e1000_82583:
@@ -1193,7 +1164,7 @@ static s32 e1000_reset_hw_82571(struct e1000_hw *hw)
 		/* Install any alternate MAC address into RAR0 */
 		ret_val = e1000_check_alt_mac_addr_generic(hw);
 		if (ret_val)
-			goto out;
+			return ret_val;
 
 		e1000_set_laa_state_82571(hw, TRUE);
 	}
@@ -1202,8 +1173,7 @@ static s32 e1000_reset_hw_82571(struct e1000_hw *hw)
 	if (hw->phy.media_type == e1000_media_type_internal_serdes)
 		hw->mac.serdes_link_state = e1000_serdes_link_down;
 
-out:
-	return ret_val;
+	return E1000_SUCCESS;
 }
 
 /**
@@ -1225,16 +1195,15 @@ static s32 e1000_init_hw_82571(struct e1000_hw *hw)
 
 	/* Initialize identification LED */
 	ret_val = mac->ops.id_led_init(hw);
+	/* An error is not fatal and we should not stop init due to this */
 	if (ret_val)
 		DEBUGOUT("Error initializing identification LED\n");
-		/* This is not fatal and we should not stop init due to this */
 
 	/* Disabling VLAN filtering */
 	DEBUGOUT("Initializing the IEEE VLAN\n");
 	mac->ops.clear_vfta(hw);
 
-	/* Setup the receive address. */
-	/*
+	/* Setup the receive address.
 	 * If, however, a locally administered address was assigned to the
 	 * 82571, we must reserve a RAR for it to work around an issue where
 	 * resetting one port will reload the MAC on the other port.
@@ -1277,8 +1246,7 @@ static s32 e1000_init_hw_82571(struct e1000_hw *hw)
 		break;
 	}
 
-	/*
-	 * Clear all of the statistics registers (clear on read).  It is
+	/* Clear all of the statistics registers (clear on read).  It is
 	 * important that we do this after we have tried to establish link
 	 * because the symbol error count will increment wildly if there
 	 * is no link.
@@ -1377,8 +1345,7 @@ static void e1000_initialize_hw_bits_82571(struct e1000_hw *hw)
 		E1000_WRITE_REG(hw, E1000_PBA_ECC, reg);
 	}
 
-	/*
-	 * Workaround for hardware errata.
+	/* Workaround for hardware errata.
 	 * Ensure that DMA Dynamic Clock gating is disabled on 82571 and 82572
 	 */
 	if ((hw->mac.type == e1000_82571) ||
@@ -1388,6 +1355,15 @@ static void e1000_initialize_hw_bits_82571(struct e1000_hw *hw)
 		E1000_WRITE_REG(hw, E1000_CTRL_EXT, reg);
 	}
 
+	/* Disable IPv6 extension header parsing because some malformed
+	 * IPv6 headers can hang the Rx.
+	 */
+	if (hw->mac.type <= e1000_82573) {
+		reg = E1000_READ_REG(hw, E1000_RFCTL);
+		reg |= (E1000_RFCTL_IPV6_EX_DIS | E1000_RFCTL_NEW_IPV6_EXT_DIS);
+		E1000_WRITE_REG(hw, E1000_RFCTL, reg);
+	}
+
 	/* PCI-Ex Control Registers */
 	switch (hw->mac.type) {
 	case e1000_82574:
@@ -1396,8 +1372,7 @@ static void e1000_initialize_hw_bits_82571(struct e1000_hw *hw)
 		reg |= (1 << 22);
 		E1000_WRITE_REG(hw, E1000_GCR, reg);
 
-		/*
-		 * Workaround for hardware errata.
+		/* Workaround for hardware errata.
 		 * apply workaround for hardware errata documented in errata
 		 * docs Fixes issue where some error prone or unreliable PCIe
 		 * completions are occurring, particularly with ASPM enabled.
@@ -1435,25 +1410,25 @@ static void e1000_clear_vfta_82571(struct e1000_hw *hw)
 	case e1000_82574:
 	case e1000_82583:
 		if (hw->mng_cookie.vlan_id != 0) {
-			/*
-			 * The VFTA is a 4096b bit-field, each identifying
+			/* The VFTA is a 4096b bit-field, each identifying
 			 * a single VLAN ID.  The following operations
 			 * determine which 32b entry (i.e. offset) into the
 			 * array we want to set the VLAN ID (i.e. bit) of
 			 * the manageability unit.
 			 */
 			vfta_offset = (hw->mng_cookie.vlan_id >>
-				E1000_VFTA_ENTRY_SHIFT) & E1000_VFTA_ENTRY_MASK;
-			vfta_bit_in_reg = 1 << (hw->mng_cookie.vlan_id &
-				E1000_VFTA_ENTRY_BIT_SHIFT_MASK);
+				       E1000_VFTA_ENTRY_SHIFT) &
+			    E1000_VFTA_ENTRY_MASK;
+			vfta_bit_in_reg =
+			    1 << (hw->mng_cookie.vlan_id &
+				  E1000_VFTA_ENTRY_BIT_SHIFT_MASK);
 		}
 		break;
 	default:
 		break;
 	}
 	for (offset = 0; offset < E1000_VLAN_FILTER_TBL_SIZE; offset++) {
-		/*
-		 * If the offset we want to clear is the same offset of the
+		/* If the offset we want to clear is the same offset of the
 		 * manageability VLAN ID, then clear all bits except that of
 		 * the manageability unit.
 		 */
@@ -1495,8 +1470,7 @@ static s32 e1000_led_on_82574(struct e1000_hw *hw)
 
 	ctrl = hw->mac.ledctl_mode2;
 	if (!(E1000_STATUS_LU & E1000_READ_REG(hw, E1000_STATUS))) {
-		/*
-		 * If no link, then turn LED on by setting the invert bit
+		/* If no link, then turn LED on by setting the invert bit
 		 * for each LED that's "on" (0x0E) in ledctl_mode2.
 		 */
 		for (i = 0; i < 4; i++)
@@ -1519,30 +1493,28 @@ bool e1000_check_phy_82574(struct e1000_hw *hw)
 {
 	u16 status_1kbt = 0;
 	u16 receive_errors = 0;
-	bool phy_hung = FALSE;
-	s32 ret_val = E1000_SUCCESS;
+	s32 ret_val;
 
 	DEBUGFUNC("e1000_check_phy_82574");
 
-	/*
-	 * Read PHY Receive Error counter first, if its is max - all F's then
+	/* Read PHY Receive Error counter first, if its is max - all F's then
 	 * read the Base1000T status register If both are max then PHY is hung.
 	 */
 	ret_val = hw->phy.ops.read_reg(hw, E1000_RECEIVE_ERROR_COUNTER,
 				       &receive_errors);
 	if (ret_val)
-		goto out;
+		return FALSE;
 	if (receive_errors == E1000_RECEIVE_ERROR_MAX) {
 		ret_val = hw->phy.ops.read_reg(hw, E1000_BASE1000T_STATUS,
 					       &status_1kbt);
 		if (ret_val)
-			goto out;
+			return FALSE;
 		if ((status_1kbt & E1000_IDLE_ERROR_COUNT_MASK) ==
 		    E1000_IDLE_ERROR_COUNT_MASK)
-			phy_hung = TRUE;
+			return TRUE;
 	}
-out:
-	return phy_hung;
+
+	return FALSE;
 }
 
 
@@ -1560,8 +1532,7 @@ static s32 e1000_setup_link_82571(struct e1000_hw *hw)
 {
 	DEBUGFUNC("e1000_setup_link_82571");
 
-	/*
-	 * 82573 does not have a word in the NVM to determine
+	/* 82573 does not have a word in the NVM to determine
 	 * the default flow control setting, so we explicitly
 	 * set it to full.
 	 */
@@ -1608,17 +1579,14 @@ static s32 e1000_setup_copper_link_82571(struct e1000_hw *hw)
 		ret_val = e1000_copper_link_setup_igp(hw);
 		break;
 	default:
-		ret_val = -E1000_ERR_PHY;
+		return -E1000_ERR_PHY;
 		break;
 	}
 
 	if (ret_val)
-		goto out;
-
-	ret_val = e1000_setup_copper_link_generic(hw);
+		return ret_val;
 
-out:
-	return ret_val;
+	return e1000_setup_copper_link_generic(hw);
 }
 
 /**
@@ -1635,8 +1603,7 @@ static s32 e1000_setup_fiber_serdes_link_82571(struct e1000_hw *hw)
 	switch (hw->mac.type) {
 	case e1000_82571:
 	case e1000_82572:
-		/*
-		 * If SerDes loopback mode is entered, there is no form
+		/* If SerDes loopback mode is entered, there is no form
 		 * of reset to take the adapter out of that mode.  So we
 		 * have to explicitly take the adapter out of loopback
 		 * mode.  This prevents drivers from twiddling their thumbs
@@ -1685,16 +1652,17 @@ static s32 e1000_check_for_serdes_link_82571(struct e1000_hw *hw)
 
 	ctrl = E1000_READ_REG(hw, E1000_CTRL);
 	status = E1000_READ_REG(hw, E1000_STATUS);
+	E1000_READ_REG(hw, E1000_RXCW);
+	/* SYNCH bit and IV bit are sticky */
+	usec_delay(10);
 	rxcw = E1000_READ_REG(hw, E1000_RXCW);
 
 	if ((rxcw & E1000_RXCW_SYNCH) && !(rxcw & E1000_RXCW_IV)) {
-
 		/* Receiver is synchronized with no invalid bits.  */
 		switch (mac->serdes_link_state) {
 		case e1000_serdes_link_autoneg_complete:
 			if (!(status & E1000_STATUS_LU)) {
-				/*
-				 * We have lost link, retry autoneg before
+				/* We have lost link, retry autoneg before
 				 * reporting link failure
 				 */
 				mac->serdes_link_state =
@@ -1707,15 +1675,12 @@ static s32 e1000_check_for_serdes_link_82571(struct e1000_hw *hw)
 			break;
 
 		case e1000_serdes_link_forced_up:
-			/*
-			 * If we are receiving /C/ ordered sets, re-enable
+			/* If we are receiving /C/ ordered sets, re-enable
 			 * auto-negotiation in the TXCW register and disable
 			 * forced link in the Device Control register in an
 			 * attempt to auto-negotiate with our link partner.
-			 * If the partner code word is null, stop forcing
-			 * and restart auto negotiation.
 			 */
-			if ((rxcw & E1000_RXCW_C) || !(rxcw & E1000_RXCW_CW))  {
+			if (rxcw & E1000_RXCW_C) {
 				/* Enable autoneg, and unforce link up */
 				E1000_WRITE_REG(hw, E1000_TXCW, mac->txcw);
 				E1000_WRITE_REG(hw, E1000_CTRL,
@@ -1731,8 +1696,7 @@ static s32 e1000_check_for_serdes_link_82571(struct e1000_hw *hw)
 
 		case e1000_serdes_link_autoneg_progress:
 			if (rxcw & E1000_RXCW_C) {
-				/*
-				 * We received /C/ ordered sets, meaning the
+				/* We received /C/ ordered sets, meaning the
 				 * link partner has autonegotiated, and we can
 				 * trust the Link Up (LU) status bit.
 				 */
@@ -1748,8 +1712,7 @@ static s32 e1000_check_for_serdes_link_82571(struct e1000_hw *hw)
 					DEBUGOUT("AN_PROG   -> DOWN\n");
 				}
 			} else {
-				/*
-				 * The link partner did not autoneg.
+				/* The link partner did not autoneg.
 				 * Force link up and full duplex, and change
 				 * state to forced.
 				 */
@@ -1774,8 +1737,7 @@ static s32 e1000_check_for_serdes_link_82571(struct e1000_hw *hw)
 
 		case e1000_serdes_link_down:
 		default:
-			/*
-			 * The link was down but the receiver has now gained
+			/* The link was down but the receiver has now gained
 			 * valid sync, so lets see if we can bring the link
 			 * up.
 			 */
@@ -1794,17 +1756,18 @@ static s32 e1000_check_for_serdes_link_82571(struct e1000_hw *hw)
 			mac->serdes_link_state = e1000_serdes_link_down;
 			DEBUGOUT("ANYSTATE  -> DOWN\n");
 		} else {
-			/*
-			 * Check several times, if Sync and Config
-			 * both are consistently 1 then simply ignore
-			 * the Invalid bit and restart Autoneg
+			/* Check several times, if SYNCH bit and CONFIG
+			 * bit both are consistently 1 then simply ignore
+			 * the IV bit and restart Autoneg
 			 */
 			for (i = 0; i < AN_RETRY_COUNT; i++) {
 				usec_delay(10);
 				rxcw = E1000_READ_REG(hw, E1000_RXCW);
-				if ((rxcw & E1000_RXCW_IV) &&
-				    !((rxcw & E1000_RXCW_SYNCH) &&
-				      (rxcw & E1000_RXCW_C))) {
+				if ((rxcw & E1000_RXCW_SYNCH) &&
+				    (rxcw & E1000_RXCW_C))
+					continue;
+
+				if (rxcw & E1000_RXCW_IV) {
 					mac->serdes_has_link = FALSE;
 					mac->serdes_link_state =
 							e1000_serdes_link_down;
@@ -1845,7 +1808,7 @@ static s32 e1000_valid_led_default_82571(struct e1000_hw *hw, u16 *data)
 	ret_val = hw->nvm.ops.read(hw, NVM_ID_LED_SETTINGS, 1, data);
 	if (ret_val) {
 		DEBUGOUT("NVM Read Error\n");
-		goto out;
+		return ret_val;
 	}
 
 	switch (hw->mac.type) {
@@ -1862,8 +1825,7 @@ static s32 e1000_valid_led_default_82571(struct e1000_hw *hw, u16 *data)
 		break;
 	}
 
-out:
-	return ret_val;
+	return E1000_SUCCESS;
 }
 
 /**
@@ -1900,15 +1862,14 @@ void e1000_set_laa_state_82571(struct e1000_hw *hw, bool state)
 
 	/* If workaround is activated... */
 	if (state)
-		/*
-		 * Hold a copy of the LAA in RAR[14] This is done so that
+		/* Hold a copy of the LAA in RAR[14] This is done so that
 		 * between the time RAR[0] gets clobbered and the time it
 		 * gets fixed, the actual LAA is in one of the RARs and no
 		 * incoming packets directed to this port are dropped.
 		 * Eventually the LAA will be in RAR[0] and RAR[14].
 		 */
-		e1000_rar_set_generic(hw, hw->mac.addr,
-				      hw->mac.rar_entry_count - 1);
+		hw->mac.ops.rar_set(hw, hw->mac.addr,
+				    hw->mac.rar_entry_count - 1);
 	return;
 }
 
@@ -1925,25 +1886,23 @@ void e1000_set_laa_state_82571(struct e1000_hw *hw, bool state)
 static s32 e1000_fix_nvm_checksum_82571(struct e1000_hw *hw)
 {
 	struct e1000_nvm_info *nvm = &hw->nvm;
-	s32 ret_val = E1000_SUCCESS;
+	s32 ret_val;
 	u16 data;
 
 	DEBUGFUNC("e1000_fix_nvm_checksum_82571");
 
 	if (nvm->type != e1000_nvm_flash_hw)
-		goto out;
+		return E1000_SUCCESS;
 
-	/*
-	 * Check bit 4 of word 10h.  If it is 0, firmware is done updating
+	/* Check bit 4 of word 10h.  If it is 0, firmware is done updating
 	 * 10h-12h.  Checksum may need to be fixed.
 	 */
 	ret_val = nvm->ops.read(hw, 0x10, 1, &data);
 	if (ret_val)
-		goto out;
+		return ret_val;
 
 	if (!(data & 0x10)) {
-		/*
-		 * Read 0x23 and check bit 15.  This bit is a 1
+		/* Read 0x23 and check bit 15.  This bit is a 1
 		 * when the checksum has already been fixed.  If
 		 * the checksum is still wrong and this bit is a
 		 * 1, we need to return bad checksum.  Otherwise,
@@ -1952,19 +1911,20 @@ static s32 e1000_fix_nvm_checksum_82571(struct e1000_hw *hw)
 		 */
 		ret_val = nvm->ops.read(hw, 0x23, 1, &data);
 		if (ret_val)
-			goto out;
+			return ret_val;
 
 		if (!(data & 0x8000)) {
 			data |= 0x8000;
 			ret_val = nvm->ops.write(hw, 0x23, 1, &data);
 			if (ret_val)
-				goto out;
+				return ret_val;
 			ret_val = nvm->ops.update(hw);
+			if (ret_val)
+				return ret_val;
 		}
 	}
 
-out:
-	return ret_val;
+	return E1000_SUCCESS;
 }
 
 
@@ -1974,25 +1934,21 @@ out:
  **/
 static s32 e1000_read_mac_addr_82571(struct e1000_hw *hw)
 {
-	s32 ret_val = E1000_SUCCESS;
-
 	DEBUGFUNC("e1000_read_mac_addr_82571");
 
 	if (hw->mac.type == e1000_82571) {
-		/*
-		 * If there's an alternate MAC address place it in RAR0
+		s32 ret_val;
+
+		/* If there's an alternate MAC address place it in RAR0
 		 * so that it will override the Si installed default perm
 		 * address.
 		 */
 		ret_val = e1000_check_alt_mac_addr_generic(hw);
 		if (ret_val)
-			goto out;
+			return ret_val;
 	}
 
-	ret_val = e1000_read_mac_addr_generic(hw);
-
-out:
-	return ret_val;
+	return e1000_read_mac_addr_generic(hw);
 }
 
 /**
@@ -2007,7 +1963,7 @@ static void e1000_power_down_phy_copper_82571(struct e1000_hw *hw)
 	struct e1000_phy_info *phy = &hw->phy;
 	struct e1000_mac_info *mac = &hw->mac;
 
-	if (!(phy->ops.check_reset_block))
+	if (!phy->ops.check_reset_block)
 		return;
 
 	/* If the management interface is not enabled, then power down */
diff --git a/sys/dev/e1000/e1000_82575.c b/sys/dev/e1000/e1000_82575.c
index 75fe0a4..5722f46 100644
--- a/sys/dev/e1000/e1000_82575.c
+++ b/sys/dev/e1000/e1000_82575.c
@@ -1,6 +1,6 @@
 /******************************************************************************
 
-  Copyright (c) 2001-2011, Intel Corporation 
+  Copyright (c) 2001-2013, Intel Corporation 
   All rights reserved.
   
   Redistribution and use in source and binary forms, with or without 
@@ -38,9 +38,12 @@
  * 82575GB Gigabit Network Connection
  * 82576 Gigabit Network Connection
  * 82576 Quad Port Gigabit Mezzanine Adapter
+ * 82580 Gigabit Network Connection
+ * I350 Gigabit Network Connection
  */
 
 #include "e1000_api.h"
+#include "e1000_i210.h"
 
 static s32  e1000_init_phy_params_82575(struct e1000_hw *hw);
 static s32  e1000_init_mac_params_82575(struct e1000_hw *hw);
@@ -141,6 +144,8 @@ static bool e1000_sgmii_uses_mdio_82575(struct e1000_hw *hw)
 		break;
 	case e1000_82580:
 	case e1000_i350:
+	case e1000_i210:
+	case e1000_i211:
 		reg = E1000_READ_REG(hw, E1000_MDICNFG);
 		ext_mdio = !!(reg & E1000_MDICNFG_EXT_MDIO);
 		break;
@@ -162,6 +167,9 @@ static s32 e1000_init_phy_params_82575(struct e1000_hw *hw)
 
 	DEBUGFUNC("e1000_init_phy_params_82575");
 
+	phy->ops.read_i2c_byte = e1000_read_i2c_byte_generic;
+	phy->ops.write_i2c_byte = e1000_write_i2c_byte_generic;
+
 	if (hw->phy.media_type != e1000_media_type_copper) {
 		phy->type = e1000_phy_none;
 		goto out;
@@ -195,12 +203,22 @@ static s32 e1000_init_phy_params_82575(struct e1000_hw *hw)
 	if (e1000_sgmii_active_82575(hw) && !e1000_sgmii_uses_mdio_82575(hw)) {
 		phy->ops.read_reg = e1000_read_phy_reg_sgmii_82575;
 		phy->ops.write_reg = e1000_write_phy_reg_sgmii_82575;
-	} else if (hw->mac.type >= e1000_82580) {
-		phy->ops.read_reg = e1000_read_phy_reg_82580;
-		phy->ops.write_reg = e1000_write_phy_reg_82580;
 	} else {
-		phy->ops.read_reg = e1000_read_phy_reg_igp;
-		phy->ops.write_reg = e1000_write_phy_reg_igp;
+		switch (hw->mac.type) {
+		case e1000_82580:
+		case e1000_i350:
+			phy->ops.read_reg = e1000_read_phy_reg_82580;
+			phy->ops.write_reg = e1000_write_phy_reg_82580;
+			break;
+		case e1000_i210:
+		case e1000_i211:
+			phy->ops.read_reg = e1000_read_phy_reg_gs40g;
+			phy->ops.write_reg = e1000_write_phy_reg_gs40g;
+			break;
+		default:
+			phy->ops.read_reg = e1000_read_phy_reg_igp;
+			phy->ops.write_reg = e1000_write_phy_reg_igp;
+		}
 	}
 
 	/* Set phy->phy_addr and phy->id. */
@@ -245,6 +263,15 @@ static s32 e1000_init_phy_params_82575(struct e1000_hw *hw)
 		phy->ops.set_d0_lplu_state = e1000_set_d0_lplu_state_82580;
 		phy->ops.set_d3_lplu_state = e1000_set_d3_lplu_state_82580;
 		break;
+	case I210_I_PHY_ID:
+		phy->type		= e1000_phy_i210;
+		phy->ops.check_polarity	= e1000_check_polarity_m88;
+		phy->ops.get_info	= e1000_get_phy_info_m88;
+		phy->ops.get_cable_length = e1000_get_cable_length_m88_gen2;
+		phy->ops.set_d0_lplu_state = e1000_set_d0_lplu_state_82580;
+		phy->ops.set_d3_lplu_state = e1000_set_d3_lplu_state_82580;
+		phy->ops.force_speed_duplex = e1000_phy_force_speed_duplex_m88;
+		break;
 	default:
 		ret_val = -E1000_ERR_PHY;
 		goto out;
@@ -281,27 +308,32 @@ s32 e1000_init_nvm_params_82575(struct e1000_hw *hw)
 		size = 15;
 
 	nvm->word_size = 1 << size;
-	nvm->opcode_bits = 8;
-	nvm->delay_usec = 1;
-	switch (nvm->override) {
-	case e1000_nvm_override_spi_large:
-		nvm->page_size = 32;
-		nvm->address_bits = 16;
-		break;
-	case e1000_nvm_override_spi_small:
-		nvm->page_size = 8;
-		nvm->address_bits = 8;
-		break;
-	default:
-		nvm->page_size = eecd & E1000_EECD_ADDR_BITS ? 32 : 8;
-		nvm->address_bits = eecd & E1000_EECD_ADDR_BITS ? 16 : 8;
-		break;
-	}
-
-	nvm->type = e1000_nvm_eeprom_spi;
+	if (hw->mac.type < e1000_i210) {
+		nvm->opcode_bits = 8;
+		nvm->delay_usec = 1;
+
+		switch (nvm->override) {
+		case e1000_nvm_override_spi_large:
+			nvm->page_size = 32;
+			nvm->address_bits = 16;
+			break;
+		case e1000_nvm_override_spi_small:
+			nvm->page_size = 8;
+			nvm->address_bits = 8;
+			break;
+		default:
+			nvm->page_size = eecd & E1000_EECD_ADDR_BITS ? 32 : 8;
+			nvm->address_bits = eecd & E1000_EECD_ADDR_BITS ?
+					    16 : 8;
+			break;
+		}
+		if (nvm->word_size == (1 << 15))
+			nvm->page_size = 128;
 
-	if (nvm->word_size == (1 << 15))
-		nvm->page_size = 128;
+		nvm->type = e1000_nvm_eeprom_spi;
+	} else {
+		nvm->type = e1000_nvm_flash_hw;
+	}
 
 	/* Function Pointers */
 	nvm->ops.acquire = e1000_acquire_nvm_82575;
@@ -316,7 +348,7 @@ s32 e1000_init_nvm_params_82575(struct e1000_hw *hw)
 	nvm->ops.update = e1000_update_nvm_checksum_generic;
 	nvm->ops.valid_led_default = e1000_valid_led_default_82575;
 
-	/* override genric family function pointers for specific descendants */
+	/* override generic family function pointers for specific descendants */
 	switch (hw->mac.type) {
 	case e1000_82580:
 		nvm->ops.validate = e1000_validate_nvm_checksum_82580;
@@ -356,11 +388,16 @@ static s32 e1000_init_mac_params_82575(struct e1000_hw *hw)
 		mac->rar_entry_count = E1000_RAR_ENTRIES_82576;
 	if (mac->type == e1000_82580)
 		mac->rar_entry_count = E1000_RAR_ENTRIES_82580;
-	if (mac->type == e1000_i350) {
+	if (mac->type == e1000_i350)
 		mac->rar_entry_count = E1000_RAR_ENTRIES_I350;
-		/* Enable EEE default settings for i350 */
+
+	/* Enable EEE default settings for EEE supported devices */
+	if (mac->type >= e1000_i350)
 		dev_spec->eee_disable = FALSE;
-	}
+
+	/* Allow a single clear of the SW semaphore on I210 and newer */
+	if (mac->type >= e1000_i210)
+		dev_spec->clear_semaphore_once = TRUE;
 
 	/* Set if part includes ASF firmware */
 	mac->asf_firmware_present = TRUE;
@@ -368,8 +405,7 @@ static s32 e1000_init_mac_params_82575(struct e1000_hw *hw)
 	mac->has_fwsm = TRUE;
 	/* ARC supported; valid only if manageability features are enabled. */
 	mac->arc_subsystem_valid =
-		(E1000_READ_REG(hw, E1000_FWSM) & E1000_FWSM_MODE_MASK)
-			? TRUE : FALSE;
+		!!(E1000_READ_REG(hw, E1000_FWSM) & E1000_FWSM_MODE_MASK);
 
 	/* Function pointers */
 
@@ -394,15 +430,13 @@ static s32 e1000_init_mac_params_82575(struct e1000_hw *hw)
 	mac->ops.power_up_serdes = e1000_power_up_serdes_link_82575;
 	/* check for link */
 	mac->ops.check_for_link = e1000_check_for_link_82575;
-	/* receive address register setting */
-	mac->ops.rar_set = e1000_rar_set_generic;
 	/* read mac address */
 	mac->ops.read_mac_addr = e1000_read_mac_addr_82575;
 	/* configure collision distance */
 	mac->ops.config_collision_dist = e1000_config_collision_dist_82575;
 	/* multicast address update */
 	mac->ops.update_mc_addr_list = e1000_update_mc_addr_list_generic;
-	if (hw->mac.type == e1000_i350) {
+	if (mac->type == e1000_i350) {
 		/* writing VFTA */
 		mac->ops.write_vfta = e1000_write_vfta_i350;
 		/* clearing VFTA */
@@ -413,6 +447,9 @@ static s32 e1000_init_mac_params_82575(struct e1000_hw *hw)
 		/* clearing VFTA */
 		mac->ops.clear_vfta = e1000_clear_vfta_generic;
 	}
+	if (hw->mac.type >= e1000_82580)
+		mac->ops.validate_mdi_setting =
+				e1000_validate_mdi_setting_crossover_generic;
 	/* ID LED init */
 	mac->ops.id_led_init = e1000_id_led_init_generic;
 	/* blink LED */
@@ -428,6 +465,13 @@ static s32 e1000_init_mac_params_82575(struct e1000_hw *hw)
 	mac->ops.clear_hw_cntrs = e1000_clear_hw_cntrs_82575;
 	/* link info */
 	mac->ops.get_link_up_info = e1000_get_link_up_info_82575;
+	/* acquire SW_FW sync */
+	mac->ops.acquire_swfw_sync = e1000_acquire_swfw_sync_82575;
+	mac->ops.release_swfw_sync = e1000_release_swfw_sync_82575;
+	if (mac->type >= e1000_i210) {
+		mac->ops.acquire_swfw_sync = e1000_acquire_swfw_sync_i210;
+		mac->ops.release_swfw_sync = e1000_release_swfw_sync_i210;
+	}
 
 	/* set lan id for port to determine which phy lock to use */
 	hw->mac.ops.set_lan_id(hw);
@@ -470,7 +514,7 @@ static s32 e1000_acquire_phy_82575(struct e1000_hw *hw)
 	else if (hw->bus.func == E1000_FUNC_3)
 		mask = E1000_SWFW_PHY3_SM;
 
-	return e1000_acquire_swfw_sync_82575(hw, mask);
+	return hw->mac.ops.acquire_swfw_sync(hw, mask);
 }
 
 /**
@@ -492,7 +536,7 @@ static void e1000_release_phy_82575(struct e1000_hw *hw)
 	else if (hw->bus.func == E1000_FUNC_3)
 		mask = E1000_SWFW_PHY3_SM;
 
-	e1000_release_swfw_sync_82575(hw, mask);
+	hw->mac.ops.release_swfw_sync(hw, mask);
 }
 
 /**
@@ -601,6 +645,8 @@ static s32 e1000_get_phy_id_82575(struct e1000_hw *hw)
 			break;
 		case e1000_82580:
 		case e1000_i350:
+		case e1000_i210:
+		case e1000_i211:
 			mdic = E1000_READ_REG(hw, E1000_MDICNFG);
 			mdic &= E1000_MDICNFG_PHY_MASK;
 			phy->addr = mdic >> E1000_MDICNFG_PHY_SHIFT;
@@ -796,7 +842,7 @@ static s32 e1000_set_d0_lplu_state_82580(struct e1000_hw *hw, bool active)
 {
 	struct e1000_phy_info *phy = &hw->phy;
 	s32 ret_val = E1000_SUCCESS;
-	u16 data;
+	u32 data;
 
 	DEBUGFUNC("e1000_set_d0_lplu_state_82580");
 
@@ -844,7 +890,7 @@ s32 e1000_set_d3_lplu_state_82580(struct e1000_hw *hw, bool active)
 {
 	struct e1000_phy_info *phy = &hw->phy;
 	s32 ret_val = E1000_SUCCESS;
-	u16 data;
+	u32 data;
 
 	DEBUGFUNC("e1000_set_d3_lplu_state_82580");
 
@@ -918,11 +964,7 @@ static s32 e1000_acquire_nvm_82575(struct e1000_hw *hw)
 	}
 
 
-	switch (hw->mac.type) {
-	default:
-		ret_val = e1000_acquire_nvm_generic(hw);
-	}
-
+	ret_val = e1000_acquire_nvm_generic(hw);
 	if (ret_val)
 		e1000_release_swfw_sync_82575(hw, E1000_SWFW_EEP_SM);
 
@@ -941,10 +983,8 @@ static void e1000_release_nvm_82575(struct e1000_hw *hw)
 {
 	DEBUGFUNC("e1000_release_nvm_82575");
 
-	switch (hw->mac.type) {
-	default:
-		e1000_release_nvm_generic(hw);
-	}
+	e1000_release_nvm_generic(hw);
+
 	e1000_release_swfw_sync_82575(hw, E1000_SWFW_EEP_SM);
 }
 
@@ -1058,7 +1098,7 @@ static s32 e1000_get_cfg_done_82575(struct e1000_hw *hw)
 		DEBUGOUT("MNG configuration cycle has not completed.\n");
 
 	/* If EEPROM is not marked present, init the PHY manually */
-	if (((E1000_READ_REG(hw, E1000_EECD) & E1000_EECD_PRES) == 0) &&
+	if (!(E1000_READ_REG(hw, E1000_EECD) & E1000_EECD_PRES) &&
 	    (hw->phy.type == e1000_phy_igp_3))
 		e1000_phy_init_script_igp3(hw);
 
@@ -1115,6 +1155,16 @@ static s32 e1000_check_for_link_82575(struct e1000_hw *hw)
 		 * continue to check for link.
 		 */
 		hw->mac.get_link_status = !hw->mac.serdes_has_link;
+
+		/*
+		 * Configure Flow Control now that Auto-Neg has completed.
+		 * First, we need to restore the desired flow control
+		 * settings because we may have had to re-autoneg with a
+		 * different link partner.
+		 */
+		ret_val = e1000_config_fc_after_link_up_generic(hw);
+		if (ret_val)
+			DEBUGOUT("Error configuring flow control\n");
 	} else {
 		ret_val = e1000_check_for_copper_link_generic(hw);
 	}
@@ -1168,11 +1218,6 @@ static s32 e1000_get_pcs_speed_and_duplex_82575(struct e1000_hw *hw,
 
 	DEBUGFUNC("e1000_get_pcs_speed_and_duplex_82575");
 
-	/* Set up defaults for the return values of this function */
-	mac->serdes_has_link = FALSE;
-	*speed = 0;
-	*duplex = 0;
-
 	/*
 	 * Read the PCS Status register for link state. For non-copper mode,
 	 * the status register is not accurate. The PCS status register is
@@ -1181,11 +1226,9 @@ static s32 e1000_get_pcs_speed_and_duplex_82575(struct e1000_hw *hw,
 	pcs = E1000_READ_REG(hw, E1000_PCS_LSTAT);
 
 	/*
-	 * The link up bit determines when link is up on autoneg. The sync ok
-	 * gets set once both sides sync up and agree upon link. Stable link
-	 * can be determined by checking for both link up and link sync ok
+	 * The link up bit determines when link is up on autoneg.
 	 */
-	if ((pcs & E1000_PCS_LSTS_LINK_OK) && (pcs & E1000_PCS_LSTS_SYNK_OK)) {
+	if (pcs & E1000_PCS_LSTS_LINK_OK) {
 		mac->serdes_has_link = TRUE;
 
 		/* Detect and store PCS speed */
@@ -1201,6 +1244,11 @@ static s32 e1000_get_pcs_speed_and_duplex_82575(struct e1000_hw *hw,
 			*duplex = FULL_DUPLEX;
 		else
 			*duplex = HALF_DUPLEX;
+
+	} else {
+		mac->serdes_has_link = FALSE;
+		*speed = 0;
+		*duplex = 0;
 	}
 
 	return E1000_SUCCESS;
@@ -1293,7 +1341,7 @@ static s32 e1000_reset_hw_82575(struct e1000_hw *hw)
 	}
 
 	/* If EEPROM is not present, run manual init scripts */
-	if ((E1000_READ_REG(hw, E1000_EECD) & E1000_EECD_PRES) == 0)
+	if (!(E1000_READ_REG(hw, E1000_EECD) & E1000_EECD_PRES))
 		e1000_reset_init_script_82575(hw);
 
 	/* Clear any pending interrupt events. */
@@ -1372,7 +1420,8 @@ static s32 e1000_init_hw_82575(struct e1000_hw *hw)
 static s32 e1000_setup_copper_link_82575(struct e1000_hw *hw)
 {
 	u32 ctrl;
-	s32  ret_val;
+	s32 ret_val;
+	u32 phpm_reg;
 
 	DEBUGFUNC("e1000_setup_copper_link_82575");
 
@@ -1381,6 +1430,13 @@ static s32 e1000_setup_copper_link_82575(struct e1000_hw *hw)
 	ctrl &= ~(E1000_CTRL_FRCSPD | E1000_CTRL_FRCDPX);
 	E1000_WRITE_REG(hw, E1000_CTRL, ctrl);
 
+	/* Clear Go Link Disconnect bit */
+	if (hw->mac.type >= e1000_82580) {
+		phpm_reg = E1000_READ_REG(hw, E1000_82580_PHY_POWER_MGMT);
+		phpm_reg &= ~E1000_82580_PM_GO_LINKD;
+		E1000_WRITE_REG(hw, E1000_82580_PHY_POWER_MGMT, phpm_reg);
+	}
+
 	ret_val = e1000_setup_serdes_link_82575(hw);
 	if (ret_val)
 		goto out;
@@ -1396,13 +1452,19 @@ static s32 e1000_setup_copper_link_82575(struct e1000_hw *hw)
 		}
 	}
 	switch (hw->phy.type) {
+	case e1000_phy_i210:
 	case e1000_phy_m88:
-		if (hw->phy.id == I347AT4_E_PHY_ID ||
-		    hw->phy.id == M88E1112_E_PHY_ID ||
-		    hw->phy.id == M88E1340M_E_PHY_ID)
+		switch (hw->phy.id) {
+		case I347AT4_E_PHY_ID:
+		case M88E1112_E_PHY_ID:
+		case M88E1340M_E_PHY_ID:
+		case I210_I_PHY_ID:
 			ret_val = e1000_copper_link_setup_m88_gen2(hw);
-		else
+			break;
+		default:
 			ret_val = e1000_copper_link_setup_m88(hw);
+			break;
+		}
 		break;
 	case e1000_phy_igp_3:
 		ret_val = e1000_copper_link_setup_igp(hw);
@@ -1434,7 +1496,7 @@ out:
  **/
 static s32 e1000_setup_serdes_link_82575(struct e1000_hw *hw)
 {
-	u32 ctrl_ext, ctrl_reg, reg;
+	u32 ctrl_ext, ctrl_reg, reg, anadv_reg;
 	bool pcs_autoneg;
 	s32 ret_val = E1000_SUCCESS;
 	u16 data;
@@ -1518,26 +1580,47 @@ static s32 e1000_setup_serdes_link_82575(struct e1000_hw *hw)
 	reg &= ~(E1000_PCS_LCTL_AN_ENABLE | E1000_PCS_LCTL_FLV_LINK_UP |
 		 E1000_PCS_LCTL_FSD | E1000_PCS_LCTL_FORCE_LINK);
 
-	/*
-	 * We force flow control to prevent the CTRL register values from being
-	 * overwritten by the autonegotiated flow control values
-	 */
-	reg |= E1000_PCS_LCTL_FORCE_FCTRL;
-
 	if (pcs_autoneg) {
 		/* Set PCS register for autoneg */
 		reg |= E1000_PCS_LCTL_AN_ENABLE | /* Enable Autoneg */
 		       E1000_PCS_LCTL_AN_RESTART; /* Restart autoneg */
+
+		/* Disable force flow control for autoneg */
+		reg &= ~E1000_PCS_LCTL_FORCE_FCTRL;
+
+		/* Configure flow control advertisement for autoneg */
+		anadv_reg = E1000_READ_REG(hw, E1000_PCS_ANADV);
+		anadv_reg &= ~(E1000_TXCW_ASM_DIR | E1000_TXCW_PAUSE);
+
+		switch (hw->fc.requested_mode) {
+		case e1000_fc_full:
+		case e1000_fc_rx_pause:
+			anadv_reg |= E1000_TXCW_ASM_DIR;
+			anadv_reg |= E1000_TXCW_PAUSE;
+			break;
+		case e1000_fc_tx_pause:
+			anadv_reg |= E1000_TXCW_ASM_DIR;
+			break;
+		default:
+			break;
+		}
+
+		E1000_WRITE_REG(hw, E1000_PCS_ANADV, anadv_reg);
+
 		DEBUGOUT1("Configuring Autoneg:PCS_LCTL=0x%08X\n", reg);
 	} else {
 		/* Set PCS register for forced link */
 		reg |= E1000_PCS_LCTL_FSD;	/* Force Speed */
+
+		/* Force flow control for forced link */
+		reg |= E1000_PCS_LCTL_FORCE_FCTRL;
+
 		DEBUGOUT1("Configuring Forced Link:PCS_LCTL=0x%08X\n", reg);
 	}
 
 	E1000_WRITE_REG(hw, E1000_PCS_LCTL, reg);
 
-	if (!e1000_sgmii_active_82575(hw))
+	if (!pcs_autoneg && !e1000_sgmii_active_82575(hw))
 		e1000_force_mac_fc_generic(hw);
 
 	return ret_val;
@@ -1556,140 +1639,70 @@ static s32 e1000_setup_serdes_link_82575(struct e1000_hw *hw)
  **/
 static s32 e1000_get_media_type_82575(struct e1000_hw *hw)
 {
-	u32 lan_id = 0;
-	s32 ret_val = E1000_ERR_CONFIG;
 	struct e1000_dev_spec_82575 *dev_spec = &hw->dev_spec._82575;
+	s32 ret_val = E1000_SUCCESS;
 	u32 ctrl_ext = 0;
-	u32 current_link_mode = 0;
-	u16 init_ctrl_wd_3 = 0;
-	u8 init_ctrl_wd_3_offset = 0;
-	u8 init_ctrl_wd_3_bit_offset = 0;
+	u32 link_mode = 0;
 
 	/* Set internal phy as default */
 	dev_spec->sgmii_active = FALSE;
 	dev_spec->module_plugged = FALSE;
 
-	/*
-	 * Check if NVM access method is attached already.
-	 * If it is then Init Control Word #3 is considered
-	 * otherwise runtime CSR register content is taken.
-	 */
-
 	/* Get CSR setting */
 	ctrl_ext = E1000_READ_REG(hw, E1000_CTRL_EXT);
 
-	/* Get link mode setting */
-	if ((hw->nvm.ops.read) && (hw->nvm.ops.read != e1000_null_read_nvm)) {
-		/* Take link mode from EEPROM */
-
-		/*
-		 * Get LAN port ID to derive its
-		 * adequate Init Control Word #3
-		 */
-		lan_id = ((E1000_READ_REG(hw, E1000_STATUS) &
-		      E1000_STATUS_LAN_ID_MASK) >> E1000_STATUS_LAN_ID_OFFSET);
-		/*
-		 * Derive Init Control Word #3 offset
-		 * and mask to pick up link mode setting.
-		 */
-		if (hw->mac.type < e1000_82580) {
-			init_ctrl_wd_3_offset = lan_id ?
-			   NVM_INIT_CONTROL3_PORT_A : NVM_INIT_CONTROL3_PORT_B;
-			init_ctrl_wd_3_bit_offset = NVM_WORD24_LNK_MODE_OFFSET;
-		} else {
-			init_ctrl_wd_3_offset =
-					    NVM_82580_LAN_FUNC_OFFSET(lan_id) +
-					    NVM_INIT_CONTROL3_PORT_A;
-			init_ctrl_wd_3_bit_offset =
-					      NVM_WORD24_82580_LNK_MODE_OFFSET;
-		}
-		/* Read Init Control Word #3*/
-		hw->nvm.ops.read(hw, init_ctrl_wd_3_offset, 1, &init_ctrl_wd_3);
-		current_link_mode = init_ctrl_wd_3;
-		/*
-		 * Switch to CSR for all but internal PHY.
-		 */
-		if ((init_ctrl_wd_3 << (E1000_CTRL_EXT_LINK_MODE_OFFSET -
-		    init_ctrl_wd_3_bit_offset)) !=
-		    E1000_CTRL_EXT_LINK_MODE_GMII) {
-			current_link_mode = ctrl_ext;
-			init_ctrl_wd_3_bit_offset =
-					      E1000_CTRL_EXT_LINK_MODE_OFFSET;
-		}
-	} else {
-		/* Take link mode from CSR */
-		current_link_mode = ctrl_ext;
-		init_ctrl_wd_3_bit_offset = E1000_CTRL_EXT_LINK_MODE_OFFSET;
-	}
-
-	/*
-	 * Align link mode bits to
-	 * their CTRL_EXT location.
-	 */
-	current_link_mode <<= (E1000_CTRL_EXT_LINK_MODE_OFFSET -
-			       init_ctrl_wd_3_bit_offset);
-	current_link_mode &= E1000_CTRL_EXT_LINK_MODE_MASK;
-
-	switch (current_link_mode) {
+	/* extract link mode setting */
+	link_mode = ctrl_ext & E1000_CTRL_EXT_LINK_MODE_MASK;
 
+	switch (link_mode) {
 	case E1000_CTRL_EXT_LINK_MODE_1000BASE_KX:
 		hw->phy.media_type = e1000_media_type_internal_serdes;
-		current_link_mode = E1000_CTRL_EXT_LINK_MODE_1000BASE_KX;
 		break;
 	case E1000_CTRL_EXT_LINK_MODE_GMII:
 		hw->phy.media_type = e1000_media_type_copper;
-		current_link_mode = E1000_CTRL_EXT_LINK_MODE_GMII;
 		break;
 	case E1000_CTRL_EXT_LINK_MODE_SGMII:
-	case E1000_CTRL_EXT_LINK_MODE_PCIE_SERDES:
 		/* Get phy control interface type set (MDIO vs. I2C)*/
 		if (e1000_sgmii_uses_mdio_82575(hw)) {
 			hw->phy.media_type = e1000_media_type_copper;
 			dev_spec->sgmii_active = TRUE;
-			current_link_mode = E1000_CTRL_EXT_LINK_MODE_SGMII;
-		} else {
-			ret_val = e1000_set_sfp_media_type_82575(hw);
-			if (ret_val != E1000_SUCCESS)
-				goto out;
-			if (hw->phy.media_type ==
-				e1000_media_type_internal_serdes) {
-				current_link_mode =
-					 E1000_CTRL_EXT_LINK_MODE_PCIE_SERDES;
-			} else if (hw->phy.media_type ==
-				e1000_media_type_copper) {
-				current_link_mode =
-					       E1000_CTRL_EXT_LINK_MODE_SGMII;
+			break;
+		}
+		/* fall through for I2C based SGMII */
+	case E1000_CTRL_EXT_LINK_MODE_PCIE_SERDES:
+		/* read media type from SFP EEPROM */
+		ret_val = e1000_set_sfp_media_type_82575(hw);
+		if ((ret_val != E1000_SUCCESS) ||
+		    (hw->phy.media_type == e1000_media_type_unknown)) {
+			/*
+			 * If media type was not identified then return media
+			 * type defined by the CTRL_EXT settings.
+			 */
+			hw->phy.media_type = e1000_media_type_internal_serdes;
+
+			if (link_mode == E1000_CTRL_EXT_LINK_MODE_SGMII) {
+				hw->phy.media_type = e1000_media_type_copper;
+				dev_spec->sgmii_active = TRUE;
 			}
+
+			break;
 		}
-		break;
-	default:
-		DEBUGOUT("Link mode mask doesn't fit bit field size\n");
-		goto out;
-	}
-	/*
-	 * Do not change current link mode setting
-	 * if media type is fibre or has not been
-	 * recognized.
-	 */
-	if ((hw->phy.media_type != e1000_media_type_unknown) &&
-	    (hw->phy.media_type != e1000_media_type_fiber)) {
-		/* Update link mode */
+
+		/* do not change link mode for 100BaseFX */
+		if (dev_spec->eth_flags.e100_base_fx)
+			break;
+
+		/* change current link mode setting */
 		ctrl_ext &= ~E1000_CTRL_EXT_LINK_MODE_MASK;
-		E1000_WRITE_REG(hw, E1000_CTRL_EXT, ctrl_ext |
-				current_link_mode);
-	}
 
-	ret_val = E1000_SUCCESS;
-out:
-	/*
-	 * If media type was not identified then return media type
-	 * defined by the CTRL_EXT settings.
-	 */
-	if (hw->phy.media_type == e1000_media_type_unknown) {
-		if (current_link_mode == E1000_CTRL_EXT_LINK_MODE_SGMII)
-			hw->phy.media_type = e1000_media_type_copper;
+		if (hw->phy.media_type == e1000_media_type_copper)
+			ctrl_ext |= E1000_CTRL_EXT_LINK_MODE_SGMII;
 		else
-			hw->phy.media_type = e1000_media_type_internal_serdes;
+			ctrl_ext |= E1000_CTRL_EXT_LINK_MODE_PCIE_SERDES;
+
+		E1000_WRITE_REG(hw, E1000_CTRL_EXT, ctrl_ext);
+
+		break;
 	}
 
 	return ret_val;
@@ -1707,40 +1720,52 @@ static s32 e1000_set_sfp_media_type_82575(struct e1000_hw *hw)
 	s32 ret_val = E1000_ERR_CONFIG;
 	u32 ctrl_ext = 0;
 	struct e1000_dev_spec_82575 *dev_spec = &hw->dev_spec._82575;
-	struct sfp_e1000_flags eth_flags = {0};
+	struct sfp_e1000_flags *eth_flags = &dev_spec->eth_flags;
 	u8 tranceiver_type = 0;
+	s32 timeout = 3;
 
-	/* Turn I2C interface ON */
+	/* Turn I2C interface ON and power on sfp cage */
 	ctrl_ext = E1000_READ_REG(hw, E1000_CTRL_EXT);
+	ctrl_ext &= ~E1000_CTRL_EXT_SDP3_DATA;
 	E1000_WRITE_REG(hw, E1000_CTRL_EXT, ctrl_ext | E1000_CTRL_I2C_ENA);
 
+	E1000_WRITE_FLUSH(hw);
+
 	/* Read SFP module data */
-	ret_val = e1000_read_sfp_data_byte(hw,
+	while (timeout) {
+		ret_val = e1000_read_sfp_data_byte(hw,
 			E1000_I2CCMD_SFP_DATA_ADDR(E1000_SFF_IDENTIFIER_OFFSET),
 			&tranceiver_type);
+		if (ret_val == E1000_SUCCESS)
+			break;
+		msec_delay(100);
+		timeout--;
+	}
 	if (ret_val != E1000_SUCCESS)
 		goto out;
+
 	ret_val = e1000_read_sfp_data_byte(hw,
 			E1000_I2CCMD_SFP_DATA_ADDR(E1000_SFF_ETH_FLAGS_OFFSET),
-			(u8 *)&eth_flags);
+			(u8 *)eth_flags);
 	if (ret_val != E1000_SUCCESS)
 		goto out;
-	/*
-	 * Check if there is some SFP
-	 * module plugged and powered
-	 */
+
+	/* Check if there is some SFP module plugged and powered */
 	if ((tranceiver_type == E1000_SFF_IDENTIFIER_SFP) ||
 	    (tranceiver_type == E1000_SFF_IDENTIFIER_SFF)) {
 		dev_spec->module_plugged = TRUE;
-		if (eth_flags.e1000_base_lx || eth_flags.e1000_base_sx) {
+		if (eth_flags->e1000_base_lx || eth_flags->e1000_base_sx) {
 			hw->phy.media_type = e1000_media_type_internal_serdes;
-		} else if (eth_flags.e1000_base_t) {
+		} else if (eth_flags->e100_base_fx) {
+			dev_spec->sgmii_active = TRUE;
+			hw->phy.media_type = e1000_media_type_internal_serdes;
+		} else if (eth_flags->e1000_base_t) {
 			dev_spec->sgmii_active = TRUE;
 			hw->phy.media_type = e1000_media_type_copper;
 		} else {
-				hw->phy.media_type = e1000_media_type_unknown;
-				DEBUGOUT("PHY module has not been recognized\n");
-				goto out;
+			hw->phy.media_type = e1000_media_type_unknown;
+			DEBUGOUT("PHY module has not been recognized\n");
+			goto out;
 		}
 	} else {
 		hw->phy.media_type = e1000_media_type_unknown;
@@ -2311,6 +2336,10 @@ static s32 e1000_reset_hw_82580(struct e1000_hw *hw)
 
 	hw->dev_spec._82575.global_device_reset = FALSE;
 
+	/* 82580 does not reliably do global_device_reset due to hw errata */
+	if (hw->mac.type == e1000_82580)
+		global_device_reset = FALSE;
+
 	/* Get current control state. */
 	ctrl = E1000_READ_REG(hw, E1000_CTRL);
 
@@ -2331,7 +2360,7 @@ static s32 e1000_reset_hw_82580(struct e1000_hw *hw)
 	msec_delay(10);
 
 	/* Determine whether or not a global dev reset is requested */
-	if (global_device_reset && e1000_acquire_swfw_sync_82575(hw,
+	if (global_device_reset && hw->mac.ops.acquire_swfw_sync(hw,
 	    swmbsw_mask))
 			global_device_reset = FALSE;
 
@@ -2359,7 +2388,7 @@ static s32 e1000_reset_hw_82580(struct e1000_hw *hw)
 	}
 
 	/* If EEPROM is not present, run manual init scripts */
-	if ((E1000_READ_REG(hw, E1000_EECD) & E1000_EECD_PRES) == 0)
+	if (!(E1000_READ_REG(hw, E1000_EECD) & E1000_EECD_PRES))
 		e1000_reset_init_script_82575(hw);
 
 	/* clear global device reset status bit */
@@ -2378,7 +2407,7 @@ static s32 e1000_reset_hw_82580(struct e1000_hw *hw)
 
 	/* Release semaphore */
 	if (global_device_reset)
-		e1000_release_swfw_sync_82575(hw, swmbsw_mask);
+		hw->mac.ops.release_swfw_sync(hw, swmbsw_mask);
 
 	return ret_val;
 }
@@ -2538,7 +2567,7 @@ static s32 e1000_update_nvm_checksum_82580(struct e1000_hw *hw)
 		goto out;
 	}
 
-	if ((nvm_data & NVM_COMPATIBILITY_BIT_MASK) == 0) {
+	if (!(nvm_data & NVM_COMPATIBILITY_BIT_MASK)) {
 		/* set compatibility bit to validate checksums appropriately */
 		nvm_data = nvm_data | NVM_COMPATIBILITY_BIT_MASK;
 		ret_val = hw->nvm.ops.write(hw, NVM_COMPATIBILITY_REG_3, 1,
@@ -2637,10 +2666,15 @@ s32 e1000_set_eee_i350(struct e1000_hw *hw)
 
 	/* enable or disable per user setting */
 	if (!(hw->dev_spec._82575.eee_disable)) {
+		u32 eee_su = E1000_READ_REG(hw, E1000_EEE_SU);
+
 		ipcnfg |= (E1000_IPCNFG_EEE_1G_AN | E1000_IPCNFG_EEE_100M_AN);
 		eeer |= (E1000_EEER_TX_LPI_EN | E1000_EEER_RX_LPI_EN |
 			 E1000_EEER_LPI_FC);
 
+		/* This bit should not be set in normal operation. */
+		if (eee_su & E1000_EEE_SU_LPI_CLK_STP)
+			DEBUGOUT("LPI Clock Stop Bit should not be set!\n");
 	} else {
 		ipcnfg &= ~(E1000_IPCNFG_EEE_1G_AN | E1000_IPCNFG_EEE_100M_AN);
 		eeer &= ~(E1000_EEER_TX_LPI_EN | E1000_EEER_RX_LPI_EN |
@@ -2737,6 +2771,7 @@ s32 e1000_set_i2c_bb(struct e1000_hw *hw)
  *  e1000_read_i2c_byte_generic - Reads 8 bit word over I2C
  *  @hw: pointer to hardware structure
  *  @byte_offset: byte offset to read
+ *  @dev_addr: device address
  *  @data: value read
  *
  *  Performs byte read operation over I2C interface at
@@ -2750,14 +2785,14 @@ s32 e1000_read_i2c_byte_generic(struct e1000_hw *hw, u8 byte_offset,
 	u32 retry = 1;
 	u16 swfw_mask = 0;
 
-	bool nack = 1;
+	bool nack = TRUE;
 
 	DEBUGFUNC("e1000_read_i2c_byte_generic");
 
 	swfw_mask = E1000_SWFW_PHY0_SM;
 
 	do {
-		if (e1000_acquire_swfw_sync_82575(hw, swfw_mask)
+		if (hw->mac.ops.acquire_swfw_sync(hw, swfw_mask)
 		    != E1000_SUCCESS) {
 			status = E1000_ERR_SWFW_SYNC;
 			goto read_byte_out;
@@ -2805,7 +2840,7 @@ s32 e1000_read_i2c_byte_generic(struct e1000_hw *hw, u8 byte_offset,
 		break;
 
 fail:
-		e1000_release_swfw_sync_82575(hw, swfw_mask);
+		hw->mac.ops.release_swfw_sync(hw, swfw_mask);
 		msec_delay(100);
 		e1000_i2c_bus_clear(hw);
 		retry++;
@@ -2816,7 +2851,7 @@ fail:
 
 	} while (retry < max_retry);
 
-	e1000_release_swfw_sync_82575(hw, swfw_mask);
+	hw->mac.ops.release_swfw_sync(hw, swfw_mask);
 
 read_byte_out:
 
@@ -2827,6 +2862,7 @@ read_byte_out:
  *  e1000_write_i2c_byte_generic - Writes 8 bit word over I2C
  *  @hw: pointer to hardware structure
  *  @byte_offset: byte offset to write
+ *  @dev_addr: device address
  *  @data: value to write
  *
  *  Performs byte write operation over I2C interface at
@@ -2844,7 +2880,7 @@ s32 e1000_write_i2c_byte_generic(struct e1000_hw *hw, u8 byte_offset,
 
 	swfw_mask = E1000_SWFW_PHY0_SM;
 
-	if (e1000_acquire_swfw_sync_82575(hw, swfw_mask) != E1000_SUCCESS) {
+	if (hw->mac.ops.acquire_swfw_sync(hw, swfw_mask) != E1000_SUCCESS) {
 		status = E1000_ERR_SWFW_SYNC;
 		goto write_byte_out;
 	}
@@ -2888,7 +2924,7 @@ fail:
 			DEBUGOUT("I2C byte write error.\n");
 	} while (retry < max_retry);
 
-	e1000_release_swfw_sync_82575(hw, swfw_mask);
+	hw->mac.ops.release_swfw_sync(hw, swfw_mask);
 
 write_byte_out:
 
@@ -3020,7 +3056,7 @@ static s32 e1000_get_i2c_ack(struct e1000_hw *hw)
 	u32 i = 0;
 	u32 i2cctl = E1000_READ_REG(hw, E1000_I2CPARAMS);
 	u32 timeout = 10;
-	bool ack = 1;
+	bool ack = TRUE;
 
 	DEBUGFUNC("e1000_get_i2c_ack");
 
@@ -3040,7 +3076,7 @@ static s32 e1000_get_i2c_ack(struct e1000_hw *hw)
 		return E1000_ERR_I2C;
 
 	ack = e1000_get_i2c_data(&i2cctl);
-	if (ack == 1) {
+	if (ack) {
 		DEBUGOUT("I2C ack was not received.\n");
 		status = E1000_ERR_I2C;
 	}
@@ -3250,3 +3286,4 @@ void e1000_i2c_bus_clear(struct e1000_hw *hw)
 	e1000_i2c_stop(hw);
 }
 
+
diff --git a/sys/dev/e1000/e1000_82575.h b/sys/dev/e1000/e1000_82575.h
index 4b2b245..c6bbe18 100644
--- a/sys/dev/e1000/e1000_82575.h
+++ b/sys/dev/e1000/e1000_82575.h
@@ -1,6 +1,6 @@
 /******************************************************************************
 
-  Copyright (c) 2001-2011, Intel Corporation 
+  Copyright (c) 2001-2013, Intel Corporation 
   All rights reserved.
   
   Redistribution and use in source and binary forms, with or without 
@@ -360,10 +360,13 @@ struct e1000_adv_tx_context_desc {
 #define E1000_DCA_RXCTRL_DESC_DCA_EN	(1 << 5) /* DCA Rx Desc enable */
 #define E1000_DCA_RXCTRL_HEAD_DCA_EN	(1 << 6) /* DCA Rx Desc header ena */
 #define E1000_DCA_RXCTRL_DATA_DCA_EN	(1 << 7) /* DCA Rx Desc payload ena */
+#define E1000_DCA_RXCTRL_DESC_RRO_EN	(1 << 9) /* DCA Rx Desc Relax Order */
 
 #define E1000_DCA_TXCTRL_CPUID_MASK	0x0000001F /* Tx CPUID Mask */
 #define E1000_DCA_TXCTRL_DESC_DCA_EN	(1 << 5) /* DCA Tx Desc enable */
+#define E1000_DCA_TXCTRL_DESC_RRO_EN	(1 << 9) /* Tx rd Desc Relax Order */
 #define E1000_DCA_TXCTRL_TX_WB_RO_EN	(1 << 11) /* Tx Desc writeback RO bit */
+#define E1000_DCA_TXCTRL_DATA_RRO_EN	(1 << 13) /* Tx rd data Relax Order */
 
 #define E1000_DCA_TXCTRL_CPUID_MASK_82576	0xFF000000 /* Tx CPUID Mask */
 #define E1000_DCA_RXCTRL_CPUID_MASK_82576	0xFF000000 /* Rx CPUID Mask */
diff --git a/sys/dev/e1000/e1000_api.c b/sys/dev/e1000/e1000_api.c
index fdfc4bb..09f05c8 100644
--- a/sys/dev/e1000/e1000_api.c
+++ b/sys/dev/e1000/e1000_api.c
@@ -1,6 +1,6 @@
 /******************************************************************************
 
-  Copyright (c) 2001-2011, Intel Corporation 
+  Copyright (c) 2001-2013, Intel Corporation 
   All rights reserved.
   
   Redistribution and use in source and binary forms, with or without 
@@ -289,6 +289,12 @@ s32 e1000_set_mac_type(struct e1000_hw *hw)
 	case E1000_DEV_ID_PCH2_LV_V:
 		mac->type = e1000_pch2lan;
 		break;
+	case E1000_DEV_ID_PCH_LPT_I217_LM:
+	case E1000_DEV_ID_PCH_LPT_I217_V:
+	case E1000_DEV_ID_PCH_LPTLP_I218_LM:
+	case E1000_DEV_ID_PCH_LPTLP_I218_V:
+		mac->type = e1000_pch_lpt;
+		break;
 	case E1000_DEV_ID_82575EB_COPPER:
 	case E1000_DEV_ID_82575EB_FIBER_SERDES:
 	case E1000_DEV_ID_82575GB_QUAD_COPPER:
@@ -323,12 +329,26 @@ s32 e1000_set_mac_type(struct e1000_hw *hw)
 	case E1000_DEV_ID_I350_DA4:
 		mac->type = e1000_i350;
 		break;
+	case E1000_DEV_ID_I210_COPPER:
+	case E1000_DEV_ID_I210_COPPER_OEM1:
+	case E1000_DEV_ID_I210_COPPER_IT:
+	case E1000_DEV_ID_I210_FIBER:
+	case E1000_DEV_ID_I210_SERDES:
+	case E1000_DEV_ID_I210_SGMII:
+		mac->type = e1000_i210;
+		break;
+	case E1000_DEV_ID_I211_COPPER:
+		mac->type = e1000_i211;
+		break;
 	case E1000_DEV_ID_82576_VF:
+	case E1000_DEV_ID_82576_VF_HV:
 		mac->type = e1000_vfadapt;
 		break;
 	case E1000_DEV_ID_I350_VF:
+	case E1000_DEV_ID_I350_VF_HV:
 		mac->type = e1000_vfadapt_i350;
 		break;
+
 	default:
 		/* Should never have loaded on this device */
 		ret_val = -E1000_ERR_MAC_INIT;
@@ -417,6 +437,7 @@ s32 e1000_setup_init_funcs(struct e1000_hw *hw, bool init_device)
 	case e1000_ich10lan:
 	case e1000_pchlan:
 	case e1000_pch2lan:
+	case e1000_pch_lpt:
 		e1000_init_function_pointers_ich8lan(hw);
 		break;
 	case e1000_82575:
@@ -425,6 +446,10 @@ s32 e1000_setup_init_funcs(struct e1000_hw *hw, bool init_device)
 	case e1000_i350:
 		e1000_init_function_pointers_82575(hw);
 		break;
+	case e1000_i210:
+	case e1000_i211:
+		e1000_init_function_pointers_i210(hw);
+		break;
 	case e1000_vfadapt:
 		e1000_init_function_pointers_vf(hw);
 		break;
@@ -858,11 +883,7 @@ bool e1000_enable_tx_pkt_filtering(struct e1000_hw *hw)
 s32 e1000_mng_host_if_write(struct e1000_hw *hw, u8 *buffer, u16 length,
 			    u16 offset, u8 *sum)
 {
-	if (hw->mac.ops.mng_host_if_write)
-		return hw->mac.ops.mng_host_if_write(hw, buffer, length,
-						     offset, sum);
-
-	return E1000_NOT_IMPLEMENTED;
+	return e1000_mng_host_if_write_generic(hw, buffer, length, offset, sum);
 }
 
 /**
@@ -875,10 +896,7 @@ s32 e1000_mng_host_if_write(struct e1000_hw *hw, u8 *buffer, u16 length,
 s32 e1000_mng_write_cmd_header(struct e1000_hw *hw,
 			       struct e1000_host_mng_command_header *hdr)
 {
-	if (hw->mac.ops.mng_write_cmd_header)
-		return hw->mac.ops.mng_write_cmd_header(hw, hdr);
-
-	return E1000_NOT_IMPLEMENTED;
+	return e1000_mng_write_cmd_header_generic(hw, hdr);
 }
 
 /**
@@ -893,23 +911,20 @@ s32 e1000_mng_write_cmd_header(struct e1000_hw *hw,
  **/
 s32 e1000_mng_enable_host_if(struct e1000_hw *hw)
 {
-	if (hw->mac.ops.mng_enable_host_if)
-		return hw->mac.ops.mng_enable_host_if(hw);
-
-	return E1000_NOT_IMPLEMENTED;
+	return e1000_mng_enable_host_if_generic(hw);
 }
 
 /**
- *  e1000_wait_autoneg - Waits for autonegotiation completion
+ *  e1000_set_obff_timer - Set Optimized Buffer Flush/Fill timer
  *  @hw: pointer to the HW structure
+ *  @itr: u32 indicating itr value
  *
- *  Waits for autoneg to complete. Currently no func pointer exists and all
- *  implementations are handled in the generic version of this function.
+ *  Set the OBFF timer based on the given interrupt rate.
  **/
-s32 e1000_wait_autoneg(struct e1000_hw *hw)
+s32 e1000_set_obff_timer(struct e1000_hw *hw, u32 itr)
 {
-	if (hw->mac.ops.wait_autoneg)
-		return hw->mac.ops.wait_autoneg(hw);
+	if (hw->mac.ops.set_obff_timer)
+		return hw->mac.ops.set_obff_timer(hw, itr);
 
 	return E1000_SUCCESS;
 }
diff --git a/sys/dev/e1000/e1000_api.h b/sys/dev/e1000/e1000_api.h
index 70aaa15..69db1be 100644
--- a/sys/dev/e1000/e1000_api.h
+++ b/sys/dev/e1000/e1000_api.h
@@ -1,6 +1,6 @@
 /******************************************************************************
 
-  Copyright (c) 2001-2011, Intel Corporation 
+  Copyright (c) 2001-2013, Intel Corporation 
   All rights reserved.
   
   Redistribution and use in source and binary forms, with or without 
@@ -49,7 +49,9 @@ extern void e1000_rx_fifo_flush_82575(struct e1000_hw *hw);
 extern void e1000_init_function_pointers_vf(struct e1000_hw *hw);
 extern void e1000_power_up_fiber_serdes_link(struct e1000_hw *hw);
 extern void e1000_shutdown_fiber_serdes_link(struct e1000_hw *hw);
+extern void e1000_init_function_pointers_i210(struct e1000_hw *hw);
 
+s32 e1000_set_obff_timer(struct e1000_hw *hw, u32 itr);
 s32 e1000_set_mac_type(struct e1000_hw *hw);
 s32 e1000_setup_init_funcs(struct e1000_hw *hw, bool init_device);
 s32 e1000_init_mac_params(struct e1000_hw *hw);
@@ -104,7 +106,6 @@ s32 e1000_read_nvm(struct e1000_hw *hw, u16 offset, u16 words, u16 *data);
 s32 e1000_read_kmrn_reg(struct e1000_hw *hw, u32 offset, u16 *data);
 s32 e1000_write_kmrn_reg(struct e1000_hw *hw, u32 offset, u16 data);
 s32 e1000_write_nvm(struct e1000_hw *hw, u16 offset, u16 words, u16 *data);
-s32 e1000_wait_autoneg(struct e1000_hw *hw);
 s32 e1000_set_d3_lplu_state(struct e1000_hw *hw, bool active);
 s32 e1000_set_d0_lplu_state(struct e1000_hw *hw, bool active);
 bool e1000_check_mng_mode(struct e1000_hw *hw);
@@ -118,6 +119,7 @@ s32 e1000_mng_write_dhcp_info(struct e1000_hw *hw, u8 *buffer, u16 length);
 u32  e1000_translate_register_82542(u32 reg);
 
 
+
 /*
  * TBI_ACCEPT macro definition:
  *
@@ -160,4 +162,6 @@ u32  e1000_translate_register_82542(u32 reg);
 	  (((length) > min_frame_size) && \
 	  ((length) <= (max_frame_size + VLAN_TAG_SIZE + 1)))))
 
-#endif
+#define E1000_MAX(a, b) ((a) > (b) ? (a) : (b))
+#define E1000_DIVIDE_ROUND_UP(a, b)	(((a) + (b) - 1) / (b)) /* ceil(a/b) */
+#endif /* _E1000_API_H_ */
diff --git a/sys/dev/e1000/e1000_defines.h b/sys/dev/e1000/e1000_defines.h
index 69ef386..48c04b0 100644
--- a/sys/dev/e1000/e1000_defines.h
+++ b/sys/dev/e1000/e1000_defines.h
@@ -1,6 +1,6 @@
 /******************************************************************************
 
-  Copyright (c) 2001-2011, Intel Corporation 
+  Copyright (c) 2001-2013, Intel Corporation 
   All rights reserved.
   
   Redistribution and use in source and binary forms, with or without 
@@ -43,15 +43,7 @@
 /* Wake Up Control */
 #define E1000_WUC_APME		0x00000001 /* APM Enable */
 #define E1000_WUC_PME_EN	0x00000002 /* PME Enable */
-#define E1000_WUC_PME_STATUS	0x00000004 /* PME Status */
-#define E1000_WUC_APMPME	0x00000008 /* Assert PME on APM Wakeup */
-#define E1000_WUC_LSCWE		0x00000010 /* Link Status wake up enable */
-#define E1000_WUC_PPROXYE	0x00000010 /* Protocol Proxy Enable */
-#define E1000_WUC_LSCWO		0x00000020 /* Link Status wake up override */
-#define E1000_WUC_SPM		0x80000000 /* Enable SPM */
 #define E1000_WUC_PHY_WAKE	0x00000100 /* if PHY supports wakeup */
-#define E1000_WUC_FLX6_PHY	0x4000 /* Flexible Filter 6 Enable */
-#define E1000_WUC_FLX7_PHY	0x8000 /* Flexible Filter 7 Enable */
 
 /* Wake Up Filter Control */
 #define E1000_WUFC_LNKC	0x00000001 /* Link Status Change Wakeup Enable */
@@ -61,41 +53,7 @@
 #define E1000_WUFC_BC	0x00000010 /* Broadcast Wakeup Enable */
 #define E1000_WUFC_ARP	0x00000020 /* ARP Request Packet Wakeup Enable */
 #define E1000_WUFC_IPV4	0x00000040 /* Directed IPv4 Packet Wakeup Enable */
-#define E1000_WUFC_IPV6	0x00000080 /* Directed IPv6 Packet Wakeup Enable */
-#define E1000_WUFC_IGNORE_TCO_PHY 0x00000800 /* Ignore WakeOn TCO packets */
-#define E1000_WUFC_FLX0_PHY	0x00001000 /* Flexible Filter 0 Enable */
-#define E1000_WUFC_FLX1_PHY	0x00002000 /* Flexible Filter 1 Enable */
-#define E1000_WUFC_FLX2_PHY	0x00004000 /* Flexible Filter 2 Enable */
-#define E1000_WUFC_FLX3_PHY	0x00008000 /* Flexible Filter 3 Enable */
-#define E1000_WUFC_FLX4_PHY	0x00000200 /* Flexible Filter 4 Enable */
-#define E1000_WUFC_FLX5_PHY	0x00000400 /* Flexible Filter 5 Enable */
-#define E1000_WUFC_IGNORE_TCO	0x00008000 /* Ignore WakeOn TCO packets */
 #define E1000_WUFC_FLX0		0x00010000 /* Flexible Filter 0 Enable */
-#define E1000_WUFC_FLX1		0x00020000 /* Flexible Filter 1 Enable */
-#define E1000_WUFC_FLX2		0x00040000 /* Flexible Filter 2 Enable */
-#define E1000_WUFC_FLX3		0x00080000 /* Flexible Filter 3 Enable */
-#define E1000_WUFC_FLX4		0x00100000 /* Flexible Filter 4 Enable */
-#define E1000_WUFC_FLX5		0x00200000 /* Flexible Filter 5 Enable */
-#define E1000_WUFC_FLX6		0x00400000 /* Flexible Filter 6 Enable */
-#define E1000_WUFC_FLX7		0x00800000 /* Flexible Filter 7 Enable */
-#define E1000_WUFC_FW_RST	0x80000000 /* Wake on FW Reset Enable */
-#define E1000_WUFC_ALL_FILTERS_PHY_4	0x0000F0FF /* wakeup filters mask */
-#define E1000_WUFC_FLX_OFFSET_PHY	12 /* Flexible Filters bits offset */
-#define E1000_WUFC_FLX_FILTERS_PHY_4	0x0000F000 /* 4 flexible filters mask */
-#define E1000_WUFC_ALL_FILTERS_PHY_6	0x0000F6FF /* 6 wakeup filters mask */
-#define E1000_WUFC_FLX_FILTERS_PHY_6	0x0000F600 /* 6 flexible filters mask */
-#define E1000_WUFC_ALL_FILTERS		0x000F00FF /* all wakeup filters mask */
-#define E1000_WUFC_ALL_FILTERS_6	0x003F00FF /* Mask all 6 wu filters */
-#define E1000_WUFC_ALL_FILTERS_8	0x00FF00FF /* Mask all 8 wu filters */
-#define E1000_WUFC_FLX_OFFSET		16 /* Flexible Filters bits offset */
-#define E1000_WUFC_FLX_FILTERS		0x000F0000 /* 4 flexible filters mask */
-#define E1000_WUFC_FLX_FILTERS_6	0x003F0000 /* 6 flexible filters mask */
-#define E1000_WUFC_FLX_FILTERS_8	0x00FF0000 /* 8 flexible filters mask */
-/*
- * For 82576 to utilize Extended filter masks in addition to
- * existing (filter) masks
- */
-#define E1000_WUFC_EXT_FLX_FILTERS	0x00300000 /* Ext. FLX filter mask */
 
 /* Wake Up Status */
 #define E1000_WUS_LNKC		E1000_WUFC_LNKC
@@ -103,74 +61,18 @@
 #define E1000_WUS_EX		E1000_WUFC_EX
 #define E1000_WUS_MC		E1000_WUFC_MC
 #define E1000_WUS_BC		E1000_WUFC_BC
-#define E1000_WUS_ARP		E1000_WUFC_ARP
-#define E1000_WUS_IPV4		E1000_WUFC_IPV4
-#define E1000_WUS_IPV6		E1000_WUFC_IPV6
-#define E1000_WUS_FLX0_PHY	E1000_WUFC_FLX0_PHY
-#define E1000_WUS_FLX1_PHY	E1000_WUFC_FLX1_PHY
-#define E1000_WUS_FLX2_PHY	E1000_WUFC_FLX2_PHY
-#define E1000_WUS_FLX3_PHY	E1000_WUFC_FLX3_PHY
-#define E1000_WUS_FLX_FILTERS_PHY_4	E1000_WUFC_FLX_FILTERS_PHY_4
-#define E1000_WUS_FLX0		E1000_WUFC_FLX0
-#define E1000_WUS_FLX1		E1000_WUFC_FLX1
-#define E1000_WUS_FLX2		E1000_WUFC_FLX2
-#define E1000_WUS_FLX3		E1000_WUFC_FLX3
-#define E1000_WUS_FLX4		E1000_WUFC_FLX4
-#define E1000_WUS_FLX5		E1000_WUFC_FLX5
-#define E1000_WUS_FLX6		E1000_WUFC_FLX6
-#define E1000_WUS_FLX7		E1000_WUFC_FLX7
-#define E1000_WUS_FLX4_PHY	E1000_WUFC_FLX4_PHY
-#define E1000_WUS_FLX5_PHY	E1000_WUFC_FLX5_PHY
-#define E1000_WUS_FLX6_PHY	0x0400
-#define E1000_WUS_FLX7_PHY	0x0800
-#define E1000_WUS_FLX_FILTERS	E1000_WUFC_FLX_FILTERS
-#define E1000_WUS_FLX_FILTERS_6		E1000_WUFC_FLX_FILTERS_6
-#define E1000_WUS_FLX_FILTERS_8		E1000_WUFC_FLX_FILTERS_8
-#define E1000_WUS_FLX_FILTERS_PHY_6	E1000_WUFC_FLX_FILTERS_PHY_6
-
-/* Wake Up Packet Length */
-#define E1000_WUPL_LENGTH_MASK	0x0FFF   /* Only the lower 12 bits are valid */
-
-/* Four Flexible Filters are supported */
-#define E1000_FLEXIBLE_FILTER_COUNT_MAX		4
-/* Six Flexible Filters are supported */
-#define E1000_FLEXIBLE_FILTER_COUNT_MAX_6	6
-/* Eight Flexible Filters are supported */
-#define E1000_FLEXIBLE_FILTER_COUNT_MAX_8	8
-/* Two Extended Flexible Filters are supported (82576) */
-#define E1000_EXT_FLEXIBLE_FILTER_COUNT_MAX	2
-#define E1000_FHFT_LENGTH_OFFSET	0xFC /* Length byte in FHFT */
-#define E1000_FHFT_LENGTH_MASK		0x0FF /* Length in lower byte */
-
-/* Each Flexible Filter is at most 128 (0x80) bytes in length */
-#define E1000_FLEXIBLE_FILTER_SIZE_MAX	128
-
-#define E1000_FFLT_SIZE		E1000_FLEXIBLE_FILTER_COUNT_MAX
-#define E1000_FFLT_SIZE_6	E1000_FLEXIBLE_FILTER_COUNT_MAX_6
-#define E1000_FFLT_SIZE_8	E1000_FLEXIBLE_FILTER_COUNT_MAX_8
-#define E1000_FFMT_SIZE		E1000_FLEXIBLE_FILTER_SIZE_MAX
-#define E1000_FFVT_SIZE		E1000_FLEXIBLE_FILTER_SIZE_MAX
 
 /* Extended Device Control */
-#define E1000_CTRL_EXT_GPI0_EN		0x00000001 /* Maps SDP4 to GPI0 */
-#define E1000_CTRL_EXT_GPI1_EN		0x00000002 /* Maps SDP5 to GPI1 */
-#define E1000_CTRL_EXT_PHYINT_EN	E1000_CTRL_EXT_GPI1_EN
-#define E1000_CTRL_EXT_GPI2_EN		0x00000004 /* Maps SDP6 to GPI2 */
-#define E1000_CTRL_EXT_GPI3_EN		0x00000008 /* Maps SDP7 to GPI3 */
-/* Reserved (bits 4,5) in >= 82575 */
+#define E1000_CTRL_EXT_LPCD		0x00000004 /* LCD Power Cycle Done */
 #define E1000_CTRL_EXT_SDP4_DATA	0x00000010 /* SW Definable Pin 4 data */
-#define E1000_CTRL_EXT_SDP5_DATA	0x00000020 /* SW Definable Pin 5 data */
-#define E1000_CTRL_EXT_PHY_INT		E1000_CTRL_EXT_SDP5_DATA
 #define E1000_CTRL_EXT_SDP6_DATA	0x00000040 /* SW Definable Pin 6 data */
 #define E1000_CTRL_EXT_SDP3_DATA	0x00000080 /* SW Definable Pin 3 data */
 /* SDP 4/5 (bits 8,9) are reserved in >= 82575 */
 #define E1000_CTRL_EXT_SDP4_DIR	0x00000100 /* Direction of SDP4 0=in 1=out */
-#define E1000_CTRL_EXT_SDP5_DIR	0x00000200 /* Direction of SDP5 0=in 1=out */
 #define E1000_CTRL_EXT_SDP6_DIR	0x00000400 /* Direction of SDP6 0=in 1=out */
 #define E1000_CTRL_EXT_SDP3_DIR	0x00000800 /* Direction of SDP3 0=in 1=out */
-#define E1000_CTRL_EXT_ASDCHK	0x00001000 /* Initiate an ASD sequence */
+#define E1000_CTRL_EXT_FORCE_SMBUS	0x00000800 /* Force SMBus mode */
 #define E1000_CTRL_EXT_EE_RST	0x00002000 /* Reinitialize from EEPROM */
-#define E1000_CTRL_EXT_IPS	0x00004000 /* Invert Power State */
 /* Physical Func Reset Done Indication */
 #define E1000_CTRL_EXT_PFRSTD	0x00004000
 #define E1000_CTRL_EXT_SPD_BYPS	0x00008000 /* Speed Select Bypass */
@@ -179,42 +81,22 @@
 #define E1000_CTRL_EXT_LINK_MODE_MASK	0x00C00000
 /* Offset of the link mode field in Ctrl Ext register */
 #define E1000_CTRL_EXT_LINK_MODE_OFFSET	22
-#define E1000_CTRL_EXT_LINK_MODE_82580_MASK	0x01C00000 /*82580 bit 24:22*/
 #define E1000_CTRL_EXT_LINK_MODE_1000BASE_KX	0x00400000
 #define E1000_CTRL_EXT_LINK_MODE_GMII	0x00000000
-#define E1000_CTRL_EXT_LINK_MODE_TBI	0x00C00000
-#define E1000_CTRL_EXT_LINK_MODE_KMRN	0x00000000
 #define E1000_CTRL_EXT_LINK_MODE_PCIE_SERDES	0x00C00000
-#define E1000_CTRL_EXT_LINK_MODE_PCIX_SERDES	0x00800000
 #define E1000_CTRL_EXT_LINK_MODE_SGMII	0x00800000
 #define E1000_CTRL_EXT_EIAME		0x01000000
 #define E1000_CTRL_EXT_IRCA		0x00000001
-#define E1000_CTRL_EXT_WR_WMARK_MASK	0x03000000
-#define E1000_CTRL_EXT_WR_WMARK_256	0x00000000
-#define E1000_CTRL_EXT_WR_WMARK_320	0x01000000
-#define E1000_CTRL_EXT_WR_WMARK_384	0x02000000
-#define E1000_CTRL_EXT_WR_WMARK_448	0x03000000
-#define E1000_CTRL_EXT_CANC		0x04000000 /* Int delay cancellation */
 #define E1000_CTRL_EXT_DRV_LOAD		0x10000000 /* Drv loaded bit for FW */
-/* IAME enable bit (27) was removed in >= 82575 */
 #define E1000_CTRL_EXT_IAME		0x08000000 /* Int ACK Auto-mask */
-/* packet buffer parity error detection enabled */
-#define E1000_CRTL_EXT_PB_PAREN		0x01000000
-/* descriptor FIFO parity error detection enable */
-#define E1000_CTRL_EXT_DF_PAREN		0x02000000
-#define E1000_CTRL_EXT_GHOST_PAREN	0x40000000
 #define E1000_CTRL_EXT_PBA_CLR		0x80000000 /* PBA Clear */
 #define E1000_CTRL_EXT_LSECCK		0x00001000
 #define E1000_CTRL_EXT_PHYPDEN		0x00100000
 #define E1000_I2CCMD_REG_ADDR_SHIFT	16
-#define E1000_I2CCMD_REG_ADDR		0x00FF0000
 #define E1000_I2CCMD_PHY_ADDR_SHIFT	24
-#define E1000_I2CCMD_PHY_ADDR		0x07000000
 #define E1000_I2CCMD_OPCODE_READ	0x08000000
 #define E1000_I2CCMD_OPCODE_WRITE	0x00000000
-#define E1000_I2CCMD_RESET		0x10000000
 #define E1000_I2CCMD_READY		0x20000000
-#define E1000_I2CCMD_INTERRUPT_ENA	0x40000000
 #define E1000_I2CCMD_ERROR		0x80000000
 #define E1000_I2CCMD_SFP_DATA_ADDR(a)	(0x0000 + (a))
 #define E1000_I2CCMD_SFP_DIAG_ADDR(a)	(0x0100 + (a))
@@ -235,11 +117,9 @@
 #define E1000_RXD_STAT_TCPCS	0x20    /* TCP xsum calculated */
 #define E1000_RXD_STAT_IPCS	0x40    /* IP xsum calculated */
 #define E1000_RXD_STAT_PIF	0x80    /* passed in-exact filter */
-#define E1000_RXD_STAT_CRCV	0x100   /* Speculative CRC Valid */
 #define E1000_RXD_STAT_IPIDV	0x200   /* IP identification valid */
 #define E1000_RXD_STAT_UDPV	0x400   /* Valid UDP checksum */
 #define E1000_RXD_STAT_DYNINT	0x800   /* Pkt caused INT via DYNINT */
-#define E1000_RXD_STAT_ACK	0x8000  /* ACK Packet indication */
 #define E1000_RXD_ERR_CE	0x01    /* CRC Error */
 #define E1000_RXD_ERR_SE	0x02    /* Symbol Error */
 #define E1000_RXD_ERR_SEQ	0x04    /* Sequence Error */
@@ -248,11 +128,8 @@
 #define E1000_RXD_ERR_IPE	0x40    /* IP Checksum Error */
 #define E1000_RXD_ERR_RXE	0x80    /* Rx Data Error */
 #define E1000_RXD_SPC_VLAN_MASK	0x0FFF  /* VLAN ID is in lower 12 bits */
-#define E1000_RXD_SPC_PRI_MASK	0xE000  /* Priority is in upper 3 bits */
-#define E1000_RXD_SPC_PRI_SHIFT	13
-#define E1000_RXD_SPC_CFI_MASK	0x1000  /* CFI is bit 12 */
-#define E1000_RXD_SPC_CFI_SHIFT	12
 
+#define E1000_RXDEXT_STATERR_TST	0x00000100 /* Time Stamp taken */
 #define E1000_RXDEXT_STATERR_LB		0x00040000
 #define E1000_RXDEXT_STATERR_CE		0x01000000
 #define E1000_RXDEXT_STATERR_SE		0x02000000
@@ -262,13 +139,6 @@
 #define E1000_RXDEXT_STATERR_IPE	0x40000000
 #define E1000_RXDEXT_STATERR_RXE	0x80000000
 
-#define E1000_RXDEXT_LSECH		0x01000000
-#define E1000_RXDEXT_LSECE_MASK		0x60000000
-#define E1000_RXDEXT_LSECE_NO_ERROR	0x00000000
-#define E1000_RXDEXT_LSECE_NO_SA_MATCH	0x20000000
-#define E1000_RXDEXT_LSECE_REPLAY_DETECT 0x40000000
-#define E1000_RXDEXT_LSECE_BAD_SIG	0x60000000
-
 /* mask to determine if packets should be dropped due to frame errors */
 #define E1000_RXD_ERR_FRAME_ERR_MASK ( \
 	E1000_RXD_ERR_CE  |		\
@@ -285,57 +155,25 @@
 	E1000_RXDEXT_STATERR_CXE |	\
 	E1000_RXDEXT_STATERR_RXE)
 
-#define E1000_MRQC_ENABLE_MASK			0x00000007
-#define E1000_MRQC_ENABLE_RSS_2Q		0x00000001
-#define E1000_MRQC_ENABLE_RSS_INT		0x00000004
 #define E1000_MRQC_RSS_FIELD_MASK		0xFFFF0000
 #define E1000_MRQC_RSS_FIELD_IPV4_TCP		0x00010000
 #define E1000_MRQC_RSS_FIELD_IPV4		0x00020000
 #define E1000_MRQC_RSS_FIELD_IPV6_TCP_EX	0x00040000
-#define E1000_MRQC_RSS_FIELD_IPV6_EX		0x00080000
 #define E1000_MRQC_RSS_FIELD_IPV6		0x00100000
 #define E1000_MRQC_RSS_FIELD_IPV6_TCP		0x00200000
 
 #define E1000_RXDPS_HDRSTAT_HDRSP		0x00008000
-#define E1000_RXDPS_HDRSTAT_HDRLEN_MASK		0x000003FF
 
 /* Management Control */
 #define E1000_MANC_SMBUS_EN	0x00000001 /* SMBus Enabled - RO */
 #define E1000_MANC_ASF_EN	0x00000002 /* ASF Enabled - RO */
-#define E1000_MANC_R_ON_FORCE	0x00000004 /* Reset on Force TCO - RO */
-#define E1000_MANC_RMCP_EN	0x00000100 /* Enable RCMP 026Fh Filtering */
-#define E1000_MANC_0298_EN	0x00000200 /* Enable RCMP 0298h Filtering */
-#define E1000_MANC_IPV4_EN	0x00000400 /* Enable IPv4 */
-#define E1000_MANC_IPV6_EN	0x00000800 /* Enable IPv6 */
-#define E1000_MANC_SNAP_EN	0x00001000 /* Accept LLC/SNAP */
 #define E1000_MANC_ARP_EN	0x00002000 /* Enable ARP Request Filtering */
-/* Enable Neighbor Discovery Filtering */
-#define E1000_MANC_NEIGHBOR_EN	0x00004000
-#define E1000_MANC_ARP_RES_EN	0x00008000 /* Enable ARP response Filtering */
-#define E1000_MANC_TCO_RESET	0x00010000 /* TCO Reset Occurred */
 #define E1000_MANC_RCV_TCO_EN	0x00020000 /* Receive TCO Packets Enabled */
-#define E1000_MANC_REPORT_STATUS 0x00040000 /* Status Reporting Enabled */
-#define E1000_MANC_RCV_ALL	0x00080000 /* Receive All Enabled */
 #define E1000_MANC_BLK_PHY_RST_ON_IDE	0x00040000 /* Block phy resets */
 /* Enable MAC address filtering */
 #define E1000_MANC_EN_MAC_ADDR_FILTER	0x00100000
 /* Enable MNG packets to host memory */
 #define E1000_MANC_EN_MNG2HOST		0x00200000
-/* Enable IP address filtering */
-#define E1000_MANC_EN_IP_ADDR_FILTER	0x00400000
-#define E1000_MANC_EN_XSUM_FILTER	0x00800000 /* Ena checksum filtering */
-#define E1000_MANC_BR_EN		0x01000000 /* Ena broadcast filtering */
-#define E1000_MANC_SMB_REQ		0x01000000 /* SMBus Request */
-#define E1000_MANC_SMB_GNT		0x02000000 /* SMBus Grant */
-#define E1000_MANC_SMB_CLK_IN		0x04000000 /* SMBus Clock In */
-#define E1000_MANC_SMB_DATA_IN		0x08000000 /* SMBus Data In */
-#define E1000_MANC_SMB_DATA_OUT		0x10000000 /* SMBus Data Out */
-#define E1000_MANC_SMB_CLK_OUT		0x20000000 /* SMBus Clock Out */
-#define E1000_MANC_MPROXYE		0x40000000 /* Mngment Proxy Enable */
-#define E1000_MANC_EN_BMC2OS		0x10000000 /* OS2BMC is enabld or not */
-
-#define E1000_MANC_SMB_DATA_OUT_SHIFT	28 /* SMBus Data Out Shift */
-#define E1000_MANC_SMB_CLK_OUT_SHIFT	29 /* SMBus Clock Out Shift */
 
 #define E1000_MANC2H_PORT_623		0x00000020 /* Port 0x26f */
 #define E1000_MANC2H_PORT_664		0x00000040 /* Port 0x298 */
@@ -351,19 +189,11 @@
 #define E1000_RCTL_LPE		0x00000020 /* long packet enable */
 #define E1000_RCTL_LBM_NO	0x00000000 /* no loopback mode */
 #define E1000_RCTL_LBM_MAC	0x00000040 /* MAC loopback mode */
-#define E1000_RCTL_LBM_SLP	0x00000080 /* serial link loopback mode */
 #define E1000_RCTL_LBM_TCVR	0x000000C0 /* tcvr loopback mode */
-#define E1000_RCTL_DTYP_MASK	0x00000C00 /* Descriptor type mask */
 #define E1000_RCTL_DTYP_PS	0x00000400 /* Packet Split descriptor */
 #define E1000_RCTL_RDMTS_HALF	0x00000000 /* Rx desc min thresh size */
-#define E1000_RCTL_RDMTS_QUAT	0x00000100 /* Rx desc min thresh size */
-#define E1000_RCTL_RDMTS_EIGTH	0x00000200 /* Rx desc min thresh size */
 #define E1000_RCTL_MO_SHIFT	12 /* multicast offset shift */
-#define E1000_RCTL_MO_0		0x00000000 /* multicast offset 11:0 */
-#define E1000_RCTL_MO_1		0x00001000 /* multicast offset 12:1 */
-#define E1000_RCTL_MO_2		0x00002000 /* multicast offset 13:2 */
 #define E1000_RCTL_MO_3		0x00003000 /* multicast offset 15:4 */
-#define E1000_RCTL_MDR		0x00004000 /* multicast desc ring 0 */
 #define E1000_RCTL_BAM		0x00008000 /* broadcast enable */
 /* these buffer sizes are valid if E1000_RCTL_BSEX is 0 */
 #define E1000_RCTL_SZ_2048	0x00000000 /* Rx buffer size 2048 */
@@ -381,11 +211,8 @@
 #define E1000_RCTL_PMCF		0x00800000 /* pass MAC control frames */
 #define E1000_RCTL_BSEX		0x02000000 /* Buffer size extension */
 #define E1000_RCTL_SECRC	0x04000000 /* Strip Ethernet CRC */
-#define E1000_RCTL_FLXBUF_MASK	0x78000000 /* Flexible buffer size */
-#define E1000_RCTL_FLXBUF_SHIFT	27 /* Flexible buffer shift */
 
-/*
- * Use byte values for the following shift parameters
+/* Use byte values for the following shift parameters
  * Usage:
  *     psrctl |= (((ROUNDUP(value0, 128) >> E1000_PSRCTL_BSIZE0_SHIFT) &
  *		  E1000_PSRCTL_BSIZE0_MASK) |
@@ -420,16 +247,11 @@
 #define E1000_SWFW_PHY3_SM	0x40
 #define E1000_SWFW_SW_MNG_SM	0x400
 
-/* FACTPS Definitions */
-#define E1000_FACTPS_LFS	0x40000000  /* LAN Function Select */
 /* Device Control */
 #define E1000_CTRL_FD		0x00000001  /* Full duplex.0=half; 1=full */
-#define E1000_CTRL_BEM		0x00000002  /* Endian Mode.0=little,1=big */
 #define E1000_CTRL_PRIOR	0x00000004  /* Priority on PCI. 0=rx,1=fair */
 #define E1000_CTRL_GIO_MASTER_DISABLE 0x00000004 /*Blocks new Master reqs */
 #define E1000_CTRL_LRST		0x00000008  /* Link reset. 0=normal,1=reset */
-#define E1000_CTRL_TME		0x00000010  /* Test mode. 0=normal,1=test */
-#define E1000_CTRL_SLE		0x00000020  /* Serial Link on 0=dis,1=en */
 #define E1000_CTRL_ASDE		0x00000020  /* Auto-speed detect enable */
 #define E1000_CTRL_SLU		0x00000040  /* Set link up (Force Link) */
 #define E1000_CTRL_ILOS		0x00000080  /* Invert Loss-Of Signal */
@@ -437,50 +259,35 @@
 #define E1000_CTRL_SPD_10	0x00000000  /* Force 10Mb */
 #define E1000_CTRL_SPD_100	0x00000100  /* Force 100Mb */
 #define E1000_CTRL_SPD_1000	0x00000200  /* Force 1Gb */
-#define E1000_CTRL_BEM32	0x00000400  /* Big Endian 32 mode */
 #define E1000_CTRL_FRCSPD	0x00000800  /* Force Speed */
 #define E1000_CTRL_FRCDPX	0x00001000  /* Force Duplex */
-#define E1000_CTRL_D_UD_EN	0x00002000  /* Dock/Undock enable */
-/* Defined polarity of Dock/Undock indication in SDP[0] */
-#define E1000_CTRL_D_UD_POLARITY	0x00004000
-/* Reset both PHY ports, through PHYRST_N pin */
-#define E1000_CTRL_FORCE_PHY_RESET	0x00008000
-/* enable link status from external LINK_0 and LINK_1 pins */
-#define E1000_CTRL_EXT_LINK_EN		0x00010000
 #define E1000_CTRL_LANPHYPC_OVERRIDE	0x00010000 /* SW control of LANPHYPC */
 #define E1000_CTRL_LANPHYPC_VALUE	0x00020000 /* SW value of LANPHYPC */
+#define E1000_CTRL_MEHE		0x00080000 /* Memory Error Handling Enable */
 #define E1000_CTRL_SWDPIN0	0x00040000 /* SWDPIN 0 value */
 #define E1000_CTRL_SWDPIN1	0x00080000 /* SWDPIN 1 value */
 #define E1000_CTRL_SWDPIN2	0x00100000 /* SWDPIN 2 value */
 #define E1000_CTRL_ADVD3WUC	0x00100000 /* D3 WUC */
+#define E1000_CTRL_EN_PHY_PWR_MGMT	0x00200000 /* PHY PM enable */
 #define E1000_CTRL_SWDPIN3	0x00200000 /* SWDPIN 3 value */
 #define E1000_CTRL_SWDPIO0	0x00400000 /* SWDPIN 0 Input or output */
-#define E1000_CTRL_SWDPIO1	0x00800000 /* SWDPIN 1 input or output */
 #define E1000_CTRL_SWDPIO2	0x01000000 /* SWDPIN 2 input or output */
 #define E1000_CTRL_SWDPIO3	0x02000000 /* SWDPIN 3 input or output */
 #define E1000_CTRL_RST		0x04000000 /* Global reset */
 #define E1000_CTRL_RFCE		0x08000000 /* Receive Flow Control enable */
 #define E1000_CTRL_TFCE		0x10000000 /* Transmit flow control enable */
-#define E1000_CTRL_RTE		0x20000000 /* Routing tag enable */
 #define E1000_CTRL_VME		0x40000000 /* IEEE VLAN mode enable */
 #define E1000_CTRL_PHY_RST	0x80000000 /* PHY Reset */
-#define E1000_CTRL_SW2FW_INT	0x02000000 /* Initiate an interrupt to ME */
 #define E1000_CTRL_I2C_ENA	0x02000000 /* I2C enable */
 
-/*
- * Bit definitions for the Management Data IO (MDIO) and Management Data
- * Clock (MDC) pins in the Device Control Register.
- */
-#define E1000_CTRL_PHY_RESET_DIR	E1000_CTRL_SWDPIO0
-#define E1000_CTRL_PHY_RESET		E1000_CTRL_SWDPIN0
 #define E1000_CTRL_MDIO_DIR		E1000_CTRL_SWDPIO2
 #define E1000_CTRL_MDIO			E1000_CTRL_SWDPIN2
 #define E1000_CTRL_MDC_DIR		E1000_CTRL_SWDPIO3
 #define E1000_CTRL_MDC			E1000_CTRL_SWDPIN3
-#define E1000_CTRL_PHY_RESET_DIR4	E1000_CTRL_EXT_SDP4_DIR
-#define E1000_CTRL_PHY_RESET4		E1000_CTRL_EXT_SDP4_DATA
 
 #define E1000_CONNSW_ENRGSRC		0x4
+#define E1000_CONNSW_PHYSD		0x400
+#define E1000_CONNSW_SERDESD		0x200
 #define E1000_PCS_CFG_PCS_EN		8
 #define E1000_PCS_LCTL_FLV_LINK_UP	1
 #define E1000_PCS_LCTL_FSV_10		0
@@ -489,65 +296,37 @@
 #define E1000_PCS_LCTL_FDV_FULL		8
 #define E1000_PCS_LCTL_FSD		0x10
 #define E1000_PCS_LCTL_FORCE_LINK	0x20
-#define E1000_PCS_LCTL_LOW_LINK_LATCH	0x40
 #define E1000_PCS_LCTL_FORCE_FCTRL	0x80
 #define E1000_PCS_LCTL_AN_ENABLE	0x10000
 #define E1000_PCS_LCTL_AN_RESTART	0x20000
 #define E1000_PCS_LCTL_AN_TIMEOUT	0x40000
-#define E1000_PCS_LCTL_AN_SGMII_BYPASS	0x80000
-#define E1000_PCS_LCTL_AN_SGMII_TRIGGER	0x100000
-#define E1000_PCS_LCTL_FAST_LINK_TIMER	0x1000000
-#define E1000_PCS_LCTL_LINK_OK_FIX	0x2000000
-#define E1000_PCS_LCTL_CRS_ON_NI	0x4000000
 #define E1000_ENABLE_SERDES_LOOPBACK	0x0410
 
 #define E1000_PCS_LSTS_LINK_OK		1
-#define E1000_PCS_LSTS_SPEED_10		0
 #define E1000_PCS_LSTS_SPEED_100	2
 #define E1000_PCS_LSTS_SPEED_1000	4
 #define E1000_PCS_LSTS_DUPLEX_FULL	8
 #define E1000_PCS_LSTS_SYNK_OK		0x10
 #define E1000_PCS_LSTS_AN_COMPLETE	0x10000
-#define E1000_PCS_LSTS_AN_PAGE_RX	0x20000
-#define E1000_PCS_LSTS_AN_TIMED_OUT	0x40000
-#define E1000_PCS_LSTS_AN_REMOTE_FAULT	0x80000
-#define E1000_PCS_LSTS_AN_ERROR_RWS	0x100000
 
 /* Device Status */
 #define E1000_STATUS_FD			0x00000001 /* Duplex 0=half 1=full */
 #define E1000_STATUS_LU			0x00000002 /* Link up.0=no,1=link */
 #define E1000_STATUS_FUNC_MASK		0x0000000C /* PCI Function Mask */
 #define E1000_STATUS_FUNC_SHIFT		2
-#define E1000_STATUS_FUNC_0		0x00000000 /* Function 0 */
 #define E1000_STATUS_FUNC_1		0x00000004 /* Function 1 */
 #define E1000_STATUS_TXOFF		0x00000010 /* transmission paused */
-#define E1000_STATUS_TBIMODE		0x00000020 /* TBI mode */
-#define E1000_STATUS_SPEED_MASK		0x000000C0
+#define E1000_STATUS_SPEED_MASK	0x000000C0
 #define E1000_STATUS_SPEED_10		0x00000000 /* Speed 10Mb/s */
 #define E1000_STATUS_SPEED_100		0x00000040 /* Speed 100Mb/s */
 #define E1000_STATUS_SPEED_1000		0x00000080 /* Speed 1000Mb/s */
 #define E1000_STATUS_LAN_INIT_DONE	0x00000200 /* Lan Init Compltn by NVM */
-#define E1000_STATUS_ASDV		0x00000300 /* Auto speed detect value */
 #define E1000_STATUS_PHYRA		0x00000400 /* PHY Reset Asserted */
-/* Change in Dock/Undock state clear on write '0'. */
-#define E1000_STATUS_DOCK_CI		0x00000800
 #define E1000_STATUS_GIO_MASTER_ENABLE	0x00080000 /* Master request status */
-#define E1000_STATUS_MTXCKOK		0x00000400 /* MTX clock running OK */
 #define E1000_STATUS_PCI66		0x00000800 /* In 66Mhz slot */
 #define E1000_STATUS_BUS64		0x00001000 /* In 64 bit slot */
 #define E1000_STATUS_PCIX_MODE		0x00002000 /* PCI-X mode */
 #define E1000_STATUS_PCIX_SPEED		0x0000C000 /* PCI-X bus speed */
-#define E1000_STATUS_BMC_SKU_0		0x00100000 /* BMC USB redirect disbld */
-#define E1000_STATUS_BMC_SKU_1		0x00200000 /* BMC SRAM disabled */
-#define E1000_STATUS_BMC_SKU_2		0x00400000 /* BMC SDRAM disabled */
-#define E1000_STATUS_BMC_CRYPTO		0x00800000 /* BMC crypto disabled */
-/* BMC external code execution disabled */
-#define E1000_STATUS_BMC_LITE		0x01000000
-#define E1000_STATUS_RGMII_ENABLE	0x02000000 /* RGMII disabled */
-#define E1000_STATUS_FUSE_8		0x04000000
-#define E1000_STATUS_FUSE_9		0x08000000
-#define E1000_STATUS_SERDES0_DIS	0x10000000 /* SERDES disbld on port 0 */
-#define E1000_STATUS_SERDES1_DIS	0x20000000 /* SERDES disbld on port 1 */
 
 /* Constants used to interpret the masked PCI-X bus speed. */
 #define E1000_STATUS_PCIX_SPEED_66	0x00000000 /* PCI-X bus spd 50-66MHz */
@@ -578,8 +357,6 @@
 	ADVERTISE_100_FULL)
 #define E1000_ALL_100_SPEED	(ADVERTISE_100_HALF | ADVERTISE_100_FULL)
 #define E1000_ALL_10_SPEED	(ADVERTISE_10_HALF | ADVERTISE_10_FULL)
-#define E1000_ALL_FULL_DUPLEX	( \
-	ADVERTISE_10_FULL | ADVERTISE_100_FULL | ADVERTISE_1000_FULL)
 #define E1000_ALL_HALF_DUPLEX	(ADVERTISE_10_HALF | ADVERTISE_100_HALF)
 
 #define AUTONEG_ADVERTISE_SPEED_DEFAULT		E1000_ALL_SPEED_DUPLEX
@@ -587,51 +364,20 @@
 /* LED Control */
 #define E1000_PHY_LED0_MODE_MASK	0x00000007
 #define E1000_PHY_LED0_IVRT		0x00000008
-#define E1000_PHY_LED0_BLINK		0x00000010
 #define E1000_PHY_LED0_MASK		0x0000001F
 
 #define E1000_LEDCTL_LED0_MODE_MASK	0x0000000F
 #define E1000_LEDCTL_LED0_MODE_SHIFT	0
-#define E1000_LEDCTL_LED0_BLINK_RATE	0x00000020
 #define E1000_LEDCTL_LED0_IVRT		0x00000040
 #define E1000_LEDCTL_LED0_BLINK		0x00000080
-#define E1000_LEDCTL_LED1_MODE_MASK	0x00000F00
-#define E1000_LEDCTL_LED1_MODE_SHIFT	8
-#define E1000_LEDCTL_LED1_BLINK_RATE	0x00002000
-#define E1000_LEDCTL_LED1_IVRT		0x00004000
-#define E1000_LEDCTL_LED1_BLINK		0x00008000
-#define E1000_LEDCTL_LED2_MODE_MASK	0x000F0000
-#define E1000_LEDCTL_LED2_MODE_SHIFT	16
-#define E1000_LEDCTL_LED2_BLINK_RATE	0x00200000
-#define E1000_LEDCTL_LED2_IVRT		0x00400000
-#define E1000_LEDCTL_LED2_BLINK		0x00800000
-#define E1000_LEDCTL_LED3_MODE_MASK	0x0F000000
-#define E1000_LEDCTL_LED3_MODE_SHIFT	24
-#define E1000_LEDCTL_LED3_BLINK_RATE	0x20000000
-#define E1000_LEDCTL_LED3_IVRT		0x40000000
-#define E1000_LEDCTL_LED3_BLINK		0x80000000
-
-#define E1000_LEDCTL_MODE_LINK_10_1000	0x0
-#define E1000_LEDCTL_MODE_LINK_100_1000	0x1
+
 #define E1000_LEDCTL_MODE_LINK_UP	0x2
-#define E1000_LEDCTL_MODE_ACTIVITY	0x3
-#define E1000_LEDCTL_MODE_LINK_ACTIVITY	0x4
-#define E1000_LEDCTL_MODE_LINK_10	0x5
-#define E1000_LEDCTL_MODE_LINK_100	0x6
-#define E1000_LEDCTL_MODE_LINK_1000	0x7
-#define E1000_LEDCTL_MODE_PCIX_MODE	0x8
-#define E1000_LEDCTL_MODE_FULL_DUPLEX	0x9
-#define E1000_LEDCTL_MODE_COLLISION	0xA
-#define E1000_LEDCTL_MODE_BUS_SPEED	0xB
-#define E1000_LEDCTL_MODE_BUS_SIZE	0xC
-#define E1000_LEDCTL_MODE_PAUSED	0xD
 #define E1000_LEDCTL_MODE_LED_ON	0xE
 #define E1000_LEDCTL_MODE_LED_OFF	0xF
 
 /* Transmit Descriptor bit definitions */
 #define E1000_TXD_DTYP_D	0x00100000 /* Data Descriptor */
 #define E1000_TXD_DTYP_C	0x00000000 /* Context Descriptor */
-#define E1000_TXD_POPTS_SHIFT	8          /* POPTS shift */
 #define E1000_TXD_POPTS_IXSM	0x01       /* Insert IP checksum */
 #define E1000_TXD_POPTS_TXSM	0x02       /* Insert TCP/UDP checksum */
 #define E1000_TXD_CMD_EOP	0x01000000 /* End of Packet */
@@ -650,21 +396,14 @@
 #define E1000_TXD_CMD_IP	0x02000000 /* IP packet */
 #define E1000_TXD_CMD_TSE	0x04000000 /* TCP Seg enable */
 #define E1000_TXD_STAT_TC	0x00000004 /* Tx Underrun */
-/* Extended desc bits for Linksec and timesync */
-#define E1000_TXD_CMD_LINKSEC	0x10000000 /* Apply LinkSec on packet */
 #define E1000_TXD_EXTCMD_TSTAMP	0x00000010 /* IEEE1588 Timestamp packet */
 
 /* Transmit Control */
-#define E1000_TCTL_RST		0x00000001 /* software reset */
 #define E1000_TCTL_EN		0x00000002 /* enable Tx */
-#define E1000_TCTL_BCE		0x00000004 /* busy check enable */
 #define E1000_TCTL_PSP		0x00000008 /* pad short packets */
 #define E1000_TCTL_CT		0x00000ff0 /* collision threshold */
 #define E1000_TCTL_COLD		0x003ff000 /* collision distance */
-#define E1000_TCTL_SWXOFF	0x00400000 /* SW Xoff transmission */
-#define E1000_TCTL_PBE		0x00800000 /* Packet Burst Enable */
 #define E1000_TCTL_RTLC		0x01000000 /* Re-transmit on late collision */
-#define E1000_TCTL_NRTU		0x02000000 /* No Re-transmit on underrun */
 #define E1000_TCTL_MULR		0x10000000 /* Multiple request support */
 
 /* Transmit Arbitration Count */
@@ -672,29 +411,19 @@
 
 /* SerDes Control */
 #define E1000_SCTL_DISABLE_SERDES_LOOPBACK	0x0400
+#define E1000_SCTL_ENABLE_SERDES_LOOPBACK	0x0410
 
 /* Receive Checksum Control */
-#define E1000_RXCSUM_PCSS_MASK	0x000000FF /* Packet Checksum Start */
 #define E1000_RXCSUM_IPOFL	0x00000100 /* IPv4 checksum offload */
 #define E1000_RXCSUM_TUOFL	0x00000200 /* TCP / UDP checksum offload */
-#define E1000_RXCSUM_IPV6OFL	0x00000400 /* IPv6 checksum offload */
 #define E1000_RXCSUM_CRCOFL	0x00000800 /* CRC32 offload enable */
 #define E1000_RXCSUM_IPPCSE	0x00001000 /* IP payload checksum enable */
 #define E1000_RXCSUM_PCSD	0x00002000 /* packet checksum disabled */
 
 /* Header split receive */
-#define E1000_RFCTL_ISCSI_DIS		0x00000001
-#define E1000_RFCTL_ISCSI_DWC_MASK	0x0000003E
-#define E1000_RFCTL_ISCSI_DWC_SHIFT	1
 #define E1000_RFCTL_NFSW_DIS		0x00000040
 #define E1000_RFCTL_NFSR_DIS		0x00000080
-#define E1000_RFCTL_NFS_VER_MASK	0x00000300
-#define E1000_RFCTL_NFS_VER_SHIFT	8
-#define E1000_RFCTL_IPV6_DIS		0x00000400
-#define E1000_RFCTL_IPV6_XSUM_DIS	0x00000800
 #define E1000_RFCTL_ACK_DIS		0x00001000
-#define E1000_RFCTL_ACKD_DIS		0x00002000
-#define E1000_RFCTL_IPFRSP_DIS		0x00004000
 #define E1000_RFCTL_EXTEN		0x00008000
 #define E1000_RFCTL_IPV6_EX_DIS		0x00010000
 #define E1000_RFCTL_NEW_IPV6_EXT_DIS	0x00020000
@@ -712,8 +441,6 @@
 #define DEFAULT_82543_TIPG_IPGT_COPPER	8
 
 #define E1000_TIPG_IPGT_MASK		0x000003FF
-#define E1000_TIPG_IPGR1_MASK		0x000FFC00
-#define E1000_TIPG_IPGR2_MASK		0x3FF00000
 
 #define DEFAULT_82542_TIPG_IPGR1	2
 #define DEFAULT_82543_TIPG_IPGR1	8
@@ -741,7 +468,6 @@
 #define E1000_EXTCNF_CTRL_EXT_CNF_POINTER_MASK	0x0FFF0000
 #define E1000_EXTCNF_CTRL_EXT_CNF_POINTER_SHIFT	16
 
-#define E1000_PHY_CTRL_SPD_EN			0x00000001
 #define E1000_PHY_CTRL_D0A_LPLU			0x00000002
 #define E1000_PHY_CTRL_NOND0A_LPLU		0x00000004
 #define E1000_PHY_CTRL_NOND0A_GBE_DISABLE	0x00000008
@@ -749,8 +475,10 @@
 
 #define E1000_KABGTXD_BGSQLBIAS			0x00050000
 
+/* Low Power IDLE Control */
+#define E1000_LPIC_LPIET_SHIFT		24	/* Low Power Idle Entry Time */
+
 /* PBA constants */
-#define E1000_PBA_6K		0x0006    /* 6KB */
 #define E1000_PBA_8K		0x0008    /* 8KB */
 #define E1000_PBA_10K		0x000A    /* 10KB */
 #define E1000_PBA_12K		0x000C    /* 12KB */
@@ -770,10 +498,15 @@
 #define E1000_PBA_48K		0x0030    /* 48KB */
 #define E1000_PBA_64K		0x0040    /* 64KB */
 
-#define E1000_PBA_RXA_MASK	0xFFFF;
+#define E1000_PBA_RXA_MASK	0xFFFF
 
 #define E1000_PBS_16K		E1000_PBA_16K
-#define E1000_PBS_24K		E1000_PBA_24K
+
+/* Uncorrectable/correctable ECC Error counts and enable bits */
+#define E1000_PBECCSTS_CORR_ERR_CNT_MASK	0x000000FF
+#define E1000_PBECCSTS_UNCORR_ERR_CNT_MASK	0x0000FF00
+#define E1000_PBECCSTS_UNCORR_ERR_CNT_SHIFT	8
+#define E1000_PBECCSTS_ECC_ENABLE		0x00010000
 
 #define IFS_MAX			80
 #define IFS_MIN			40
@@ -784,7 +517,6 @@
 /* SW Semaphore Register */
 #define E1000_SWSM_SMBI		0x00000001 /* Driver Semaphore bit */
 #define E1000_SWSM_SWESMBI	0x00000002 /* FW Semaphore bit */
-#define E1000_SWSM_WMNG		0x00000004 /* Wake MNG Clock */
 #define E1000_SWSM_DRV_LOAD	0x00000008 /* Driver Loaded Bit */
 
 #define E1000_SWSM2_LOCK	0x00000002 /* Secondary driver semaphore bit */
@@ -798,33 +530,19 @@
 #define E1000_ICR_RXO		0x00000040 /* Rx overrun */
 #define E1000_ICR_RXT0		0x00000080 /* Rx timer intr (ring 0) */
 #define E1000_ICR_VMMB		0x00000100 /* VM MB event */
-#define E1000_ICR_MDAC		0x00000200 /* MDIO access complete */
 #define E1000_ICR_RXCFG		0x00000400 /* Rx /c/ ordered set */
 #define E1000_ICR_GPI_EN0	0x00000800 /* GP Int 0 */
 #define E1000_ICR_GPI_EN1	0x00001000 /* GP Int 1 */
 #define E1000_ICR_GPI_EN2	0x00002000 /* GP Int 2 */
 #define E1000_ICR_GPI_EN3	0x00004000 /* GP Int 3 */
 #define E1000_ICR_TXD_LOW	0x00008000
-#define E1000_ICR_SRPD		0x00010000
-#define E1000_ICR_ACK		0x00020000 /* Receive Ack frame */
 #define E1000_ICR_MNG		0x00040000 /* Manageability event */
-#define E1000_ICR_DOCK		0x00080000 /* Dock/Undock */
+#define E1000_ICR_ECCER		0x00400000 /* Uncorrectable ECC Error */
+#define E1000_ICR_TS		0x00080000 /* Time Sync Interrupt */
 #define E1000_ICR_DRSTA		0x40000000 /* Device Reset Asserted */
 /* If this bit asserted, the driver should claim the interrupt */
 #define E1000_ICR_INT_ASSERTED	0x80000000
-#define E1000_ICR_RXD_FIFO_PAR0	0x00100000 /* Q0 Rx desc FIFO parity error */
-#define E1000_ICR_TXD_FIFO_PAR0	0x00200000 /* Q0 Tx desc FIFO parity error */
-#define E1000_ICR_HOST_ARB_PAR	0x00400000 /* host arb read buffer parity err */
-#define E1000_ICR_PB_PAR	0x00800000 /* packet buffer parity error */
-#define E1000_ICR_RXD_FIFO_PAR1	0x01000000 /* Q1 Rx desc FIFO parity error */
-#define E1000_ICR_TXD_FIFO_PAR1	0x02000000 /* Q1 Tx desc FIFO parity error */
-#define E1000_ICR_ALL_PARITY	0x03F00000 /* all parity error bits */
-/* FW changed the status of DISSW bit in the FWSM */
-#define E1000_ICR_DSW		0x00000020
-/* LAN connected device generates an interrupt */
-#define E1000_ICR_PHYINT	0x00001000
 #define E1000_ICR_DOUTSYNC	0x10000000 /* NIC DMA out of sync */
-#define E1000_ICR_EPRST		0x00100000 /* ME hardware reset occurs */
 #define E1000_ICR_RXQ0		0x00100000 /* Rx Queue 0 Interrupt */
 #define E1000_ICR_RXQ1		0x00200000 /* Rx Queue 1 Interrupt */
 #define E1000_ICR_TXQ0		0x00400000 /* Tx Queue 0 Interrupt */
@@ -862,18 +580,7 @@
 #define E1000_TCPTIMER_COUNT_FINISH	0x00000400 /* Count finish */
 #define E1000_TCPTIMER_LOOP	0x00000800 /* Loop */
 
-/*
- * This defines the bits that are set in the Interrupt Mask
- * Set/Read Register.  Each bit is documented below:
- *   o RXDMT0 = Receive Descriptor Minimum Threshold hit (ring 0)
- *   o RXSEQ  = Receive Sequence Error
- */
-#define POLL_IMS_ENABLE_MASK ( \
-	E1000_IMS_RXDMT0 |    \
-	E1000_IMS_RXSEQ)
-
-/*
- * This defines the bits that are set in the Interrupt Mask
+/* This defines the bits that are set in the Interrupt Mask
  * Set/Read Register.  Each bit is documented below:
  *   o RXT0   = Receiver Timer Interrupt (ring 0)
  *   o TXDW   = Transmit Descriptor Written Back
@@ -897,34 +604,11 @@
 #define E1000_IMS_RXDMT0	E1000_ICR_RXDMT0  /* Rx desc min. threshold */
 #define E1000_IMS_RXO		E1000_ICR_RXO     /* Rx overrun */
 #define E1000_IMS_RXT0		E1000_ICR_RXT0    /* Rx timer intr */
-#define E1000_IMS_MDAC		E1000_ICR_MDAC    /* MDIO access complete */
-#define E1000_IMS_RXCFG		E1000_ICR_RXCFG   /* Rx /c/ ordered set */
-#define E1000_IMS_GPI_EN0	E1000_ICR_GPI_EN0 /* GP Int 0 */
-#define E1000_IMS_GPI_EN1	E1000_ICR_GPI_EN1 /* GP Int 1 */
-#define E1000_IMS_GPI_EN2	E1000_ICR_GPI_EN2 /* GP Int 2 */
-#define E1000_IMS_GPI_EN3	E1000_ICR_GPI_EN3 /* GP Int 3 */
 #define E1000_IMS_TXD_LOW	E1000_ICR_TXD_LOW
-#define E1000_IMS_SRPD		E1000_ICR_SRPD
-#define E1000_IMS_ACK		E1000_ICR_ACK     /* Receive Ack frame */
-#define E1000_IMS_MNG		E1000_ICR_MNG     /* Manageability event */
-#define E1000_IMS_DOCK		E1000_ICR_DOCK    /* Dock/Undock */
+#define E1000_IMS_ECCER		E1000_ICR_ECCER   /* Uncorrectable ECC Error */
+#define E1000_IMS_TS		E1000_ICR_TS      /* Time Sync Interrupt */
 #define E1000_IMS_DRSTA		E1000_ICR_DRSTA   /* Device Reset Asserted */
-/* Q0 Rx desc FIFO parity error */
-#define E1000_IMS_RXD_FIFO_PAR0	E1000_ICR_RXD_FIFO_PAR0
-/* Q0 Tx desc FIFO parity error */
-#define E1000_IMS_TXD_FIFO_PAR0	E1000_ICR_TXD_FIFO_PAR0
-/* host arb read buffer parity error */
-#define E1000_IMS_HOST_ARB_PAR	E1000_ICR_HOST_ARB_PAR
-/* packet buffer parity error */
-#define E1000_IMS_PB_PAR	E1000_ICR_PB_PAR
-/* Q1 Rx desc FIFO parity error */
-#define E1000_IMS_RXD_FIFO_PAR1	E1000_ICR_RXD_FIFO_PAR1
-/* Q1 Tx desc FIFO parity error */
-#define E1000_IMS_TXD_FIFO_PAR1	E1000_ICR_TXD_FIFO_PAR1
-#define E1000_IMS_DSW		E1000_ICR_DSW
-#define E1000_IMS_PHYINT	E1000_ICR_PHYINT
 #define E1000_IMS_DOUTSYNC	E1000_ICR_DOUTSYNC /* NIC DMA out of sync */
-#define E1000_IMS_EPRST		E1000_ICR_EPRST
 #define E1000_IMS_RXQ0		E1000_ICR_RXQ0 /* Rx Queue 0 Interrupt */
 #define E1000_IMS_RXQ1		E1000_ICR_RXQ1 /* Rx Queue 1 Interrupt */
 #define E1000_IMS_TXQ0		E1000_ICR_TXQ0 /* Tx Queue 0 Interrupt */
@@ -947,41 +631,9 @@
 #define E1000_EIMS_OTHER	E1000_EICR_OTHER   /* Interrupt Cause Active */
 
 /* Interrupt Cause Set */
-#define E1000_ICS_TXDW		E1000_ICR_TXDW      /* Tx desc written back */
-#define E1000_ICS_TXQE		E1000_ICR_TXQE      /* Transmit Queue empty */
 #define E1000_ICS_LSC		E1000_ICR_LSC       /* Link Status Change */
 #define E1000_ICS_RXSEQ		E1000_ICR_RXSEQ     /* Rx sequence error */
 #define E1000_ICS_RXDMT0	E1000_ICR_RXDMT0    /* Rx desc min. threshold */
-#define E1000_ICS_RXO		E1000_ICR_RXO       /* Rx overrun */
-#define E1000_ICS_RXT0		E1000_ICR_RXT0      /* Rx timer intr */
-#define E1000_ICS_MDAC		E1000_ICR_MDAC      /* MDIO access complete */
-#define E1000_ICS_RXCFG		E1000_ICR_RXCFG     /* Rx /c/ ordered set */
-#define E1000_ICS_GPI_EN0	E1000_ICR_GPI_EN0   /* GP Int 0 */
-#define E1000_ICS_GPI_EN1	E1000_ICR_GPI_EN1   /* GP Int 1 */
-#define E1000_ICS_GPI_EN2	E1000_ICR_GPI_EN2   /* GP Int 2 */
-#define E1000_ICS_GPI_EN3	E1000_ICR_GPI_EN3   /* GP Int 3 */
-#define E1000_ICS_TXD_LOW	E1000_ICR_TXD_LOW
-#define E1000_ICS_SRPD		E1000_ICR_SRPD
-#define E1000_ICS_ACK		E1000_ICR_ACK       /* Receive Ack frame */
-#define E1000_ICS_MNG		E1000_ICR_MNG       /* Manageability event */
-#define E1000_ICS_DOCK		E1000_ICR_DOCK      /* Dock/Undock */
-#define E1000_ICS_DRSTA		E1000_ICR_DRSTA     /* Device Reset Aserted */
-/* Q0 Rx desc FIFO parity error */
-#define E1000_ICS_RXD_FIFO_PAR0	E1000_ICR_RXD_FIFO_PAR0
-/* Q0 Tx desc FIFO parity error */
-#define E1000_ICS_TXD_FIFO_PAR0	E1000_ICR_TXD_FIFO_PAR0
-/* host arb read buffer parity error */
-#define E1000_ICS_HOST_ARB_PAR	E1000_ICR_HOST_ARB_PAR
-/* packet buffer parity error */
-#define E1000_ICS_PB_PAR	E1000_ICR_PB_PAR
-/* Q1 Rx desc FIFO parity error */
-#define E1000_ICS_RXD_FIFO_PAR1	E1000_ICR_RXD_FIFO_PAR1
-/* Q1 Tx desc FIFO parity error */
-#define E1000_ICS_TXD_FIFO_PAR1	E1000_ICR_TXD_FIFO_PAR1
-#define E1000_ICS_DSW		E1000_ICR_DSW
-#define E1000_ICS_DOUTSYNC	E1000_ICR_DOUTSYNC /* NIC DMA out of sync */
-#define E1000_ICS_PHYINT	E1000_ICR_PHYINT
-#define E1000_ICS_EPRST		E1000_ICR_EPRST
 
 /* Extended Interrupt Cause Set */
 #define E1000_EICS_RX_QUEUE0	E1000_EICR_RX_QUEUE0 /* Rx Queue 0 Interrupt */
@@ -1004,7 +656,6 @@
 #define E1000_TXDCTL_HTHRESH	0x00003F00 /* TXDCTL Host Threshold */
 #define E1000_TXDCTL_WTHRESH	0x003F0000 /* TXDCTL Writeback Threshold */
 #define E1000_TXDCTL_GRAN	0x01000000 /* TXDCTL Granularity */
-#define E1000_TXDCTL_LWTHRESH	0xFE000000 /* TXDCTL Low Threshold */
 #define E1000_TXDCTL_FULL_TX_DESC_WB	0x01010000 /* GRAN=1, WTHRESH=1 */
 #define E1000_TXDCTL_MAX_TX_DESC_PREFETCH 0x0100001F /* GRAN=1, PTHRESH=31 */
 /* Enable the counting of descriptors still to be processed. */
@@ -1019,8 +670,7 @@
 #define VLAN_TAG_SIZE			4    /* 802.3ac tag (not DMA'd) */
 #define E1000_VLAN_FILTER_TBL_SIZE	128  /* VLAN Filter Table (4096 bits) */
 
-/* Receive Address */
-/*
+/* Receive Address
  * Number of high/low register pairs in the RAR. The RAR (Receive Address
  * Registers) holds the directed and multicast addresses that we monitor.
  * Technically, we have 16 spots.  However, we reserve one of these spots
@@ -1032,8 +682,6 @@
 #define E1000_RAL_MAC_ADDR_LEN	4
 #define E1000_RAH_MAC_ADDR_LEN	2
 #define E1000_RAH_QUEUE_MASK_82575	0x000C0000
-#define E1000_RAH_POOL_MASK	0x03FC0000
-#define E1000_RAH_POOL_SHIFT	18
 #define E1000_RAH_POOL_1	0x00040000
 
 /* Error Codes */
@@ -1073,30 +721,21 @@
 
 /* Flow Control */
 #define E1000_FCRTH_RTH		0x0000FFF8 /* Mask Bits[15:3] for RTH */
-#define E1000_FCRTH_XFCE	0x80000000 /* External Flow Control Enable */
 #define E1000_FCRTL_RTL		0x0000FFF8 /* Mask Bits[15:3] for RTL */
 #define E1000_FCRTL_XONE	0x80000000 /* Enable XON frame transmission */
 
 /* Transmit Configuration Word */
 #define E1000_TXCW_FD		0x00000020 /* TXCW full duplex */
-#define E1000_TXCW_HD		0x00000040 /* TXCW half duplex */
 #define E1000_TXCW_PAUSE	0x00000080 /* TXCW sym pause request */
 #define E1000_TXCW_ASM_DIR	0x00000100 /* TXCW astm pause direction */
 #define E1000_TXCW_PAUSE_MASK	0x00000180 /* TXCW pause request mask */
-#define E1000_TXCW_RF		0x00003000 /* TXCW remote fault */
-#define E1000_TXCW_NP		0x00008000 /* TXCW next page */
-#define E1000_TXCW_CW		0x0000ffff /* TxConfigWord mask */
-#define E1000_TXCW_TXC		0x40000000 /* Transmit Config control */
 #define E1000_TXCW_ANE		0x80000000 /* Auto-neg enable */
 
 /* Receive Configuration Word */
 #define E1000_RXCW_CW		0x0000ffff /* RxConfigWord mask */
-#define E1000_RXCW_NC		0x04000000 /* Receive config no carrier */
 #define E1000_RXCW_IV		0x08000000 /* Receive config invalid */
-#define E1000_RXCW_CC		0x10000000 /* Receive config change */
 #define E1000_RXCW_C		0x20000000 /* Receive config */
 #define E1000_RXCW_SYNCH	0x40000000 /* Receive config synch */
-#define E1000_RXCW_ANC		0x80000000 /* Auto-neg complete */
 
 #define E1000_TSYNCTXCTL_VALID		0x00000001 /* Tx timestamp valid */
 #define E1000_TSYNCTXCTL_ENABLED	0x00000010 /* enable Tx timestamping */
@@ -1109,6 +748,13 @@
 #define E1000_TSYNCRXCTL_TYPE_ALL	0x08
 #define E1000_TSYNCRXCTL_TYPE_EVENT_V2	0x0A
 #define E1000_TSYNCRXCTL_ENABLED	0x00000010 /* enable Rx timestamping */
+#define E1000_TSYNCRXCTL_SYSCFI		0x00000020 /* Sys clock frequency */
+
+#define E1000_RXMTRL_PTP_V1_SYNC_MESSAGE	0x00000000
+#define E1000_RXMTRL_PTP_V1_DELAY_REQ_MESSAGE	0x00010000
+
+#define E1000_RXMTRL_PTP_V2_SYNC_MESSAGE	0x00000000
+#define E1000_RXMTRL_PTP_V2_DELAY_REQ_MESSAGE	0x01000000
 
 #define E1000_TSYNCRXCFG_PTP_V1_CTRLT_MASK		0x000000FF
 #define E1000_TSYNCRXCFG_PTP_V1_SYNC_MESSAGE		0x00
@@ -1130,6 +776,11 @@
 #define E1000_TSYNCRXCFG_PTP_V2_MANAGEMENT_MESSAGE	0x0D00
 
 #define E1000_TIMINCA_16NS_SHIFT	24
+#define E1000_TIMINCA_INCPERIOD_SHIFT	24
+#define E1000_TIMINCA_INCVALUE_MASK	0x00FFFFFF
+
+#define E1000_TSICR_TXTS		0x00000002
+#define E1000_TSIM_TXTS			0x00000002
 /* TUPLE Filtering Configuration */
 #define E1000_TTQF_DISABLE_MASK		0xF0008000 /* TTQF Disable Mask */
 #define E1000_TTQF_QUEUE_ENABLE		0x100   /* TTQF Queue Enable Bit */
@@ -1170,7 +821,7 @@
 #define E1000_EEER_EEE_NEG		0x20000000 /* EEE capability nego */
 #define E1000_EEER_RX_LPI_STATUS	0x40000000 /* Rx in LPI state */
 #define E1000_EEER_TX_LPI_STATUS	0x80000000 /* Tx in LPI state */
-
+#define E1000_EEE_SU_LPI_CLK_STP	0x00800000 /* EEE LPI Clock Stop */
 /* PCI Express Control */
 #define E1000_GCR_RXD_NO_SNOOP		0x00000001
 #define E1000_GCR_RXDSCW_NO_SNOOP	0x00000002
@@ -1314,10 +965,6 @@
 #define E1000_EECD_CS		0x00000002 /* NVM Chip Select */
 #define E1000_EECD_DI		0x00000004 /* NVM Data In */
 #define E1000_EECD_DO		0x00000008 /* NVM Data Out */
-#define E1000_EECD_FWE_MASK	0x00000030
-#define E1000_EECD_FWE_DIS	0x00000010 /* Disable FLASH writes */
-#define E1000_EECD_FWE_EN	0x00000020 /* Enable FLASH writes */
-#define E1000_EECD_FWE_SHIFT	4
 #define E1000_EECD_REQ		0x00000040 /* NVM Access Request */
 #define E1000_EECD_GNT		0x00000080 /* NVM Access Grant */
 #define E1000_EECD_PRES		0x00000100 /* NVM Present */
@@ -1335,18 +982,28 @@
 #define E1000_EECD_AUTO_RD		0x00000200  /* NVM Auto Read done */
 #define E1000_EECD_SIZE_EX_MASK		0x00007800  /* NVM Size */
 #define E1000_EECD_SIZE_EX_SHIFT	11
-#define E1000_EECD_NVADDS		0x00018000 /* NVM Address Size */
-#define E1000_EECD_SELSHAD		0x00020000 /* Select Shadow RAM */
-#define E1000_EECD_INITSRAM		0x00040000 /* Initialize Shadow RAM */
 #define E1000_EECD_FLUPD		0x00080000 /* Update FLASH */
 #define E1000_EECD_AUPDEN		0x00100000 /* Ena Auto FLASH update */
-#define E1000_EECD_SHADV		0x00200000 /* Shadow RAM Data Valid */
 #define E1000_EECD_SEC1VAL		0x00400000 /* Sector One Valid */
-#define E1000_EECD_SECVAL_SHIFT		22
 #define E1000_EECD_SEC1VAL_VALID_MASK	(E1000_EECD_AUTO_RD | E1000_EECD_PRES)
+#define E1000_EECD_FLUPD_I210		0x00800000 /* Update FLASH */
+#define E1000_EECD_FLUDONE_I210		0x04000000 /* Update FLASH done */
+#define E1000_EECD_FLASH_DETECTED_I210	0x00080000 /* FLASH detected */
+#define E1000_EECD_SEC1VAL_I210		0x02000000 /* Sector One Valid */
+#define E1000_FLUDONE_ATTEMPTS		20000
+#define E1000_EERD_EEWR_MAX_COUNT	512 /* buffered EEPROM words rw */
+#define E1000_I210_FIFO_SEL_RX		0x00
+#define E1000_I210_FIFO_SEL_TX_QAV(_i)	(0x02 + (_i))
+#define E1000_I210_FIFO_SEL_TX_LEGACY	E1000_I210_FIFO_SEL_TX_QAV(0)
+#define E1000_I210_FIFO_SEL_BMC2OS_TX	0x06
+#define E1000_I210_FIFO_SEL_BMC2OS_RX	0x01
+
+#define E1000_I210_FLASH_SECTOR_SIZE	0x1000 /* 4KB FLASH sector unit size */
+/* Secure FLASH mode requires removing MSb */
+#define E1000_I210_FW_PTR_MASK		0x7FFF
+/* Firmware code revision field word offset*/
+#define E1000_I210_FW_VER_OFFSET	328
 
-#define E1000_NVM_SWDPIN0	0x0001 /* SWDPIN 0 NVM Value */
-#define E1000_NVM_LED_LOGIC	0x0020 /* Led Logic Word */
 #define E1000_NVM_RW_REG_DATA	16  /* Offset to data in NVM read/write regs */
 #define E1000_NVM_RW_REG_DONE	2   /* Offset to READ/WRITE done bit */
 #define E1000_NVM_RW_REG_START	1   /* Start operation */
@@ -1358,18 +1015,30 @@
 /* NVM Word Offsets */
 #define NVM_COMPAT			0x0003
 #define NVM_ID_LED_SETTINGS		0x0004
-#define NVM_VERSION			0x0005
 #define NVM_SERDES_AMPLITUDE		0x0006 /* SERDES output amplitude */
 #define NVM_PHY_CLASS_WORD		0x0007
-#define NVM_INIT_CONTROL1_REG		0x000A
+#define E1000_I210_NVM_FW_MODULE_PTR	0x0010
+#define E1000_I350_NVM_FW_MODULE_PTR	0x0051
+#define NVM_FUTURE_INIT_WORD1		0x0019
+#define NVM_MAC_ADDR			0x0000
+#define NVM_SUB_DEV_ID			0x000B
+#define NVM_SUB_VEN_ID			0x000C
+#define NVM_DEV_ID			0x000D
+#define NVM_VEN_ID			0x000E
+#define NVM_INIT_CTRL_2			0x000F
+#define NVM_INIT_CTRL_4			0x0013
+#define NVM_LED_1_CFG			0x001C
+#define NVM_LED_0_2_CFG			0x001F
+
+#define NVM_COMPAT_VALID_CSUM		0x0001
+#define NVM_FUTURE_INIT_WORD1_VALID_CSUM	0x0040
+
 #define NVM_INIT_CONTROL2_REG		0x000F
-#define NVM_SWDEF_PINS_CTRL_PORT_1	0x0010
 #define NVM_INIT_CONTROL3_PORT_B	0x0014
 #define NVM_INIT_3GIO_3			0x001A
 #define NVM_SWDEF_PINS_CTRL_PORT_0	0x0020
 #define NVM_INIT_CONTROL3_PORT_A	0x0024
 #define NVM_CFG				0x0012
-#define NVM_FLASH_VERSION		0x0032
 #define NVM_ALT_MAC_ADDR_PTR		0x0037
 #define NVM_CHECKSUM_REG		0x003F
 #define NVM_COMPATIBILITY_REG_3		0x0003
@@ -1380,12 +1049,12 @@
 #define E1000_NVM_CFG_DONE_PORT_2	0x100000 /* ...for third port */
 #define E1000_NVM_CFG_DONE_PORT_3	0x200000 /* ...for fourth port */
 
-#define NVM_82580_LAN_FUNC_OFFSET(a)	(a ? (0x40 + (0x40 * a)) : 0)
+#define NVM_82580_LAN_FUNC_OFFSET(a)	((a) ? (0x40 + (0x40 * (a))) : 0)
 
 /* Mask bits for fields in Word 0x24 of the NVM */
 #define NVM_WORD24_COM_MDIO		0x0008 /* MDIO interface shared */
 #define NVM_WORD24_EXT_MDIO		0x0004 /* MDIO accesses routed extrnl */
-/* Offset of Link Mode bits for 82575 up to Kawela */
+/* Offset of Link Mode bits for 82575/82576 */
 #define NVM_WORD24_LNK_MODE_OFFSET	8
 /* Offset of Link Mode bits for 82580 up */
 #define NVM_WORD24_82580_LNK_MODE_OFFSET	4
@@ -1395,9 +1064,7 @@
 #define NVM_WORD0F_PAUSE_MASK		0x3000
 #define NVM_WORD0F_PAUSE		0x1000
 #define NVM_WORD0F_ASM_DIR		0x2000
-#define NVM_WORD0F_ANE			0x0800
 #define NVM_WORD0F_SWPDIO_EXT_MASK	0x00F0
-#define NVM_WORD0F_LPLU			0x0001
 
 /* Mask bits for fields in Word 0x1a of the NVM */
 #define NVM_WORD1A_ASPM_MASK		0x000C
@@ -1411,7 +1078,7 @@
 /* For checksumming, the sum of all words in the NVM should equal 0xBABA. */
 #define NVM_SUM				0xBABA
 
-#define NVM_MAC_ADDR_OFFSET		0
+/* PBA (printed board assembly) number words */
 #define NVM_PBA_OFFSET_0		8
 #define NVM_PBA_OFFSET_1		9
 #define NVM_PBA_PTR_GUARD		0xFAFA
@@ -1436,16 +1103,10 @@
 #define NVM_WRITE_OPCODE_SPI	0x02 /* NVM write opcode */
 #define NVM_A8_OPCODE_SPI	0x08 /* opcode bit-3 = address bit-8 */
 #define NVM_WREN_OPCODE_SPI	0x06 /* NVM set Write Enable latch */
-#define NVM_WRDI_OPCODE_SPI	0x04 /* NVM reset Write Enable latch */
 #define NVM_RDSR_OPCODE_SPI	0x05 /* NVM read Status register */
-#define NVM_WRSR_OPCODE_SPI	0x01 /* NVM write Status register */
 
 /* SPI NVM Status Register */
 #define NVM_STATUS_RDY_SPI	0x01
-#define NVM_STATUS_WEN_SPI	0x02
-#define NVM_STATUS_BP0_SPI	0x04
-#define NVM_STATUS_BP1_SPI	0x08
-#define NVM_STATUS_WPEN_SPI	0x80
 
 /* Word definitions for ID LED Settings */
 #define ID_LED_RESERVED_0000	0x0000
@@ -1499,8 +1160,7 @@
 #define MAX_PHY_REG_ADDRESS		0x1F  /* 5 bit address bus (0-0x1F) */
 #define MAX_PHY_MULTI_PAGE_REG		0xF
 
-/* Bit definitions for valid PHY IDs. */
-/*
+/* Bit definitions for valid PHY IDs.
  * I = Integrated
  * E = External
  */
@@ -1508,7 +1168,6 @@
 #define M88E1000_I_PHY_ID	0x01410C30
 #define M88E1011_I_PHY_ID	0x01410C20
 #define IGP01E1000_I_PHY_ID	0x02A80380
-#define M88E1011_I_REV_4	0x04
 #define M88E1111_I_PHY_ID	0x01410CC0
 #define M88E1112_E_PHY_ID	0x01410C90
 #define I347AT4_E_PHY_ID	0x01410DC0
@@ -1523,16 +1182,16 @@
 #define I82577_E_PHY_ID		0x01540050
 #define I82578_E_PHY_ID		0x004DD040
 #define I82579_E_PHY_ID		0x01540090
+#define I217_E_PHY_ID		0x015400A0
 #define I82580_I_PHY_ID		0x015403A0
 #define I350_I_PHY_ID		0x015403B0
+#define I210_I_PHY_ID		0x01410C00
 #define IGP04E1000_E_PHY_ID	0x02A80391
 #define M88_VENDOR		0x0141
 
 /* M88E1000 Specific Registers */
 #define M88E1000_PHY_SPEC_CTRL		0x10  /* PHY Specific Control Reg */
 #define M88E1000_PHY_SPEC_STATUS	0x11  /* PHY Specific Status Reg */
-#define M88E1000_INT_ENABLE		0x12  /* Interrupt Enable Reg */
-#define M88E1000_INT_STATUS		0x13  /* Interrupt Status Reg */
 #define M88E1000_EXT_PHY_SPEC_CTRL	0x14  /* Extended PHY Specific Cntrl */
 #define M88E1000_RX_ERR_CNTR		0x15  /* Receive Error Counter */
 
@@ -1543,11 +1202,7 @@
 #define M88E1000_PHY_VCO_REG_BIT11	0x800 /* improved BER performance */
 
 /* M88E1000 PHY Specific Control Register */
-#define M88E1000_PSCR_JABBER_DISABLE	0x0001 /* 1=Jabber Function disabled */
 #define M88E1000_PSCR_POLARITY_REVERSAL	0x0002 /* 1=Polarity Reverse enabled */
-#define M88E1000_PSCR_SQE_TEST		0x0004 /* 1=SQE Test enabled */
-/* 1=CLK125 low, 0=CLK125 toggling */
-#define M88E1000_PSCR_CLK125_DISABLE	0x0010
 /* MDI Crossover Mode bits 6:5 Manual MDI configuration */
 #define M88E1000_PSCR_MDI_MANUAL_MODE	0x0000
 #define M88E1000_PSCR_MDIX_MANUAL_MODE	0x0020  /* Manual MDIX configuration */
@@ -1555,24 +1210,13 @@
 #define M88E1000_PSCR_AUTO_X_1000T	0x0040
 /* Auto crossover enabled all speeds */
 #define M88E1000_PSCR_AUTO_X_MODE	0x0060
-/*
- * 1=Enable Extended 10BASE-T distance (Lower 10BASE-T Rx Threshold
- * 0=Normal 10BASE-T Rx Threshold
- */
-#define M88E1000_PSCR_EN_10BT_EXT_DIST	0x0080
-/* 1=5-bit interface in 100BASE-TX, 0=MII interface in 100BASE-TX */
-#define M88E1000_PSCR_MII_5BIT_ENABLE	0x0100
-#define M88E1000_PSCR_SCRAMBLER_DISABLE	0x0200 /* 1=Scrambler disable */
-#define M88E1000_PSCR_FORCE_LINK_GOOD	0x0400 /* 1=Force link good */
 #define M88E1000_PSCR_ASSERT_CRS_ON_TX	0x0800 /* 1=Assert CRS on Tx */
 
 /* M88E1000 PHY Specific Status Register */
-#define M88E1000_PSSR_JABBER		0x0001 /* 1=Jabber */
 #define M88E1000_PSSR_REV_POLARITY	0x0002 /* 1=Polarity reversed */
 #define M88E1000_PSSR_DOWNSHIFT		0x0020 /* 1=Downshifted */
 #define M88E1000_PSSR_MDIX		0x0040 /* 1=MDIX; 0=MDI */
-/*
- * 0 = <50M
+/* 0 = <50M
  * 1 = 50-80M
  * 2 = 80-110M
  * 3 = 110-140M
@@ -1581,64 +1225,33 @@
 #define M88E1000_PSSR_CABLE_LENGTH	0x0380
 #define M88E1000_PSSR_LINK		0x0400 /* 1=Link up, 0=Link down */
 #define M88E1000_PSSR_SPD_DPLX_RESOLVED	0x0800 /* 1=Speed & Duplex resolved */
-#define M88E1000_PSSR_PAGE_RCVD		0x1000 /* 1=Page received */
 #define M88E1000_PSSR_DPLX		0x2000 /* 1=Duplex 0=Half Duplex */
 #define M88E1000_PSSR_SPEED		0xC000 /* Speed, bits 14:15 */
-#define M88E1000_PSSR_10MBS		0x0000 /* 00=10Mbs */
 #define M88E1000_PSSR_100MBS		0x4000 /* 01=100Mbs */
 #define M88E1000_PSSR_1000MBS		0x8000 /* 10=1000Mbs */
 
 #define M88E1000_PSSR_CABLE_LENGTH_SHIFT	7
 
-/* M88E1000 Extended PHY Specific Control Register */
-#define M88E1000_EPSCR_FIBER_LOOPBACK	0x4000 /* 1=Fiber loopback */
-/*
- * 1 = Lost lock detect enabled.
- * Will assert lost lock and bring
- * link down if idle not seen
- * within 1ms in 1000BASE-T
- */
-#define M88E1000_EPSCR_DOWN_NO_IDLE	0x8000
-/*
- * Number of times we will attempt to autonegotiate before downshifting if we
+/* Number of times we will attempt to autonegotiate before downshifting if we
  * are the master
  */
 #define M88E1000_EPSCR_MASTER_DOWNSHIFT_MASK	0x0C00
 #define M88E1000_EPSCR_MASTER_DOWNSHIFT_1X	0x0000
-#define M88E1000_EPSCR_MASTER_DOWNSHIFT_2X	0x0400
-#define M88E1000_EPSCR_MASTER_DOWNSHIFT_3X	0x0800
-#define M88E1000_EPSCR_MASTER_DOWNSHIFT_4X	0x0C00
-/*
- * Number of times we will attempt to autonegotiate before downshifting if we
+/* Number of times we will attempt to autonegotiate before downshifting if we
  * are the slave
  */
 #define M88E1000_EPSCR_SLAVE_DOWNSHIFT_MASK	0x0300
-#define M88E1000_EPSCR_SLAVE_DOWNSHIFT_DIS	0x0000
 #define M88E1000_EPSCR_SLAVE_DOWNSHIFT_1X	0x0100
-#define M88E1000_EPSCR_SLAVE_DOWNSHIFT_2X	0x0200
-#define M88E1000_EPSCR_SLAVE_DOWNSHIFT_3X	0x0300
-#define M88E1000_EPSCR_TX_CLK_2_5	0x0060 /* 2.5 MHz TX_CLK */
 #define M88E1000_EPSCR_TX_CLK_25	0x0070 /* 25  MHz TX_CLK */
-#define M88E1000_EPSCR_TX_CLK_0		0x0000 /* NO  TX_CLK */
-
-/* M88E1111 Specific Registers */
-#define M88E1111_PHY_PAGE_SELECT1	0x16  /* for registers 0-28 */
-#define M88E1111_PHY_PAGE_SELECT2	0x1D  /* for registers 30-31 */
-
-/* M88E1111 page select register mask */
-#define M88E1111_PHY_PAGE_SELECT_MASK1	0xFF
-#define M88E1111_PHY_PAGE_SELECT_MASK2	0x3F
 
 /* Intel I347AT4 Registers */
-
 #define I347AT4_PCDL		0x10 /* PHY Cable Diagnostics Length */
 #define I347AT4_PCDC		0x15 /* PHY Cable Diagnostics Control */
 #define I347AT4_PAGE_SELECT	0x16
 
 /* I347AT4 Extended PHY Specific Control Register */
 
-/*
- * Number of times we will attempt to autonegotiate before downshifting if we
+/* Number of times we will attempt to autonegotiate before downshifting if we
  * are the master
  */
 #define I347AT4_PSCR_DOWNSHIFT_ENABLE	0x0800
@@ -1660,14 +1273,7 @@
 
 /* M88EC018 Rev 2 specific DownShift settings */
 #define M88EC018_EPSCR_DOWNSHIFT_COUNTER_MASK	0x0E00
-#define M88EC018_EPSCR_DOWNSHIFT_COUNTER_1X	0x0000
-#define M88EC018_EPSCR_DOWNSHIFT_COUNTER_2X	0x0200
-#define M88EC018_EPSCR_DOWNSHIFT_COUNTER_3X	0x0400
-#define M88EC018_EPSCR_DOWNSHIFT_COUNTER_4X	0x0600
 #define M88EC018_EPSCR_DOWNSHIFT_COUNTER_5X	0x0800
-#define M88EC018_EPSCR_DOWNSHIFT_COUNTER_6X	0x0A00
-#define M88EC018_EPSCR_DOWNSHIFT_COUNTER_7X	0x0C00
-#define M88EC018_EPSCR_DOWNSHIFT_COUNTER_8X	0x0E00
 
 #define I82578_EPSCR_DOWNSHIFT_ENABLE		0x0020
 #define I82578_EPSCR_DOWNSHIFT_COUNTER_MASK	0x001C
@@ -1675,8 +1281,7 @@
 /* BME1000 PHY Specific Control Register */
 #define BME1000_PSCR_ENABLE_DOWNSHIFT	0x0800 /* 1 = enable downshift */
 
-/*
- * Bits...
+/* Bits...
  * 15-5: page
  * 4-0: register offset
  */
@@ -1687,49 +1292,24 @@
 
 /* GG82563 Specific Registers */
 #define GG82563_PHY_SPEC_CTRL		GG82563_REG(0, 16) /* PHY Spec Cntrl */
-#define GG82563_PHY_SPEC_STATUS		GG82563_REG(0, 17) /* PHY Spec Status */
-#define GG82563_PHY_INT_ENABLE		GG82563_REG(0, 18) /* Interrupt Ena */
-#define GG82563_PHY_SPEC_STATUS_2	GG82563_REG(0, 19) /* PHY Spec Stat2 */
-#define GG82563_PHY_RX_ERR_CNTR		GG82563_REG(0, 21) /* Rx Err Counter */
 #define GG82563_PHY_PAGE_SELECT		GG82563_REG(0, 22) /* Page Select */
 #define GG82563_PHY_SPEC_CTRL_2		GG82563_REG(0, 26) /* PHY Spec Cntrl2 */
 #define GG82563_PHY_PAGE_SELECT_ALT	GG82563_REG(0, 29) /* Alt Page Select */
-/* Test Clock Control (use reg. 29 to select) */
-#define GG82563_PHY_TEST_CLK_CTRL	GG82563_REG(0, 30)
 
 /* MAC Specific Control Register */
 #define GG82563_PHY_MAC_SPEC_CTRL	GG82563_REG(2, 21)
-#define GG82563_PHY_MAC_SPEC_CTRL_2	GG82563_REG(2, 26) /* MAC Spec Ctrl 2 */
 
 #define GG82563_PHY_DSP_DISTANCE	GG82563_REG(5, 26) /* DSP Distance */
 
 /* Page 193 - Port Control Registers */
 /* Kumeran Mode Control */
 #define GG82563_PHY_KMRN_MODE_CTRL	GG82563_REG(193, 16)
-#define GG82563_PHY_PORT_RESET		GG82563_REG(193, 17) /* Port Reset */
-#define GG82563_PHY_REVISION_ID		GG82563_REG(193, 18) /* Revision ID */
-#define GG82563_PHY_DEVICE_ID		GG82563_REG(193, 19) /* Device ID */
 #define GG82563_PHY_PWR_MGMT_CTRL	GG82563_REG(193, 20) /* Pwr Mgt Ctrl */
-/* Rate Adaptation Control */
-#define GG82563_PHY_RATE_ADAPT_CTRL	GG82563_REG(193, 25)
 
 /* Page 194 - KMRN Registers */
-/* FIFO's Control/Status */
-#define GG82563_PHY_KMRN_FIFO_CTRL_STAT	GG82563_REG(194, 16)
-#define GG82563_PHY_KMRN_CTRL		GG82563_REG(194, 17) /* Control */
 #define GG82563_PHY_INBAND_CTRL		GG82563_REG(194, 18) /* Inband Ctrl */
-#define GG82563_PHY_KMRN_DIAGNOSTIC	GG82563_REG(194, 19) /* Diagnostic */
-#define GG82563_PHY_ACK_TIMEOUTS	GG82563_REG(194, 20) /* Ack Timeouts */
-#define GG82563_PHY_ADV_ABILITY		GG82563_REG(194, 21) /* Adver Ability */
-/* Link Partner Advertised Ability */
-#define GG82563_PHY_LINK_PARTNER_ADV_ABILITY	GG82563_REG(194, 23)
-#define GG82563_PHY_ADV_NEXT_PAGE	GG82563_REG(194, 24) /* Adver Next Pg */
-/* Link Partner Advertised Next page */
-#define GG82563_PHY_LINK_PARTNER_ADV_NEXT_PAGE	GG82563_REG(194, 25)
-#define GG82563_PHY_KMRN_MISC		GG82563_REG(194, 26) /* Misc. */
 
 /* MDI Control */
-#define E1000_MDIC_DATA_MASK	0x0000FFFF
 #define E1000_MDIC_REG_MASK	0x001F0000
 #define E1000_MDIC_REG_SHIFT	16
 #define E1000_MDIC_PHY_MASK	0x03E00000
@@ -1737,7 +1317,6 @@
 #define E1000_MDIC_OP_WRITE	0x04000000
 #define E1000_MDIC_OP_READ	0x08000000
 #define E1000_MDIC_READY	0x10000000
-#define E1000_MDIC_INT_EN	0x20000000
 #define E1000_MDIC_ERROR	0x40000000
 #define E1000_MDIC_DEST		0x80000000
 
@@ -1787,6 +1366,8 @@
 #define E1000_DMACR_DMAC_LX_MASK	0x30000000
 #define E1000_DMACR_DMAC_LX_SHIFT	28
 #define E1000_DMACR_DMAC_EN		0x80000000 /* Enable DMA Coalescing */
+/* DMA Coalescing BMC-to-OS Watchdog Enable */
+#define E1000_DMACR_DC_BMC2OSW_EN	0x00008000
 
 /* DMA Coalescing Transmit Threshold */
 #define E1000_DMCTXTH_DMCTTHR_MASK	0x00000FFF
@@ -1807,35 +1388,13 @@
 /* Lx power decision based on DMA coal */
 #define E1000_PCIEMISC_LX_DECISION	0x00000080
 
-#define E1000_LTRC_EEEMS_EN		0x00000005 /* Enable EEE LTR max send */
+#define E1000_RXPBS_CFG_TS_EN		0x80000000 /* Timestamp in Rx buffer */
 #define E1000_RXPBS_SIZE_I210_MASK	0x0000003F /* Rx packet buffer size */
-/* Minimum time for 1000BASE-T where no data will be transmit following move out
- * of EEE LPI Tx state
- */
-#define E1000_TW_SYSTEM_1000_MASK	0x000000FF
-/* Minimum time for 100BASE-T where no data will be transmit following move out
- * of EEE LPI Tx state
- */
-#define E1000_TW_SYSTEM_100_MASK	0x0000FF00
-#define E1000_TW_SYSTEM_100_SHIFT	8
-#define E1000_LTRMINV_LTRV_MASK		0x000003FF /* LTR minimum value */
-#define E1000_LTRMAXV_LTRV_MASK		0x000003FF /* LTR maximum value */
-#define E1000_LTRMINV_SCALE_MASK	0x00001C00 /* LTR minimum scale */
-#define E1000_LTRMINV_SCALE_SHIFT	10
-/* Reg val to set scale to 1024 nsec */
-#define E1000_LTRMINV_SCALE_1024	2
-/* Reg val to set scale to 32768 nsec */
-#define E1000_LTRMINV_SCALE_32768	3
-#define E1000_LTRMAXV_SCALE_MASK	0x00001C00 /* LTR maximum scale */
-#define E1000_LTRMAXV_SCALE_SHIFT	10
-/* Reg val to set scale to 1024 nsec */
-#define E1000_LTRMAXV_SCALE_1024	2
-/* Reg val to set scale to 32768 nsec */
-#define E1000_LTRMAXV_SCALE_32768	3
+#define E1000_TXPB0S_SIZE_I210_MASK	0x0000003F /* Tx packet buffer 0 size */
 #define E1000_DOBFFCTL_OBFFTHR_MASK	0x000000FF /* OBFF threshold */
 #define E1000_DOBFFCTL_EXIT_ACT_MASK	0x01000000 /* Exit active CB */
 
-/* Proxy Filer Control */
+/* Proxy Filter Control */
 #define E1000_PROXYFC_D0		0x00000001 /* Enable offload in D0 */
 #define E1000_PROXYFC_EX		0x00000004 /* Directed exact proxy */
 #define E1000_PROXYFC_MC		0x00000008 /* Directed MC Proxy */
@@ -1843,7 +1402,7 @@
 #define E1000_PROXYFC_ARP_DIRECTED	0x00000020 /* Directed ARP Proxy Ena */
 #define E1000_PROXYFC_IPV4		0x00000040 /* Directed IPv4 Enable */
 #define E1000_PROXYFC_IPV6		0x00000080 /* Directed IPv6 Enable */
-#define E1000_PROXYFC_NS		0x00000200 /* IPv4 NBRHD Solicitation */
+#define E1000_PROXYFC_NS		0x00000200 /* IPv6 Neighbor Solicitation */
 #define E1000_PROXYFC_ARP		0x00000800 /* ARP Request Proxy Ena */
 /* Proxy Status */
 #define E1000_PROXYS_CLEAR		0xFFFFFFFF /* Clear */
diff --git a/sys/dev/e1000/e1000_hw.h b/sys/dev/e1000/e1000_hw.h
index 16cfa8f..e8a8c17 100644
--- a/sys/dev/e1000/e1000_hw.h
+++ b/sys/dev/e1000/e1000_hw.h
@@ -1,6 +1,6 @@
 /******************************************************************************
 
-  Copyright (c) 2001-2011, Intel Corporation 
+  Copyright (c) 2001-2013, Intel Corporation 
   All rights reserved.
   
   Redistribution and use in source and binary forms, with or without 
@@ -123,13 +123,16 @@ struct e1000_hw;
 #define E1000_DEV_ID_ICH10_D_BM_LM		0x10DE
 #define E1000_DEV_ID_ICH10_D_BM_LF		0x10DF
 #define E1000_DEV_ID_ICH10_D_BM_V		0x1525
-
 #define E1000_DEV_ID_PCH_M_HV_LM		0x10EA
 #define E1000_DEV_ID_PCH_M_HV_LC		0x10EB
 #define E1000_DEV_ID_PCH_D_HV_DM		0x10EF
 #define E1000_DEV_ID_PCH_D_HV_DC		0x10F0
 #define E1000_DEV_ID_PCH2_LV_LM			0x1502
 #define E1000_DEV_ID_PCH2_LV_V			0x1503
+#define E1000_DEV_ID_PCH_LPT_I217_LM		0x153A
+#define E1000_DEV_ID_PCH_LPT_I217_V		0x153B
+#define E1000_DEV_ID_PCH_LPTLP_I218_LM		0x155A
+#define E1000_DEV_ID_PCH_LPTLP_I218_V		0x1559
 #define E1000_DEV_ID_82576			0x10C9
 #define E1000_DEV_ID_82576_FIBER		0x10E6
 #define E1000_DEV_ID_82576_SERDES		0x10E7
@@ -139,7 +142,9 @@ struct e1000_hw;
 #define E1000_DEV_ID_82576_NS_SERDES		0x1518
 #define E1000_DEV_ID_82576_SERDES_QUAD		0x150D
 #define E1000_DEV_ID_82576_VF			0x10CA
+#define E1000_DEV_ID_82576_VF_HV		0x152D
 #define E1000_DEV_ID_I350_VF			0x1520
+#define E1000_DEV_ID_I350_VF_HV			0x152F
 #define E1000_DEV_ID_82575EB_COPPER		0x10A7
 #define E1000_DEV_ID_82575EB_FIBER_SERDES	0x10A9
 #define E1000_DEV_ID_82575GB_QUAD_COPPER	0x10D6
@@ -154,10 +159,18 @@ struct e1000_hw;
 #define E1000_DEV_ID_I350_SERDES		0x1523
 #define E1000_DEV_ID_I350_SGMII			0x1524
 #define E1000_DEV_ID_I350_DA4			0x1546
+#define E1000_DEV_ID_I210_COPPER		0x1533
+#define E1000_DEV_ID_I210_COPPER_OEM1		0x1534
+#define E1000_DEV_ID_I210_COPPER_IT		0x1535
+#define E1000_DEV_ID_I210_FIBER			0x1536
+#define E1000_DEV_ID_I210_SERDES		0x1537
+#define E1000_DEV_ID_I210_SGMII			0x1538
+#define E1000_DEV_ID_I211_COPPER		0x1539
 #define E1000_DEV_ID_DH89XXCC_SGMII		0x0438
 #define E1000_DEV_ID_DH89XXCC_SERDES		0x043A
 #define E1000_DEV_ID_DH89XXCC_BACKPLANE		0x043C
 #define E1000_DEV_ID_DH89XXCC_SFP		0x0440
+
 #define E1000_REVISION_0	0
 #define E1000_REVISION_1	1
 #define E1000_REVISION_2	2
@@ -199,10 +212,13 @@ enum e1000_mac_type {
 	e1000_ich10lan,
 	e1000_pchlan,
 	e1000_pch2lan,
+	e1000_pch_lpt,
 	e1000_82575,
 	e1000_82576,
 	e1000_82580,
 	e1000_i350,
+	e1000_i210,
+	e1000_i211,
 	e1000_vfadapt,
 	e1000_vfadapt_i350,
 	e1000_num_macs  /* List is 1-based, so subtract 1 for TRUE count. */
@@ -246,8 +262,10 @@ enum e1000_phy_type {
 	e1000_phy_82578,
 	e1000_phy_82577,
 	e1000_phy_82579,
+	e1000_phy_i217,
 	e1000_phy_82580,
 	e1000_phy_vf,
+	e1000_phy_i210,
 };
 
 enum e1000_bus_type {
@@ -641,13 +659,13 @@ struct e1000_host_mng_command_info {
 #include "e1000_manage.h"
 #include "e1000_mbx.h"
 
+/* Function pointers for the MAC. */
 struct e1000_mac_operations {
-	/* Function pointers for the MAC. */
 	s32  (*init_params)(struct e1000_hw *);
 	s32  (*id_led_init)(struct e1000_hw *);
 	s32  (*blink_led)(struct e1000_hw *);
+	bool (*check_mng_mode)(struct e1000_hw *);
 	s32  (*check_for_link)(struct e1000_hw *);
-	bool (*check_mng_mode)(struct e1000_hw *hw);
 	s32  (*cleanup_led)(struct e1000_hw *);
 	void (*clear_hw_cntrs)(struct e1000_hw *);
 	void (*clear_vfta)(struct e1000_hw *);
@@ -669,15 +687,12 @@ struct e1000_mac_operations {
 	void (*rar_set)(struct e1000_hw *, u8*, u32);
 	s32  (*read_mac_addr)(struct e1000_hw *);
 	s32  (*validate_mdi_setting)(struct e1000_hw *);
-	s32  (*mng_host_if_write)(struct e1000_hw *, u8*, u16, u16, u8*);
-	s32  (*mng_write_cmd_header)(struct e1000_hw *hw,
-				     struct e1000_host_mng_command_header*);
-	s32  (*mng_enable_host_if)(struct e1000_hw *);
-	s32  (*wait_autoneg)(struct e1000_hw *);
+	s32  (*set_obff_timer)(struct e1000_hw *, u32);
+	s32  (*acquire_swfw_sync)(struct e1000_hw *, u16);
+	void (*release_swfw_sync)(struct e1000_hw *, u16);
 };
 
-/*
- * When to use various PHY register access functions:
+/* When to use various PHY register access functions:
  *
  *                 Func   Caller
  *   Function      Does   Does    When to use
@@ -719,6 +734,7 @@ struct e1000_phy_operations {
 	s32 (*write_i2c_byte)(struct e1000_hw *, u8, u8, u8);
 };
 
+/* Function pointers for the NVM. */
 struct e1000_nvm_operations {
 	s32  (*init_params)(struct e1000_hw *);
 	s32  (*acquire)(struct e1000_hw *);
@@ -773,6 +789,7 @@ struct e1000_mac_info {
 	enum e1000_serdes_link_state serdes_link_state;
 	bool serdes_has_link;
 	bool tx_pkt_filtering;
+	u32 max_frame_size;
 };
 
 struct e1000_phy_info {
@@ -903,7 +920,7 @@ struct e1000_shadow_ram {
 	bool modified;
 };
 
-#define E1000_SHADOW_RAM_WORDS  2048
+#define E1000_SHADOW_RAM_WORDS		2048
 
 struct e1000_dev_spec_ich8lan {
 	bool kmrn_lock_loss_workaround_enabled;
@@ -911,15 +928,18 @@ struct e1000_dev_spec_ich8lan {
 	E1000_MUTEX nvm_mutex;
 	E1000_MUTEX swflag_mutex;
 	bool nvm_k1_enabled;
-	int eee_disable;
+	bool eee_disable;
+	u16 eee_lp_ability;
 };
 
 struct e1000_dev_spec_82575 {
 	bool sgmii_active;
 	bool global_device_reset;
-	int eee_disable;
+	bool eee_disable;
 	bool module_plugged;
+	bool clear_semaphore_once;
 	u32 mtu;
+	struct sfp_e1000_flags eth_flags;
 };
 
 struct e1000_dev_spec_vf {
@@ -967,6 +987,7 @@ struct e1000_hw {
 #include "e1000_80003es2lan.h"
 #include "e1000_ich8lan.h"
 #include "e1000_82575.h"
+#include "e1000_i210.h"
 
 /* These functions must be implemented by drivers */
 void e1000_pci_clear_mwi(struct e1000_hw *hw);
diff --git a/sys/dev/e1000/e1000_i210.c b/sys/dev/e1000/e1000_i210.c
new file mode 100644
index 0000000..63302c0
--- /dev/null
+++ b/sys/dev/e1000/e1000_i210.c
@@ -0,0 +1,754 @@
+/******************************************************************************
+
+  Copyright (c) 2001-2013, Intel Corporation 
+  All rights reserved.
+  
+  Redistribution and use in source and binary forms, with or without 
+  modification, are permitted provided that the following conditions are met:
+  
+   1. Redistributions of source code must retain the above copyright notice, 
+      this list of conditions and the following disclaimer.
+  
+   2. Redistributions in binary form must reproduce the above copyright 
+      notice, this list of conditions and the following disclaimer in the 
+      documentation and/or other materials provided with the distribution.
+  
+   3. Neither the name of the Intel Corporation nor the names of its 
+      contributors may be used to endorse or promote products derived from 
+      this software without specific prior written permission.
+  
+  THIS SOFTWARE IS PROVIDED BY THE COPYRIGHT HOLDERS AND CONTRIBUTORS "AS IS"
+  AND ANY EXPRESS OR IMPLIED WARRANTIES, INCLUDING, BUT NOT LIMITED TO, THE 
+  IMPLIED WARRANTIES OF MERCHANTABILITY AND FITNESS FOR A PARTICULAR PURPOSE 
+  ARE DISCLAIMED. IN NO EVENT SHALL THE COPYRIGHT OWNER OR CONTRIBUTORS BE 
+  LIABLE FOR ANY DIRECT, INDIRECT, INCIDENTAL, SPECIAL, EXEMPLARY, OR 
+  CONSEQUENTIAL DAMAGES (INCLUDING, BUT NOT LIMITED TO, PROCUREMENT OF 
+  SUBSTITUTE GOODS OR SERVICES; LOSS OF USE, DATA, OR PROFITS; OR BUSINESS 
+  INTERRUPTION) HOWEVER CAUSED AND ON ANY THEORY OF LIABILITY, WHETHER IN 
+  CONTRACT, STRICT LIABILITY, OR TORT (INCLUDING NEGLIGENCE OR OTHERWISE) 
+  ARISING IN ANY WAY OUT OF THE USE OF THIS SOFTWARE, EVEN IF ADVISED OF THE
+  POSSIBILITY OF SUCH DAMAGE.
+
+******************************************************************************/
+/*$FreeBSD$*/
+
+#include "e1000_api.h"
+
+
+static s32 e1000_acquire_nvm_i210(struct e1000_hw *hw);
+static void e1000_release_nvm_i210(struct e1000_hw *hw);
+static s32 e1000_get_hw_semaphore_i210(struct e1000_hw *hw);
+static s32 e1000_write_nvm_srwr(struct e1000_hw *hw, u16 offset, u16 words,
+				u16 *data);
+static s32 e1000_pool_flash_update_done_i210(struct e1000_hw *hw);
+static s32 e1000_valid_led_default_i210(struct e1000_hw *hw, u16 *data);
+static s32 e1000_read_nvm_i211(struct e1000_hw *hw, u16 offset, u16 words,
+			       u16 *data);
+
+/**
+ *  e1000_acquire_nvm_i210 - Request for access to EEPROM
+ *  @hw: pointer to the HW structure
+ *
+ *  Acquire the necessary semaphores for exclusive access to the EEPROM.
+ *  Set the EEPROM access request bit and wait for EEPROM access grant bit.
+ *  Return successful if access grant bit set, else clear the request for
+ *  EEPROM access and return -E1000_ERR_NVM (-1).
+ **/
+static s32 e1000_acquire_nvm_i210(struct e1000_hw *hw)
+{
+	s32 ret_val;
+
+	DEBUGFUNC("e1000_acquire_nvm_i210");
+
+	ret_val = e1000_acquire_swfw_sync_i210(hw, E1000_SWFW_EEP_SM);
+
+	return ret_val;
+}
+
+/**
+ *  e1000_release_nvm_i210 - Release exclusive access to EEPROM
+ *  @hw: pointer to the HW structure
+ *
+ *  Stop any current commands to the EEPROM and clear the EEPROM request bit,
+ *  then release the semaphores acquired.
+ **/
+static void e1000_release_nvm_i210(struct e1000_hw *hw)
+{
+	DEBUGFUNC("e1000_release_nvm_i210");
+
+	e1000_release_swfw_sync_i210(hw, E1000_SWFW_EEP_SM);
+}
+
+/**
+ *  e1000_acquire_swfw_sync_i210 - Acquire SW/FW semaphore
+ *  @hw: pointer to the HW structure
+ *  @mask: specifies which semaphore to acquire
+ *
+ *  Acquire the SW/FW semaphore to access the PHY or NVM.  The mask
+ *  will also specify which port we're acquiring the lock for.
+ **/
+s32 e1000_acquire_swfw_sync_i210(struct e1000_hw *hw, u16 mask)
+{
+	u32 swfw_sync;
+	u32 swmask = mask;
+	u32 fwmask = mask << 16;
+	s32 ret_val = E1000_SUCCESS;
+	s32 i = 0, timeout = 200; /* FIXME: find real value to use here */
+
+	DEBUGFUNC("e1000_acquire_swfw_sync_i210");
+
+	while (i < timeout) {
+		if (e1000_get_hw_semaphore_i210(hw)) {
+			ret_val = -E1000_ERR_SWFW_SYNC;
+			goto out;
+		}
+
+		swfw_sync = E1000_READ_REG(hw, E1000_SW_FW_SYNC);
+		if (!(swfw_sync & (fwmask | swmask)))
+			break;
+
+		/*
+		 * Firmware currently using resource (fwmask)
+		 * or other software thread using resource (swmask)
+		 */
+		e1000_put_hw_semaphore_generic(hw);
+		msec_delay_irq(5);
+		i++;
+	}
+
+	if (i == timeout) {
+		DEBUGOUT("Driver can't access resource, SW_FW_SYNC timeout.\n");
+		ret_val = -E1000_ERR_SWFW_SYNC;
+		goto out;
+	}
+
+	swfw_sync |= swmask;
+	E1000_WRITE_REG(hw, E1000_SW_FW_SYNC, swfw_sync);
+
+	e1000_put_hw_semaphore_generic(hw);
+
+out:
+	return ret_val;
+}
+
+/**
+ *  e1000_release_swfw_sync_i210 - Release SW/FW semaphore
+ *  @hw: pointer to the HW structure
+ *  @mask: specifies which semaphore to acquire
+ *
+ *  Release the SW/FW semaphore used to access the PHY or NVM.  The mask
+ *  will also specify which port we're releasing the lock for.
+ **/
+void e1000_release_swfw_sync_i210(struct e1000_hw *hw, u16 mask)
+{
+	u32 swfw_sync;
+
+	DEBUGFUNC("e1000_release_swfw_sync_i210");
+
+	while (e1000_get_hw_semaphore_i210(hw) != E1000_SUCCESS)
+		; /* Empty */
+
+	swfw_sync = E1000_READ_REG(hw, E1000_SW_FW_SYNC);
+	swfw_sync &= ~mask;
+	E1000_WRITE_REG(hw, E1000_SW_FW_SYNC, swfw_sync);
+
+	e1000_put_hw_semaphore_generic(hw);
+}
+
+/**
+ *  e1000_get_hw_semaphore_i210 - Acquire hardware semaphore
+ *  @hw: pointer to the HW structure
+ *
+ *  Acquire the HW semaphore to access the PHY or NVM
+ **/
+static s32 e1000_get_hw_semaphore_i210(struct e1000_hw *hw)
+{
+	u32 swsm;
+	s32 timeout = hw->nvm.word_size + 1;
+	s32 i = 0;
+
+	DEBUGFUNC("e1000_get_hw_semaphore_i210");
+
+	/* Get the SW semaphore */
+	while (i < timeout) {
+		swsm = E1000_READ_REG(hw, E1000_SWSM);
+		if (!(swsm & E1000_SWSM_SMBI))
+			break;
+
+		usec_delay(50);
+		i++;
+	}
+
+	if (i == timeout) {
+		/*
+		 * In rare circumstances, the driver may not have released the
+		 * SW semaphore. Clear the semaphore once before giving up.
+		 */
+		if (hw->dev_spec._82575.clear_semaphore_once) {
+			hw->dev_spec._82575.clear_semaphore_once = FALSE;
+			e1000_put_hw_semaphore_generic(hw);
+			for (i = 0; i < timeout; i++) {
+				swsm = E1000_READ_REG(hw, E1000_SWSM);
+				if (!(swsm & E1000_SWSM_SMBI))
+					break;
+
+				usec_delay(50);
+			}
+		}
+
+		/* If we do not have the semaphore here, we have to give up. */
+		if (i == timeout) {
+			DEBUGOUT("Driver can't access device - SMBI bit is set.\n");
+			return -E1000_ERR_NVM;
+		}
+	}
+
+	/* Get the FW semaphore. */
+	for (i = 0; i < timeout; i++) {
+		swsm = E1000_READ_REG(hw, E1000_SWSM);
+		E1000_WRITE_REG(hw, E1000_SWSM, swsm | E1000_SWSM_SWESMBI);
+
+		/* Semaphore acquired if bit latched */
+		if (E1000_READ_REG(hw, E1000_SWSM) & E1000_SWSM_SWESMBI)
+			break;
+
+		usec_delay(50);
+	}
+
+	if (i == timeout) {
+		/* Release semaphores */
+		e1000_put_hw_semaphore_generic(hw);
+		DEBUGOUT("Driver can't access the NVM\n");
+		return -E1000_ERR_NVM;
+	}
+
+	return E1000_SUCCESS;
+}
+
+/**
+ *  e1000_read_nvm_srrd_i210 - Reads Shadow Ram using EERD register
+ *  @hw: pointer to the HW structure
+ *  @offset: offset of word in the Shadow Ram to read
+ *  @words: number of words to read
+ *  @data: word read from the Shadow Ram
+ *
+ *  Reads a 16 bit word from the Shadow Ram using the EERD register.
+ *  Uses necessary synchronization semaphores.
+ **/
+s32 e1000_read_nvm_srrd_i210(struct e1000_hw *hw, u16 offset, u16 words,
+			     u16 *data)
+{
+	s32 status = E1000_SUCCESS;
+	u16 i, count;
+
+	DEBUGFUNC("e1000_read_nvm_srrd_i210");
+
+	/* We cannot hold synchronization semaphores for too long,
+	 * because of forceful takeover procedure. However it is more efficient
+	 * to read in bursts than synchronizing access for each word. */
+	for (i = 0; i < words; i += E1000_EERD_EEWR_MAX_COUNT) {
+		count = (words - i) / E1000_EERD_EEWR_MAX_COUNT > 0 ?
+			E1000_EERD_EEWR_MAX_COUNT : (words - i);
+		if (hw->nvm.ops.acquire(hw) == E1000_SUCCESS) {
+			status = e1000_read_nvm_eerd(hw, offset, count,
+						     data + i);
+			hw->nvm.ops.release(hw);
+		} else {
+			status = E1000_ERR_SWFW_SYNC;
+		}
+
+		if (status != E1000_SUCCESS)
+			break;
+	}
+
+	return status;
+}
+
+/**
+ *  e1000_write_nvm_srwr_i210 - Write to Shadow RAM using EEWR
+ *  @hw: pointer to the HW structure
+ *  @offset: offset within the Shadow RAM to be written to
+ *  @words: number of words to write
+ *  @data: 16 bit word(s) to be written to the Shadow RAM
+ *
+ *  Writes data to Shadow RAM at offset using EEWR register.
+ *
+ *  If e1000_update_nvm_checksum is not called after this function , the
+ *  data will not be committed to FLASH and also Shadow RAM will most likely
+ *  contain an invalid checksum.
+ *
+ *  If error code is returned, data and Shadow RAM may be inconsistent - buffer
+ *  partially written.
+ **/
+s32 e1000_write_nvm_srwr_i210(struct e1000_hw *hw, u16 offset, u16 words,
+			      u16 *data)
+{
+	s32 status = E1000_SUCCESS;
+	u16 i, count;
+
+	DEBUGFUNC("e1000_write_nvm_srwr_i210");
+
+	/* We cannot hold synchronization semaphores for too long,
+	 * because of forceful takeover procedure. However it is more efficient
+	 * to write in bursts than synchronizing access for each word. */
+	for (i = 0; i < words; i += E1000_EERD_EEWR_MAX_COUNT) {
+		count = (words - i) / E1000_EERD_EEWR_MAX_COUNT > 0 ?
+			E1000_EERD_EEWR_MAX_COUNT : (words - i);
+		if (hw->nvm.ops.acquire(hw) == E1000_SUCCESS) {
+			status = e1000_write_nvm_srwr(hw, offset, count,
+						      data + i);
+			hw->nvm.ops.release(hw);
+		} else {
+			status = E1000_ERR_SWFW_SYNC;
+		}
+
+		if (status != E1000_SUCCESS)
+			break;
+	}
+
+	return status;
+}
+
+/**
+ *  e1000_write_nvm_srwr - Write to Shadow Ram using EEWR
+ *  @hw: pointer to the HW structure
+ *  @offset: offset within the Shadow Ram to be written to
+ *  @words: number of words to write
+ *  @data: 16 bit word(s) to be written to the Shadow Ram
+ *
+ *  Writes data to Shadow Ram at offset using EEWR register.
+ *
+ *  If e1000_update_nvm_checksum is not called after this function , the
+ *  Shadow Ram will most likely contain an invalid checksum.
+ **/
+static s32 e1000_write_nvm_srwr(struct e1000_hw *hw, u16 offset, u16 words,
+				u16 *data)
+{
+	struct e1000_nvm_info *nvm = &hw->nvm;
+	u32 i, k, eewr = 0;
+	u32 attempts = 100000;
+	s32 ret_val = E1000_SUCCESS;
+
+	DEBUGFUNC("e1000_write_nvm_srwr");
+
+	/*
+	 * A check for invalid values:  offset too large, too many words,
+	 * too many words for the offset, and not enough words.
+	 */
+	if ((offset >= nvm->word_size) || (words > (nvm->word_size - offset)) ||
+	    (words == 0)) {
+		DEBUGOUT("nvm parameter(s) out of bounds\n");
+		ret_val = -E1000_ERR_NVM;
+		goto out;
+	}
+
+	for (i = 0; i < words; i++) {
+		eewr = ((offset+i) << E1000_NVM_RW_ADDR_SHIFT) |
+			(data[i] << E1000_NVM_RW_REG_DATA) |
+			E1000_NVM_RW_REG_START;
+
+		E1000_WRITE_REG(hw, E1000_SRWR, eewr);
+
+		for (k = 0; k < attempts; k++) {
+			if (E1000_NVM_RW_REG_DONE &
+			    E1000_READ_REG(hw, E1000_SRWR)) {
+				ret_val = E1000_SUCCESS;
+				break;
+			}
+			usec_delay(5);
+		}
+
+		if (ret_val != E1000_SUCCESS) {
+			DEBUGOUT("Shadow RAM write EEWR timed out\n");
+			break;
+		}
+	}
+
+out:
+	return ret_val;
+}
+
+/**
+ *  e1000_read_nvm_i211 - Read NVM wrapper function for I211
+ *  @hw: pointer to the HW structure
+ *  @address: the word address (aka eeprom offset) to read
+ *  @data: pointer to the data read
+ *
+ *  Wrapper function to return data formerly found in the NVM.
+ **/
+static s32 e1000_read_nvm_i211(struct e1000_hw *hw, u16 offset,
+			       u16 words, u16 *data)
+{
+	s32 ret_val = E1000_SUCCESS;
+
+	DEBUGFUNC("e1000_read_nvm_i211");
+
+	/* Only the MAC addr is required to be present in the iNVM */
+	switch (offset) {
+	case NVM_MAC_ADDR:
+		ret_val = e1000_read_invm_i211(hw, (u8)offset, &data[0]);
+		ret_val |= e1000_read_invm_i211(hw, (u8)offset+1, &data[1]);
+		ret_val |= e1000_read_invm_i211(hw, (u8)offset+2, &data[2]);
+		if (ret_val != E1000_SUCCESS)
+			DEBUGOUT("MAC Addr not found in iNVM\n");
+		break;
+	case NVM_INIT_CTRL_2:
+		ret_val = e1000_read_invm_i211(hw, (u8)offset, data);
+		if (ret_val != E1000_SUCCESS) {
+			*data = NVM_INIT_CTRL_2_DEFAULT_I211;
+			ret_val = E1000_SUCCESS;
+		}
+		break;
+	case NVM_INIT_CTRL_4:
+		ret_val = e1000_read_invm_i211(hw, (u8)offset, data);
+		if (ret_val != E1000_SUCCESS) {
+			*data = NVM_INIT_CTRL_4_DEFAULT_I211;
+			ret_val = E1000_SUCCESS;
+		}
+		break;
+	case NVM_LED_1_CFG:
+		ret_val = e1000_read_invm_i211(hw, (u8)offset, data);
+		if (ret_val != E1000_SUCCESS) {
+			*data = NVM_LED_1_CFG_DEFAULT_I211;
+			ret_val = E1000_SUCCESS;
+		}
+		break;
+	case NVM_LED_0_2_CFG:
+		ret_val = e1000_read_invm_i211(hw, (u8)offset, data);
+		if (ret_val != E1000_SUCCESS) {
+			*data = NVM_LED_0_2_CFG_DEFAULT_I211;
+			ret_val = E1000_SUCCESS;
+		}
+		break;
+	case NVM_ID_LED_SETTINGS:
+		ret_val = e1000_read_invm_i211(hw, (u8)offset, data);
+		if (ret_val != E1000_SUCCESS) {
+			*data = ID_LED_RESERVED_FFFF;
+			ret_val = E1000_SUCCESS;
+		}
+		break;
+	case NVM_SUB_DEV_ID:
+		*data = hw->subsystem_device_id;
+		break;
+	case NVM_SUB_VEN_ID:
+		*data = hw->subsystem_vendor_id;
+		break;
+	case NVM_DEV_ID:
+		*data = hw->device_id;
+		break;
+	case NVM_VEN_ID:
+		*data = hw->vendor_id;
+		break;
+	default:
+		DEBUGOUT1("NVM word 0x%02x is not mapped.\n", offset);
+		*data = NVM_RESERVED_WORD;
+		break;
+	}
+	return ret_val;
+}
+
+/**
+ *  e1000_read_invm_i211 - Reads OTP
+ *  @hw: pointer to the HW structure
+ *  @address: the word address (aka eeprom offset) to read
+ *  @data: pointer to the data read
+ *
+ *  Reads 16-bit words from the OTP. Return error when the word is not
+ *  stored in OTP.
+ **/
+s32 e1000_read_invm_i211(struct e1000_hw *hw, u8 address, u16 *data)
+{
+	s32 status = -E1000_ERR_INVM_VALUE_NOT_FOUND;
+	u32 invm_dword;
+	u16 i;
+	u8 record_type, word_address;
+
+	DEBUGFUNC("e1000_read_invm_i211");
+
+	for (i = 0; i < E1000_INVM_SIZE; i++) {
+		invm_dword = E1000_READ_REG(hw, E1000_INVM_DATA_REG(i));
+		/* Get record type */
+		record_type = INVM_DWORD_TO_RECORD_TYPE(invm_dword);
+		if (record_type == E1000_INVM_UNINITIALIZED_STRUCTURE)
+			break;
+		if (record_type == E1000_INVM_CSR_AUTOLOAD_STRUCTURE)
+			i += E1000_INVM_CSR_AUTOLOAD_DATA_SIZE_IN_DWORDS;
+		if (record_type == E1000_INVM_RSA_KEY_SHA256_STRUCTURE)
+			i += E1000_INVM_RSA_KEY_SHA256_DATA_SIZE_IN_DWORDS;
+		if (record_type == E1000_INVM_WORD_AUTOLOAD_STRUCTURE) {
+			word_address = INVM_DWORD_TO_WORD_ADDRESS(invm_dword);
+			if (word_address == address) {
+				*data = INVM_DWORD_TO_WORD_DATA(invm_dword);
+				DEBUGOUT2("Read INVM Word 0x%02x = %x",
+					  address, *data);
+				status = E1000_SUCCESS;
+				break;
+			}
+		}
+	}
+	if (status != E1000_SUCCESS)
+		DEBUGOUT1("Requested word 0x%02x not found in OTP\n", address);
+	return status;
+}
+
+/**
+ *  e1000_validate_nvm_checksum_i210 - Validate EEPROM checksum
+ *  @hw: pointer to the HW structure
+ *
+ *  Calculates the EEPROM checksum by reading/adding each word of the EEPROM
+ *  and then verifies that the sum of the EEPROM is equal to 0xBABA.
+ **/
+s32 e1000_validate_nvm_checksum_i210(struct e1000_hw *hw)
+{
+	s32 status = E1000_SUCCESS;
+	s32 (*read_op_ptr)(struct e1000_hw *, u16, u16, u16 *);
+
+	DEBUGFUNC("e1000_validate_nvm_checksum_i210");
+
+	if (hw->nvm.ops.acquire(hw) == E1000_SUCCESS) {
+
+		/*
+		 * Replace the read function with semaphore grabbing with
+		 * the one that skips this for a while.
+		 * We have semaphore taken already here.
+		 */
+		read_op_ptr = hw->nvm.ops.read;
+		hw->nvm.ops.read = e1000_read_nvm_eerd;
+
+		status = e1000_validate_nvm_checksum_generic(hw);
+
+		/* Revert original read operation. */
+		hw->nvm.ops.read = read_op_ptr;
+
+		hw->nvm.ops.release(hw);
+	} else {
+		status = E1000_ERR_SWFW_SYNC;
+	}
+
+	return status;
+}
+
+
+/**
+ *  e1000_update_nvm_checksum_i210 - Update EEPROM checksum
+ *  @hw: pointer to the HW structure
+ *
+ *  Updates the EEPROM checksum by reading/adding each word of the EEPROM
+ *  up to the checksum.  Then calculates the EEPROM checksum and writes the
+ *  value to the EEPROM. Next commit EEPROM data onto the Flash.
+ **/
+s32 e1000_update_nvm_checksum_i210(struct e1000_hw *hw)
+{
+	s32 ret_val = E1000_SUCCESS;
+	u16 checksum = 0;
+	u16 i, nvm_data;
+
+	DEBUGFUNC("e1000_update_nvm_checksum_i210");
+
+	/*
+	 * Read the first word from the EEPROM. If this times out or fails, do
+	 * not continue or we could be in for a very long wait while every
+	 * EEPROM read fails
+	 */
+	ret_val = e1000_read_nvm_eerd(hw, 0, 1, &nvm_data);
+	if (ret_val != E1000_SUCCESS) {
+		DEBUGOUT("EEPROM read failed\n");
+		goto out;
+	}
+
+	if (hw->nvm.ops.acquire(hw) == E1000_SUCCESS) {
+		/*
+		 * Do not use hw->nvm.ops.write, hw->nvm.ops.read
+		 * because we do not want to take the synchronization
+		 * semaphores twice here.
+		 */
+
+		for (i = 0; i < NVM_CHECKSUM_REG; i++) {
+			ret_val = e1000_read_nvm_eerd(hw, i, 1, &nvm_data);
+			if (ret_val) {
+				hw->nvm.ops.release(hw);
+				DEBUGOUT("NVM Read Error while updating checksum.\n");
+				goto out;
+			}
+			checksum += nvm_data;
+		}
+		checksum = (u16) NVM_SUM - checksum;
+		ret_val = e1000_write_nvm_srwr(hw, NVM_CHECKSUM_REG, 1,
+						&checksum);
+		if (ret_val != E1000_SUCCESS) {
+			hw->nvm.ops.release(hw);
+			DEBUGOUT("NVM Write Error while updating checksum.\n");
+			goto out;
+		}
+
+		hw->nvm.ops.release(hw);
+
+		ret_val = e1000_update_flash_i210(hw);
+	} else {
+		ret_val = E1000_ERR_SWFW_SYNC;
+	}
+out:
+	return ret_val;
+}
+
+/**
+ *  e1000_update_flash_i210 - Commit EEPROM to the flash
+ *  @hw: pointer to the HW structure
+ *
+ **/
+s32 e1000_update_flash_i210(struct e1000_hw *hw)
+{
+	s32 ret_val = E1000_SUCCESS;
+	u32 flup;
+
+	DEBUGFUNC("e1000_update_flash_i210");
+
+	ret_val = e1000_pool_flash_update_done_i210(hw);
+	if (ret_val == -E1000_ERR_NVM) {
+		DEBUGOUT("Flash update time out\n");
+		goto out;
+	}
+
+	flup = E1000_READ_REG(hw, E1000_EECD) | E1000_EECD_FLUPD_I210;
+	E1000_WRITE_REG(hw, E1000_EECD, flup);
+
+	ret_val = e1000_pool_flash_update_done_i210(hw);
+	if (ret_val == E1000_SUCCESS)
+		DEBUGOUT("Flash update complete\n");
+	else
+		DEBUGOUT("Flash update time out\n");
+
+out:
+	return ret_val;
+}
+
+/**
+ *  e1000_pool_flash_update_done_i210 - Pool FLUDONE status.
+ *  @hw: pointer to the HW structure
+ *
+ **/
+s32 e1000_pool_flash_update_done_i210(struct e1000_hw *hw)
+{
+	s32 ret_val = -E1000_ERR_NVM;
+	u32 i, reg;
+
+	DEBUGFUNC("e1000_pool_flash_update_done_i210");
+
+	for (i = 0; i < E1000_FLUDONE_ATTEMPTS; i++) {
+		reg = E1000_READ_REG(hw, E1000_EECD);
+		if (reg & E1000_EECD_FLUDONE_I210) {
+			ret_val = E1000_SUCCESS;
+			break;
+		}
+		usec_delay(5);
+	}
+
+	return ret_val;
+}
+
+/**
+ *  e1000_init_nvm_params_i210 - Initialize i210 NVM function pointers
+ *  @hw: pointer to the HW structure
+ *
+ *  Initialize the i210 NVM parameters and function pointers.
+ **/
+static s32 e1000_init_nvm_params_i210(struct e1000_hw *hw)
+{
+	s32 ret_val = E1000_SUCCESS;
+	struct e1000_nvm_info *nvm = &hw->nvm;
+
+	DEBUGFUNC("e1000_init_nvm_params_i210");
+
+	ret_val = e1000_init_nvm_params_82575(hw);
+
+	nvm->ops.acquire = e1000_acquire_nvm_i210;
+	nvm->ops.release = e1000_release_nvm_i210;
+	nvm->ops.read    = e1000_read_nvm_srrd_i210;
+	nvm->ops.write   = e1000_write_nvm_srwr_i210;
+	nvm->ops.valid_led_default = e1000_valid_led_default_i210;
+	nvm->ops.validate = e1000_validate_nvm_checksum_i210;
+	nvm->ops.update   = e1000_update_nvm_checksum_i210;
+
+	return ret_val;
+}
+
+/**
+ *  e1000_init_nvm_params_i211 - Initialize i211 NVM function pointers
+ *  @hw: pointer to the HW structure
+ *
+ *  Initialize the NVM parameters and function pointers for i211.
+ **/
+static s32 e1000_init_nvm_params_i211(struct e1000_hw *hw)
+{
+	struct e1000_nvm_info *nvm = &hw->nvm;
+
+	DEBUGFUNC("e1000_init_nvm_params_i211");
+
+	nvm->ops.acquire  = e1000_acquire_nvm_i210;
+	nvm->ops.release  = e1000_release_nvm_i210;
+	nvm->ops.read     = e1000_read_nvm_i211;
+	nvm->ops.valid_led_default = e1000_valid_led_default_i210;
+	nvm->ops.write    = e1000_null_write_nvm;
+	nvm->ops.validate = e1000_null_ops_generic;
+	nvm->ops.update   = e1000_null_ops_generic;
+
+	return E1000_SUCCESS;
+}
+
+/**
+ *  e1000_init_function_pointers_i210 - Init func ptrs.
+ *  @hw: pointer to the HW structure
+ *
+ *  Called to initialize all function pointers and parameters.
+ **/
+void e1000_init_function_pointers_i210(struct e1000_hw *hw)
+{
+	e1000_init_function_pointers_82575(hw);
+
+	switch (hw->mac.type) {
+	case e1000_i210:
+		hw->nvm.ops.init_params = e1000_init_nvm_params_i210;
+		break;
+	case e1000_i211:
+		hw->nvm.ops.init_params = e1000_init_nvm_params_i211;
+		break;
+	default:
+		break;
+	}
+	return;
+}
+
+/**
+ *  e1000_valid_led_default_i210 - Verify a valid default LED config
+ *  @hw: pointer to the HW structure
+ *  @data: pointer to the NVM (EEPROM)
+ *
+ *  Read the EEPROM for the current default LED configuration.  If the
+ *  LED configuration is not valid, set to a valid LED configuration.
+ **/
+static s32 e1000_valid_led_default_i210(struct e1000_hw *hw, u16 *data)
+{
+	s32 ret_val;
+
+	DEBUGFUNC("e1000_valid_led_default_i210");
+
+	ret_val = hw->nvm.ops.read(hw, NVM_ID_LED_SETTINGS, 1, data);
+	if (ret_val) {
+		DEBUGOUT("NVM Read Error\n");
+		goto out;
+	}
+
+	if (*data == ID_LED_RESERVED_0000 || *data == ID_LED_RESERVED_FFFF) {
+		switch (hw->phy.media_type) {
+		case e1000_media_type_internal_serdes:
+			*data = ID_LED_DEFAULT_I210_SERDES;
+			break;
+		case e1000_media_type_copper:
+		default:
+			*data = ID_LED_DEFAULT_I210;
+			break;
+		}
+	}
+out:
+	return ret_val;
+}
diff --git a/sys/dev/e1000/e1000_i210.h b/sys/dev/e1000/e1000_i210.h
new file mode 100644
index 0000000..d7711fe
--- /dev/null
+++ b/sys/dev/e1000/e1000_i210.h
@@ -0,0 +1,92 @@
+/******************************************************************************
+
+  Copyright (c) 2001-2013, Intel Corporation 
+  All rights reserved.
+  
+  Redistribution and use in source and binary forms, with or without 
+  modification, are permitted provided that the following conditions are met:
+  
+   1. Redistributions of source code must retain the above copyright notice, 
+      this list of conditions and the following disclaimer.
+  
+   2. Redistributions in binary form must reproduce the above copyright 
+      notice, this list of conditions and the following disclaimer in the 
+      documentation and/or other materials provided with the distribution.
+  
+   3. Neither the name of the Intel Corporation nor the names of its 
+      contributors may be used to endorse or promote products derived from 
+      this software without specific prior written permission.
+  
+  THIS SOFTWARE IS PROVIDED BY THE COPYRIGHT HOLDERS AND CONTRIBUTORS "AS IS"
+  AND ANY EXPRESS OR IMPLIED WARRANTIES, INCLUDING, BUT NOT LIMITED TO, THE 
+  IMPLIED WARRANTIES OF MERCHANTABILITY AND FITNESS FOR A PARTICULAR PURPOSE 
+  ARE DISCLAIMED. IN NO EVENT SHALL THE COPYRIGHT OWNER OR CONTRIBUTORS BE 
+  LIABLE FOR ANY DIRECT, INDIRECT, INCIDENTAL, SPECIAL, EXEMPLARY, OR 
+  CONSEQUENTIAL DAMAGES (INCLUDING, BUT NOT LIMITED TO, PROCUREMENT OF 
+  SUBSTITUTE GOODS OR SERVICES; LOSS OF USE, DATA, OR PROFITS; OR BUSINESS 
+  INTERRUPTION) HOWEVER CAUSED AND ON ANY THEORY OF LIABILITY, WHETHER IN 
+  CONTRACT, STRICT LIABILITY, OR TORT (INCLUDING NEGLIGENCE OR OTHERWISE) 
+  ARISING IN ANY WAY OUT OF THE USE OF THIS SOFTWARE, EVEN IF ADVISED OF THE
+  POSSIBILITY OF SUCH DAMAGE.
+
+******************************************************************************/
+/*$FreeBSD$*/
+
+#ifndef _E1000_I210_H_
+#define _E1000_I210_H_
+
+s32 e1000_update_flash_i210(struct e1000_hw *hw);
+s32 e1000_update_nvm_checksum_i210(struct e1000_hw *hw);
+s32 e1000_validate_nvm_checksum_i210(struct e1000_hw *hw);
+s32 e1000_write_nvm_srwr_i210(struct e1000_hw *hw, u16 offset,
+			      u16 words, u16 *data);
+s32 e1000_read_nvm_srrd_i210(struct e1000_hw *hw, u16 offset,
+			     u16 words, u16 *data);
+s32 e1000_read_invm_i211(struct e1000_hw *hw, u8 address, u16 *data);
+s32 e1000_acquire_swfw_sync_i210(struct e1000_hw *hw, u16 mask);
+void e1000_release_swfw_sync_i210(struct e1000_hw *hw, u16 mask);
+
+#define E1000_STM_OPCODE		0xDB00
+#define E1000_EEPROM_FLASH_SIZE_WORD	0x11
+
+#define INVM_DWORD_TO_RECORD_TYPE(invm_dword) \
+	(u8)((invm_dword) & 0x7)
+#define INVM_DWORD_TO_WORD_ADDRESS(invm_dword) \
+	(u8)(((invm_dword) & 0x0000FE00) >> 9)
+#define INVM_DWORD_TO_WORD_DATA(invm_dword) \
+	(u16)(((invm_dword) & 0xFFFF0000) >> 16)
+
+enum E1000_INVM_STRUCTURE_TYPE {
+	E1000_INVM_UNINITIALIZED_STRUCTURE		= 0x00,
+	E1000_INVM_WORD_AUTOLOAD_STRUCTURE		= 0x01,
+	E1000_INVM_CSR_AUTOLOAD_STRUCTURE		= 0x02,
+	E1000_INVM_PHY_REGISTER_AUTOLOAD_STRUCTURE	= 0x03,
+	E1000_INVM_RSA_KEY_SHA256_STRUCTURE		= 0x04,
+	E1000_INVM_INVALIDATED_STRUCTURE		= 0x0F,
+};
+
+#define E1000_INVM_RSA_KEY_SHA256_DATA_SIZE_IN_DWORDS	8
+#define E1000_INVM_CSR_AUTOLOAD_DATA_SIZE_IN_DWORDS	1
+#define E1000_INVM_ULT_BYTES_SIZE	8
+#define E1000_INVM_RECORD_SIZE_IN_BYTES	4
+#define E1000_INVM_VER_FIELD_ONE	0x1FF8
+#define E1000_INVM_VER_FIELD_TWO	0x7FE000
+#define E1000_INVM_IMGTYPE_FIELD	0x1F800000
+
+#define E1000_INVM_MAJOR_MASK	0x3F0
+#define E1000_INVM_MINOR_MASK	0xF
+#define E1000_INVM_MAJOR_SHIFT	4
+
+#define ID_LED_DEFAULT_I210		((ID_LED_OFF1_ON2  << 8) | \
+					 (ID_LED_DEF1_DEF2 <<  4) | \
+					 (ID_LED_OFF1_OFF2))
+#define ID_LED_DEFAULT_I210_SERDES	((ID_LED_DEF1_DEF2 << 8) | \
+					 (ID_LED_DEF1_DEF2 <<  4) | \
+					 (ID_LED_DEF1_DEF2))
+
+/* NVM offset defaults for I211 devices */
+#define NVM_INIT_CTRL_2_DEFAULT_I211	0X7243
+#define NVM_INIT_CTRL_4_DEFAULT_I211	0x00C1
+#define NVM_LED_1_CFG_DEFAULT_I211	0x0184
+#define NVM_LED_0_2_CFG_DEFAULT_I211	0x200C
+#endif
diff --git a/sys/dev/e1000/e1000_ich8lan.c b/sys/dev/e1000/e1000_ich8lan.c
index aa4802c..bd94355 100644
--- a/sys/dev/e1000/e1000_ich8lan.c
+++ b/sys/dev/e1000/e1000_ich8lan.c
@@ -1,6 +1,6 @@
 /******************************************************************************
 
-  Copyright (c) 2001-2011, Intel Corporation 
+  Copyright (c) 2001-2013, Intel Corporation 
   All rights reserved.
   
   Redistribution and use in source and binary forms, with or without 
@@ -32,8 +32,7 @@
 ******************************************************************************/
 /*$FreeBSD$*/
 
-/*
- * 82562G 10/100 Network Connection
+/* 82562G 10/100 Network Connection
  * 82562G-2 10/100 Network Connection
  * 82562GT 10/100 Network Connection
  * 82562GT-2 10/100 Network Connection
@@ -64,10 +63,6 @@
 
 #include "e1000_api.h"
 
-static s32  e1000_init_phy_params_ich8lan(struct e1000_hw *hw);
-static s32 e1000_init_phy_params_pchlan(struct e1000_hw *hw);
-static s32  e1000_init_nvm_params_ich8lan(struct e1000_hw *hw);
-static s32  e1000_init_mac_params_ich8lan(struct e1000_hw *hw);
 static s32  e1000_acquire_swflag_ich8lan(struct e1000_hw *hw);
 static void e1000_release_swflag_ich8lan(struct e1000_hw *hw);
 static s32  e1000_acquire_nvm_ich8lan(struct e1000_hw *hw);
@@ -75,6 +70,7 @@ static void e1000_release_nvm_ich8lan(struct e1000_hw *hw);
 static bool e1000_check_mng_mode_ich8lan(struct e1000_hw *hw);
 static bool e1000_check_mng_mode_pchlan(struct e1000_hw *hw);
 static void e1000_rar_set_pch2lan(struct e1000_hw *hw, u8 *addr, u32 index);
+static void e1000_rar_set_pch_lpt(struct e1000_hw *hw, u8 *addr, u32 index);
 static void e1000_update_mc_addr_list_pch2lan(struct e1000_hw *hw,
 					      u8 *mc_addr_list,
 					      u32 mc_addr_count);
@@ -99,6 +95,7 @@ static s32  e1000_reset_hw_ich8lan(struct e1000_hw *hw);
 static s32  e1000_init_hw_ich8lan(struct e1000_hw *hw);
 static s32  e1000_setup_link_ich8lan(struct e1000_hw *hw);
 static s32  e1000_setup_copper_link_ich8lan(struct e1000_hw *hw);
+static s32  e1000_setup_copper_link_pch_lpt(struct e1000_hw *hw);
 static s32  e1000_get_link_up_info_ich8lan(struct e1000_hw *hw,
 					   u16 *speed, u16 *duplex);
 static s32  e1000_cleanup_led_ich8lan(struct e1000_hw *hw);
@@ -111,8 +108,6 @@ static s32  e1000_led_on_pchlan(struct e1000_hw *hw);
 static s32  e1000_led_off_pchlan(struct e1000_hw *hw);
 static void e1000_clear_hw_cntrs_ich8lan(struct e1000_hw *hw);
 static s32  e1000_erase_flash_bank_ich8lan(struct e1000_hw *hw, u32 bank);
-static s32  e1000_flash_cycle_ich8lan(struct e1000_hw *hw, u32 timeout);
-static s32  e1000_flash_cycle_init_ich8lan(struct e1000_hw *hw);
 static void e1000_initialize_hw_bits_ich8lan(struct e1000_hw *hw);
 static s32  e1000_kmrn_lock_loss_workaround_ich8lan(struct e1000_hw *hw);
 static s32  e1000_read_flash_byte_ich8lan(struct e1000_hw *hw,
@@ -123,21 +118,13 @@ static s32  e1000_read_flash_word_ich8lan(struct e1000_hw *hw,
 					  u32 offset, u16 *data);
 static s32  e1000_retry_write_flash_byte_ich8lan(struct e1000_hw *hw,
 						 u32 offset, u8 byte);
-static s32  e1000_write_flash_byte_ich8lan(struct e1000_hw *hw,
-					   u32 offset, u8 data);
-static s32  e1000_write_flash_data_ich8lan(struct e1000_hw *hw, u32 offset,
-					   u8 size, u16 data);
 static s32 e1000_get_cfg_done_ich8lan(struct e1000_hw *hw);
 static void e1000_power_down_phy_copper_ich8lan(struct e1000_hw *hw);
 static s32 e1000_check_for_copper_link_ich8lan(struct e1000_hw *hw);
-static void e1000_lan_init_done_ich8lan(struct e1000_hw *hw);
-static s32 e1000_sw_lcd_config_ich8lan(struct e1000_hw *hw);
 static s32 e1000_set_mdio_slow_mode_hv(struct e1000_hw *hw);
 static s32 e1000_k1_workaround_lv(struct e1000_hw *hw);
 static void e1000_gate_hw_phy_config_ich8lan(struct e1000_hw *hw, bool gate);
-#if defined(NAHUM6_HW) && (defined(LTR_SUPPORT) || defined(OBFF_SUPPORT))
-
-#endif /* NAHUM6_HW && (LTR_SUPPORT || OBFF_SUPPORT) */
+static s32 e1000_set_obff_timer_pch_lpt(struct e1000_hw *hw, u32 itr);
 
 /* ICH GbE Flash Hardware Sequencing Flash Status Register bit breakdown */
 /* Offset 04h HSFSTS */
@@ -180,20 +167,190 @@ union ich8_hws_flash_regacc {
 	u16 regval;
 };
 
-static void e1000_toggle_lanphypc_value_ich8lan(struct e1000_hw *hw)
+/**
+ *  e1000_phy_is_accessible_pchlan - Check if able to access PHY registers
+ *  @hw: pointer to the HW structure
+ *
+ *  Test access to the PHY registers by reading the PHY ID registers.  If
+ *  the PHY ID is already known (e.g. resume path) compare it with known ID,
+ *  otherwise assume the read PHY ID is correct if it is valid.
+ *
+ *  Assumes the sw/fw/hw semaphore is already acquired.
+ **/
+static bool e1000_phy_is_accessible_pchlan(struct e1000_hw *hw)
 {
-	u32 ctrl;
+	u16 phy_reg = 0;
+	u32 phy_id = 0;
+	s32 ret_val;
+	u16 retry_count;
 
-	DEBUGFUNC("e1000_toggle_lanphypc_value_ich8lan");
+	for (retry_count = 0; retry_count < 2; retry_count++) {
+		ret_val = hw->phy.ops.read_reg_locked(hw, PHY_ID1, &phy_reg);
+		if (ret_val || (phy_reg == 0xFFFF))
+			continue;
+		phy_id = (u32)(phy_reg << 16);
 
-	ctrl = E1000_READ_REG(hw, E1000_CTRL);
-	ctrl |= E1000_CTRL_LANPHYPC_OVERRIDE;
-	ctrl &= ~E1000_CTRL_LANPHYPC_VALUE;
-	E1000_WRITE_REG(hw, E1000_CTRL, ctrl);
-	E1000_WRITE_FLUSH(hw);
-	usec_delay(10);
-	ctrl &= ~E1000_CTRL_LANPHYPC_OVERRIDE;
-	E1000_WRITE_REG(hw, E1000_CTRL, ctrl);
+		ret_val = hw->phy.ops.read_reg_locked(hw, PHY_ID2, &phy_reg);
+		if (ret_val || (phy_reg == 0xFFFF)) {
+			phy_id = 0;
+			continue;
+		}
+		phy_id |= (u32)(phy_reg & PHY_REVISION_MASK);
+		break;
+	}
+
+	if (hw->phy.id) {
+		if  (hw->phy.id == phy_id)
+			return TRUE;
+	} else if (phy_id) {
+		hw->phy.id = phy_id;
+		hw->phy.revision = (u32)(phy_reg & ~PHY_REVISION_MASK);
+		return TRUE;
+	}
+
+	/* In case the PHY needs to be in mdio slow mode,
+	 * set slow mode and try to get the PHY id again.
+	 */
+	hw->phy.ops.release(hw);
+	ret_val = e1000_set_mdio_slow_mode_hv(hw);
+	if (!ret_val)
+		ret_val = e1000_get_phy_id(hw);
+	hw->phy.ops.acquire(hw);
+
+	return !ret_val;
+}
+
+/**
+ *  e1000_init_phy_workarounds_pchlan - PHY initialization workarounds
+ *  @hw: pointer to the HW structure
+ *
+ *  Workarounds/flow necessary for PHY initialization during driver load
+ *  and resume paths.
+ **/
+static s32 e1000_init_phy_workarounds_pchlan(struct e1000_hw *hw)
+{
+	u32 mac_reg, fwsm = E1000_READ_REG(hw, E1000_FWSM);
+	s32 ret_val;
+	u16 phy_reg;
+
+	DEBUGFUNC("e1000_init_phy_workarounds_pchlan");
+
+	/* Gate automatic PHY configuration by hardware on managed and
+	 * non-managed 82579 and newer adapters.
+	 */
+	e1000_gate_hw_phy_config_ich8lan(hw, TRUE);
+
+	ret_val = hw->phy.ops.acquire(hw);
+	if (ret_val) {
+		DEBUGOUT("Failed to initialize PHY flow\n");
+		goto out;
+	}
+
+	/* The MAC-PHY interconnect may be in SMBus mode.  If the PHY is
+	 * inaccessible and resetting the PHY is not blocked, toggle the
+	 * LANPHYPC Value bit to force the interconnect to PCIe mode.
+	 */
+	switch (hw->mac.type) {
+	case e1000_pch_lpt:
+		if (e1000_phy_is_accessible_pchlan(hw))
+			break;
+
+		/* Before toggling LANPHYPC, see if PHY is accessible by
+		 * forcing MAC to SMBus mode first.
+		 */
+		mac_reg = E1000_READ_REG(hw, E1000_CTRL_EXT);
+		mac_reg |= E1000_CTRL_EXT_FORCE_SMBUS;
+		E1000_WRITE_REG(hw, E1000_CTRL_EXT, mac_reg);
+
+		/* fall-through */
+	case e1000_pch2lan:
+		if (e1000_phy_is_accessible_pchlan(hw)) {
+			if (hw->mac.type == e1000_pch_lpt) {
+				/* Unforce SMBus mode in PHY */
+				hw->phy.ops.read_reg_locked(hw, CV_SMB_CTRL,
+							    &phy_reg);
+				phy_reg &= ~CV_SMB_CTRL_FORCE_SMBUS;
+				hw->phy.ops.write_reg_locked(hw, CV_SMB_CTRL,
+							     phy_reg);
+
+				/* Unforce SMBus mode in MAC */
+				mac_reg = E1000_READ_REG(hw, E1000_CTRL_EXT);
+				mac_reg &= ~E1000_CTRL_EXT_FORCE_SMBUS;
+				E1000_WRITE_REG(hw, E1000_CTRL_EXT, mac_reg);
+			}
+			break;
+		}
+
+		/* fall-through */
+	case e1000_pchlan:
+		if ((hw->mac.type == e1000_pchlan) &&
+		    (fwsm & E1000_ICH_FWSM_FW_VALID))
+			break;
+
+		if (hw->phy.ops.check_reset_block(hw)) {
+			DEBUGOUT("Required LANPHYPC toggle blocked by ME\n");
+			break;
+		}
+
+		DEBUGOUT("Toggling LANPHYPC\n");
+
+		/* Set Phy Config Counter to 50msec */
+		mac_reg = E1000_READ_REG(hw, E1000_FEXTNVM3);
+		mac_reg &= ~E1000_FEXTNVM3_PHY_CFG_COUNTER_MASK;
+		mac_reg |= E1000_FEXTNVM3_PHY_CFG_COUNTER_50MSEC;
+		E1000_WRITE_REG(hw, E1000_FEXTNVM3, mac_reg);
+
+		if (hw->mac.type == e1000_pch_lpt) {
+			/* Toggling LANPHYPC brings the PHY out of SMBus mode
+			 * So ensure that the MAC is also out of SMBus mode
+			 */
+			mac_reg = E1000_READ_REG(hw, E1000_CTRL_EXT);
+			mac_reg &= ~E1000_CTRL_EXT_FORCE_SMBUS;
+			E1000_WRITE_REG(hw, E1000_CTRL_EXT, mac_reg);
+		}
+
+		/* Toggle LANPHYPC Value bit */
+		mac_reg = E1000_READ_REG(hw, E1000_CTRL);
+		mac_reg |= E1000_CTRL_LANPHYPC_OVERRIDE;
+		mac_reg &= ~E1000_CTRL_LANPHYPC_VALUE;
+		E1000_WRITE_REG(hw, E1000_CTRL, mac_reg);
+		E1000_WRITE_FLUSH(hw);
+		usec_delay(10);
+		mac_reg &= ~E1000_CTRL_LANPHYPC_OVERRIDE;
+		E1000_WRITE_REG(hw, E1000_CTRL, mac_reg);
+		E1000_WRITE_FLUSH(hw);
+		if (hw->mac.type < e1000_pch_lpt) {
+			msec_delay(50);
+		} else {
+			u16 count = 20;
+			do {
+				msec_delay(5);
+			} while (!(E1000_READ_REG(hw, E1000_CTRL_EXT) &
+				   E1000_CTRL_EXT_LPCD) && count--);
+		}
+		break;
+	default:
+		break;
+	}
+
+	hw->phy.ops.release(hw);
+
+	/* Reset the PHY before any access to it.  Doing so, ensures
+	 * that the PHY is in a known good state before we read/write
+	 * PHY registers.  The generic reset is sufficient here,
+	 * because we haven't determined the PHY type yet.
+	 */
+	ret_val = e1000_phy_hw_reset_generic(hw);
+
+out:
+	/* Ungate automatic PHY configuration on non-managed 82579 */
+	if ((hw->mac.type == e1000_pch2lan) &&
+	    !(fwsm & E1000_ICH_FWSM_FW_VALID)) {
+		msec_delay(10);
+		e1000_gate_hw_phy_config_ich8lan(hw, FALSE);
+	}
+
+	return ret_val;
 }
 
 /**
@@ -205,7 +362,7 @@ static void e1000_toggle_lanphypc_value_ich8lan(struct e1000_hw *hw)
 static s32 e1000_init_phy_params_pchlan(struct e1000_hw *hw)
 {
 	struct e1000_phy_info *phy = &hw->phy;
-	s32 ret_val = E1000_SUCCESS;
+	s32 ret_val;
 
 	DEBUGFUNC("e1000_init_phy_params_pchlan");
 
@@ -230,70 +387,40 @@ static s32 e1000_init_phy_params_pchlan(struct e1000_hw *hw)
 	phy->ops.power_down	= e1000_power_down_phy_copper_ich8lan;
 	phy->autoneg_mask	= AUTONEG_ADVERTISE_SPEED_DEFAULT;
 
-	if (!hw->phy.ops.check_reset_block(hw)) {
-		u32 fwsm = E1000_READ_REG(hw, E1000_FWSM);
-
-		/*
-		 * The MAC-PHY interconnect may still be in SMBus mode after
-		 * Sx->S0.  If resetting the PHY is not blocked, toggle the
-		 * LANPHYPC Value bit to force the interconnect to PCIe mode.
-		 */
-		e1000_toggle_lanphypc_value_ich8lan(hw);
-		msec_delay(50);
-
-		/*
-		 * Gate automatic PHY configuration by hardware on
-		 * non-managed 82579
-		 */
-		if ((hw->mac.type == e1000_pch2lan) &&
-		    !(fwsm & E1000_ICH_FWSM_FW_VALID))
-			e1000_gate_hw_phy_config_ich8lan(hw, TRUE);
-
-		/*
-		 * Reset the PHY before any access to it.  Doing so, ensures
-		 * that the PHY is in a known good state before we read/write
-		 * PHY registers.  The generic reset is sufficient here,
-		 * because we haven't determined the PHY type yet.
-		 */
-		ret_val = e1000_phy_hw_reset_generic(hw);
-		if (ret_val)
-			goto out;
+	phy->id = e1000_phy_unknown;
 
-		/* Ungate automatic PHY configuration on non-managed 82579 */
-		if ((hw->mac.type == e1000_pch2lan) &&
-		    !(fwsm & E1000_ICH_FWSM_FW_VALID)) {
-			msec_delay(10);
-			e1000_gate_hw_phy_config_ich8lan(hw, FALSE);
-		}
-	}
+	ret_val = e1000_init_phy_workarounds_pchlan(hw);
+	if (ret_val)
+		return ret_val;
 
-	phy->id = e1000_phy_unknown;
-	switch (hw->mac.type) {
-	default:
-		ret_val = e1000_get_phy_id(hw);
-		if (ret_val)
-			goto out;
-		if ((phy->id != 0) && (phy->id != PHY_REVISION_MASK))
+	if (phy->id == e1000_phy_unknown)
+		switch (hw->mac.type) {
+		default:
+			ret_val = e1000_get_phy_id(hw);
+			if (ret_val)
+				return ret_val;
+			if ((phy->id != 0) && (phy->id != PHY_REVISION_MASK))
+				break;
+			/* fall-through */
+		case e1000_pch2lan:
+		case e1000_pch_lpt:
+			/* In case the PHY needs to be in mdio slow mode,
+			 * set slow mode and try to get the PHY id again.
+			 */
+			ret_val = e1000_set_mdio_slow_mode_hv(hw);
+			if (ret_val)
+				return ret_val;
+			ret_val = e1000_get_phy_id(hw);
+			if (ret_val)
+				return ret_val;
 			break;
-		/* fall-through */
-	case e1000_pch2lan:
-		/*
-		 * In case the PHY needs to be in mdio slow mode,
-		 * set slow mode and try to get the PHY id again.
-		 */
-		ret_val = e1000_set_mdio_slow_mode_hv(hw);
-		if (ret_val)
-			goto out;
-		ret_val = e1000_get_phy_id(hw);
-		if (ret_val)
-			goto out;
-		break;
-	}
+		}
 	phy->type = e1000_get_phy_type_from_id(phy->id);
 
 	switch (phy->type) {
 	case e1000_phy_82577:
 	case e1000_phy_82579:
+	case e1000_phy_i217:
 		phy->ops.check_polarity = e1000_check_polarity_82577;
 		phy->ops.force_speed_duplex =
 			e1000_phy_force_speed_duplex_82577;
@@ -312,7 +439,6 @@ static s32 e1000_init_phy_params_pchlan(struct e1000_hw *hw)
 		break;
 	}
 
-out:
 	return ret_val;
 }
 
@@ -325,7 +451,7 @@ out:
 static s32 e1000_init_phy_params_ich8lan(struct e1000_hw *hw)
 {
 	struct e1000_phy_info *phy = &hw->phy;
-	s32 ret_val = E1000_SUCCESS;
+	s32 ret_val;
 	u16 i = 0;
 
 	DEBUGFUNC("e1000_init_phy_params_ich8lan");
@@ -346,8 +472,7 @@ static s32 e1000_init_phy_params_ich8lan(struct e1000_hw *hw)
 	phy->ops.power_up	= e1000_power_up_phy_copper;
 	phy->ops.power_down	= e1000_power_down_phy_copper_ich8lan;
 
-	/*
-	 * We may need to do this twice - once for IGP and if that fails,
+	/* We may need to do this twice - once for IGP and if that fails,
 	 * we'll set BM func pointers and try again
 	 */
 	ret_val = e1000_determine_phy_address(hw);
@@ -357,7 +482,7 @@ static s32 e1000_init_phy_params_ich8lan(struct e1000_hw *hw)
 		ret_val = e1000_determine_phy_address(hw);
 		if (ret_val) {
 			DEBUGOUT("Cannot determine PHY addr. Erroring out\n");
-			goto out;
+			return ret_val;
 		}
 	}
 
@@ -367,7 +492,7 @@ static s32 e1000_init_phy_params_ich8lan(struct e1000_hw *hw)
 		msec_delay(1);
 		ret_val = e1000_get_phy_id(hw);
 		if (ret_val)
-			goto out;
+			return ret_val;
 	}
 
 	/* Verify phy id */
@@ -401,12 +526,11 @@ static s32 e1000_init_phy_params_ich8lan(struct e1000_hw *hw)
 		phy->ops.force_speed_duplex = e1000_phy_force_speed_duplex_m88;
 		break;
 	default:
-		ret_val = -E1000_ERR_PHY;
-		goto out;
+		return -E1000_ERR_PHY;
+		break;
 	}
 
-out:
-	return ret_val;
+	return E1000_SUCCESS;
 }
 
 /**
@@ -421,7 +545,6 @@ static s32 e1000_init_nvm_params_ich8lan(struct e1000_hw *hw)
 	struct e1000_nvm_info *nvm = &hw->nvm;
 	struct e1000_dev_spec_ich8lan *dev_spec = &hw->dev_spec.ich8lan;
 	u32 gfpreg, sector_base_addr, sector_end_addr;
-	s32 ret_val = E1000_SUCCESS;
 	u16 i;
 
 	DEBUGFUNC("e1000_init_nvm_params_ich8lan");
@@ -429,16 +552,14 @@ static s32 e1000_init_nvm_params_ich8lan(struct e1000_hw *hw)
 	/* Can't read flash registers if the register set isn't mapped. */
 	if (!hw->flash_address) {
 		DEBUGOUT("ERROR: Flash registers not mapped\n");
-		ret_val = -E1000_ERR_CONFIG;
-		goto out;
+		return -E1000_ERR_CONFIG;
 	}
 
 	nvm->type = e1000_nvm_flash_sw;
 
 	gfpreg = E1000_READ_FLASH_REG(hw, ICH_FLASH_GFPREG);
 
-	/*
-	 * sector_X_addr is a "sector"-aligned address (4096 bytes)
+	/* sector_X_addr is a "sector"-aligned address (4096 bytes)
 	 * Add 1 to sector_end_addr since this sector is included in
 	 * the overall size.
 	 */
@@ -448,8 +569,7 @@ static s32 e1000_init_nvm_params_ich8lan(struct e1000_hw *hw)
 	/* flash_base_addr is byte-aligned */
 	nvm->flash_base_addr = sector_base_addr << FLASH_SECTOR_ADDR_SHIFT;
 
-	/*
-	 * find total size of the NVM, then cut in half since the total
+	/* find total size of the NVM, then cut in half since the total
 	 * size represents two separate NVM banks.
 	 */
 	nvm->flash_bank_size = (sector_end_addr - sector_base_addr)
@@ -478,8 +598,7 @@ static s32 e1000_init_nvm_params_ich8lan(struct e1000_hw *hw)
 	nvm->ops.validate	= e1000_validate_nvm_checksum_ich8lan;
 	nvm->ops.write		= e1000_write_nvm_ich8lan;
 
-out:
-	return ret_val;
+	return E1000_SUCCESS;
 }
 
 /**
@@ -536,7 +655,7 @@ static s32 e1000_init_mac_params_ich8lan(struct e1000_hw *hw)
 	/* clear hardware counters */
 	mac->ops.clear_hw_cntrs = e1000_clear_hw_cntrs_ich8lan;
 
-	/* LED operations */
+	/* LED and other operations */
 	switch (mac->type) {
 	case e1000_ich8lan:
 	case e1000_ich9lan:
@@ -558,10 +677,11 @@ static s32 e1000_init_mac_params_ich8lan(struct e1000_hw *hw)
 	case e1000_pch2lan:
 		mac->rar_entry_count = E1000_PCH2_RAR_ENTRIES;
 		mac->ops.rar_set = e1000_rar_set_pch2lan;
+		/* fall-through */
+	case e1000_pch_lpt:
 		/* multicast address update for pch2 */
 		mac->ops.update_mc_addr_list =
 			e1000_update_mc_addr_list_pch2lan;
-		/* fall-through */
 	case e1000_pchlan:
 		/* check management mode */
 		mac->ops.check_mng_mode = e1000_check_mng_mode_pchlan;
@@ -579,56 +699,386 @@ static s32 e1000_init_mac_params_ich8lan(struct e1000_hw *hw)
 		break;
 	}
 
-#if defined(NAHUM6_HW) && (defined(LTR_SUPPORT) || defined(OBFF_SUPPORT))
 	if (mac->type == e1000_pch_lpt) {
+		mac->rar_entry_count = E1000_PCH_LPT_RAR_ENTRIES;
+		mac->ops.rar_set = e1000_rar_set_pch_lpt;
+		mac->ops.setup_physical_interface = e1000_setup_copper_link_pch_lpt;
+		mac->ops.set_obff_timer = e1000_set_obff_timer_pch_lpt;
 	}
 
-#endif /* NAHUM6_HW && (LTR_SUPPORT || OBFF_SUPPORT) */
 	/* Enable PCS Lock-loss workaround for ICH8 */
 	if (mac->type == e1000_ich8lan)
 		e1000_set_kmrn_lock_loss_workaround_ich8lan(hw, TRUE);
 
-	/* Gate automatic PHY configuration by hardware on managed 82579 */
-	if ((mac->type == e1000_pch2lan) &&
-	    (E1000_READ_REG(hw, E1000_FWSM) & E1000_ICH_FWSM_FW_VALID))
-		e1000_gate_hw_phy_config_ich8lan(hw, TRUE);
-
 	return E1000_SUCCESS;
 }
 
 /**
+ *  __e1000_access_emi_reg_locked - Read/write EMI register
+ *  @hw: pointer to the HW structure
+ *  @addr: EMI address to program
+ *  @data: pointer to value to read/write from/to the EMI address
+ *  @read: boolean flag to indicate read or write
+ *
+ *  This helper function assumes the SW/FW/HW Semaphore is already acquired.
+ **/
+static s32 __e1000_access_emi_reg_locked(struct e1000_hw *hw, u16 address,
+					 u16 *data, bool read)
+{
+	s32 ret_val;
+
+	DEBUGFUNC("__e1000_access_emi_reg_locked");
+
+	ret_val = hw->phy.ops.write_reg_locked(hw, I82579_EMI_ADDR, address);
+	if (ret_val)
+		return ret_val;
+
+	if (read)
+		ret_val = hw->phy.ops.read_reg_locked(hw, I82579_EMI_DATA,
+						      data);
+	else
+		ret_val = hw->phy.ops.write_reg_locked(hw, I82579_EMI_DATA,
+						       *data);
+
+	return ret_val;
+}
+
+/**
+ *  e1000_read_emi_reg_locked - Read Extended Management Interface register
+ *  @hw: pointer to the HW structure
+ *  @addr: EMI address to program
+ *  @data: value to be read from the EMI address
+ *
+ *  Assumes the SW/FW/HW Semaphore is already acquired.
+ **/
+s32 e1000_read_emi_reg_locked(struct e1000_hw *hw, u16 addr, u16 *data)
+{
+	DEBUGFUNC("e1000_read_emi_reg_locked");
+
+	return __e1000_access_emi_reg_locked(hw, addr, data, TRUE);
+}
+
+/**
+ *  e1000_write_emi_reg_locked - Write Extended Management Interface register
+ *  @hw: pointer to the HW structure
+ *  @addr: EMI address to program
+ *  @data: value to be written to the EMI address
+ *
+ *  Assumes the SW/FW/HW Semaphore is already acquired.
+ **/
+static s32 e1000_write_emi_reg_locked(struct e1000_hw *hw, u16 addr, u16 data)
+{
+	DEBUGFUNC("e1000_read_emi_reg_locked");
+
+	return __e1000_access_emi_reg_locked(hw, addr, &data, FALSE);
+}
+
+/**
  *  e1000_set_eee_pchlan - Enable/disable EEE support
  *  @hw: pointer to the HW structure
  *
- *  Enable/disable EEE based on setting in dev_spec structure.  The bits in
- *  the LPI Control register will remain set only if/when link is up.
+ *  Enable/disable EEE based on setting in dev_spec structure, the duplex of
+ *  the link and the EEE capabilities of the link partner.  The LPI Control
+ *  register bits will remain set only if/when link is up.
  **/
 static s32 e1000_set_eee_pchlan(struct e1000_hw *hw)
 {
 	struct e1000_dev_spec_ich8lan *dev_spec = &hw->dev_spec.ich8lan;
-	s32 ret_val = E1000_SUCCESS;
-	u16 phy_reg;
+	s32 ret_val;
+	u16 lpi_ctrl;
 
 	DEBUGFUNC("e1000_set_eee_pchlan");
 
-	if (hw->phy.type != e1000_phy_82579)
-		goto out;
+	if ((hw->phy.type != e1000_phy_82579) &&
+	    (hw->phy.type != e1000_phy_i217))
+		return E1000_SUCCESS;
 
-	ret_val = hw->phy.ops.read_reg(hw, I82579_LPI_CTRL, &phy_reg);
+	ret_val = hw->phy.ops.acquire(hw);
 	if (ret_val)
-		goto out;
+		return ret_val;
 
-	if (dev_spec->eee_disable)
-		phy_reg &= ~I82579_LPI_CTRL_ENABLE_MASK;
-	else
-		phy_reg |= I82579_LPI_CTRL_ENABLE_MASK;
+	ret_val = hw->phy.ops.read_reg_locked(hw, I82579_LPI_CTRL, &lpi_ctrl);
+	if (ret_val)
+		goto release;
+
+	/* Clear bits that enable EEE in various speeds */
+	lpi_ctrl &= ~I82579_LPI_CTRL_ENABLE_MASK;
+
+	/* Enable EEE if not disabled by user */
+	if (!dev_spec->eee_disable) {
+		u16 lpa, pcs_status, data;
+
+		/* Save off link partner's EEE ability */
+		switch (hw->phy.type) {
+		case e1000_phy_82579:
+			lpa = I82579_EEE_LP_ABILITY;
+			pcs_status = I82579_EEE_PCS_STATUS;
+			break;
+		case e1000_phy_i217:
+			lpa = I217_EEE_LP_ABILITY;
+			pcs_status = I217_EEE_PCS_STATUS;
+			break;
+		default:
+			ret_val = -E1000_ERR_PHY;
+			goto release;
+		}
+		ret_val = e1000_read_emi_reg_locked(hw, lpa,
+						    &dev_spec->eee_lp_ability);
+		if (ret_val)
+			goto release;
+
+		/* Enable EEE only for speeds in which the link partner is
+		 * EEE capable.
+		 */
+		if (dev_spec->eee_lp_ability & I82579_EEE_1000_SUPPORTED)
+			lpi_ctrl |= I82579_LPI_CTRL_1000_ENABLE;
+
+		if (dev_spec->eee_lp_ability & I82579_EEE_100_SUPPORTED) {
+			hw->phy.ops.read_reg_locked(hw, PHY_LP_ABILITY, &data);
+			if (data & NWAY_LPAR_100TX_FD_CAPS)
+				lpi_ctrl |= I82579_LPI_CTRL_100_ENABLE;
+			else
+				/* EEE is not supported in 100Half, so ignore
+				 * partner's EEE in 100 ability if full-duplex
+				 * is not advertised.
+				 */
+				dev_spec->eee_lp_ability &=
+				    ~I82579_EEE_100_SUPPORTED;
+		}
+
+		/* R/Clr IEEE MMD 3.1 bits 11:10 - Tx/Rx LPI Received */
+		ret_val = e1000_read_emi_reg_locked(hw, pcs_status, &data);
+		if (ret_val)
+			goto release;
+	}
+
+	ret_val = hw->phy.ops.write_reg_locked(hw, I82579_LPI_CTRL, lpi_ctrl);
+release:
+	hw->phy.ops.release(hw);
 
-	ret_val = hw->phy.ops.write_reg(hw, I82579_LPI_CTRL, phy_reg);
-out:
 	return ret_val;
 }
 
 /**
+ *  e1000_k1_workaround_lpt_lp - K1 workaround on Lynxpoint-LP
+ *  @hw:   pointer to the HW structure
+ *  @link: link up bool flag
+ *
+ *  When K1 is enabled for 1Gbps, the MAC can miss 2 DMA completion indications
+ *  preventing further DMA write requests.  Workaround the issue by disabling
+ *  the de-assertion of the clock request when in 1Gpbs mode.
+ **/
+static s32 e1000_k1_workaround_lpt_lp(struct e1000_hw *hw, bool link)
+{
+	u32 fextnvm6 = E1000_READ_REG(hw, E1000_FEXTNVM6);
+	s32 ret_val = E1000_SUCCESS;
+
+	if (link && (E1000_READ_REG(hw, E1000_STATUS) &
+		     E1000_STATUS_SPEED_1000)) {
+		u16 kmrn_reg;
+
+		ret_val = hw->phy.ops.acquire(hw);
+		if (ret_val)
+			return ret_val;
+
+		ret_val =
+		    e1000_read_kmrn_reg_locked(hw, E1000_KMRNCTRLSTA_K1_CONFIG,
+					       &kmrn_reg);
+		if (ret_val)
+			goto release;
+
+		ret_val =
+		    e1000_write_kmrn_reg_locked(hw,
+						E1000_KMRNCTRLSTA_K1_CONFIG,
+						kmrn_reg &
+						~E1000_KMRNCTRLSTA_K1_ENABLE);
+		if (ret_val)
+			goto release;
+
+		usec_delay(10);
+
+		E1000_WRITE_REG(hw, E1000_FEXTNVM6,
+				fextnvm6 | E1000_FEXTNVM6_REQ_PLL_CLK);
+
+		ret_val =
+		    e1000_write_kmrn_reg_locked(hw,
+						E1000_KMRNCTRLSTA_K1_CONFIG,
+						kmrn_reg);
+release:
+		hw->phy.ops.release(hw);
+	} else {
+		/* clear FEXTNVM6 bit 8 on link down or 10/100 */
+		E1000_WRITE_REG(hw, E1000_FEXTNVM6,
+				fextnvm6 & ~E1000_FEXTNVM6_REQ_PLL_CLK);
+	}
+
+	return ret_val;
+}
+
+static u64 e1000_ltr2ns(u16 ltr)
+{
+	u32 value, scale;
+
+	/* Determine the latency in nsec based on the LTR value & scale */
+	value = ltr & E1000_LTRV_VALUE_MASK;
+	scale = (ltr & E1000_LTRV_SCALE_MASK) >> E1000_LTRV_SCALE_SHIFT;
+
+	return value * (1 << (scale * E1000_LTRV_SCALE_FACTOR));
+}
+
+/**
+ *  e1000_platform_pm_pch_lpt - Set platform power management values
+ *  @hw: pointer to the HW structure
+ *  @link: bool indicating link status
+ *
+ *  Set the Latency Tolerance Reporting (LTR) values for the "PCIe-like"
+ *  GbE MAC in the Lynx Point PCH based on Rx buffer size and link speed
+ *  when link is up (which must not exceed the maximum latency supported
+ *  by the platform), otherwise specify there is no LTR requirement.
+ *  Unlike TRUE-PCIe devices which set the LTR maximum snoop/no-snoop
+ *  latencies in the LTR Extended Capability Structure in the PCIe Extended
+ *  Capability register set, on this device LTR is set by writing the
+ *  equivalent snoop/no-snoop latencies in the LTRV register in the MAC and
+ *  set the SEND bit to send an Intel On-chip System Fabric sideband (IOSF-SB)
+ *  message to the PMC.
+ *
+ *  Use the LTR value to calculate the Optimized Buffer Flush/Fill (OBFF)
+ *  high-water mark.
+ **/
+static s32 e1000_platform_pm_pch_lpt(struct e1000_hw *hw, bool link)
+{
+	u32 reg = link << (E1000_LTRV_REQ_SHIFT + E1000_LTRV_NOSNOOP_SHIFT) |
+		  link << E1000_LTRV_REQ_SHIFT | E1000_LTRV_SEND;
+	u16 lat_enc = 0;	/* latency encoded */
+	s32 obff_hwm = 0;
+
+	DEBUGFUNC("e1000_platform_pm_pch_lpt");
+
+	if (link) {
+		u16 speed, duplex, scale = 0;
+		u16 max_snoop, max_nosnoop;
+		u16 max_ltr_enc;	/* max LTR latency encoded */
+		s64 lat_ns;		/* latency (ns) */
+		s64 value;
+		u32 rxa;
+
+		if (!hw->mac.max_frame_size) {
+			DEBUGOUT("max_frame_size not set.\n");
+			return -E1000_ERR_CONFIG;
+		}
+
+		hw->mac.ops.get_link_up_info(hw, &speed, &duplex);
+		if (!speed) {
+			DEBUGOUT("Speed not set.\n");
+			return -E1000_ERR_CONFIG;
+		}
+
+		/* Rx Packet Buffer Allocation size (KB) */
+		rxa = E1000_READ_REG(hw, E1000_PBA) & E1000_PBA_RXA_MASK;
+
+		/* Determine the maximum latency tolerated by the device.
+		 *
+		 * Per the PCIe spec, the tolerated latencies are encoded as
+		 * a 3-bit encoded scale (only 0-5 are valid) multiplied by
+		 * a 10-bit value (0-1023) to provide a range from 1 ns to
+		 * 2^25*(2^10-1) ns.  The scale is encoded as 0=2^0ns,
+		 * 1=2^5ns, 2=2^10ns,...5=2^25ns.
+		 */
+		lat_ns = ((s64)rxa * 1024 -
+			  (2 * (s64)hw->mac.max_frame_size)) * 8 * 1000;
+		if (lat_ns < 0)
+			lat_ns = 0;
+		else
+			lat_ns /= speed;
+
+		value = lat_ns;
+		while (value > E1000_LTRV_VALUE_MASK) {
+			scale++;
+			value = E1000_DIVIDE_ROUND_UP(value, (1 << 5));
+		}
+		if (scale > E1000_LTRV_SCALE_MAX) {
+			DEBUGOUT1("Invalid LTR latency scale %d\n", scale);
+			return -E1000_ERR_CONFIG;
+		}
+		lat_enc = (u16)((scale << E1000_LTRV_SCALE_SHIFT) | value);
+
+		/* Determine the maximum latency tolerated by the platform */
+		e1000_read_pci_cfg(hw, E1000_PCI_LTR_CAP_LPT, &max_snoop);
+		e1000_read_pci_cfg(hw, E1000_PCI_LTR_CAP_LPT + 2, &max_nosnoop);
+		max_ltr_enc = E1000_MAX(max_snoop, max_nosnoop);
+
+		if (lat_enc > max_ltr_enc) {
+			lat_enc = max_ltr_enc;
+			lat_ns = e1000_ltr2ns(max_ltr_enc);
+		}
+
+		if (lat_ns) {
+			lat_ns *= speed * 1000;
+			lat_ns /= 8;
+			lat_ns /= 1000000000;
+			obff_hwm = (s32)(rxa - lat_ns);
+		}
+
+		if ((obff_hwm < 0) || (obff_hwm > E1000_SVT_OFF_HWM_MASK)) {
+			DEBUGOUT1("Invalid high water mark %d\n", obff_hwm);
+			return -E1000_ERR_CONFIG;
+		}
+	}
+
+	/* Set Snoop and No-Snoop latencies the same */
+	reg |= lat_enc | (lat_enc << E1000_LTRV_NOSNOOP_SHIFT);
+	E1000_WRITE_REG(hw, E1000_LTRV, reg);
+
+	/* Set OBFF high water mark */
+	reg = E1000_READ_REG(hw, E1000_SVT) & ~E1000_SVT_OFF_HWM_MASK;
+	reg |= obff_hwm;
+	E1000_WRITE_REG(hw, E1000_SVT, reg);
+
+	/* Enable OBFF */
+	reg = E1000_READ_REG(hw, E1000_SVCR);
+	reg |= E1000_SVCR_OFF_EN;
+	/* Always unblock interrupts to the CPU even when the system is
+	 * in OBFF mode. This ensures that small round-robin traffic
+	 * (like ping) does not get dropped or experience long latency.
+	 */
+	reg |= E1000_SVCR_OFF_MASKINT;
+	E1000_WRITE_REG(hw, E1000_SVCR, reg);
+
+	return E1000_SUCCESS;
+}
+
+/**
+ *  e1000_set_obff_timer_pch_lpt - Update Optimized Buffer Flush/Fill timer
+ *  @hw: pointer to the HW structure
+ *  @itr: interrupt throttling rate
+ *
+ *  Configure OBFF with the updated interrupt rate.
+ **/
+static s32 e1000_set_obff_timer_pch_lpt(struct e1000_hw *hw, u32 itr)
+{
+	u32 svcr;
+	s32 timer;
+
+	DEBUGFUNC("e1000_set_obff_timer_pch_lpt");
+
+	/* Convert ITR value into microseconds for OBFF timer */
+	timer = itr & E1000_ITR_MASK;
+	timer = (timer * E1000_ITR_MULT) / 1000;
+
+	if ((timer < 0) || (timer > E1000_ITR_MASK)) {
+		DEBUGOUT1("Invalid OBFF timer %d\n", timer);
+		return -E1000_ERR_CONFIG;
+	}
+
+	svcr = E1000_READ_REG(hw, E1000_SVCR);
+	svcr &= ~E1000_SVCR_OFF_TIMER_MASK;
+	svcr |= timer << E1000_SVCR_OFF_TIMER_SHIFT;
+	E1000_WRITE_REG(hw, E1000_SVCR, svcr);
+
+	return E1000_SUCCESS;
+}
+
+/**
  *  e1000_check_for_copper_link_ich8lan - Check for link (Copper)
  *  @hw: pointer to the HW structure
  *
@@ -645,39 +1095,77 @@ static s32 e1000_check_for_copper_link_ich8lan(struct e1000_hw *hw)
 
 	DEBUGFUNC("e1000_check_for_copper_link_ich8lan");
 
-	/*
-	 * We only want to go out to the PHY registers to see if Auto-Neg
+	/* We only want to go out to the PHY registers to see if Auto-Neg
 	 * has completed and/or if our link status has changed.  The
 	 * get_link_status flag is set upon receiving a Link Status
 	 * Change or Rx Sequence Error interrupt.
 	 */
-	if (!mac->get_link_status) {
-		ret_val = E1000_SUCCESS;
-		goto out;
-	}
+	if (!mac->get_link_status)
+		return E1000_SUCCESS;
 
-	/*
-	 * First we want to see if the MII Status Register reports
+	/* First we want to see if the MII Status Register reports
 	 * link.  If so, then we want to get the current speed/duplex
 	 * of the PHY.
 	 */
 	ret_val = e1000_phy_has_link_generic(hw, 1, 0, &link);
 	if (ret_val)
-		goto out;
+		return ret_val;
+
+	if (hw->mac.type == e1000_pchlan) {
+		ret_val = e1000_k1_gig_workaround_hv(hw, link);
+		if (ret_val)
+			return ret_val;
+	}
+
+	/* When connected at 10Mbps half-duplex, 82579 parts are excessively
+	 * aggressive resulting in many collisions. To avoid this, increase
+	 * the IPG and reduce Rx latency in the PHY.
+	 */
+	if ((hw->mac.type == e1000_pch2lan) && link) {
+		u32 reg;
+		reg = E1000_READ_REG(hw, E1000_STATUS);
+		if (!(reg & (E1000_STATUS_FD | E1000_STATUS_SPEED_MASK))) {
+			reg = E1000_READ_REG(hw, E1000_TIPG);
+			reg &= ~E1000_TIPG_IPGT_MASK;
+			reg |= 0xFF;
+			E1000_WRITE_REG(hw, E1000_TIPG, reg);
+
+			/* Reduce Rx latency in analog PHY */
+			ret_val = hw->phy.ops.acquire(hw);
+			if (ret_val)
+				return ret_val;
+
+			ret_val = e1000_write_emi_reg_locked(hw, I82579_RX_CONFIG, 0);
+
+			hw->phy.ops.release(hw);
+
+			if (ret_val)
+				return ret_val;
+		}
+	}
 
-	if (hw->mac.type == e1000_pchlan) {
-		ret_val = e1000_k1_gig_workaround_hv(hw, link);
+	/* Work-around I218 hang issue */
+	if ((hw->device_id == E1000_DEV_ID_PCH_LPTLP_I218_LM) ||
+	    (hw->device_id == E1000_DEV_ID_PCH_LPTLP_I218_V)) {
+		ret_val = e1000_k1_workaround_lpt_lp(hw, link);
 		if (ret_val)
-			goto out;
+			return ret_val;
 	}
 
-#if defined(NAHUM6_HW) && (defined(LTR_SUPPORT) || defined(OBFF_SUPPORT))
 	if (hw->mac.type == e1000_pch_lpt) {
+		/* Set platform power management values for Latency Tolerance
+		 * Reporting (LTR) and Optimized Buffer Flush/Fill (OBFF).
+		 */
+		ret_val = e1000_platform_pm_pch_lpt(hw, link);
+		if (ret_val)
+			return ret_val;
 	}
 
-#endif /* NAHUM6_HW && (LTR_SUPPORT || OBFF_SUPPORT) */
+	/* Clear link partner's EEE ability */
+	hw->dev_spec.ich8lan.eee_lp_ability = 0;
+
 	if (!link)
-		goto out; /* No link detected */
+		return E1000_SUCCESS; /* No link detected */
 
 	mac->get_link_status = FALSE;
 
@@ -685,17 +1173,16 @@ static s32 e1000_check_for_copper_link_ich8lan(struct e1000_hw *hw)
 	case e1000_pch2lan:
 		ret_val = e1000_k1_workaround_lv(hw);
 		if (ret_val)
-			goto out;
+			return ret_val;
 		/* fall-thru */
 	case e1000_pchlan:
 		if (hw->phy.type == e1000_phy_82578) {
 			ret_val = e1000_link_stall_workaround_hv(hw);
 			if (ret_val)
-				goto out;
+				return ret_val;
 		}
 
-		/*
-		 * Workaround for PCHx parts in half-duplex:
+		/* Workaround for PCHx parts in half-duplex:
 		 * Set the number of preambles removed from the packet
 		 * when it is passed from the PHY to the MAC to prevent
 		 * the MAC from misinterpreting the packet type.
@@ -713,8 +1200,7 @@ static s32 e1000_check_for_copper_link_ich8lan(struct e1000_hw *hw)
 		break;
 	}
 
-	/*
-	 * Check if there was DownShift, must be checked
+	/* Check if there was DownShift, must be checked
 	 * immediately after link-up
 	 */
 	e1000_check_downshift_generic(hw);
@@ -722,26 +1208,21 @@ static s32 e1000_check_for_copper_link_ich8lan(struct e1000_hw *hw)
 	/* Enable/Disable EEE after link up */
 	ret_val = e1000_set_eee_pchlan(hw);
 	if (ret_val)
-		goto out;
+		return ret_val;
 
-	/*
-	 * If we are forcing speed/duplex, then we simply return since
+	/* If we are forcing speed/duplex, then we simply return since
 	 * we have already determined whether we have link or not.
 	 */
-	if (!mac->autoneg) {
-		ret_val = -E1000_ERR_CONFIG;
-		goto out;
-	}
+	if (!mac->autoneg)
+		return -E1000_ERR_CONFIG;
 
-	/*
-	 * Auto-Neg is enabled.  Auto Speed Detection takes care
+	/* Auto-Neg is enabled.  Auto Speed Detection takes care
 	 * of MAC speed/duplex configuration.  So we only need to
 	 * configure Collision Distance in the MAC.
 	 */
-	e1000_config_collision_dist_generic(hw);
+	mac->ops.config_collision_dist(hw);
 
-	/*
-	 * Configure Flow Control now that Auto-Neg has completed.
+	/* Configure Flow Control now that Auto-Neg has completed.
 	 * First, we need to restore the desired flow control
 	 * settings because we may have had to re-autoneg with a
 	 * different link partner.
@@ -750,7 +1231,6 @@ static s32 e1000_check_for_copper_link_ich8lan(struct e1000_hw *hw)
 	if (ret_val)
 		DEBUGOUT("Error configuring flow control\n");
 
-out:
 	return ret_val;
 }
 
@@ -774,6 +1254,7 @@ void e1000_init_function_pointers_ich8lan(struct e1000_hw *hw)
 		break;
 	case e1000_pchlan:
 	case e1000_pch2lan:
+	case e1000_pch_lpt:
 		hw->phy.ops.init_params = e1000_init_phy_params_pchlan;
 		break;
 	default:
@@ -957,8 +1438,7 @@ static void e1000_rar_set_pch2lan(struct e1000_hw *hw, u8 *addr, u32 index)
 
 	DEBUGFUNC("e1000_rar_set_pch2lan");
 
-	/*
-	 * HW expects these in little endian so we reverse the byte order
+	/* HW expects these in little endian so we reverse the byte order
 	 * from network order (big endian) to little endian
 	 */
 	rar_low = ((u32) addr[0] |
@@ -980,11 +1460,19 @@ static void e1000_rar_set_pch2lan(struct e1000_hw *hw, u8 *addr, u32 index)
 	}
 
 	if (index < hw->mac.rar_entry_count) {
+		s32 ret_val;
+
+		ret_val = e1000_acquire_swflag_ich8lan(hw);
+		if (ret_val)
+			goto out;
+
 		E1000_WRITE_REG(hw, E1000_SHRAL(index - 1), rar_low);
 		E1000_WRITE_FLUSH(hw);
 		E1000_WRITE_REG(hw, E1000_SHRAH(index - 1), rar_high);
 		E1000_WRITE_FLUSH(hw);
 
+		e1000_release_swflag_ich8lan(hw);
+
 		/* verify the register updates */
 		if ((E1000_READ_REG(hw, E1000_SHRAL(index - 1)) == rar_low) &&
 		    (E1000_READ_REG(hw, E1000_SHRAH(index - 1)) == rar_high))
@@ -994,6 +1482,85 @@ static void e1000_rar_set_pch2lan(struct e1000_hw *hw, u8 *addr, u32 index)
 			 (index - 1), E1000_READ_REG(hw, E1000_FWSM));
 	}
 
+out:
+	DEBUGOUT1("Failed to write receive address at index %d\n", index);
+}
+
+/**
+ *  e1000_rar_set_pch_lpt - Set receive address registers
+ *  @hw: pointer to the HW structure
+ *  @addr: pointer to the receive address
+ *  @index: receive address array register
+ *
+ *  Sets the receive address register array at index to the address passed
+ *  in by addr. For LPT, RAR[0] is the base address register that is to
+ *  contain the MAC address. SHRA[0-10] are the shared receive address
+ *  registers that are shared between the Host and manageability engine (ME).
+ **/
+static void e1000_rar_set_pch_lpt(struct e1000_hw *hw, u8 *addr, u32 index)
+{
+	u32 rar_low, rar_high;
+	u32 wlock_mac;
+
+	DEBUGFUNC("e1000_rar_set_pch_lpt");
+
+	/* HW expects these in little endian so we reverse the byte order
+	 * from network order (big endian) to little endian
+	 */
+	rar_low = ((u32) addr[0] | ((u32) addr[1] << 8) |
+		   ((u32) addr[2] << 16) | ((u32) addr[3] << 24));
+
+	rar_high = ((u32) addr[4] | ((u32) addr[5] << 8));
+
+	/* If MAC address zero, no need to set the AV bit */
+	if (rar_low || rar_high)
+		rar_high |= E1000_RAH_AV;
+
+	if (index == 0) {
+		E1000_WRITE_REG(hw, E1000_RAL(index), rar_low);
+		E1000_WRITE_FLUSH(hw);
+		E1000_WRITE_REG(hw, E1000_RAH(index), rar_high);
+		E1000_WRITE_FLUSH(hw);
+		return;
+	}
+
+	/* The manageability engine (ME) can lock certain SHRAR registers that
+	 * it is using - those registers are unavailable for use.
+	 */
+	if (index < hw->mac.rar_entry_count) {
+		wlock_mac = E1000_READ_REG(hw, E1000_FWSM) &
+			    E1000_FWSM_WLOCK_MAC_MASK;
+		wlock_mac >>= E1000_FWSM_WLOCK_MAC_SHIFT;
+
+		/* Check if all SHRAR registers are locked */
+		if (wlock_mac == 1)
+			goto out;
+
+		if ((wlock_mac == 0) || (index <= wlock_mac)) {
+			s32 ret_val;
+
+			ret_val = e1000_acquire_swflag_ich8lan(hw);
+
+			if (ret_val)
+				goto out;
+
+			E1000_WRITE_REG(hw, E1000_SHRAL_PCH_LPT(index - 1),
+					rar_low);
+			E1000_WRITE_FLUSH(hw);
+			E1000_WRITE_REG(hw, E1000_SHRAH_PCH_LPT(index - 1),
+					rar_high);
+			E1000_WRITE_FLUSH(hw);
+
+			e1000_release_swflag_ich8lan(hw);
+
+			/* verify the register updates */
+			if ((E1000_READ_REG(hw, E1000_SHRAL_PCH_LPT(index - 1)) == rar_low) &&
+			    (E1000_READ_REG(hw, E1000_SHRAH_PCH_LPT(index - 1)) == rar_high))
+				return;
+		}
+	}
+
+out:
 	DEBUGOUT1("Failed to write receive address at index %d\n", index);
 }
 
@@ -1072,21 +1639,34 @@ static s32 e1000_write_smbus_addr(struct e1000_hw *hw)
 {
 	u16 phy_data;
 	u32 strap = E1000_READ_REG(hw, E1000_STRAP);
-	s32 ret_val = E1000_SUCCESS;
+	u32 freq = (strap & E1000_STRAP_SMT_FREQ_MASK) >>
+		E1000_STRAP_SMT_FREQ_SHIFT;
+	s32 ret_val;
 
 	strap &= E1000_STRAP_SMBUS_ADDRESS_MASK;
 
 	ret_val = e1000_read_phy_reg_hv_locked(hw, HV_SMB_ADDR, &phy_data);
 	if (ret_val)
-		goto out;
+		return ret_val;
 
 	phy_data &= ~HV_SMB_ADDR_MASK;
 	phy_data |= (strap >> E1000_STRAP_SMBUS_ADDRESS_SHIFT);
 	phy_data |= HV_SMB_ADDR_PEC_EN | HV_SMB_ADDR_VALID;
-	ret_val = e1000_write_phy_reg_hv_locked(hw, HV_SMB_ADDR, phy_data);
 
-out:
-	return ret_val;
+	if (hw->phy.type == e1000_phy_i217) {
+		/* Restore SMBus frequency */
+		if (freq--) {
+			phy_data &= ~HV_SMB_ADDR_FREQ_MASK;
+			phy_data |= (freq & (1 << 0)) <<
+				HV_SMB_ADDR_FREQ_LOW_SHIFT;
+			phy_data |= (freq & (1 << 1)) <<
+				(HV_SMB_ADDR_FREQ_HIGH_SHIFT - 1);
+		} else {
+			DEBUGOUT("Unsupported SMB frequency in PHY\n");
+		}
+	}
+
+	return e1000_write_phy_reg_hv_locked(hw, HV_SMB_ADDR, phy_data);
 }
 
 /**
@@ -1105,8 +1685,7 @@ static s32 e1000_sw_lcd_config_ich8lan(struct e1000_hw *hw)
 
 	DEBUGFUNC("e1000_sw_lcd_config_ich8lan");
 
-	/*
-	 * Initialize the PHY from the NVM on ICH platforms.  This
+	/* Initialize the PHY from the NVM on ICH platforms.  This
 	 * is needed due to an issue where the NVM configuration is
 	 * not properly autoloaded after power transitions.
 	 * Therefore, after each PHY reset, we will load the
@@ -1125,6 +1704,7 @@ static s32 e1000_sw_lcd_config_ich8lan(struct e1000_hw *hw)
 		/* Fall-thru */
 	case e1000_pchlan:
 	case e1000_pch2lan:
+	case e1000_pch_lpt:
 		sw_cfg_mask = E1000_FEXTNVM_SW_CONFIG_ICH8M;
 		break;
 	default:
@@ -1137,45 +1717,42 @@ static s32 e1000_sw_lcd_config_ich8lan(struct e1000_hw *hw)
 
 	data = E1000_READ_REG(hw, E1000_FEXTNVM);
 	if (!(data & sw_cfg_mask))
-		goto out;
+		goto release;
 
-	/*
-	 * Make sure HW does not configure LCD from PHY
+	/* Make sure HW does not configure LCD from PHY
 	 * extended configuration before SW configuration
 	 */
 	data = E1000_READ_REG(hw, E1000_EXTCNF_CTRL);
-	if (!(hw->mac.type == e1000_pch2lan)) {
-		if (data & E1000_EXTCNF_CTRL_LCD_WRITE_ENABLE)
-			goto out;
-	}
+	if ((hw->mac.type < e1000_pch2lan) &&
+	    (data & E1000_EXTCNF_CTRL_LCD_WRITE_ENABLE))
+			goto release;
 
 	cnf_size = E1000_READ_REG(hw, E1000_EXTCNF_SIZE);
 	cnf_size &= E1000_EXTCNF_SIZE_EXT_PCIE_LENGTH_MASK;
 	cnf_size >>= E1000_EXTCNF_SIZE_EXT_PCIE_LENGTH_SHIFT;
 	if (!cnf_size)
-		goto out;
+		goto release;
 
 	cnf_base_addr = data & E1000_EXTCNF_CTRL_EXT_CNF_POINTER_MASK;
 	cnf_base_addr >>= E1000_EXTCNF_CTRL_EXT_CNF_POINTER_SHIFT;
 
-	if ((!(data & E1000_EXTCNF_CTRL_OEM_WRITE_ENABLE) &&
-	    (hw->mac.type == e1000_pchlan)) ||
-	     (hw->mac.type == e1000_pch2lan)) {
-		/*
-		 * HW configures the SMBus address and LEDs when the
+	if (((hw->mac.type == e1000_pchlan) &&
+	     !(data & E1000_EXTCNF_CTRL_OEM_WRITE_ENABLE)) ||
+	    (hw->mac.type > e1000_pchlan)) {
+		/* HW configures the SMBus address and LEDs when the
 		 * OEM and LCD Write Enable bits are set in the NVM.
 		 * When both NVM bits are cleared, SW will configure
 		 * them instead.
 		 */
 		ret_val = e1000_write_smbus_addr(hw);
 		if (ret_val)
-			goto out;
+			goto release;
 
 		data = E1000_READ_REG(hw, E1000_LEDCTL);
 		ret_val = e1000_write_phy_reg_hv_locked(hw, HV_LED_CONFIG,
 							(u16)data);
 		if (ret_val)
-			goto out;
+			goto release;
 	}
 
 	/* Configure LCD from extended configuration region. */
@@ -1187,12 +1764,12 @@ static s32 e1000_sw_lcd_config_ich8lan(struct e1000_hw *hw)
 		ret_val = hw->nvm.ops.read(hw, (word_addr + i * 2), 1,
 					   &reg_data);
 		if (ret_val)
-			goto out;
+			goto release;
 
 		ret_val = hw->nvm.ops.read(hw, (word_addr + i * 2 + 1),
 					   1, &reg_addr);
 		if (ret_val)
-			goto out;
+			goto release;
 
 		/* Save off the PHY page for future writes. */
 		if (reg_addr == IGP01E1000_PHY_PAGE_SELECT) {
@@ -1206,10 +1783,10 @@ static s32 e1000_sw_lcd_config_ich8lan(struct e1000_hw *hw)
 		ret_val = phy->ops.write_reg_locked(hw, (u32)reg_addr,
 						    reg_data);
 		if (ret_val)
-			goto out;
+			goto release;
 	}
 
-out:
+release:
 	hw->phy.ops.release(hw);
 	return ret_val;
 }
@@ -1233,12 +1810,12 @@ static s32 e1000_k1_gig_workaround_hv(struct e1000_hw *hw, bool link)
 	DEBUGFUNC("e1000_k1_gig_workaround_hv");
 
 	if (hw->mac.type != e1000_pchlan)
-		goto out;
+		return E1000_SUCCESS;
 
 	/* Wrap the whole flow with the sw flag */
 	ret_val = hw->phy.ops.acquire(hw);
 	if (ret_val)
-		goto out;
+		return ret_val;
 
 	/* Disable K1 when link is 1Gbps, otherwise use the NVM setting */
 	if (link) {
@@ -1292,7 +1869,7 @@ static s32 e1000_k1_gig_workaround_hv(struct e1000_hw *hw, bool link)
 
 release:
 	hw->phy.ops.release(hw);
-out:
+
 	return ret_val;
 }
 
@@ -1308,7 +1885,7 @@ out:
  **/
 s32 e1000_configure_k1_ich8lan(struct e1000_hw *hw, bool k1_enable)
 {
-	s32 ret_val = E1000_SUCCESS;
+	s32 ret_val;
 	u32 ctrl_reg = 0;
 	u32 ctrl_ext = 0;
 	u32 reg = 0;
@@ -1319,7 +1896,7 @@ s32 e1000_configure_k1_ich8lan(struct e1000_hw *hw, bool k1_enable)
 	ret_val = e1000_read_kmrn_reg_locked(hw, E1000_KMRNCTRLSTA_K1_CONFIG,
 					     &kmrn_reg);
 	if (ret_val)
-		goto out;
+		return ret_val;
 
 	if (k1_enable)
 		kmrn_reg |= E1000_KMRNCTRLSTA_K1_ENABLE;
@@ -1329,7 +1906,7 @@ s32 e1000_configure_k1_ich8lan(struct e1000_hw *hw, bool k1_enable)
 	ret_val = e1000_write_kmrn_reg_locked(hw, E1000_KMRNCTRLSTA_K1_CONFIG,
 					      kmrn_reg);
 	if (ret_val)
-		goto out;
+		return ret_val;
 
 	usec_delay(20);
 	ctrl_ext = E1000_READ_REG(hw, E1000_CTRL_EXT);
@@ -1347,8 +1924,7 @@ s32 e1000_configure_k1_ich8lan(struct e1000_hw *hw, bool k1_enable)
 	E1000_WRITE_FLUSH(hw);
 	usec_delay(20);
 
-out:
-	return ret_val;
+	return E1000_SUCCESS;
 }
 
 /**
@@ -1368,28 +1944,28 @@ static s32 e1000_oem_bits_config_ich8lan(struct e1000_hw *hw, bool d0_state)
 
 	DEBUGFUNC("e1000_oem_bits_config_ich8lan");
 
-	if ((hw->mac.type != e1000_pch2lan) && (hw->mac.type != e1000_pchlan))
+	if (hw->mac.type < e1000_pchlan)
 		return ret_val;
 
 	ret_val = hw->phy.ops.acquire(hw);
 	if (ret_val)
 		return ret_val;
 
-	if (!(hw->mac.type == e1000_pch2lan)) {
+	if (hw->mac.type == e1000_pchlan) {
 		mac_reg = E1000_READ_REG(hw, E1000_EXTCNF_CTRL);
 		if (mac_reg & E1000_EXTCNF_CTRL_OEM_WRITE_ENABLE)
-			goto out;
+			goto release;
 	}
 
 	mac_reg = E1000_READ_REG(hw, E1000_FEXTNVM);
 	if (!(mac_reg & E1000_FEXTNVM_SW_CONFIG_ICH8M))
-		goto out;
+		goto release;
 
 	mac_reg = E1000_READ_REG(hw, E1000_PHY_CTRL);
 
 	ret_val = hw->phy.ops.read_reg_locked(hw, HV_OEM_BITS, &oem_reg);
 	if (ret_val)
-		goto out;
+		goto release;
 
 	oem_reg &= ~(HV_OEM_BITS_GBE_DIS | HV_OEM_BITS_LPLU);
 
@@ -1399,10 +1975,6 @@ static s32 e1000_oem_bits_config_ich8lan(struct e1000_hw *hw, bool d0_state)
 
 		if (mac_reg & E1000_PHY_CTRL_D0A_LPLU)
 			oem_reg |= HV_OEM_BITS_LPLU;
-
-		/* Set Restart auto-neg to activate the bits */
-		if (!hw->phy.ops.check_reset_block(hw))
-			oem_reg |= HV_OEM_BITS_RESTART_AN;
 	} else {
 		if (mac_reg & (E1000_PHY_CTRL_GBE_DISABLE |
 		    E1000_PHY_CTRL_NOND0A_GBE_DISABLE))
@@ -1413,9 +1985,14 @@ static s32 e1000_oem_bits_config_ich8lan(struct e1000_hw *hw, bool d0_state)
 			oem_reg |= HV_OEM_BITS_LPLU;
 	}
 
+	/* Set Restart auto-neg to activate the bits */
+	if ((d0_state || (hw->mac.type != e1000_pchlan)) &&
+	    !hw->phy.ops.check_reset_block(hw))
+		oem_reg |= HV_OEM_BITS_RESTART_AN;
+
 	ret_val = hw->phy.ops.write_reg_locked(hw, HV_OEM_BITS, oem_reg);
 
-out:
+release:
 	hw->phy.ops.release(hw);
 
 	return ret_val;
@@ -1456,13 +2033,13 @@ static s32 e1000_hv_phy_workarounds_ich8lan(struct e1000_hw *hw)
 	DEBUGFUNC("e1000_hv_phy_workarounds_ich8lan");
 
 	if (hw->mac.type != e1000_pchlan)
-		goto out;
+		return E1000_SUCCESS;
 
 	/* Set MDIO slow mode before any other MDIO access */
 	if (hw->phy.type == e1000_phy_82577) {
 		ret_val = e1000_set_mdio_slow_mode_hv(hw);
 		if (ret_val)
-			goto out;
+			return ret_val;
 	}
 
 	if (((hw->phy.type == e1000_phy_82577) &&
@@ -1471,18 +2048,17 @@ static s32 e1000_hv_phy_workarounds_ich8lan(struct e1000_hw *hw)
 		/* Disable generation of early preamble */
 		ret_val = hw->phy.ops.write_reg(hw, PHY_REG(769, 25), 0x4431);
 		if (ret_val)
-			goto out;
+			return ret_val;
 
 		/* Preamble tuning for SSC */
 		ret_val = hw->phy.ops.write_reg(hw, HV_KMRN_FIFO_CTRLSTA,
 						0xA204);
 		if (ret_val)
-			goto out;
+			return ret_val;
 	}
 
 	if (hw->phy.type == e1000_phy_82578) {
-		/*
-		 * Return registers to default by doing a soft reset then
+		/* Return registers to default by doing a soft reset then
 		 * writing 0x3140 to the control register.
 		 */
 		if (hw->phy.revision < 2) {
@@ -1495,34 +2071,38 @@ static s32 e1000_hv_phy_workarounds_ich8lan(struct e1000_hw *hw)
 	/* Select page 0 */
 	ret_val = hw->phy.ops.acquire(hw);
 	if (ret_val)
-		goto out;
+		return ret_val;
 
 	hw->phy.addr = 1;
 	ret_val = e1000_write_phy_reg_mdic(hw, IGP01E1000_PHY_PAGE_SELECT, 0);
 	hw->phy.ops.release(hw);
 	if (ret_val)
-		goto out;
+		return ret_val;
 
-	/*
-	 * Configure the K1 Si workaround during phy reset assuming there is
+	/* Configure the K1 Si workaround during phy reset assuming there is
 	 * link so that it disables K1 if link is in 1Gbps.
 	 */
 	ret_val = e1000_k1_gig_workaround_hv(hw, TRUE);
 	if (ret_val)
-		goto out;
+		return ret_val;
 
 	/* Workaround for link disconnects on a busy hub in half duplex */
 	ret_val = hw->phy.ops.acquire(hw);
 	if (ret_val)
-		goto out;
+		return ret_val;
 	ret_val = hw->phy.ops.read_reg_locked(hw, BM_PORT_GEN_CFG, &phy_data);
 	if (ret_val)
 		goto release;
 	ret_val = hw->phy.ops.write_reg_locked(hw, BM_PORT_GEN_CFG,
 					       phy_data & 0x00FF);
+	if (ret_val)
+		goto release;
+
+	/* set MSE higher to enable link to stay up when noise is high */
+	ret_val = e1000_write_emi_reg_locked(hw, I82577_MSE_THRESHOLD, 0x0034);
 release:
 	hw->phy.ops.release(hw);
-out:
+
 	return ret_val;
 }
 
@@ -1600,19 +2180,18 @@ s32 e1000_lv_jumbo_workaround_ich8lan(struct e1000_hw *hw, bool enable)
 
 	DEBUGFUNC("e1000_lv_jumbo_workaround_ich8lan");
 
-	if (hw->mac.type != e1000_pch2lan)
-		goto out;
+	if (hw->mac.type < e1000_pch2lan)
+		return E1000_SUCCESS;
 
 	/* disable Rx path while enabling/disabling workaround */
 	hw->phy.ops.read_reg(hw, PHY_REG(769, 20), &phy_reg);
 	ret_val = hw->phy.ops.write_reg(hw, PHY_REG(769, 20),
 					phy_reg | (1 << 14));
 	if (ret_val)
-		goto out;
+		return ret_val;
 
 	if (enable) {
-		/*
-		 * Write Rx addresses (rar_entry_count for RAL/H, +4 for
+		/* Write Rx addresses (rar_entry_count for RAL/H, +4 for
 		 * SHRAL/H) and initial CRC values to the MAC
 		 */
 		for (i = 0; i < (hw->mac.rar_entry_count + 4); i++) {
@@ -1651,24 +2230,24 @@ s32 e1000_lv_jumbo_workaround_ich8lan(struct e1000_hw *hw, bool enable)
 						E1000_KMRNCTRLSTA_CTRL_OFFSET,
 						&data);
 		if (ret_val)
-			goto out;
+			return ret_val;
 		ret_val = e1000_write_kmrn_reg_generic(hw,
 						E1000_KMRNCTRLSTA_CTRL_OFFSET,
 						data | (1 << 0));
 		if (ret_val)
-			goto out;
+			return ret_val;
 		ret_val = e1000_read_kmrn_reg_generic(hw,
 						E1000_KMRNCTRLSTA_HD_CTRL,
 						&data);
 		if (ret_val)
-			goto out;
+			return ret_val;
 		data &= ~(0xF << 8);
 		data |= (0xB << 8);
 		ret_val = e1000_write_kmrn_reg_generic(hw,
 						E1000_KMRNCTRLSTA_HD_CTRL,
 						data);
 		if (ret_val)
-			goto out;
+			return ret_val;
 
 		/* Enable jumbo frame workaround in the PHY */
 		hw->phy.ops.read_reg(hw, PHY_REG(769, 23), &data);
@@ -1676,26 +2255,26 @@ s32 e1000_lv_jumbo_workaround_ich8lan(struct e1000_hw *hw, bool enable)
 		data |= (0x37 << 5);
 		ret_val = hw->phy.ops.write_reg(hw, PHY_REG(769, 23), data);
 		if (ret_val)
-			goto out;
+			return ret_val;
 		hw->phy.ops.read_reg(hw, PHY_REG(769, 16), &data);
 		data &= ~(1 << 13);
 		ret_val = hw->phy.ops.write_reg(hw, PHY_REG(769, 16), data);
 		if (ret_val)
-			goto out;
+			return ret_val;
 		hw->phy.ops.read_reg(hw, PHY_REG(776, 20), &data);
 		data &= ~(0x3FF << 2);
 		data |= (0x1A << 2);
 		ret_val = hw->phy.ops.write_reg(hw, PHY_REG(776, 20), data);
 		if (ret_val)
-			goto out;
+			return ret_val;
 		ret_val = hw->phy.ops.write_reg(hw, PHY_REG(776, 23), 0xF100);
 		if (ret_val)
-			goto out;
+			return ret_val;
 		hw->phy.ops.read_reg(hw, HV_PM_CTRL, &data);
 		ret_val = hw->phy.ops.write_reg(hw, HV_PM_CTRL, data |
 						(1 << 10));
 		if (ret_val)
-			goto out;
+			return ret_val;
 	} else {
 		/* Write MAC register values back to h/w defaults */
 		mac_reg = E1000_READ_REG(hw, E1000_FFLT_DBG);
@@ -1710,58 +2289,55 @@ s32 e1000_lv_jumbo_workaround_ich8lan(struct e1000_hw *hw, bool enable)
 						E1000_KMRNCTRLSTA_CTRL_OFFSET,
 						&data);
 		if (ret_val)
-			goto out;
+			return ret_val;
 		ret_val = e1000_write_kmrn_reg_generic(hw,
 						E1000_KMRNCTRLSTA_CTRL_OFFSET,
 						data & ~(1 << 0));
 		if (ret_val)
-			goto out;
+			return ret_val;
 		ret_val = e1000_read_kmrn_reg_generic(hw,
 						E1000_KMRNCTRLSTA_HD_CTRL,
 						&data);
 		if (ret_val)
-			goto out;
+			return ret_val;
 		data &= ~(0xF << 8);
 		data |= (0xB << 8);
 		ret_val = e1000_write_kmrn_reg_generic(hw,
 						E1000_KMRNCTRLSTA_HD_CTRL,
 						data);
 		if (ret_val)
-			goto out;
+			return ret_val;
 
 		/* Write PHY register values back to h/w defaults */
 		hw->phy.ops.read_reg(hw, PHY_REG(769, 23), &data);
 		data &= ~(0x7F << 5);
 		ret_val = hw->phy.ops.write_reg(hw, PHY_REG(769, 23), data);
 		if (ret_val)
-			goto out;
+			return ret_val;
 		hw->phy.ops.read_reg(hw, PHY_REG(769, 16), &data);
 		data |= (1 << 13);
 		ret_val = hw->phy.ops.write_reg(hw, PHY_REG(769, 16), data);
 		if (ret_val)
-			goto out;
+			return ret_val;
 		hw->phy.ops.read_reg(hw, PHY_REG(776, 20), &data);
 		data &= ~(0x3FF << 2);
 		data |= (0x8 << 2);
 		ret_val = hw->phy.ops.write_reg(hw, PHY_REG(776, 20), data);
 		if (ret_val)
-			goto out;
+			return ret_val;
 		ret_val = hw->phy.ops.write_reg(hw, PHY_REG(776, 23), 0x7E00);
 		if (ret_val)
-			goto out;
+			return ret_val;
 		hw->phy.ops.read_reg(hw, HV_PM_CTRL, &data);
 		ret_val = hw->phy.ops.write_reg(hw, HV_PM_CTRL, data &
 						~(1 << 10));
 		if (ret_val)
-			goto out;
+			return ret_val;
 	}
 
 	/* re-enable Rx path after enabling/disabling workaround */
-	ret_val = hw->phy.ops.write_reg(hw, PHY_REG(769, 20), phy_reg &
-					~(1 << 14));
-
-out:
-	return ret_val;
+	return hw->phy.ops.write_reg(hw, PHY_REG(769, 20), phy_reg &
+				     ~(1 << 14));
 }
 
 /**
@@ -1775,34 +2351,25 @@ static s32 e1000_lv_phy_workarounds_ich8lan(struct e1000_hw *hw)
 	DEBUGFUNC("e1000_lv_phy_workarounds_ich8lan");
 
 	if (hw->mac.type != e1000_pch2lan)
-		goto out;
+		return E1000_SUCCESS;
 
 	/* Set MDIO slow mode before any other MDIO access */
 	ret_val = e1000_set_mdio_slow_mode_hv(hw);
+	if (ret_val)
+		return ret_val;
 
 	ret_val = hw->phy.ops.acquire(hw);
 	if (ret_val)
-		goto out;
-	ret_val = hw->phy.ops.write_reg_locked(hw, I82579_EMI_ADDR,
-					       I82579_MSE_THRESHOLD);
-	if (ret_val)
-		goto release;
+		return ret_val;
 	/* set MSE higher to enable link to stay up when noise is high */
-	ret_val = hw->phy.ops.write_reg_locked(hw, I82579_EMI_DATA,
-					       0x0034);
-	if (ret_val)
-		goto release;
-	ret_val = hw->phy.ops.write_reg_locked(hw, I82579_EMI_ADDR,
-					       I82579_MSE_LINK_DOWN);
+	ret_val = e1000_write_emi_reg_locked(hw, I82579_MSE_THRESHOLD, 0x0034);
 	if (ret_val)
 		goto release;
 	/* drop link after 5 times MSE threshold was reached */
-	ret_val = hw->phy.ops.write_reg_locked(hw, I82579_EMI_DATA,
-					       0x0005);
+	ret_val = e1000_write_emi_reg_locked(hw, I82579_MSE_LINK_DOWN, 0x0005);
 release:
 	hw->phy.ops.release(hw);
 
-out:
 	return ret_val;
 }
 
@@ -1822,12 +2389,12 @@ static s32 e1000_k1_workaround_lv(struct e1000_hw *hw)
 	DEBUGFUNC("e1000_k1_workaround_lv");
 
 	if (hw->mac.type != e1000_pch2lan)
-		goto out;
+		return E1000_SUCCESS;
 
 	/* Set K1 beacon duration based on 1Gbps speed or otherwise */
 	ret_val = hw->phy.ops.read_reg(hw, HV_M_STATUS, &status_reg);
 	if (ret_val)
-		goto out;
+		return ret_val;
 
 	if ((status_reg & (HV_M_STATUS_LINK_UP | HV_M_STATUS_AUTONEG_COMPLETE))
 	    == (HV_M_STATUS_LINK_UP | HV_M_STATUS_AUTONEG_COMPLETE)) {
@@ -1836,11 +2403,23 @@ static s32 e1000_k1_workaround_lv(struct e1000_hw *hw)
 
 		ret_val = hw->phy.ops.read_reg(hw, I82579_LPI_CTRL, &phy_reg);
 		if (ret_val)
-			goto out;
+			return ret_val;
 
 		if (status_reg & HV_M_STATUS_SPEED_1000) {
+			u16 pm_phy_reg;
+
 			mac_reg |= E1000_FEXTNVM4_BEACON_DURATION_8USEC;
 			phy_reg &= ~I82579_LPI_CTRL_FORCE_PLL_LOCK_COUNT;
+			/* LV 1G Packet drop issue wa  */
+			ret_val = hw->phy.ops.read_reg(hw, HV_PM_CTRL,
+						       &pm_phy_reg);
+			if (ret_val)
+				return ret_val;
+			pm_phy_reg &= ~HV_PM_CTRL_PLL_STOP_IN_K1_GIGA;
+			ret_val = hw->phy.ops.write_reg(hw, HV_PM_CTRL,
+							pm_phy_reg);
+			if (ret_val)
+				return ret_val;
 		} else {
 			mac_reg |= E1000_FEXTNVM4_BEACON_DURATION_16USEC;
 			phy_reg |= I82579_LPI_CTRL_FORCE_PLL_LOCK_COUNT;
@@ -1849,7 +2428,6 @@ static s32 e1000_k1_workaround_lv(struct e1000_hw *hw)
 		ret_val = hw->phy.ops.write_reg(hw, I82579_LPI_CTRL, phy_reg);
 	}
 
-out:
 	return ret_val;
 }
 
@@ -1867,7 +2445,7 @@ static void e1000_gate_hw_phy_config_ich8lan(struct e1000_hw *hw, bool gate)
 
 	DEBUGFUNC("e1000_gate_hw_phy_config_ich8lan");
 
-	if (hw->mac.type != e1000_pch2lan)
+	if (hw->mac.type < e1000_pch2lan)
 		return;
 
 	extcnf_ctrl = E1000_READ_REG(hw, E1000_EXTCNF_CTRL);
@@ -1878,7 +2456,6 @@ static void e1000_gate_hw_phy_config_ich8lan(struct e1000_hw *hw, bool gate)
 		extcnf_ctrl &= ~E1000_EXTCNF_CTRL_GATE_PHY_CFG;
 
 	E1000_WRITE_REG(hw, E1000_EXTCNF_CTRL, extcnf_ctrl);
-	return;
 }
 
 /**
@@ -1901,8 +2478,7 @@ static void e1000_lan_init_done_ich8lan(struct e1000_hw *hw)
 		usec_delay(100);
 	} while ((!data) && --loop);
 
-	/*
-	 * If basic configuration is incomplete before the above loop
+	/* If basic configuration is incomplete before the above loop
 	 * count reaches 0, loading the configuration from NVM will
 	 * leave the PHY in a bad state possibly resulting in no link.
 	 */
@@ -1927,7 +2503,7 @@ static s32 e1000_post_phy_reset_ich8lan(struct e1000_hw *hw)
 	DEBUGFUNC("e1000_post_phy_reset_ich8lan");
 
 	if (hw->phy.ops.check_reset_block(hw))
-		goto out;
+		return E1000_SUCCESS;
 
 	/* Allow time for h/w to get to quiescent state after reset */
 	msec_delay(10);
@@ -1937,12 +2513,12 @@ static s32 e1000_post_phy_reset_ich8lan(struct e1000_hw *hw)
 	case e1000_pchlan:
 		ret_val = e1000_hv_phy_workarounds_ich8lan(hw);
 		if (ret_val)
-			goto out;
+			return ret_val;
 		break;
 	case e1000_pch2lan:
 		ret_val = e1000_lv_phy_workarounds_ich8lan(hw);
 		if (ret_val)
-			goto out;
+			return ret_val;
 		break;
 	default:
 		break;
@@ -1958,7 +2534,7 @@ static s32 e1000_post_phy_reset_ich8lan(struct e1000_hw *hw)
 	/* Configure the LCD with the extended configuration region in NVM */
 	ret_val = e1000_sw_lcd_config_ich8lan(hw);
 	if (ret_val)
-		goto out;
+		return ret_val;
 
 	/* Configure the LCD with the OEM bits in NVM */
 	ret_val = e1000_oem_bits_config_ich8lan(hw, TRUE);
@@ -1974,18 +2550,13 @@ static s32 e1000_post_phy_reset_ich8lan(struct e1000_hw *hw)
 		/* Set EEE LPI Update Timer to 200usec */
 		ret_val = hw->phy.ops.acquire(hw);
 		if (ret_val)
-			goto out;
-		ret_val = hw->phy.ops.write_reg_locked(hw, I82579_EMI_ADDR,
-						       I82579_LPI_UPDATE_TIMER);
-		if (ret_val)
-			goto release;
-		ret_val = hw->phy.ops.write_reg_locked(hw, I82579_EMI_DATA,
-						       0x1387);
-release:
+			return ret_val;
+		ret_val = e1000_write_emi_reg_locked(hw,
+						     I82579_LPI_UPDATE_TIMER,
+						     0x1387);
 		hw->phy.ops.release(hw);
 	}
 
-out:
 	return ret_val;
 }
 
@@ -2010,12 +2581,9 @@ static s32 e1000_phy_hw_reset_ich8lan(struct e1000_hw *hw)
 
 	ret_val = e1000_phy_hw_reset_generic(hw);
 	if (ret_val)
-		goto out;
-
-	ret_val = e1000_post_phy_reset_ich8lan(hw);
+		return ret_val;
 
-out:
-	return ret_val;
+	return e1000_post_phy_reset_ich8lan(hw);
 }
 
 /**
@@ -2031,14 +2599,14 @@ out:
  **/
 static s32 e1000_set_lplu_state_pchlan(struct e1000_hw *hw, bool active)
 {
-	s32 ret_val = E1000_SUCCESS;
+	s32 ret_val;
 	u16 oem_reg;
 
 	DEBUGFUNC("e1000_set_lplu_state_pchlan");
 
 	ret_val = hw->phy.ops.read_reg(hw, HV_OEM_BITS, &oem_reg);
 	if (ret_val)
-		goto out;
+		return ret_val;
 
 	if (active)
 		oem_reg |= HV_OEM_BITS_LPLU;
@@ -2048,10 +2616,7 @@ static s32 e1000_set_lplu_state_pchlan(struct e1000_hw *hw, bool active)
 	if (!hw->phy.ops.check_reset_block(hw))
 		oem_reg |= HV_OEM_BITS_RESTART_AN;
 
-	ret_val = hw->phy.ops.write_reg(hw, HV_OEM_BITS, oem_reg);
-
-out:
-	return ret_val;
+	return hw->phy.ops.write_reg(hw, HV_OEM_BITS, oem_reg);
 }
 
 /**
@@ -2077,7 +2642,7 @@ static s32 e1000_set_d0_lplu_state_ich8lan(struct e1000_hw *hw, bool active)
 	DEBUGFUNC("e1000_set_d0_lplu_state_ich8lan");
 
 	if (phy->type == e1000_phy_ife)
-		goto out;
+		return E1000_SUCCESS;
 
 	phy_ctrl = E1000_READ_REG(hw, E1000_PHY_CTRL);
 
@@ -2086,10 +2651,9 @@ static s32 e1000_set_d0_lplu_state_ich8lan(struct e1000_hw *hw, bool active)
 		E1000_WRITE_REG(hw, E1000_PHY_CTRL, phy_ctrl);
 
 		if (phy->type != e1000_phy_igp_3)
-			goto out;
+			return E1000_SUCCESS;
 
-		/*
-		 * Call gig speed drop workaround on LPLU before accessing
+		/* Call gig speed drop workaround on LPLU before accessing
 		 * any PHY registers
 		 */
 		if (hw->mac.type == e1000_ich8lan)
@@ -2099,21 +2663,22 @@ static s32 e1000_set_d0_lplu_state_ich8lan(struct e1000_hw *hw, bool active)
 		ret_val = phy->ops.read_reg(hw,
 					    IGP01E1000_PHY_PORT_CONFIG,
 					    &data);
+		if (ret_val)
+			return ret_val;
 		data &= ~IGP01E1000_PSCFR_SMART_SPEED;
 		ret_val = phy->ops.write_reg(hw,
 					     IGP01E1000_PHY_PORT_CONFIG,
 					     data);
 		if (ret_val)
-			goto out;
+			return ret_val;
 	} else {
 		phy_ctrl &= ~E1000_PHY_CTRL_D0A_LPLU;
 		E1000_WRITE_REG(hw, E1000_PHY_CTRL, phy_ctrl);
 
 		if (phy->type != e1000_phy_igp_3)
-			goto out;
+			return E1000_SUCCESS;
 
-		/*
-		 * LPLU and SmartSpeed are mutually exclusive.  LPLU is used
+		/* LPLU and SmartSpeed are mutually exclusive.  LPLU is used
 		 * during Dx states where the power conservation is most
 		 * important.  During driver activity we should enable
 		 * SmartSpeed, so performance is maintained.
@@ -2123,32 +2688,31 @@ static s32 e1000_set_d0_lplu_state_ich8lan(struct e1000_hw *hw, bool active)
 						    IGP01E1000_PHY_PORT_CONFIG,
 						    &data);
 			if (ret_val)
-				goto out;
+				return ret_val;
 
 			data |= IGP01E1000_PSCFR_SMART_SPEED;
 			ret_val = phy->ops.write_reg(hw,
 						     IGP01E1000_PHY_PORT_CONFIG,
 						     data);
 			if (ret_val)
-				goto out;
+				return ret_val;
 		} else if (phy->smart_speed == e1000_smart_speed_off) {
 			ret_val = phy->ops.read_reg(hw,
 						    IGP01E1000_PHY_PORT_CONFIG,
 						    &data);
 			if (ret_val)
-				goto out;
+				return ret_val;
 
 			data &= ~IGP01E1000_PSCFR_SMART_SPEED;
 			ret_val = phy->ops.write_reg(hw,
 						     IGP01E1000_PHY_PORT_CONFIG,
 						     data);
 			if (ret_val)
-				goto out;
+				return ret_val;
 		}
 	}
 
-out:
-	return ret_val;
+	return E1000_SUCCESS;
 }
 
 /**
@@ -2180,10 +2744,9 @@ static s32 e1000_set_d3_lplu_state_ich8lan(struct e1000_hw *hw, bool active)
 		E1000_WRITE_REG(hw, E1000_PHY_CTRL, phy_ctrl);
 
 		if (phy->type != e1000_phy_igp_3)
-			goto out;
+			return E1000_SUCCESS;
 
-		/*
-		 * LPLU and SmartSpeed are mutually exclusive.  LPLU is used
+		/* LPLU and SmartSpeed are mutually exclusive.  LPLU is used
 		 * during Dx states where the power conservation is most
 		 * important.  During driver activity we should enable
 		 * SmartSpeed, so performance is maintained.
@@ -2193,27 +2756,27 @@ static s32 e1000_set_d3_lplu_state_ich8lan(struct e1000_hw *hw, bool active)
 						    IGP01E1000_PHY_PORT_CONFIG,
 						    &data);
 			if (ret_val)
-				goto out;
+				return ret_val;
 
 			data |= IGP01E1000_PSCFR_SMART_SPEED;
 			ret_val = phy->ops.write_reg(hw,
 						     IGP01E1000_PHY_PORT_CONFIG,
 						     data);
 			if (ret_val)
-				goto out;
+				return ret_val;
 		} else if (phy->smart_speed == e1000_smart_speed_off) {
 			ret_val = phy->ops.read_reg(hw,
 						    IGP01E1000_PHY_PORT_CONFIG,
 						    &data);
 			if (ret_val)
-				goto out;
+				return ret_val;
 
 			data &= ~IGP01E1000_PSCFR_SMART_SPEED;
 			ret_val = phy->ops.write_reg(hw,
 						     IGP01E1000_PHY_PORT_CONFIG,
 						     data);
 			if (ret_val)
-				goto out;
+				return ret_val;
 		}
 	} else if ((phy->autoneg_advertised == E1000_ALL_SPEED_DUPLEX) ||
 		   (phy->autoneg_advertised == E1000_ALL_NOT_GIG) ||
@@ -2222,10 +2785,9 @@ static s32 e1000_set_d3_lplu_state_ich8lan(struct e1000_hw *hw, bool active)
 		E1000_WRITE_REG(hw, E1000_PHY_CTRL, phy_ctrl);
 
 		if (phy->type != e1000_phy_igp_3)
-			goto out;
+			return E1000_SUCCESS;
 
-		/*
-		 * Call gig speed drop workaround on LPLU before accessing
+		/* Call gig speed drop workaround on LPLU before accessing
 		 * any PHY registers
 		 */
 		if (hw->mac.type == e1000_ich8lan)
@@ -2236,7 +2798,7 @@ static s32 e1000_set_d3_lplu_state_ich8lan(struct e1000_hw *hw, bool active)
 					    IGP01E1000_PHY_PORT_CONFIG,
 					    &data);
 		if (ret_val)
-			goto out;
+			return ret_val;
 
 		data &= ~IGP01E1000_PSCFR_SMART_SPEED;
 		ret_val = phy->ops.write_reg(hw,
@@ -2244,7 +2806,6 @@ static s32 e1000_set_d3_lplu_state_ich8lan(struct e1000_hw *hw, bool active)
 					     data);
 	}
 
-out:
 	return ret_val;
 }
 
@@ -2263,7 +2824,7 @@ static s32 e1000_valid_nvm_bank_detect_ich8lan(struct e1000_hw *hw, u32 *bank)
 	u32 bank1_offset = nvm->flash_bank_size * sizeof(u16);
 	u32 act_offset = E1000_ICH_NVM_SIG_WORD * 2 + 1;
 	u8 sig_byte = 0;
-	s32 ret_val = E1000_SUCCESS;
+	s32 ret_val;
 
 	DEBUGFUNC("e1000_valid_nvm_bank_detect_ich8lan");
 
@@ -2278,7 +2839,7 @@ static s32 e1000_valid_nvm_bank_detect_ich8lan(struct e1000_hw *hw, u32 *bank)
 			else
 				*bank = 0;
 
-			goto out;
+			return E1000_SUCCESS;
 		}
 		DEBUGOUT("Unable to determine valid NVM bank via EEC - reading flash signature\n");
 		/* fall-thru */
@@ -2290,11 +2851,11 @@ static s32 e1000_valid_nvm_bank_detect_ich8lan(struct e1000_hw *hw, u32 *bank)
 		ret_val = e1000_read_flash_byte_ich8lan(hw, act_offset,
 							&sig_byte);
 		if (ret_val)
-			goto out;
+			return ret_val;
 		if ((sig_byte & E1000_ICH_NVM_VALID_SIG_MASK) ==
 		    E1000_ICH_NVM_SIG_VALUE) {
 			*bank = 0;
-			goto out;
+			return E1000_SUCCESS;
 		}
 
 		/* Check bank 1 */
@@ -2302,19 +2863,16 @@ static s32 e1000_valid_nvm_bank_detect_ich8lan(struct e1000_hw *hw, u32 *bank)
 							bank1_offset,
 							&sig_byte);
 		if (ret_val)
-			goto out;
+			return ret_val;
 		if ((sig_byte & E1000_ICH_NVM_VALID_SIG_MASK) ==
 		    E1000_ICH_NVM_SIG_VALUE) {
 			*bank = 1;
-			goto out;
+			return E1000_SUCCESS;
 		}
 
 		DEBUGOUT("ERROR: No valid NVM bank present\n");
-		ret_val = -E1000_ERR_NVM;
-		break;
+		return -E1000_ERR_NVM;
 	}
-out:
-	return ret_val;
 }
 
 /**
@@ -2396,9 +2954,9 @@ static s32 e1000_flash_cycle_init_ich8lan(struct e1000_hw *hw)
 	hsfsts.regval = E1000_READ_FLASH_REG16(hw, ICH_FLASH_HSFSTS);
 
 	/* Check if the flash descriptor is valid */
-	if (hsfsts.hsf_status.fldesvalid == 0) {
+	if (!hsfsts.hsf_status.fldesvalid) {
 		DEBUGOUT("Flash descriptor invalid.  SW Sequencing must be used.\n");
-		goto out;
+		return -E1000_ERR_NVM;
 	}
 
 	/* Clear FCERR and DAEL in hw status by writing 1 */
@@ -2407,8 +2965,7 @@ static s32 e1000_flash_cycle_init_ich8lan(struct e1000_hw *hw)
 
 	E1000_WRITE_FLASH_REG16(hw, ICH_FLASH_HSFSTS, hsfsts.regval);
 
-	/*
-	 * Either we should have a hardware SPI cycle in progress
+	/* Either we should have a hardware SPI cycle in progress
 	 * bit to check against, in order to start a new cycle or
 	 * FDONE bit should be changed in the hardware so that it
 	 * is 1 after hardware reset, which can then be used as an
@@ -2416,9 +2973,8 @@ static s32 e1000_flash_cycle_init_ich8lan(struct e1000_hw *hw)
 	 * completed.
 	 */
 
-	if (hsfsts.hsf_status.flcinprog == 0) {
-		/*
-		 * There is no cycle running at present,
+	if (!hsfsts.hsf_status.flcinprog) {
+		/* There is no cycle running at present,
 		 * so we can start a cycle.
 		 * Begin by setting Flash Cycle Done.
 		 */
@@ -2428,22 +2984,20 @@ static s32 e1000_flash_cycle_init_ich8lan(struct e1000_hw *hw)
 	} else {
 		s32 i;
 
-		/*
-		 * Otherwise poll for sometime so the current
+		/* Otherwise poll for sometime so the current
 		 * cycle has a chance to end before giving up.
 		 */
 		for (i = 0; i < ICH_FLASH_READ_COMMAND_TIMEOUT; i++) {
 			hsfsts.regval = E1000_READ_FLASH_REG16(hw,
 							      ICH_FLASH_HSFSTS);
-			if (hsfsts.hsf_status.flcinprog == 0) {
+			if (!hsfsts.hsf_status.flcinprog) {
 				ret_val = E1000_SUCCESS;
 				break;
 			}
 			usec_delay(1);
 		}
 		if (ret_val == E1000_SUCCESS) {
-			/*
-			 * Successful in waiting for previous cycle to timeout,
+			/* Successful in waiting for previous cycle to timeout,
 			 * now set the Flash Cycle Done.
 			 */
 			hsfsts.hsf_status.flcdone = 1;
@@ -2454,7 +3008,6 @@ static s32 e1000_flash_cycle_init_ich8lan(struct e1000_hw *hw)
 		}
 	}
 
-out:
 	return ret_val;
 }
 
@@ -2469,7 +3022,6 @@ static s32 e1000_flash_cycle_ich8lan(struct e1000_hw *hw, u32 timeout)
 {
 	union ich8_hws_flash_ctrl hsflctl;
 	union ich8_hws_flash_status hsfsts;
-	s32 ret_val = -E1000_ERR_NVM;
 	u32 i = 0;
 
 	DEBUGFUNC("e1000_flash_cycle_ich8lan");
@@ -2482,15 +3034,15 @@ static s32 e1000_flash_cycle_ich8lan(struct e1000_hw *hw, u32 timeout)
 	/* wait till FDONE bit is set to 1 */
 	do {
 		hsfsts.regval = E1000_READ_FLASH_REG16(hw, ICH_FLASH_HSFSTS);
-		if (hsfsts.hsf_status.flcdone == 1)
+		if (hsfsts.hsf_status.flcdone)
 			break;
 		usec_delay(1);
 	} while (i++ < timeout);
 
-	if (hsfsts.hsf_status.flcdone == 1 && hsfsts.hsf_status.flcerr == 0)
-		ret_val = E1000_SUCCESS;
+	if (hsfsts.hsf_status.flcdone && !hsfsts.hsf_status.flcerr)
+		return E1000_SUCCESS;
 
-	return ret_val;
+	return -E1000_ERR_NVM;
 }
 
 /**
@@ -2505,22 +3057,15 @@ static s32 e1000_flash_cycle_ich8lan(struct e1000_hw *hw, u32 timeout)
 static s32 e1000_read_flash_word_ich8lan(struct e1000_hw *hw, u32 offset,
 					 u16 *data)
 {
-	s32 ret_val;
-
 	DEBUGFUNC("e1000_read_flash_word_ich8lan");
 
-	if (!data) {
-		ret_val = -E1000_ERR_NVM;
-		goto out;
-	}
+	if (!data)
+		return -E1000_ERR_NVM;
 
 	/* Must convert offset into bytes. */
 	offset <<= 1;
 
-	ret_val = e1000_read_flash_data_ich8lan(hw, offset, 2, data);
-
-out:
-	return ret_val;
+	return e1000_read_flash_data_ich8lan(hw, offset, 2, data);
 }
 
 /**
@@ -2534,17 +3079,16 @@ out:
 static s32 e1000_read_flash_byte_ich8lan(struct e1000_hw *hw, u32 offset,
 					 u8 *data)
 {
-	s32 ret_val = E1000_SUCCESS;
+	s32 ret_val;
 	u16 word = 0;
 
 	ret_val = e1000_read_flash_data_ich8lan(hw, offset, 1, &word);
 	if (ret_val)
-		goto out;
+		return ret_val;
 
 	*data = (u8)word;
 
-out:
-	return ret_val;
+	return E1000_SUCCESS;
 }
 
 /**
@@ -2569,7 +3113,7 @@ static s32 e1000_read_flash_data_ich8lan(struct e1000_hw *hw, u32 offset,
 	DEBUGFUNC("e1000_read_flash_data_ich8lan");
 
 	if (size < 1  || size > 2 || offset > ICH_FLASH_LINEAR_ADDR_MASK)
-		goto out;
+		return -E1000_ERR_NVM;
 
 	flash_linear_addr = (ICH_FLASH_LINEAR_ADDR_MASK & offset) +
 			    hw->nvm.flash_base_addr;
@@ -2592,8 +3136,7 @@ static s32 e1000_read_flash_data_ich8lan(struct e1000_hw *hw, u32 offset,
 		ret_val = e1000_flash_cycle_ich8lan(hw,
 						ICH_FLASH_READ_COMMAND_TIMEOUT);
 
-		/*
-		 * Check if FCERR is set to 1, if set to 1, clear it
+		/* Check if FCERR is set to 1, if set to 1, clear it
 		 * and try the whole sequence a few more times, else
 		 * read in (shift in) the Flash Data0, the order is
 		 * least significant byte first msb to lsb
@@ -2606,25 +3149,23 @@ static s32 e1000_read_flash_data_ich8lan(struct e1000_hw *hw, u32 offset,
 				*data = (u16)(flash_data & 0x0000FFFF);
 			break;
 		} else {
-			/*
-			 * If we've gotten here, then things are probably
+			/* If we've gotten here, then things are probably
 			 * completely hosed, but if the error condition is
 			 * detected, it won't hurt to give it another try...
 			 * ICH_FLASH_CYCLE_REPEAT_COUNT times.
 			 */
 			hsfsts.regval = E1000_READ_FLASH_REG16(hw,
 							      ICH_FLASH_HSFSTS);
-			if (hsfsts.hsf_status.flcerr == 1) {
+			if (hsfsts.hsf_status.flcerr) {
 				/* Repeat for some time before giving up. */
 				continue;
-			} else if (hsfsts.hsf_status.flcdone == 0) {
+			} else if (!hsfsts.hsf_status.flcdone) {
 				DEBUGOUT("Timeout error - flash cycle did not complete.\n");
 				break;
 			}
 		}
 	} while (count++ < ICH_FLASH_CYCLE_REPEAT_COUNT);
 
-out:
 	return ret_val;
 }
 
@@ -2642,7 +3183,6 @@ static s32 e1000_write_nvm_ich8lan(struct e1000_hw *hw, u16 offset, u16 words,
 {
 	struct e1000_nvm_info *nvm = &hw->nvm;
 	struct e1000_dev_spec_ich8lan *dev_spec = &hw->dev_spec.ich8lan;
-	s32 ret_val = E1000_SUCCESS;
 	u16 i;
 
 	DEBUGFUNC("e1000_write_nvm_ich8lan");
@@ -2650,8 +3190,7 @@ static s32 e1000_write_nvm_ich8lan(struct e1000_hw *hw, u16 offset, u16 words,
 	if ((offset >= nvm->word_size) || (words > nvm->word_size - offset) ||
 	    (words == 0)) {
 		DEBUGOUT("nvm parameter(s) out of bounds\n");
-		ret_val = -E1000_ERR_NVM;
-		goto out;
+		return -E1000_ERR_NVM;
 	}
 
 	nvm->ops.acquire(hw);
@@ -2663,8 +3202,7 @@ static s32 e1000_write_nvm_ich8lan(struct e1000_hw *hw, u16 offset, u16 words,
 
 	nvm->ops.release(hw);
 
-out:
-	return ret_val;
+	return E1000_SUCCESS;
 }
 
 /**
@@ -2697,8 +3235,7 @@ static s32 e1000_update_nvm_checksum_ich8lan(struct e1000_hw *hw)
 
 	nvm->ops.acquire(hw);
 
-	/*
-	 * We're writing to the opposite bank so if we're on bank 1,
+	/* We're writing to the opposite bank so if we're on bank 1,
 	 * write to bank 0 etc.  We also need to erase the segment that
 	 * is going to be written
 	 */
@@ -2723,8 +3260,7 @@ static s32 e1000_update_nvm_checksum_ich8lan(struct e1000_hw *hw)
 	}
 
 	for (i = 0; i < E1000_SHADOW_RAM_WORDS; i++) {
-		/*
-		 * Determine whether to write the value stored
+		/* Determine whether to write the value stored
 		 * in the other NVM bank or a modified value stored
 		 * in the shadow RAM
 		 */
@@ -2738,8 +3274,7 @@ static s32 e1000_update_nvm_checksum_ich8lan(struct e1000_hw *hw)
 				break;
 		}
 
-		/*
-		 * If the word is 0x13, then make sure the signature bits
+		/* If the word is 0x13, then make sure the signature bits
 		 * (15:14) are 11b until the commit has completed.
 		 * This will allow us to write 10b which indicates the
 		 * signature is valid.  We want to do this after the write
@@ -2768,8 +3303,7 @@ static s32 e1000_update_nvm_checksum_ich8lan(struct e1000_hw *hw)
 			break;
 	}
 
-	/*
-	 * Don't bother writing the segment valid bits if sector
+	/* Don't bother writing the segment valid bits if sector
 	 * programming failed.
 	 */
 	if (ret_val) {
@@ -2777,8 +3311,7 @@ static s32 e1000_update_nvm_checksum_ich8lan(struct e1000_hw *hw)
 		goto release;
 	}
 
-	/*
-	 * Finally validate the new segment by setting bit 15:14
+	/* Finally validate the new segment by setting bit 15:14
 	 * to 10b in word 0x13 , this can be done without an
 	 * erase as well since these bits are 11 to start with
 	 * and we need to change bit 14 to 0b
@@ -2795,8 +3328,7 @@ static s32 e1000_update_nvm_checksum_ich8lan(struct e1000_hw *hw)
 	if (ret_val)
 		goto release;
 
-	/*
-	 * And invalidate the previously valid segment by setting
+	/* And invalidate the previously valid segment by setting
 	 * its signature word (0x13) high_byte to 0b. This can be
 	 * done without an erase because flash erase sets all bits
 	 * to 1's. We can write 1's to 0's without an erase
@@ -2815,8 +3347,7 @@ static s32 e1000_update_nvm_checksum_ich8lan(struct e1000_hw *hw)
 release:
 	nvm->ops.release(hw);
 
-	/*
-	 * Reload the EEPROM, or else modifications will not appear
+	/* Reload the EEPROM, or else modifications will not appear
 	 * until after the next adapter reset.
 	 */
 	if (!ret_val) {
@@ -2841,35 +3372,44 @@ out:
  **/
 static s32 e1000_validate_nvm_checksum_ich8lan(struct e1000_hw *hw)
 {
-	s32 ret_val = E1000_SUCCESS;
+	s32 ret_val;
 	u16 data;
+	u16 word;
+	u16 valid_csum_mask;
 
 	DEBUGFUNC("e1000_validate_nvm_checksum_ich8lan");
 
-	/*
-	 * Read 0x19 and check bit 6.  If this bit is 0, the checksum
-	 * needs to be fixed.  This bit is an indication that the NVM
-	 * was prepared by OEM software and did not calculate the
-	 * checksum...a likely scenario.
+	/* Read NVM and check Invalid Image CSUM bit.  If this bit is 0,
+	 * the checksum needs to be fixed.  This bit is an indication that
+	 * the NVM was prepared by OEM software and did not calculate
+	 * the checksum...a likely scenario.
 	 */
-	ret_val = hw->nvm.ops.read(hw, 0x19, 1, &data);
+	switch (hw->mac.type) {
+	case e1000_pch_lpt:
+		word = NVM_COMPAT;
+		valid_csum_mask = NVM_COMPAT_VALID_CSUM;
+		break;
+	default:
+		word = NVM_FUTURE_INIT_WORD1;
+		valid_csum_mask = NVM_FUTURE_INIT_WORD1_VALID_CSUM;
+		break;
+	}
+
+	ret_val = hw->nvm.ops.read(hw, word, 1, &data);
 	if (ret_val)
-		goto out;
+		return ret_val;
 
-	if ((data & 0x40) == 0) {
-		data |= 0x40;
-		ret_val = hw->nvm.ops.write(hw, 0x19, 1, &data);
+	if (!(data & valid_csum_mask)) {
+		data |= valid_csum_mask;
+		ret_val = hw->nvm.ops.write(hw, word, 1, &data);
 		if (ret_val)
-			goto out;
+			return ret_val;
 		ret_val = hw->nvm.ops.update(hw);
 		if (ret_val)
-			goto out;
+			return ret_val;
 	}
 
-	ret_val = e1000_validate_nvm_checksum_generic(hw);
-
-out:
-	return ret_val;
+	return e1000_validate_nvm_checksum_generic(hw);
 }
 
 /**
@@ -2888,14 +3428,14 @@ static s32 e1000_write_flash_data_ich8lan(struct e1000_hw *hw, u32 offset,
 	union ich8_hws_flash_ctrl hsflctl;
 	u32 flash_linear_addr;
 	u32 flash_data = 0;
-	s32 ret_val = -E1000_ERR_NVM;
+	s32 ret_val;
 	u8 count = 0;
 
 	DEBUGFUNC("e1000_write_ich8_data");
 
 	if (size < 1 || size > 2 || data > size * 0xff ||
 	    offset > ICH_FLASH_LINEAR_ADDR_MASK)
-		goto out;
+		return -E1000_ERR_NVM;
 
 	flash_linear_addr = (ICH_FLASH_LINEAR_ADDR_MASK & offset) +
 			    hw->nvm.flash_base_addr;
@@ -2922,8 +3462,7 @@ static s32 e1000_write_flash_data_ich8lan(struct e1000_hw *hw, u32 offset,
 
 		E1000_WRITE_FLASH_REG(hw, ICH_FLASH_FDATA0, flash_data);
 
-		/*
-		 * check if FCERR is set to 1 , if set to 1, clear it
+		/* check if FCERR is set to 1 , if set to 1, clear it
 		 * and try the whole sequence a few more times else done
 		 */
 		ret_val = e1000_flash_cycle_ich8lan(hw,
@@ -2931,23 +3470,21 @@ static s32 e1000_write_flash_data_ich8lan(struct e1000_hw *hw, u32 offset,
 		if (ret_val == E1000_SUCCESS)
 			break;
 
-		/*
-		 * If we're here, then things are most likely
+		/* If we're here, then things are most likely
 		 * completely hosed, but if the error condition
 		 * is detected, it won't hurt to give it another
 		 * try...ICH_FLASH_CYCLE_REPEAT_COUNT times.
 		 */
 		hsfsts.regval = E1000_READ_FLASH_REG16(hw, ICH_FLASH_HSFSTS);
-		if (hsfsts.hsf_status.flcerr == 1)
+		if (hsfsts.hsf_status.flcerr)
 			/* Repeat for some time before giving up. */
 			continue;
-		if (hsfsts.hsf_status.flcdone == 0) {
+		if (!hsfsts.hsf_status.flcdone) {
 			DEBUGOUT("Timeout error - flash cycle did not complete.\n");
 			break;
 		}
 	} while (count++ < ICH_FLASH_CYCLE_REPEAT_COUNT);
 
-out:
 	return ret_val;
 }
 
@@ -2987,8 +3524,8 @@ static s32 e1000_retry_write_flash_byte_ich8lan(struct e1000_hw *hw,
 	DEBUGFUNC("e1000_retry_write_flash_byte_ich8lan");
 
 	ret_val = e1000_write_flash_byte_ich8lan(hw, offset, byte);
-	if (ret_val == E1000_SUCCESS)
-		goto out;
+	if (!ret_val)
+		return ret_val;
 
 	for (program_retries = 0; program_retries < 100; program_retries++) {
 		DEBUGOUT2("Retrying Byte %2.2X at offset %u\n", byte, offset);
@@ -2997,13 +3534,10 @@ static s32 e1000_retry_write_flash_byte_ich8lan(struct e1000_hw *hw,
 		if (ret_val == E1000_SUCCESS)
 			break;
 	}
-	if (program_retries == 100) {
-		ret_val = -E1000_ERR_NVM;
-		goto out;
-	}
+	if (program_retries == 100)
+		return -E1000_ERR_NVM;
 
-out:
-	return ret_val;
+	return E1000_SUCCESS;
 }
 
 /**
@@ -3022,7 +3556,7 @@ static s32 e1000_erase_flash_bank_ich8lan(struct e1000_hw *hw, u32 bank)
 	u32 flash_linear_addr;
 	/* bank size is in 16bit words - adjust to bytes */
 	u32 flash_bank_size = nvm->flash_bank_size * 2;
-	s32 ret_val = E1000_SUCCESS;
+	s32 ret_val;
 	s32 count = 0;
 	s32 j, iteration, sector_size;
 
@@ -3030,8 +3564,7 @@ static s32 e1000_erase_flash_bank_ich8lan(struct e1000_hw *hw, u32 bank)
 
 	hsfsts.regval = E1000_READ_FLASH_REG16(hw, ICH_FLASH_HSFSTS);
 
-	/*
-	 * Determine HW Sector size: Read BERASE bits of hw flash status
+	/* Determine HW Sector size: Read BERASE bits of hw flash status
 	 * register
 	 * 00: The Hw sector is 256 bytes, hence we need to erase 16
 	 *     consecutive sectors.  The start index for the nth Hw sector
@@ -3062,8 +3595,7 @@ static s32 e1000_erase_flash_bank_ich8lan(struct e1000_hw *hw, u32 bank)
 		iteration = 1;
 		break;
 	default:
-		ret_val = -E1000_ERR_NVM;
-		goto out;
+		return -E1000_ERR_NVM;
 	}
 
 	/* Start with the base address, then add the sector offset. */
@@ -3075,10 +3607,9 @@ static s32 e1000_erase_flash_bank_ich8lan(struct e1000_hw *hw, u32 bank)
 			/* Steps */
 			ret_val = e1000_flash_cycle_init_ich8lan(hw);
 			if (ret_val)
-				goto out;
+				return ret_val;
 
-			/*
-			 * Write a value 11 (block Erase) in Flash
+			/* Write a value 11 (block Erase) in Flash
 			 * Cycle field in hw flash control
 			 */
 			hsflctl.regval = E1000_READ_FLASH_REG16(hw,
@@ -3087,8 +3618,7 @@ static s32 e1000_erase_flash_bank_ich8lan(struct e1000_hw *hw, u32 bank)
 			E1000_WRITE_FLASH_REG16(hw, ICH_FLASH_HSFCTL,
 						hsflctl.regval);
 
-			/*
-			 * Write the last 24 bits of an index within the
+			/* Write the last 24 bits of an index within the
 			 * block into Flash Linear address field in Flash
 			 * Address.
 			 */
@@ -3101,23 +3631,21 @@ static s32 e1000_erase_flash_bank_ich8lan(struct e1000_hw *hw, u32 bank)
 			if (ret_val == E1000_SUCCESS)
 				break;
 
-			/*
-			 * Check if FCERR is set to 1.  If 1,
+			/* Check if FCERR is set to 1.  If 1,
 			 * clear it and try the whole sequence
 			 * a few more times else Done
 			 */
 			hsfsts.regval = E1000_READ_FLASH_REG16(hw,
 						      ICH_FLASH_HSFSTS);
-			if (hsfsts.hsf_status.flcerr == 1)
+			if (hsfsts.hsf_status.flcerr)
 				/* repeat for some time before giving up */
 				continue;
-			else if (hsfsts.hsf_status.flcdone == 0)
-				goto out;
+			else if (!hsfsts.hsf_status.flcdone)
+				return ret_val;
 		} while (++count < ICH_FLASH_CYCLE_REPEAT_COUNT);
 	}
 
-out:
-	return ret_val;
+	return E1000_SUCCESS;
 }
 
 /**
@@ -3138,14 +3666,13 @@ static s32 e1000_valid_led_default_ich8lan(struct e1000_hw *hw, u16 *data)
 	ret_val = hw->nvm.ops.read(hw, NVM_ID_LED_SETTINGS, 1, data);
 	if (ret_val) {
 		DEBUGOUT("NVM Read Error\n");
-		goto out;
+		return ret_val;
 	}
 
 	if (*data == ID_LED_RESERVED_0000 || *data == ID_LED_RESERVED_FFFF)
 		*data = ID_LED_DEFAULT_ICH8LAN;
 
-out:
-	return ret_val;
+	return E1000_SUCCESS;
 }
 
 /**
@@ -3174,7 +3701,7 @@ static s32 e1000_id_led_init_pchlan(struct e1000_hw *hw)
 	/* Get default ID LED modes */
 	ret_val = hw->nvm.ops.valid_led_default(hw, &data);
 	if (ret_val)
-		goto out;
+		return ret_val;
 
 	mac->ledctl_default = E1000_READ_REG(hw, E1000_LEDCTL);
 	mac->ledctl_mode1 = mac->ledctl_default;
@@ -3219,8 +3746,7 @@ static s32 e1000_id_led_init_pchlan(struct e1000_hw *hw)
 		}
 	}
 
-out:
-	return ret_val;
+	return E1000_SUCCESS;
 }
 
 /**
@@ -3239,8 +3765,7 @@ static s32 e1000_get_bus_info_ich8lan(struct e1000_hw *hw)
 
 	ret_val = e1000_get_bus_info_pcie_generic(hw);
 
-	/*
-	 * ICH devices are "PCI Express"-ish.  They have
+	/* ICH devices are "PCI Express"-ish.  They have
 	 * a configuration space, but do not contain
 	 * PCI Express Capability registers, so bus width
 	 * must be hardcoded.
@@ -3261,14 +3786,13 @@ static s32 e1000_get_bus_info_ich8lan(struct e1000_hw *hw)
 static s32 e1000_reset_hw_ich8lan(struct e1000_hw *hw)
 {
 	struct e1000_dev_spec_ich8lan *dev_spec = &hw->dev_spec.ich8lan;
-	u16 reg;
-	u32 ctrl, kab;
+	u16 kum_cfg;
+	u32 ctrl, reg;
 	s32 ret_val;
 
 	DEBUGFUNC("e1000_reset_hw_ich8lan");
 
-	/*
-	 * Prevent the PCI-E bus from sticking if there is no TLP connection
+	/* Prevent the PCI-E bus from sticking if there is no TLP connection
 	 * on the last TLP read/write transaction when MAC is reset.
 	 */
 	ret_val = e1000_disable_pcie_master_generic(hw);
@@ -3278,8 +3802,7 @@ static s32 e1000_reset_hw_ich8lan(struct e1000_hw *hw)
 	DEBUGOUT("Masking off all interrupts\n");
 	E1000_WRITE_REG(hw, E1000_IMC, 0xffffffff);
 
-	/*
-	 * Disable the Transmit and Receive units.  Then delay to allow
+	/* Disable the Transmit and Receive units.  Then delay to allow
 	 * any pending transactions to complete before we hit the MAC
 	 * with the global reset.
 	 */
@@ -3299,11 +3822,11 @@ static s32 e1000_reset_hw_ich8lan(struct e1000_hw *hw)
 
 	if (hw->mac.type == e1000_pchlan) {
 		/* Save the NVM K1 bit setting*/
-		ret_val = e1000_read_nvm(hw, E1000_NVM_K1_CONFIG, 1, &reg);
+		ret_val = e1000_read_nvm(hw, E1000_NVM_K1_CONFIG, 1, &kum_cfg);
 		if (ret_val)
 			return ret_val;
 
-		if (reg & E1000_NVM_K1_ENABLE)
+		if (kum_cfg & E1000_NVM_K1_ENABLE)
 			dev_spec->nvm_k1_enabled = TRUE;
 		else
 			dev_spec->nvm_k1_enabled = FALSE;
@@ -3312,15 +3835,13 @@ static s32 e1000_reset_hw_ich8lan(struct e1000_hw *hw)
 	ctrl = E1000_READ_REG(hw, E1000_CTRL);
 
 	if (!hw->phy.ops.check_reset_block(hw)) {
-		/*
-		 * Full-chip reset requires MAC and PHY reset at the same
+		/* Full-chip reset requires MAC and PHY reset at the same
 		 * time to make sure the interface between MAC and the
 		 * external PHY is reset.
 		 */
 		ctrl |= E1000_CTRL_PHY_RST;
 
-		/*
-		 * Gate automatic PHY configuration by hardware on
+		/* Gate automatic PHY configuration by hardware on
 		 * non-managed 82579
 		 */
 		if ((hw->mac.type == e1000_pch2lan) &&
@@ -3333,21 +3854,28 @@ static s32 e1000_reset_hw_ich8lan(struct e1000_hw *hw)
 	/* cannot issue a flush here because it hangs the hardware */
 	msec_delay(20);
 
+	/* Set Phy Config Counter to 50msec */
+	if (hw->mac.type == e1000_pch2lan) {
+		reg = E1000_READ_REG(hw, E1000_FEXTNVM3);
+		reg &= ~E1000_FEXTNVM3_PHY_CFG_COUNTER_MASK;
+		reg |= E1000_FEXTNVM3_PHY_CFG_COUNTER_50MSEC;
+		E1000_WRITE_REG(hw, E1000_FEXTNVM3, reg);
+	}
+
 	if (!ret_val)
 		E1000_MUTEX_UNLOCK(&hw->dev_spec.ich8lan.swflag_mutex);
 
 	if (ctrl & E1000_CTRL_PHY_RST) {
 		ret_val = hw->phy.ops.get_cfg_done(hw);
 		if (ret_val)
-			goto out;
+			return ret_val;
 
 		ret_val = e1000_post_phy_reset_ich8lan(hw);
 		if (ret_val)
-			goto out;
+			return ret_val;
 	}
 
-	/*
-	 * For PCH, this write will make sure that any noise
+	/* For PCH, this write will make sure that any noise
 	 * will be detected as a CRC error and be dropped rather than show up
 	 * as a bad packet to the DMA engine.
 	 */
@@ -3357,12 +3885,11 @@ static s32 e1000_reset_hw_ich8lan(struct e1000_hw *hw)
 	E1000_WRITE_REG(hw, E1000_IMC, 0xffffffff);
 	E1000_READ_REG(hw, E1000_ICR);
 
-	kab = E1000_READ_REG(hw, E1000_KABGTXD);
-	kab |= E1000_KABGTXD_BGSQLBIAS;
-	E1000_WRITE_REG(hw, E1000_KABGTXD, kab);
+	reg = E1000_READ_REG(hw, E1000_KABGTXD);
+	reg |= E1000_KABGTXD_BGSQLBIAS;
+	E1000_WRITE_REG(hw, E1000_KABGTXD, reg);
 
-out:
-	return ret_val;
+	return E1000_SUCCESS;
 }
 
 /**
@@ -3390,9 +3917,9 @@ static s32 e1000_init_hw_ich8lan(struct e1000_hw *hw)
 
 	/* Initialize identification LED */
 	ret_val = mac->ops.id_led_init(hw);
+	/* An error is not fatal and we should not stop init due to this */
 	if (ret_val)
 		DEBUGOUT("Error initializing identification LED\n");
-		/* This is not fatal and we should not stop init due to this */
 
 	/* Setup the receive address. */
 	e1000_init_rx_addrs_generic(hw, mac->rar_entry_count);
@@ -3402,8 +3929,7 @@ static s32 e1000_init_hw_ich8lan(struct e1000_hw *hw)
 	for (i = 0; i < mac->mta_reg_count; i++)
 		E1000_WRITE_REG_ARRAY(hw, E1000_MTA, i, 0);
 
-	/*
-	 * The 82578 Rx buffer will stall if wakeup is enabled in host and
+	/* The 82578 Rx buffer will stall if wakeup is enabled in host and
 	 * the ME.  Disable wakeup by clearing the host wakeup bit.
 	 * Reset the phy after disabling host wakeup to reset the Rx buffer.
 	 */
@@ -3433,8 +3959,7 @@ static s32 e1000_init_hw_ich8lan(struct e1000_hw *hw)
 		 E1000_TXDCTL_MAX_TX_DESC_PREFETCH;
 	E1000_WRITE_REG(hw, E1000_TXDCTL(1), txdctl);
 
-	/*
-	 * ICH8 has opposite polarity of no_snoop bits.
+	/* ICH8 has opposite polarity of no_snoop bits.
 	 * By default, we should use snoop behavior.
 	 */
 	if (mac->type == e1000_ich8lan)
@@ -3447,8 +3972,7 @@ static s32 e1000_init_hw_ich8lan(struct e1000_hw *hw)
 	ctrl_ext |= E1000_CTRL_EXT_RO_DIS;
 	E1000_WRITE_REG(hw, E1000_CTRL_EXT, ctrl_ext);
 
-	/*
-	 * Clear all of the statistics registers (clear on read).  It is
+	/* Clear all of the statistics registers (clear on read).  It is
 	 * important that we do this after we have tried to establish link
 	 * because the symbol error count will increment wildly if there
 	 * is no link.
@@ -3457,6 +3981,7 @@ static s32 e1000_init_hw_ich8lan(struct e1000_hw *hw)
 
 	return ret_val;
 }
+
 /**
  *  e1000_initialize_hw_bits_ich8lan - Initialize required hardware bits
  *  @hw: pointer to the HW structure
@@ -3511,14 +4036,29 @@ static void e1000_initialize_hw_bits_ich8lan(struct e1000_hw *hw)
 		E1000_WRITE_REG(hw, E1000_STATUS, reg);
 	}
 
-	/*
-	 * work-around descriptor data corruption issue during nfs v2 udp
+	/* work-around descriptor data corruption issue during nfs v2 udp
 	 * traffic, just disable the nfs filtering capability
 	 */
 	reg = E1000_READ_REG(hw, E1000_RFCTL);
 	reg |= (E1000_RFCTL_NFSW_DIS | E1000_RFCTL_NFSR_DIS);
+	/* Disable IPv6 extension header parsing because some malformed
+	 * IPv6 headers can hang the Rx.
+	 */
+	if (hw->mac.type == e1000_ich8lan)
+		reg |= (E1000_RFCTL_IPV6_EX_DIS | E1000_RFCTL_NEW_IPV6_EXT_DIS);
 	E1000_WRITE_REG(hw, E1000_RFCTL, reg);
 
+	/* Enable ECC on Lynxpoint */
+	if (hw->mac.type == e1000_pch_lpt) {
+		reg = E1000_READ_REG(hw, E1000_PBECCSTS);
+		reg |= E1000_PBECCSTS_ECC_ENABLE;
+		E1000_WRITE_REG(hw, E1000_PBECCSTS, reg);
+
+		reg = E1000_READ_REG(hw, E1000_CTRL);
+		reg |= E1000_CTRL_MEHE;
+		E1000_WRITE_REG(hw, E1000_CTRL, reg);
+	}
+
 	return;
 }
 
@@ -3534,23 +4074,21 @@ static void e1000_initialize_hw_bits_ich8lan(struct e1000_hw *hw)
  **/
 static s32 e1000_setup_link_ich8lan(struct e1000_hw *hw)
 {
-	s32 ret_val = E1000_SUCCESS;
+	s32 ret_val;
 
 	DEBUGFUNC("e1000_setup_link_ich8lan");
 
 	if (hw->phy.ops.check_reset_block(hw))
-		goto out;
+		return E1000_SUCCESS;
 
-	/*
-	 * ICH parts do not have a word in the NVM to determine
+	/* ICH parts do not have a word in the NVM to determine
 	 * the default flow control setting, so we explicitly
 	 * set it to full.
 	 */
 	if (hw->fc.requested_mode == e1000_fc_default)
 		hw->fc.requested_mode = e1000_fc_full;
 
-	/*
-	 * Save off the requested flow control mode for use later.  Depending
+	/* Save off the requested flow control mode for use later.  Depending
 	 * on the link partner's capabilities, we may or may not use this mode.
 	 */
 	hw->fc.current_mode = hw->fc.requested_mode;
@@ -3561,11 +4099,12 @@ static s32 e1000_setup_link_ich8lan(struct e1000_hw *hw)
 	/* Continue to configure the copper link. */
 	ret_val = hw->mac.ops.setup_physical_interface(hw);
 	if (ret_val)
-		goto out;
+		return ret_val;
 
 	E1000_WRITE_REG(hw, E1000_FCTTV, hw->fc.pause_time);
 	if ((hw->phy.type == e1000_phy_82578) ||
 	    (hw->phy.type == e1000_phy_82579) ||
+	    (hw->phy.type == e1000_phy_i217) ||
 	    (hw->phy.type == e1000_phy_82577)) {
 		E1000_WRITE_REG(hw, E1000_FCRTV_PCH, hw->fc.refresh_time);
 
@@ -3573,13 +4112,10 @@ static s32 e1000_setup_link_ich8lan(struct e1000_hw *hw)
 					     PHY_REG(BM_PORT_CTRL_PAGE, 27),
 					     hw->fc.pause_time);
 		if (ret_val)
-			goto out;
+			return ret_val;
 	}
 
-	ret_val = e1000_set_fc_watermarks_generic(hw);
-
-out:
-	return ret_val;
+	return e1000_set_fc_watermarks_generic(hw);
 }
 
 /**
@@ -3603,50 +4139,49 @@ static s32 e1000_setup_copper_link_ich8lan(struct e1000_hw *hw)
 	ctrl &= ~(E1000_CTRL_FRCSPD | E1000_CTRL_FRCDPX);
 	E1000_WRITE_REG(hw, E1000_CTRL, ctrl);
 
-	/*
-	 * Set the mac to wait the maximum time between each iteration
+	/* Set the mac to wait the maximum time between each iteration
 	 * and increase the max iterations when polling the phy;
 	 * this fixes erroneous timeouts at 10Mbps.
 	 */
 	ret_val = e1000_write_kmrn_reg_generic(hw, E1000_KMRNCTRLSTA_TIMEOUTS,
 					       0xFFFF);
 	if (ret_val)
-		goto out;
+		return ret_val;
 	ret_val = e1000_read_kmrn_reg_generic(hw,
 					      E1000_KMRNCTRLSTA_INBAND_PARAM,
 					      &reg_data);
 	if (ret_val)
-		goto out;
+		return ret_val;
 	reg_data |= 0x3F;
 	ret_val = e1000_write_kmrn_reg_generic(hw,
 					       E1000_KMRNCTRLSTA_INBAND_PARAM,
 					       reg_data);
 	if (ret_val)
-		goto out;
+		return ret_val;
 
 	switch (hw->phy.type) {
 	case e1000_phy_igp_3:
 		ret_val = e1000_copper_link_setup_igp(hw);
 		if (ret_val)
-			goto out;
+			return ret_val;
 		break;
 	case e1000_phy_bm:
 	case e1000_phy_82578:
 		ret_val = e1000_copper_link_setup_m88(hw);
 		if (ret_val)
-			goto out;
+			return ret_val;
 		break;
 	case e1000_phy_82577:
 	case e1000_phy_82579:
 		ret_val = e1000_copper_link_setup_82577(hw);
 		if (ret_val)
-			goto out;
+			return ret_val;
 		break;
 	case e1000_phy_ife:
 		ret_val = hw->phy.ops.read_reg(hw, IFE_PHY_MDIX_CONTROL,
 					       &reg_data);
 		if (ret_val)
-			goto out;
+			return ret_val;
 
 		reg_data &= ~IFE_PMC_AUTO_MDIX;
 
@@ -3665,15 +4200,40 @@ static s32 e1000_setup_copper_link_ich8lan(struct e1000_hw *hw)
 		ret_val = hw->phy.ops.write_reg(hw, IFE_PHY_MDIX_CONTROL,
 						reg_data);
 		if (ret_val)
-			goto out;
+			return ret_val;
 		break;
 	default:
 		break;
 	}
-	ret_val = e1000_setup_copper_link_generic(hw);
 
-out:
-	return ret_val;
+	return e1000_setup_copper_link_generic(hw);
+}
+
+/**
+ *  e1000_setup_copper_link_pch_lpt - Configure MAC/PHY interface
+ *  @hw: pointer to the HW structure
+ *
+ *  Calls the PHY specific link setup function and then calls the
+ *  generic setup_copper_link to finish configuring the link for
+ *  Lynxpoint PCH devices
+ **/
+static s32 e1000_setup_copper_link_pch_lpt(struct e1000_hw *hw)
+{
+	u32 ctrl;
+	s32 ret_val;
+
+	DEBUGFUNC("e1000_setup_copper_link_pch_lpt");
+
+	ctrl = E1000_READ_REG(hw, E1000_CTRL);
+	ctrl |= E1000_CTRL_SLU;
+	ctrl &= ~(E1000_CTRL_FRCSPD | E1000_CTRL_FRCDPX);
+	E1000_WRITE_REG(hw, E1000_CTRL, ctrl);
+
+	ret_val = e1000_copper_link_setup_82577(hw);
+	if (ret_val)
+		return ret_val;
+
+	return e1000_setup_copper_link_generic(hw);
 }
 
 /**
@@ -3695,7 +4255,7 @@ static s32 e1000_get_link_up_info_ich8lan(struct e1000_hw *hw, u16 *speed,
 
 	ret_val = e1000_get_speed_and_duplex_copper_generic(hw, speed, duplex);
 	if (ret_val)
-		goto out;
+		return ret_val;
 
 	if ((hw->mac.type == e1000_ich8lan) &&
 	    (hw->phy.type == e1000_phy_igp_3) &&
@@ -3703,7 +4263,6 @@ static s32 e1000_get_link_up_info_ich8lan(struct e1000_hw *hw, u16 *speed,
 		ret_val = e1000_kmrn_lock_loss_workaround_ich8lan(hw);
 	}
 
-out:
 	return ret_val;
 }
 
@@ -3726,41 +4285,36 @@ static s32 e1000_kmrn_lock_loss_workaround_ich8lan(struct e1000_hw *hw)
 {
 	struct e1000_dev_spec_ich8lan *dev_spec = &hw->dev_spec.ich8lan;
 	u32 phy_ctrl;
-	s32 ret_val = E1000_SUCCESS;
+	s32 ret_val;
 	u16 i, data;
 	bool link;
 
 	DEBUGFUNC("e1000_kmrn_lock_loss_workaround_ich8lan");
 
 	if (!dev_spec->kmrn_lock_loss_workaround_enabled)
-		goto out;
+		return E1000_SUCCESS;
 
-	/*
-	 * Make sure link is up before proceeding.  If not just return.
+	/* Make sure link is up before proceeding.  If not just return.
 	 * Attempting this while link is negotiating fouled up link
 	 * stability
 	 */
 	ret_val = e1000_phy_has_link_generic(hw, 1, 0, &link);
-	if (!link) {
-		ret_val = E1000_SUCCESS;
-		goto out;
-	}
+	if (!link)
+		return E1000_SUCCESS;
 
 	for (i = 0; i < 10; i++) {
 		/* read once to clear */
 		ret_val = hw->phy.ops.read_reg(hw, IGP3_KMRN_DIAG, &data);
 		if (ret_val)
-			goto out;
+			return ret_val;
 		/* and again to get new status */
 		ret_val = hw->phy.ops.read_reg(hw, IGP3_KMRN_DIAG, &data);
 		if (ret_val)
-			goto out;
+			return ret_val;
 
 		/* check for PCS lock */
-		if (!(data & IGP3_KMRN_DIAG_PCS_LOCK_LOSS)) {
-			ret_val = E1000_SUCCESS;
-			goto out;
-		}
+		if (!(data & IGP3_KMRN_DIAG_PCS_LOCK_LOSS))
+			return E1000_SUCCESS;
 
 		/* Issue PHY reset */
 		hw->phy.ops.reset(hw);
@@ -3772,17 +4326,13 @@ static s32 e1000_kmrn_lock_loss_workaround_ich8lan(struct e1000_hw *hw)
 		     E1000_PHY_CTRL_NOND0A_GBE_DISABLE);
 	E1000_WRITE_REG(hw, E1000_PHY_CTRL, phy_ctrl);
 
-	/*
-	 * Call gig speed drop workaround on Gig disable before accessing
+	/* Call gig speed drop workaround on Gig disable before accessing
 	 * any PHY registers
 	 */
 	e1000_gig_downshift_workaround_ich8lan(hw);
 
 	/* unable to acquire PCS lock */
-	ret_val = -E1000_ERR_PHY;
-
-out:
-	return ret_val;
+	return -E1000_ERR_PHY;
 }
 
 /**
@@ -3829,7 +4379,7 @@ void e1000_igp3_phy_powerdown_workaround_ich8lan(struct e1000_hw *hw)
 	DEBUGFUNC("e1000_igp3_phy_powerdown_workaround_ich8lan");
 
 	if (hw->phy.type != e1000_phy_igp_3)
-		goto out;
+		return;
 
 	/* Try the workaround twice (if needed) */
 	do {
@@ -3839,8 +4389,7 @@ void e1000_igp3_phy_powerdown_workaround_ich8lan(struct e1000_hw *hw)
 			E1000_PHY_CTRL_NOND0A_GBE_DISABLE);
 		E1000_WRITE_REG(hw, E1000_PHY_CTRL, reg);
 
-		/*
-		 * Call gig speed drop workaround on Gig disable before
+		/* Call gig speed drop workaround on Gig disable before
 		 * accessing any PHY registers
 		 */
 		if (hw->mac.type == e1000_ich8lan)
@@ -3863,9 +4412,6 @@ void e1000_igp3_phy_powerdown_workaround_ich8lan(struct e1000_hw *hw)
 		E1000_WRITE_REG(hw, E1000_CTRL, reg | E1000_CTRL_PHY_RST);
 		retry++;
 	} while (retry);
-
-out:
-	return;
 }
 
 /**
@@ -3880,31 +4426,28 @@ out:
  **/
 void e1000_gig_downshift_workaround_ich8lan(struct e1000_hw *hw)
 {
-	s32 ret_val = E1000_SUCCESS;
+	s32 ret_val;
 	u16 reg_data;
 
 	DEBUGFUNC("e1000_gig_downshift_workaround_ich8lan");
 
 	if ((hw->mac.type != e1000_ich8lan) ||
 	    (hw->phy.type == e1000_phy_ife))
-		goto out;
+		return;
 
 	ret_val = e1000_read_kmrn_reg_generic(hw, E1000_KMRNCTRLSTA_DIAG_OFFSET,
 					      &reg_data);
 	if (ret_val)
-		goto out;
+		return;
 	reg_data |= E1000_KMRNCTRLSTA_DIAG_NELPBK;
 	ret_val = e1000_write_kmrn_reg_generic(hw,
 					       E1000_KMRNCTRLSTA_DIAG_OFFSET,
 					       reg_data);
 	if (ret_val)
-		goto out;
+		return;
 	reg_data &= ~E1000_KMRNCTRLSTA_DIAG_NELPBK;
-	ret_val = e1000_write_kmrn_reg_generic(hw,
-					       E1000_KMRNCTRLSTA_DIAG_OFFSET,
-					       reg_data);
-out:
-	return;
+	e1000_write_kmrn_reg_generic(hw, E1000_KMRNCTRLSTA_DIAG_OFFSET,
+				     reg_data);
 }
 
 /**
@@ -3917,9 +4460,13 @@ out:
  *  the LPLU setting in the NVM or custom setting.  For PCH and newer parts,
  *  the OEM bits PHY register (LED, GbE disable and LPLU configurations) also
  *  needs to be written.
+ *  Parts that support (and are linked to a partner which support) EEE in
+ *  100Mbps should disable LPLU since 100Mbps w/ EEE requires less power
+ *  than 10Mbps w/o EEE.
  **/
 void e1000_suspend_workarounds_ich8lan(struct e1000_hw *hw)
 {
+	struct e1000_dev_spec_ich8lan *dev_spec = &hw->dev_spec.ich8lan;
 	u32 phy_ctrl;
 	s32 ret_val;
 
@@ -3927,13 +4474,96 @@ void e1000_suspend_workarounds_ich8lan(struct e1000_hw *hw)
 
 	phy_ctrl = E1000_READ_REG(hw, E1000_PHY_CTRL);
 	phy_ctrl |= E1000_PHY_CTRL_GBE_DISABLE;
+
+	if (hw->phy.type == e1000_phy_i217) {
+		u16 phy_reg, device_id = hw->device_id;
+
+		if ((device_id == E1000_DEV_ID_PCH_LPTLP_I218_LM) ||
+		    (device_id == E1000_DEV_ID_PCH_LPTLP_I218_V)) {
+			u32 fextnvm6 = E1000_READ_REG(hw, E1000_FEXTNVM6);
+
+			E1000_WRITE_REG(hw, E1000_FEXTNVM6,
+					fextnvm6 & ~E1000_FEXTNVM6_REQ_PLL_CLK);
+		}
+
+		ret_val = hw->phy.ops.acquire(hw);
+		if (ret_val)
+			goto out;
+
+		if (!dev_spec->eee_disable) {
+			u16 eee_advert;
+
+			ret_val =
+			    e1000_read_emi_reg_locked(hw,
+						      I217_EEE_ADVERTISEMENT,
+						      &eee_advert);
+			if (ret_val)
+				goto release;
+
+			/* Disable LPLU if both link partners support 100BaseT
+			 * EEE and 100Full is advertised on both ends of the
+			 * link.
+			 */
+			if ((eee_advert & I82579_EEE_100_SUPPORTED) &&
+			    (dev_spec->eee_lp_ability &
+			     I82579_EEE_100_SUPPORTED) &&
+			    (hw->phy.autoneg_advertised & ADVERTISE_100_FULL))
+				phy_ctrl &= ~(E1000_PHY_CTRL_D0A_LPLU |
+					      E1000_PHY_CTRL_NOND0A_LPLU);
+		}
+
+		/* For i217 Intel Rapid Start Technology support,
+		 * when the system is going into Sx and no manageability engine
+		 * is present, the driver must configure proxy to reset only on
+		 * power good.  LPI (Low Power Idle) state must also reset only
+		 * on power good, as well as the MTA (Multicast table array).
+		 * The SMBus release must also be disabled on LCD reset.
+		 */
+		if (!(E1000_READ_REG(hw, E1000_FWSM) &
+			E1000_ICH_FWSM_FW_VALID)) {
+			/* Enable proxy to reset only on power good. */
+			hw->phy.ops.read_reg_locked(hw, I217_PROXY_CTRL,
+						    &phy_reg);
+			phy_reg |= I217_PROXY_CTRL_AUTO_DISABLE;
+			hw->phy.ops.write_reg_locked(hw, I217_PROXY_CTRL,
+						     phy_reg);
+
+			/* Set bit enable LPI (EEE) to reset only on
+			 * power good.
+			*/
+			hw->phy.ops.read_reg_locked(hw, I217_SxCTRL, &phy_reg);
+			phy_reg |= I217_SxCTRL_ENABLE_LPI_RESET;
+			hw->phy.ops.write_reg_locked(hw, I217_SxCTRL, phy_reg);
+
+			/* Disable the SMB release on LCD reset. */
+			hw->phy.ops.read_reg_locked(hw, I217_MEMPWR, &phy_reg);
+			phy_reg &= ~I217_MEMPWR_DISABLE_SMB_RELEASE;
+			hw->phy.ops.write_reg_locked(hw, I217_MEMPWR, phy_reg);
+		}
+
+		/* Enable MTA to reset for Intel Rapid Start Technology
+		 * Support
+		 */
+		hw->phy.ops.read_reg_locked(hw, I217_CGFREG, &phy_reg);
+		phy_reg |= I217_CGFREG_ENABLE_MTA_RESET;
+		hw->phy.ops.write_reg_locked(hw, I217_CGFREG, phy_reg);
+
+release:
+		hw->phy.ops.release(hw);
+	}
+out:
 	E1000_WRITE_REG(hw, E1000_PHY_CTRL, phy_ctrl);
+
 	if (hw->mac.type == e1000_ich8lan)
 		e1000_gig_downshift_workaround_ich8lan(hw);
 
 	if (hw->mac.type >= e1000_pchlan) {
 		e1000_oem_bits_config_ich8lan(hw, FALSE);
-		e1000_phy_hw_reset_ich8lan(hw);
+
+		/* Reset PHY to activate OEM bits on 82577/8 */
+		if (hw->mac.type == e1000_pchlan)
+			e1000_phy_hw_reset_generic(hw);
+
 		ret_val = hw->phy.ops.acquire(hw);
 		if (ret_val)
 			return;
@@ -3952,48 +4582,64 @@ void e1000_suspend_workarounds_ich8lan(struct e1000_hw *hw)
  *  on which PHY resets are not blocked, if the PHY registers cannot be
  *  accessed properly by the s/w toggle the LANPHYPC value to power cycle
  *  the PHY.
+ *  On i217, setup Intel Rapid Start Technology.
  **/
 void e1000_resume_workarounds_pchlan(struct e1000_hw *hw)
 {
-	u16 phy_id1, phy_id2;
 	s32 ret_val;
 
 	DEBUGFUNC("e1000_resume_workarounds_pchlan");
 
-	if ((hw->mac.type != e1000_pch2lan) ||
-	    hw->phy.ops.check_reset_block(hw))
+	if (hw->mac.type < e1000_pch2lan)
 		return;
 
-	ret_val = hw->phy.ops.acquire(hw);
+	ret_val = e1000_init_phy_workarounds_pchlan(hw);
 	if (ret_val) {
-		DEBUGOUT("Failed to acquire PHY semaphore in resume\n");
+		DEBUGOUT1("Failed to init PHY flow ret_val=%d\n", ret_val);
 		return;
 	}
 
-	/* Test access to the PHY registers by reading the ID regs */
-	ret_val = hw->phy.ops.read_reg_locked(hw, PHY_ID1, &phy_id1);
-	if (ret_val)
-		goto release;
-	ret_val = hw->phy.ops.read_reg_locked(hw, PHY_ID2, &phy_id2);
-	if (ret_val)
-		goto release;
-
-	if (hw->phy.id == ((u32)(phy_id1 << 16) |
-			   (u32)(phy_id2 & PHY_REVISION_MASK)))
-		goto release;
+	/* For i217 Intel Rapid Start Technology support when the system
+	 * is transitioning from Sx and no manageability engine is present
+	 * configure SMBus to restore on reset, disable proxy, and enable
+	 * the reset on MTA (Multicast table array).
+	 */
+	if (hw->phy.type == e1000_phy_i217) {
+		u16 phy_reg;
 
-	e1000_toggle_lanphypc_value_ich8lan(hw);
+		ret_val = hw->phy.ops.acquire(hw);
+		if (ret_val) {
+			DEBUGOUT("Failed to setup iRST\n");
+			return;
+		}
 
-	hw->phy.ops.release(hw);
-	msec_delay(50);
-	hw->phy.ops.reset(hw);
-	msec_delay(50);
-	return;
+		if (!(E1000_READ_REG(hw, E1000_FWSM) &
+		    E1000_ICH_FWSM_FW_VALID)) {
+			/* Restore clear on SMB if no manageability engine
+			 * is present
+			 */
+			ret_val = hw->phy.ops.read_reg_locked(hw, I217_MEMPWR,
+							      &phy_reg);
+			if (ret_val)
+				goto release;
+			phy_reg |= I217_MEMPWR_DISABLE_SMB_RELEASE;
+			hw->phy.ops.write_reg_locked(hw, I217_MEMPWR, phy_reg);
 
+			/* Disable Proxy */
+			hw->phy.ops.write_reg_locked(hw, I217_PROXY_CTRL, 0);
+		}
+		/* Enable reset on MTA */
+		ret_val = hw->phy.ops.read_reg_locked(hw, I217_CGFREG,
+						      &phy_reg);
+		if (ret_val)
+			goto release;
+		phy_reg &= ~I217_CGFREG_ENABLE_MTA_RESET;
+		hw->phy.ops.write_reg_locked(hw, I217_CGFREG, phy_reg);
 release:
-	hw->phy.ops.release(hw);
-
-	return;
+		if (ret_val)
+			DEBUGOUT1("Error %d in resume workarounds\n", ret_val);
+		hw->phy.ops.release(hw);
+	}
 }
 
 /**
@@ -4091,8 +4737,7 @@ static s32 e1000_led_on_pchlan(struct e1000_hw *hw)
 
 	DEBUGFUNC("e1000_led_on_pchlan");
 
-	/*
-	 * If no link, then turn LED on by setting the invert bit
+	/* If no link, then turn LED on by setting the invert bit
 	 * for each LED that's mode is "link_up" in ledctl_mode2.
 	 */
 	if (!(E1000_READ_REG(hw, E1000_STATUS) & E1000_STATUS_LU)) {
@@ -4124,8 +4769,7 @@ static s32 e1000_led_off_pchlan(struct e1000_hw *hw)
 
 	DEBUGFUNC("e1000_led_off_pchlan");
 
-	/*
-	 * If no link, then turn LED off by clearing the invert bit
+	/* If no link, then turn LED off by clearing the invert bit
 	 * for each LED that's mode is "link_up" in ledctl_mode1.
 	 */
 	if (!(E1000_READ_REG(hw, E1000_STATUS) & E1000_STATUS_LU)) {
@@ -4172,8 +4816,7 @@ static s32 e1000_get_cfg_done_ich8lan(struct e1000_hw *hw)
 	} else {
 		ret_val = e1000_get_auto_rd_done_generic(hw);
 		if (ret_val) {
-			/*
-			 * When auto config read does not complete, do not
+			/* When auto config read does not complete, do not
 			 * return with an error. This can happen in situations
 			 * where there is no eeprom and prevents getting link.
 			 */
@@ -4191,7 +4834,7 @@ static s32 e1000_get_cfg_done_ich8lan(struct e1000_hw *hw)
 
 	/* If EEPROM is not marked present, init the IGP 3 PHY manually */
 	if (hw->mac.type <= e1000_ich9lan) {
-		if (((E1000_READ_REG(hw, E1000_EECD) & E1000_EECD_PRES) == 0) &&
+		if (!(E1000_READ_REG(hw, E1000_EECD) & E1000_EECD_PRES) &&
 		    (hw->phy.type == e1000_phy_igp_3)) {
 			e1000_phy_init_script_igp3(hw);
 		}
@@ -4256,6 +4899,7 @@ static void e1000_clear_hw_cntrs_ich8lan(struct e1000_hw *hw)
 	/* Clear PHY statistics registers */
 	if ((hw->phy.type == e1000_phy_82578) ||
 	    (hw->phy.type == e1000_phy_82579) ||
+	    (hw->phy.type == e1000_phy_i217) ||
 	    (hw->phy.type == e1000_phy_82577)) {
 		ret_val = hw->phy.ops.acquire(hw);
 		if (ret_val)
diff --git a/sys/dev/e1000/e1000_ich8lan.h b/sys/dev/e1000/e1000_ich8lan.h
index 2eccb30..bf92898 100644
--- a/sys/dev/e1000/e1000_ich8lan.h
+++ b/sys/dev/e1000/e1000_ich8lan.h
@@ -1,6 +1,6 @@
 /******************************************************************************
 
-  Copyright (c) 2001-2011, Intel Corporation 
+  Copyright (c) 2001-2013, Intel Corporation 
   All rights reserved.
   
   Redistribution and use in source and binary forms, with or without 
@@ -59,12 +59,8 @@
 #define ICH_FLASH_SEG_SIZE_4K		4096
 #define ICH_FLASH_SEG_SIZE_8K		8192
 #define ICH_FLASH_SEG_SIZE_64K		65536
-#define ICH_FLASH_SECTOR_SIZE		4096
-
-#define ICH_FLASH_REG_MAPSIZE		0x00A0
 
 #define E1000_ICH_FWSM_RSPCIPHY		0x00000040 /* Reset PHY on PCI Reset */
-#define E1000_ICH_FWSM_DISSW		0x10000000 /* FW Disables SW Writes */
 /* FW established a valid mode */
 #define E1000_ICH_FWSM_FW_VALID		0x00008000
 #define E1000_ICH_FWSM_PCIM2PCI		0x01000000 /* ME PCIm-to-PCI active */
@@ -72,23 +68,12 @@
 
 #define E1000_ICH_MNG_IAMT_MODE		0x2
 
-#define E1000_FWSM_PROXY_MODE		0x00000008 /* FW is in proxy mode */
-#define E1000_FWSM_MEMC			0x00000010 /* ME Messaging capable */
+#define E1000_FWSM_WLOCK_MAC_MASK	0x0380
+#define E1000_FWSM_WLOCK_MAC_SHIFT	7
 
 /* Shared Receive Address Registers */
-#define E1000_SHRAL(_i)		(0x05438 + ((_i) * 8))
-#define E1000_SHRAH(_i)		(0x0543C + ((_i) * 8))
-#define E1000_SHRAH_AV		0x80000000 /* Addr Valid bit */
-#define E1000_SHRAH_MAV		0x40000000 /* Multicast Addr Valid bit */
-
-#define E1000_H2ME		0x05B50    /* Host to ME */
-#define E1000_H2ME_LSECREQ	0x00000001 /* Linksec Request */
-#define E1000_H2ME_LSECA	0x00000002 /* Linksec Active */
-#define E1000_H2ME_LSECSF	0x00000004 /* Linksec Failed */
-#define E1000_H2ME_LSECD	0x00000008 /* Linksec Disabled */
-#define E1000_H2ME_SLCAPD	0x00000010 /* Start LCAPD */
-#define E1000_H2ME_IPV4_ARP_EN	0x00000020 /* Arp Offload enable bit */
-#define E1000_H2ME_IPV6_NS_EN	0x00000040 /* NS Offload enable bit */
+#define E1000_SHRAL_PCH_LPT(_i)		(0x05408 + ((_i) * 8))
+#define E1000_SHRAH_PCH_LPT(_i)		(0x0540C + ((_i) * 8))
 
 #define ID_LED_DEFAULT_ICH8LAN	((ID_LED_DEF1_DEF2 << 12) | \
 				 (ID_LED_OFF1_OFF2 <<  8) | \
@@ -105,27 +90,30 @@
 #define E1000_FEXTNVM_SW_CONFIG		1
 #define E1000_FEXTNVM_SW_CONFIG_ICH8M	(1 << 27) /* Bit redefined for ICH8M */
 
+#define E1000_FEXTNVM3_PHY_CFG_COUNTER_MASK	0x0C000000
+#define E1000_FEXTNVM3_PHY_CFG_COUNTER_50MSEC	0x08000000
+
 #define E1000_FEXTNVM4_BEACON_DURATION_MASK	0x7
 #define E1000_FEXTNVM4_BEACON_DURATION_8USEC	0x7
 #define E1000_FEXTNVM4_BEACON_DURATION_16USEC	0x3
 
+#define E1000_FEXTNVM6_REQ_PLL_CLK	0x00000100
+
 #define PCIE_ICH8_SNOOP_ALL	PCIE_NO_SNOOP_ALL
 
 #define E1000_ICH_RAR_ENTRIES	7
 #define E1000_PCH2_RAR_ENTRIES	5 /* RAR[0], SHRA[0-3] */
+#define E1000_PCH_LPT_RAR_ENTRIES	12 /* RAR[0], SHRA[0-10] */
 
 #define PHY_PAGE_SHIFT		5
 #define PHY_REG(page, reg)	(((page) << PHY_PAGE_SHIFT) | \
 				 ((reg) & MAX_PHY_REG_ADDRESS))
 #define IGP3_KMRN_DIAG		PHY_REG(770, 19) /* KMRN Diagnostic */
 #define IGP3_VR_CTRL		PHY_REG(776, 18) /* Voltage Regulator Control */
-#define IGP3_CAPABILITY		PHY_REG(776, 19) /* Capability */
-#define IGP3_PM_CTRL		PHY_REG(769, 20) /* Power Management Control */
 
 #define IGP3_KMRN_DIAG_PCS_LOCK_LOSS		0x0002
 #define IGP3_VR_CTRL_DEV_POWERDOWN_MODE_MASK	0x0300
 #define IGP3_VR_CTRL_MODE_SHUTDOWN		0x0200
-#define IGP3_PM_CTRL_FORCE_PWR_DOWN		0x0020
 
 /* PHY Wakeup Registers and defines */
 #define BM_PORT_GEN_CFG		PHY_REG(BM_PORT_CTRL_PAGE, 17)
@@ -138,14 +126,6 @@
 #define BM_RAR_H(_i)		(BM_PHY_REG(BM_WUC_PAGE, 18 + ((_i) << 2)))
 #define BM_RAR_CTRL(_i)		(BM_PHY_REG(BM_WUC_PAGE, 19 + ((_i) << 2)))
 #define BM_MTA(_i)		(BM_PHY_REG(BM_WUC_PAGE, 128 + ((_i) << 1)))
-#define BM_IPAV			(BM_PHY_REG(BM_WUC_PAGE, 64))
-#define BM_IP4AT_L(_i)		(BM_PHY_REG(BM_WUC_PAGE, 82 + ((_i) * 2)))
-#define BM_IP4AT_H(_i)		(BM_PHY_REG(BM_WUC_PAGE, 83 + ((_i) * 2)))
-
-#define BM_SHRAL_LOWER(_i)	(BM_PHY_REG(BM_WUC_PAGE, 44 + ((_i) * 4)))
-#define BM_SHRAL_UPPER(_i)	(BM_PHY_REG(BM_WUC_PAGE, 45 + ((_i) * 4)))
-#define BM_SHRAH_LOWER(_i)	(BM_PHY_REG(BM_WUC_PAGE, 46 + ((_i) * 4)))
-#define BM_SHRAH_UPPER(_i)	(BM_PHY_REG(BM_WUC_PAGE, 47 + ((_i) * 4)))
 
 #define BM_RCTL_UPE		0x0001 /* Unicast Promiscuous Mode */
 #define BM_RCTL_MPE		0x0002 /* Multicast Promiscuous Mode */
@@ -177,28 +157,28 @@
 
 #define E1000_FCRTV_PCH	0x05F40 /* PCH Flow Control Refresh Timer Value */
 
-/*
- * For ICH, the name used for NVM word 17h is LED1 Config.
- * For PCH, the word was re-named to OEM Config.
- */
-#define E1000_NVM_LED1_CONFIG		0x17   /* NVM LED1/LPLU Config Word */
-#define E1000_NVM_LED1_CONFIG_LPLU_NONDOA 0x0400 /* NVM LPLU in non-D0a Bit */
-#define E1000_NVM_OEM_CONFIG		E1000_NVM_LED1_CONFIG
-#define E1000_NVM_OEM_CONFIG_LPLU_NONDOA E1000_NVM_LED1_CONFIG_LPLU_NONDOA
-
 #define E1000_NVM_K1_CONFIG	0x1B /* NVM K1 Config Word */
 #define E1000_NVM_K1_ENABLE	0x1  /* NVM Enable K1 bit */
 
+/* SMBus Control Phy Register */
+#define CV_SMB_CTRL		PHY_REG(769, 23)
+#define CV_SMB_CTRL_FORCE_SMBUS	0x0001
+
 /* SMBus Address Phy Register */
 #define HV_SMB_ADDR		PHY_REG(768, 26)
 #define HV_SMB_ADDR_MASK	0x007F
 #define HV_SMB_ADDR_PEC_EN	0x0200
 #define HV_SMB_ADDR_VALID	0x0080
+#define HV_SMB_ADDR_FREQ_MASK		0x1100
+#define HV_SMB_ADDR_FREQ_LOW_SHIFT	8
+#define HV_SMB_ADDR_FREQ_HIGH_SHIFT	12
 
 /* Strapping Option Register - RO */
 #define E1000_STRAP			0x0000C
 #define E1000_STRAP_SMBUS_ADDRESS_MASK	0x00FE0000
 #define E1000_STRAP_SMBUS_ADDRESS_SHIFT	17
+#define E1000_STRAP_SMT_FREQ_MASK	0x00003000
+#define E1000_STRAP_SMT_FREQ_SHIFT	12
 
 /* OEM Bits Phy Register */
 #define HV_OEM_BITS		PHY_REG(768, 25)
@@ -206,8 +186,6 @@
 #define HV_OEM_BITS_GBE_DIS	0x0040 /* Gigabit Disable */
 #define HV_OEM_BITS_RESTART_AN	0x0400 /* Restart Auto-negotiation */
 
-#define LCD_CFG_PHY_ADDR_BIT	0x0020 /* Phy addr bit from LCD Config word */
-
 /* KMRN Mode Control */
 #define HV_KMRN_MODE_CTRL	PHY_REG(769, 16)
 #define HV_KMRN_MDIO_SLOW	0x0400
@@ -219,47 +197,73 @@
 
 /* PHY Power Management Control */
 #define HV_PM_CTRL		PHY_REG(770, 17)
+#define HV_PM_CTRL_PLL_STOP_IN_K1_GIGA	0x100
 
 #define SW_FLAG_TIMEOUT		1000 /* SW Semaphore flag timeout in ms */
 
 /* PHY Low Power Idle Control */
 #define I82579_LPI_CTRL				PHY_REG(772, 20)
+#define I82579_LPI_CTRL_100_ENABLE		0x2000
+#define I82579_LPI_CTRL_1000_ENABLE		0x4000
 #define I82579_LPI_CTRL_ENABLE_MASK		0x6000
 #define I82579_LPI_CTRL_FORCE_PLL_LOCK_COUNT	0x80
 
-/* EMI Registers */
+/* Extended Management Interface (EMI) Registers */
 #define I82579_EMI_ADDR		0x10
 #define I82579_EMI_DATA		0x11
 #define I82579_LPI_UPDATE_TIMER	0x4805 /* in 40ns units + 40 ns base value */
-#define I82579_MSE_THRESHOLD	0x084F /* Mean Square Error Threshold */
+#define I82579_MSE_THRESHOLD	0x084F /* 82579 Mean Square Error Threshold */
+#define I82577_MSE_THRESHOLD	0x0887 /* 82577 Mean Square Error Threshold */
 #define I82579_MSE_LINK_DOWN	0x2411 /* MSE count before dropping link */
-
-/*
- * Additional interrupts need to be handled for ICH family:
- *  DSW = The FW changed the status of the DISSW bit in FWSM
- *  PHYINT = The LAN connected device generates an interrupt
- *  EPRST = Manageability reset event
- */
-#define IMS_ICH_ENABLE_MASK (\
-	E1000_IMS_DSW   | \
-	E1000_IMS_PHYINT | \
-	E1000_IMS_EPRST)
-
-/* Additional interrupt register bit definitions */
-#define E1000_ICR_LSECPNC	0x00004000  /* PN threshold - client */
-#define E1000_IMS_LSECPNC	E1000_ICR_LSECPNC   /* PN threshold - client */
-#define E1000_ICS_LSECPNC	E1000_ICR_LSECPNC   /* PN threshold - client */
-
-/* Security Processing bit Indication */
-#define E1000_RXDEXT_LINKSEC_STATUS_LSECH	0x01000000
-#define E1000_RXDEXT_LINKSEC_ERROR_BIT_MASK	0x60000000
-#define E1000_RXDEXT_LINKSEC_ERROR_NO_SA_MATCH	0x20000000
-#define E1000_RXDEXT_LINKSEC_ERROR_REPLAY_ERROR	0x40000000
-#define E1000_RXDEXT_LINKSEC_ERROR_BAD_SIG	0x60000000
+#define I82579_RX_CONFIG		0x3412 /* Receive configuration */
+#define I82579_EEE_PCS_STATUS		0x182D	/* IEEE MMD Register 3.1 >> 8 */
+#define I82579_EEE_CAPABILITY		0x0410 /* IEEE MMD Register 3.20 */
+#define I82579_EEE_ADVERTISEMENT	0x040E /* IEEE MMD Register 7.60 */
+#define I82579_EEE_LP_ABILITY		0x040F /* IEEE MMD Register 7.61 */
+#define I82579_EEE_100_SUPPORTED	(1 << 1) /* 100BaseTx EEE supported */
+#define I82579_EEE_1000_SUPPORTED	(1 << 2) /* 1000BaseTx EEE supported */
+#define I217_EEE_PCS_STATUS	0x9401   /* IEEE MMD Register 3.1 */
+#define I217_EEE_CAPABILITY	0x8000   /* IEEE MMD Register 3.20 */
+#define I217_EEE_ADVERTISEMENT	0x8001   /* IEEE MMD Register 7.60 */
+#define I217_EEE_LP_ABILITY	0x8002   /* IEEE MMD Register 7.61 */
+
+#define E1000_EEE_RX_LPI_RCVD	0x0400	/* Tx LP idle received */
+#define E1000_EEE_TX_LPI_RCVD	0x0800	/* Rx LP idle received */
+
+/* Intel Rapid Start Technology Support */
+#define I217_PROXY_CTRL		BM_PHY_REG(BM_WUC_PAGE, 70)
+#define I217_PROXY_CTRL_AUTO_DISABLE	0x0080
+#define I217_SxCTRL			PHY_REG(BM_PORT_CTRL_PAGE, 28)
+#define I217_SxCTRL_ENABLE_LPI_RESET	0x1000
+#define I217_CGFREG			PHY_REG(772, 29)
+#define I217_CGFREG_ENABLE_MTA_RESET	0x0002
+#define I217_MEMPWR			PHY_REG(772, 26)
+#define I217_MEMPWR_DISABLE_SMB_RELEASE	0x0010
 
 /* Receive Address Initial CRC Calculation */
 #define E1000_PCH_RAICC(_n)	(0x05F50 + ((_n) * 4))
 
+/* Latency Tolerance Reporting */
+#define E1000_LTRV			0x000F8
+#define E1000_LTRV_VALUE_MASK		0x000003FF
+#define E1000_LTRV_SCALE_MAX		5
+#define E1000_LTRV_SCALE_FACTOR		5
+#define E1000_LTRV_SCALE_SHIFT		10
+#define E1000_LTRV_SCALE_MASK		0x00001C00
+#define E1000_LTRV_REQ_SHIFT		15
+#define E1000_LTRV_NOSNOOP_SHIFT	16
+#define E1000_LTRV_SEND			(1 << 30)
+
+/* Proprietary Latency Tolerance Reporting PCI Capability */
+#define E1000_PCI_LTR_CAP_LPT		0xA8
+
+/* OBFF Control & Threshold Defines */
+#define E1000_SVCR_OFF_EN		0x00000001
+#define E1000_SVCR_OFF_MASKINT		0x00001000
+#define E1000_SVCR_OFF_TIMER_MASK	0xFFFF0000
+#define E1000_SVCR_OFF_TIMER_SHIFT	16
+#define E1000_SVT_OFF_HWM_MASK		0x0000001F
+
 void e1000_set_kmrn_lock_loss_workaround_ich8lan(struct e1000_hw *hw,
 						 bool state);
 void e1000_igp3_phy_powerdown_workaround_ich8lan(struct e1000_hw *hw);
@@ -269,4 +273,5 @@ void e1000_resume_workarounds_pchlan(struct e1000_hw *hw);
 s32 e1000_configure_k1_ich8lan(struct e1000_hw *hw, bool k1_enable);
 void e1000_copy_rx_addrs_to_phy_ich8lan(struct e1000_hw *hw);
 s32 e1000_lv_jumbo_workaround_ich8lan(struct e1000_hw *hw, bool enable);
-#endif
+s32 e1000_read_emi_reg_locked(struct e1000_hw *hw, u16 addr, u16 *data);
+#endif /* _E1000_ICH8LAN_H_ */
diff --git a/sys/dev/e1000/e1000_mac.c b/sys/dev/e1000/e1000_mac.c
index 4fc2a7c..9e6b30c 100644
--- a/sys/dev/e1000/e1000_mac.c
+++ b/sys/dev/e1000/e1000_mac.c
@@ -1,6 +1,6 @@
 /******************************************************************************
 
-  Copyright (c) 2001-2011, Intel Corporation 
+  Copyright (c) 2001-2013, Intel Corporation 
   All rights reserved.
   
   Redistribution and use in source and binary forms, with or without 
@@ -36,6 +36,8 @@
 
 static s32 e1000_validate_mdi_setting_generic(struct e1000_hw *hw);
 static void e1000_set_lan_id_multi_port_pcie(struct e1000_hw *hw);
+static void e1000_config_collision_dist_generic(struct e1000_hw *hw);
+static void e1000_rar_set_generic(struct e1000_hw *hw, u8 *addr, u32 index);
 
 /**
  *  e1000_init_mac_ops_generic - Initialize MAC function pointers
@@ -68,12 +70,9 @@ void e1000_init_mac_ops_generic(struct e1000_hw *hw)
 	mac->ops.setup_link = e1000_null_ops_generic;
 	mac->ops.get_link_up_info = e1000_null_link_info;
 	mac->ops.check_for_link = e1000_null_ops_generic;
-	mac->ops.wait_autoneg = e1000_wait_autoneg_generic;
+	mac->ops.set_obff_timer = e1000_null_set_obff_timer;
 	/* Management */
 	mac->ops.check_mng_mode = e1000_null_mng_mode;
-	mac->ops.mng_host_if_write = e1000_mng_host_if_write_generic;
-	mac->ops.mng_write_cmd_header = e1000_mng_write_cmd_header_generic;
-	mac->ops.mng_enable_host_if = e1000_mng_enable_host_if_generic;
 	/* VLAN, MC, etc. */
 	mac->ops.update_mc_addr_list = e1000_null_update_mc;
 	mac->ops.clear_vfta = e1000_null_mac_generic;
@@ -116,8 +115,7 @@ s32 e1000_null_link_info(struct e1000_hw *hw, u16 *s, u16 *d)
  *  e1000_null_mng_mode - No-op function, return FALSE
  *  @hw: pointer to the HW structure
  **/
-bool e1000_null_mng_mode(struct e1000_hw *hw)
-{
+bool e1000_null_mng_mode(struct e1000_hw *hw) {
 	DEBUGFUNC("e1000_null_mng_mode");
 	return FALSE;
 }
@@ -153,6 +151,16 @@ void e1000_null_rar_set(struct e1000_hw *hw, u8 *h, u32 a)
 }
 
 /**
+ *  e1000_null_set_obff_timer - No-op function, return 0
+ *  @hw: pointer to the HW structure
+ **/
+s32 e1000_null_set_obff_timer(struct e1000_hw *hw, u32 a)
+{
+	DEBUGFUNC("e1000_null_set_obff_timer");
+	return E1000_SUCCESS;
+}
+
+/**
  *  e1000_get_bus_info_pci_generic - Get PCI(x) bus information
  *  @hw: pointer to the HW structure
  *
@@ -266,8 +274,7 @@ static void e1000_set_lan_id_multi_port_pcie(struct e1000_hw *hw)
 	struct e1000_bus_info *bus = &hw->bus;
 	u32 reg;
 
-	/*
-	 * The status register reports the correct function number
+	/* The status register reports the correct function number
 	 * for the device regardless of function swap state.
 	 */
 	reg = E1000_READ_REG(hw, E1000_STATUS);
@@ -387,7 +394,7 @@ void e1000_init_rx_addrs_generic(struct e1000_hw *hw, u16 rar_count)
 s32 e1000_check_alt_mac_addr_generic(struct e1000_hw *hw)
 {
 	u32 i;
-	s32 ret_val = E1000_SUCCESS;
+	s32 ret_val;
 	u16 offset, nvm_alt_mac_addr_offset, nvm_data;
 	u8 alt_mac_addr[ETH_ADDR_LEN];
 
@@ -395,30 +402,29 @@ s32 e1000_check_alt_mac_addr_generic(struct e1000_hw *hw)
 
 	ret_val = hw->nvm.ops.read(hw, NVM_COMPAT, 1, &nvm_data);
 	if (ret_val)
-		goto out;
+		return ret_val;
 
 	/* not supported on older hardware or 82573 */
 	if ((hw->mac.type < e1000_82571) || (hw->mac.type == e1000_82573))
-		goto out;
+		return E1000_SUCCESS;
 
-	/*
-	 * Alternate MAC address is handled by the option ROM for 82580
+	/* Alternate MAC address is handled by the option ROM for 82580
 	 * and newer. SW support not required.
 	 */
 	if (hw->mac.type >= e1000_82580)
-		goto out;
+		return E1000_SUCCESS;
 
 	ret_val = hw->nvm.ops.read(hw, NVM_ALT_MAC_ADDR_PTR, 1,
 				   &nvm_alt_mac_addr_offset);
 	if (ret_val) {
 		DEBUGOUT("NVM Read Error\n");
-		goto out;
+		return ret_val;
 	}
 
 	if ((nvm_alt_mac_addr_offset == 0xFFFF) ||
 	    (nvm_alt_mac_addr_offset == 0x0000))
 		/* There is no Alternate MAC Address */
-		goto out;
+		return E1000_SUCCESS;
 
 	if (hw->bus.func == E1000_FUNC_1)
 		nvm_alt_mac_addr_offset += E1000_ALT_MAC_ADDRESS_OFFSET_LAN1;
@@ -432,7 +438,7 @@ s32 e1000_check_alt_mac_addr_generic(struct e1000_hw *hw)
 		ret_val = hw->nvm.ops.read(hw, offset, 1, &nvm_data);
 		if (ret_val) {
 			DEBUGOUT("NVM Read Error\n");
-			goto out;
+			return ret_val;
 		}
 
 		alt_mac_addr[i] = (u8)(nvm_data & 0xFF);
@@ -442,18 +448,16 @@ s32 e1000_check_alt_mac_addr_generic(struct e1000_hw *hw)
 	/* if multicast bit is set, the alternate address will not be used */
 	if (alt_mac_addr[0] & 0x01) {
 		DEBUGOUT("Ignoring Alternate Mac Address with MC bit set\n");
-		goto out;
+		return E1000_SUCCESS;
 	}
 
-	/*
-	 * We have a valid alternate MAC address, and we want to treat it the
+	/* We have a valid alternate MAC address, and we want to treat it the
 	 * same as the normal permanent MAC address stored by the HW into the
 	 * RAR. Do this by mapping this address into RAR0.
 	 */
 	hw->mac.ops.rar_set(hw, alt_mac_addr, 0);
 
-out:
-	return ret_val;
+	return E1000_SUCCESS;
 }
 
 /**
@@ -465,14 +469,13 @@ out:
  *  Sets the receive address array register at index to the address passed
  *  in by addr.
  **/
-void e1000_rar_set_generic(struct e1000_hw *hw, u8 *addr, u32 index)
+static void e1000_rar_set_generic(struct e1000_hw *hw, u8 *addr, u32 index)
 {
 	u32 rar_low, rar_high;
 
 	DEBUGFUNC("e1000_rar_set_generic");
 
-	/*
-	 * HW expects these in little endian so we reverse the byte order
+	/* HW expects these in little endian so we reverse the byte order
 	 * from network order (big endian) to little endian
 	 */
 	rar_low = ((u32) addr[0] | ((u32) addr[1] << 8) |
@@ -484,8 +487,7 @@ void e1000_rar_set_generic(struct e1000_hw *hw, u8 *addr, u32 index)
 	if (rar_low || rar_high)
 		rar_high |= E1000_RAH_AV;
 
-	/*
-	 * Some bridges will combine consecutive 32-bit writes into
+	/* Some bridges will combine consecutive 32-bit writes into
 	 * a single burst write, which will malfunction on some parts.
 	 * The flushes avoid this.
 	 */
@@ -496,43 +498,6 @@ void e1000_rar_set_generic(struct e1000_hw *hw, u8 *addr, u32 index)
 }
 
 /**
- *  e1000_update_mc_addr_list_generic - Update Multicast addresses
- *  @hw: pointer to the HW structure
- *  @mc_addr_list: array of multicast addresses to program
- *  @mc_addr_count: number of multicast addresses to program
- *
- *  Updates entire Multicast Table Array.
- *  The caller must have a packed mc_addr_list of multicast addresses.
- **/
-void e1000_update_mc_addr_list_generic(struct e1000_hw *hw,
-				       u8 *mc_addr_list, u32 mc_addr_count)
-{
-	u32 hash_value, hash_bit, hash_reg;
-	int i;
-
-	DEBUGFUNC("e1000_update_mc_addr_list_generic");
-
-	/* clear mta_shadow */
-	memset(&hw->mac.mta_shadow, 0, sizeof(hw->mac.mta_shadow));
-
-	/* update mta_shadow from mc_addr_list */
-	for (i = 0; (u32) i < mc_addr_count; i++) {
-		hash_value = e1000_hash_mc_addr_generic(hw, mc_addr_list);
-
-		hash_reg = (hash_value >> 5) & (hw->mac.mta_reg_count - 1);
-		hash_bit = hash_value & 0x1F;
-
-		hw->mac.mta_shadow[hash_reg] |= (1 << hash_bit);
-		mc_addr_list += (ETH_ADDR_LEN);
-	}
-
-	/* replace the entire MTA table */
-	for (i = hw->mac.mta_reg_count - 1; i >= 0; i--)
-		E1000_WRITE_REG_ARRAY(hw, E1000_MTA, i, hw->mac.mta_shadow[i]);
-	E1000_WRITE_FLUSH(hw);
-}
-
-/**
  *  e1000_hash_mc_addr_generic - Generate a multicast hash value
  *  @hw: pointer to the HW structure
  *  @mc_addr: pointer to a multicast address
@@ -550,15 +515,13 @@ u32 e1000_hash_mc_addr_generic(struct e1000_hw *hw, u8 *mc_addr)
 	/* Register count multiplied by bits per register */
 	hash_mask = (hw->mac.mta_reg_count * 32) - 1;
 
-	/*
-	 * For a mc_filter_type of 0, bit_shift is the number of left-shifts
+	/* For a mc_filter_type of 0, bit_shift is the number of left-shifts
 	 * where 0xFF would still fall within the hash mask.
 	 */
 	while (hash_mask >> bit_shift != 0xFF)
 		bit_shift++;
 
-	/*
-	 * The portion of the address that is used for the hash table
+	/* The portion of the address that is used for the hash table
 	 * is determined by the mc_filter_type setting.
 	 * The algorithm is such that there is a total of 8 bits of shifting.
 	 * The bit_shift for a mc_filter_type of 0 represents the number of
@@ -605,6 +568,43 @@ u32 e1000_hash_mc_addr_generic(struct e1000_hw *hw, u8 *mc_addr)
 }
 
 /**
+ *  e1000_update_mc_addr_list_generic - Update Multicast addresses
+ *  @hw: pointer to the HW structure
+ *  @mc_addr_list: array of multicast addresses to program
+ *  @mc_addr_count: number of multicast addresses to program
+ *
+ *  Updates entire Multicast Table Array.
+ *  The caller must have a packed mc_addr_list of multicast addresses.
+ **/
+void e1000_update_mc_addr_list_generic(struct e1000_hw *hw,
+				       u8 *mc_addr_list, u32 mc_addr_count)
+{
+	u32 hash_value, hash_bit, hash_reg;
+	int i;
+
+	DEBUGFUNC("e1000_update_mc_addr_list_generic");
+
+	/* clear mta_shadow */
+	memset(&hw->mac.mta_shadow, 0, sizeof(hw->mac.mta_shadow));
+
+	/* update mta_shadow from mc_addr_list */
+	for (i = 0; (u32) i < mc_addr_count; i++) {
+		hash_value = e1000_hash_mc_addr_generic(hw, mc_addr_list);
+
+		hash_reg = (hash_value >> 5) & (hw->mac.mta_reg_count - 1);
+		hash_bit = hash_value & 0x1F;
+
+		hw->mac.mta_shadow[hash_reg] |= (1 << hash_bit);
+		mc_addr_list += (ETH_ADDR_LEN);
+	}
+
+	/* replace the entire MTA table */
+	for (i = hw->mac.mta_reg_count - 1; i >= 0; i--)
+		E1000_WRITE_REG_ARRAY(hw, E1000_MTA, i, hw->mac.mta_shadow[i]);
+	E1000_WRITE_FLUSH(hw);
+}
+
+/**
  *  e1000_pcix_mmrbc_workaround_generic - Fix incorrect MMRBC value
  *  @hw: pointer to the HW structure
  *
@@ -706,55 +706,45 @@ s32 e1000_check_for_copper_link_generic(struct e1000_hw *hw)
 
 	DEBUGFUNC("e1000_check_for_copper_link");
 
-	/*
-	 * We only want to go out to the PHY registers to see if Auto-Neg
+	/* We only want to go out to the PHY registers to see if Auto-Neg
 	 * has completed and/or if our link status has changed.  The
 	 * get_link_status flag is set upon receiving a Link Status
 	 * Change or Rx Sequence Error interrupt.
 	 */
-	if (!mac->get_link_status) {
-		ret_val = E1000_SUCCESS;
-		goto out;
-	}
+	if (!mac->get_link_status)
+		return E1000_SUCCESS;
 
-	/*
-	 * First we want to see if the MII Status Register reports
+	/* First we want to see if the MII Status Register reports
 	 * link.  If so, then we want to get the current speed/duplex
 	 * of the PHY.
 	 */
 	ret_val = e1000_phy_has_link_generic(hw, 1, 0, &link);
 	if (ret_val)
-		goto out;
+		return ret_val;
 
 	if (!link)
-		goto out; /* No link detected */
+		return E1000_SUCCESS; /* No link detected */
 
 	mac->get_link_status = FALSE;
 
-	/*
-	 * Check if there was DownShift, must be checked
+	/* Check if there was DownShift, must be checked
 	 * immediately after link-up
 	 */
 	e1000_check_downshift_generic(hw);
 
-	/*
-	 * If we are forcing speed/duplex, then we simply return since
+	/* If we are forcing speed/duplex, then we simply return since
 	 * we have already determined whether we have link or not.
 	 */
-	if (!mac->autoneg) {
-		ret_val = -E1000_ERR_CONFIG;
-		goto out;
-	}
+	if (!mac->autoneg)
+		return -E1000_ERR_CONFIG;
 
-	/*
-	 * Auto-Neg is enabled.  Auto Speed Detection takes care
+	/* Auto-Neg is enabled.  Auto Speed Detection takes care
 	 * of MAC speed/duplex configuration.  So we only need to
 	 * configure Collision Distance in the MAC.
 	 */
 	mac->ops.config_collision_dist(hw);
 
-	/*
-	 * Configure Flow Control now that Auto-Neg has completed.
+	/* Configure Flow Control now that Auto-Neg has completed.
 	 * First, we need to restore the desired flow control
 	 * settings because we may have had to re-autoneg with a
 	 * different link partner.
@@ -763,7 +753,6 @@ s32 e1000_check_for_copper_link_generic(struct e1000_hw *hw)
 	if (ret_val)
 		DEBUGOUT("Error configuring flow control\n");
 
-out:
 	return ret_val;
 }
 
@@ -780,7 +769,7 @@ s32 e1000_check_for_fiber_link_generic(struct e1000_hw *hw)
 	u32 rxcw;
 	u32 ctrl;
 	u32 status;
-	s32 ret_val = E1000_SUCCESS;
+	s32 ret_val;
 
 	DEBUGFUNC("e1000_check_for_fiber_link_generic");
 
@@ -788,8 +777,7 @@ s32 e1000_check_for_fiber_link_generic(struct e1000_hw *hw)
 	status = E1000_READ_REG(hw, E1000_STATUS);
 	rxcw = E1000_READ_REG(hw, E1000_RXCW);
 
-	/*
-	 * If we don't have link (auto-negotiation failed or link partner
+	/* If we don't have link (auto-negotiation failed or link partner
 	 * cannot auto-negotiate), the cable is plugged in (we have signal),
 	 * and our link partner is not trying to auto-negotiate with us (we
 	 * are receiving idles or data), we need to force link up. We also
@@ -797,11 +785,11 @@ s32 e1000_check_for_fiber_link_generic(struct e1000_hw *hw)
 	 * was just plugged in. The autoneg_failed flag does this.
 	 */
 	/* (ctrl & E1000_CTRL_SWDPIN1) == 1 == have signal */
-	if ((ctrl & E1000_CTRL_SWDPIN1) && (!(status & E1000_STATUS_LU)) &&
-	    (!(rxcw & E1000_RXCW_C))) {
-		if (mac->autoneg_failed == 0) {
-			mac->autoneg_failed = 1;
-			goto out;
+	if ((ctrl & E1000_CTRL_SWDPIN1) && !(status & E1000_STATUS_LU) &&
+	    !(rxcw & E1000_RXCW_C)) {
+		if (!mac->autoneg_failed) {
+			mac->autoneg_failed = TRUE;
+			return E1000_SUCCESS;
 		}
 		DEBUGOUT("NOT Rx'ing /C/, disable AutoNeg and force link.\n");
 
@@ -817,11 +805,10 @@ s32 e1000_check_for_fiber_link_generic(struct e1000_hw *hw)
 		ret_val = e1000_config_fc_after_link_up_generic(hw);
 		if (ret_val) {
 			DEBUGOUT("Error configuring flow control\n");
-			goto out;
+			return ret_val;
 		}
 	} else if ((ctrl & E1000_CTRL_SLU) && (rxcw & E1000_RXCW_C)) {
-		/*
-		 * If we are forcing link and we are receiving /C/ ordered
+		/* If we are forcing link and we are receiving /C/ ordered
 		 * sets, re-enable auto-negotiation in the TXCW register
 		 * and disable forced link in the Device Control register
 		 * in an attempt to auto-negotiate with our link partner.
@@ -833,8 +820,7 @@ s32 e1000_check_for_fiber_link_generic(struct e1000_hw *hw)
 		mac->serdes_has_link = TRUE;
 	}
 
-out:
-	return ret_val;
+	return E1000_SUCCESS;
 }
 
 /**
@@ -850,7 +836,7 @@ s32 e1000_check_for_serdes_link_generic(struct e1000_hw *hw)
 	u32 rxcw;
 	u32 ctrl;
 	u32 status;
-	s32 ret_val = E1000_SUCCESS;
+	s32 ret_val;
 
 	DEBUGFUNC("e1000_check_for_serdes_link_generic");
 
@@ -858,18 +844,17 @@ s32 e1000_check_for_serdes_link_generic(struct e1000_hw *hw)
 	status = E1000_READ_REG(hw, E1000_STATUS);
 	rxcw = E1000_READ_REG(hw, E1000_RXCW);
 
-	/*
-	 * If we don't have link (auto-negotiation failed or link partner
+	/* If we don't have link (auto-negotiation failed or link partner
 	 * cannot auto-negotiate), and our link partner is not trying to
 	 * auto-negotiate with us (we are receiving idles or data),
 	 * we need to force link up. We also need to give auto-negotiation
 	 * time to complete.
 	 */
 	/* (ctrl & E1000_CTRL_SWDPIN1) == 1 == have signal */
-	if ((!(status & E1000_STATUS_LU)) && (!(rxcw & E1000_RXCW_C))) {
-		if (mac->autoneg_failed == 0) {
-			mac->autoneg_failed = 1;
-			goto out;
+	if (!(status & E1000_STATUS_LU) && !(rxcw & E1000_RXCW_C)) {
+		if (!mac->autoneg_failed) {
+			mac->autoneg_failed = TRUE;
+			return E1000_SUCCESS;
 		}
 		DEBUGOUT("NOT Rx'ing /C/, disable AutoNeg and force link.\n");
 
@@ -885,11 +870,10 @@ s32 e1000_check_for_serdes_link_generic(struct e1000_hw *hw)
 		ret_val = e1000_config_fc_after_link_up_generic(hw);
 		if (ret_val) {
 			DEBUGOUT("Error configuring flow control\n");
-			goto out;
+			return ret_val;
 		}
 	} else if ((ctrl & E1000_CTRL_SLU) && (rxcw & E1000_RXCW_C)) {
-		/*
-		 * If we are forcing link and we are receiving /C/ ordered
+		/* If we are forcing link and we are receiving /C/ ordered
 		 * sets, re-enable auto-negotiation in the TXCW register
 		 * and disable forced link in the Device Control register
 		 * in an attempt to auto-negotiate with our link partner.
@@ -900,8 +884,7 @@ s32 e1000_check_for_serdes_link_generic(struct e1000_hw *hw)
 
 		mac->serdes_has_link = TRUE;
 	} else if (!(E1000_TXCW_ANE & E1000_READ_REG(hw, E1000_TXCW))) {
-		/*
-		 * If we force link for non-auto-negotiation switch, check
+		/* If we force link for non-auto-negotiation switch, check
 		 * link status based on MAC synchronization for internal
 		 * serdes media type.
 		 */
@@ -943,8 +926,47 @@ s32 e1000_check_for_serdes_link_generic(struct e1000_hw *hw)
 		}
 	}
 
-out:
-	return ret_val;
+	return E1000_SUCCESS;
+}
+
+/**
+ *  e1000_set_default_fc_generic - Set flow control default values
+ *  @hw: pointer to the HW structure
+ *
+ *  Read the EEPROM for the default values for flow control and store the
+ *  values.
+ **/
+s32 e1000_set_default_fc_generic(struct e1000_hw *hw)
+{
+	s32 ret_val;
+	u16 nvm_data;
+
+	DEBUGFUNC("e1000_set_default_fc_generic");
+
+	/* Read and store word 0x0F of the EEPROM. This word contains bits
+	 * that determine the hardware's default PAUSE (flow control) mode,
+	 * a bit that determines whether the HW defaults to enabling or
+	 * disabling auto-negotiation, and the direction of the
+	 * SW defined pins. If there is no SW over-ride of the flow
+	 * control setting, then the variable hw->fc will
+	 * be initialized based on a value in the EEPROM.
+	 */
+	ret_val = hw->nvm.ops.read(hw, NVM_INIT_CONTROL2_REG, 1, &nvm_data);
+
+	if (ret_val) {
+		DEBUGOUT("NVM Read Error\n");
+		return ret_val;
+	}
+
+	if (!(nvm_data & NVM_WORD0F_PAUSE_MASK))
+		hw->fc.requested_mode = e1000_fc_none;
+	else if ((nvm_data & NVM_WORD0F_PAUSE_MASK) ==
+		 NVM_WORD0F_ASM_DIR)
+		hw->fc.requested_mode = e1000_fc_tx_pause;
+	else
+		hw->fc.requested_mode = e1000_fc_full;
+
+	return E1000_SUCCESS;
 }
 
 /**
@@ -959,29 +981,26 @@ out:
  **/
 s32 e1000_setup_link_generic(struct e1000_hw *hw)
 {
-	s32 ret_val = E1000_SUCCESS;
+	s32 ret_val;
 
 	DEBUGFUNC("e1000_setup_link_generic");
 
-	/*
-	 * In the case of the phy reset being blocked, we already have a link.
+	/* In the case of the phy reset being blocked, we already have a link.
 	 * We do not need to set it up again.
 	 */
-	if (e1000_check_reset_block(hw))
-		goto out;
+	if (hw->phy.ops.check_reset_block && hw->phy.ops.check_reset_block(hw))
+		return E1000_SUCCESS;
 
-	/*
-	 * If requested flow control is set to default, set flow control
+	/* If requested flow control is set to default, set flow control
 	 * based on the EEPROM flow control settings.
 	 */
 	if (hw->fc.requested_mode == e1000_fc_default) {
 		ret_val = e1000_set_default_fc_generic(hw);
 		if (ret_val)
-			goto out;
+			return ret_val;
 	}
 
-	/*
-	 * Save off the requested flow control mode for use later.  Depending
+	/* Save off the requested flow control mode for use later.  Depending
 	 * on the link partner's capabilities, we may or may not use this mode.
 	 */
 	hw->fc.current_mode = hw->fc.requested_mode;
@@ -992,10 +1011,9 @@ s32 e1000_setup_link_generic(struct e1000_hw *hw)
 	/* Call the necessary media_type subroutine to configure the link. */
 	ret_val = hw->mac.ops.setup_physical_interface(hw);
 	if (ret_val)
-		goto out;
+		return ret_val;
 
-	/*
-	 * Initialize the flow control address, type, and PAUSE timer
+	/* Initialize the flow control address, type, and PAUSE timer
 	 * registers to their default values.  This is done even if flow
 	 * control is disabled, because it does not hurt anything to
 	 * initialize these registers.
@@ -1007,10 +1025,125 @@ s32 e1000_setup_link_generic(struct e1000_hw *hw)
 
 	E1000_WRITE_REG(hw, E1000_FCTTV, hw->fc.pause_time);
 
-	ret_val = e1000_set_fc_watermarks_generic(hw);
+	return e1000_set_fc_watermarks_generic(hw);
+}
 
-out:
-	return ret_val;
+/**
+ *  e1000_commit_fc_settings_generic - Configure flow control
+ *  @hw: pointer to the HW structure
+ *
+ *  Write the flow control settings to the Transmit Config Word Register (TXCW)
+ *  base on the flow control settings in e1000_mac_info.
+ **/
+s32 e1000_commit_fc_settings_generic(struct e1000_hw *hw)
+{
+	struct e1000_mac_info *mac = &hw->mac;
+	u32 txcw;
+
+	DEBUGFUNC("e1000_commit_fc_settings_generic");
+
+	/* Check for a software override of the flow control settings, and
+	 * setup the device accordingly.  If auto-negotiation is enabled, then
+	 * software will have to set the "PAUSE" bits to the correct value in
+	 * the Transmit Config Word Register (TXCW) and re-start auto-
+	 * negotiation.  However, if auto-negotiation is disabled, then
+	 * software will have to manually configure the two flow control enable
+	 * bits in the CTRL register.
+	 *
+	 * The possible values of the "fc" parameter are:
+	 *      0:  Flow control is completely disabled
+	 *      1:  Rx flow control is enabled (we can receive pause frames,
+	 *          but not send pause frames).
+	 *      2:  Tx flow control is enabled (we can send pause frames but we
+	 *          do not support receiving pause frames).
+	 *      3:  Both Rx and Tx flow control (symmetric) are enabled.
+	 */
+	switch (hw->fc.current_mode) {
+	case e1000_fc_none:
+		/* Flow control completely disabled by a software over-ride. */
+		txcw = (E1000_TXCW_ANE | E1000_TXCW_FD);
+		break;
+	case e1000_fc_rx_pause:
+		/* Rx Flow control is enabled and Tx Flow control is disabled
+		 * by a software over-ride. Since there really isn't a way to
+		 * advertise that we are capable of Rx Pause ONLY, we will
+		 * advertise that we support both symmetric and asymmetric Rx
+		 * PAUSE.  Later, we will disable the adapter's ability to send
+		 * PAUSE frames.
+		 */
+		txcw = (E1000_TXCW_ANE | E1000_TXCW_FD | E1000_TXCW_PAUSE_MASK);
+		break;
+	case e1000_fc_tx_pause:
+		/* Tx Flow control is enabled, and Rx Flow control is disabled,
+		 * by a software over-ride.
+		 */
+		txcw = (E1000_TXCW_ANE | E1000_TXCW_FD | E1000_TXCW_ASM_DIR);
+		break;
+	case e1000_fc_full:
+		/* Flow control (both Rx and Tx) is enabled by a software
+		 * over-ride.
+		 */
+		txcw = (E1000_TXCW_ANE | E1000_TXCW_FD | E1000_TXCW_PAUSE_MASK);
+		break;
+	default:
+		DEBUGOUT("Flow control param set incorrectly\n");
+		return -E1000_ERR_CONFIG;
+		break;
+	}
+
+	E1000_WRITE_REG(hw, E1000_TXCW, txcw);
+	mac->txcw = txcw;
+
+	return E1000_SUCCESS;
+}
+
+/**
+ *  e1000_poll_fiber_serdes_link_generic - Poll for link up
+ *  @hw: pointer to the HW structure
+ *
+ *  Polls for link up by reading the status register, if link fails to come
+ *  up with auto-negotiation, then the link is forced if a signal is detected.
+ **/
+s32 e1000_poll_fiber_serdes_link_generic(struct e1000_hw *hw)
+{
+	struct e1000_mac_info *mac = &hw->mac;
+	u32 i, status;
+	s32 ret_val;
+
+	DEBUGFUNC("e1000_poll_fiber_serdes_link_generic");
+
+	/* If we have a signal (the cable is plugged in, or assumed TRUE for
+	 * serdes media) then poll for a "Link-Up" indication in the Device
+	 * Status Register.  Time-out if a link isn't seen in 500 milliseconds
+	 * seconds (Auto-negotiation should complete in less than 500
+	 * milliseconds even if the other end is doing it in SW).
+	 */
+	for (i = 0; i < FIBER_LINK_UP_LIMIT; i++) {
+		msec_delay(10);
+		status = E1000_READ_REG(hw, E1000_STATUS);
+		if (status & E1000_STATUS_LU)
+			break;
+	}
+	if (i == FIBER_LINK_UP_LIMIT) {
+		DEBUGOUT("Never got a valid link from auto-neg!!!\n");
+		mac->autoneg_failed = TRUE;
+		/* AutoNeg failed to achieve a link, so we'll call
+		 * mac->check_for_link. This routine will force the
+		 * link up if we detect a signal. This will allow us to
+		 * communicate with non-autonegotiating link partners.
+		 */
+		ret_val = mac->ops.check_for_link(hw);
+		if (ret_val) {
+			DEBUGOUT("Error while checking for link\n");
+			return ret_val;
+		}
+		mac->autoneg_failed = FALSE;
+	} else {
+		mac->autoneg_failed = FALSE;
+		DEBUGOUT("Valid Link Found\n");
+	}
+
+	return E1000_SUCCESS;
 }
 
 /**
@@ -1022,9 +1155,8 @@ out:
  **/
 s32 e1000_setup_fiber_serdes_link_generic(struct e1000_hw *hw)
 {
-	struct e1000_mac_info *mac = &hw->mac;
 	u32 ctrl;
-	s32 ret_val = E1000_SUCCESS;
+	s32 ret_val;
 
 	DEBUGFUNC("e1000_setup_fiber_serdes_link_generic");
 
@@ -1033,14 +1165,13 @@ s32 e1000_setup_fiber_serdes_link_generic(struct e1000_hw *hw)
 	/* Take the link out of reset */
 	ctrl &= ~E1000_CTRL_LRST;
 
-	mac->ops.config_collision_dist(hw);
+	hw->mac.ops.config_collision_dist(hw);
 
 	ret_val = e1000_commit_fc_settings_generic(hw);
 	if (ret_val)
-		goto out;
+		return ret_val;
 
-	/*
-	 * Since auto-negotiation is enabled, take the link out of reset (the
+	/* Since auto-negotiation is enabled, take the link out of reset (the
 	 * link will be in reset, because we previously reset the chip). This
 	 * will restart auto-negotiation.  If auto-negotiation is successful
 	 * then the link-up status bit will be set and the flow control enable
@@ -1052,8 +1183,7 @@ s32 e1000_setup_fiber_serdes_link_generic(struct e1000_hw *hw)
 	E1000_WRITE_FLUSH(hw);
 	msec_delay(1);
 
-	/*
-	 * For these adapters, the SW definable pin 1 is set when the optics
+	/* For these adapters, the SW definable pin 1 is set when the optics
 	 * detect a signal.  If we have a signal, then poll for a "Link-Up"
 	 * indication.
 	 */
@@ -1064,7 +1194,6 @@ s32 e1000_setup_fiber_serdes_link_generic(struct e1000_hw *hw)
 		DEBUGOUT("No signal detected\n");
 	}
 
-out:
 	return ret_val;
 }
 
@@ -1075,7 +1204,7 @@ out:
  *  Configures the collision distance to the default value and is used
  *  during link setup.
  **/
-void e1000_config_collision_dist_generic(struct e1000_hw *hw)
+static void e1000_config_collision_dist_generic(struct e1000_hw *hw)
 {
 	u32 tctl;
 
@@ -1091,157 +1220,27 @@ void e1000_config_collision_dist_generic(struct e1000_hw *hw)
 }
 
 /**
- *  e1000_poll_fiber_serdes_link_generic - Poll for link up
+ *  e1000_set_fc_watermarks_generic - Set flow control high/low watermarks
  *  @hw: pointer to the HW structure
  *
- *  Polls for link up by reading the status register, if link fails to come
- *  up with auto-negotiation, then the link is forced if a signal is detected.
+ *  Sets the flow control high/low threshold (watermark) registers.  If
+ *  flow control XON frame transmission is enabled, then set XON frame
+ *  transmission as well.
  **/
-s32 e1000_poll_fiber_serdes_link_generic(struct e1000_hw *hw)
-{
-	struct e1000_mac_info *mac = &hw->mac;
-	u32 i, status;
-	s32 ret_val = E1000_SUCCESS;
-
-	DEBUGFUNC("e1000_poll_fiber_serdes_link_generic");
-
-	/*
-	 * If we have a signal (the cable is plugged in, or assumed TRUE for
-	 * serdes media) then poll for a "Link-Up" indication in the Device
-	 * Status Register.  Time-out if a link isn't seen in 500 milliseconds
-	 * seconds (Auto-negotiation should complete in less than 500
-	 * milliseconds even if the other end is doing it in SW).
-	 */
-	for (i = 0; i < FIBER_LINK_UP_LIMIT; i++) {
-		msec_delay(10);
-		status = E1000_READ_REG(hw, E1000_STATUS);
-		if (status & E1000_STATUS_LU)
-			break;
-	}
-	if (i == FIBER_LINK_UP_LIMIT) {
-		DEBUGOUT("Never got a valid link from auto-neg!!!\n");
-		mac->autoneg_failed = 1;
-		/*
-		 * AutoNeg failed to achieve a link, so we'll call
-		 * mac->check_for_link. This routine will force the
-		 * link up if we detect a signal. This will allow us to
-		 * communicate with non-autonegotiating link partners.
-		 */
-		ret_val = mac->ops.check_for_link(hw);
-		if (ret_val) {
-			DEBUGOUT("Error while checking for link\n");
-			goto out;
-		}
-		mac->autoneg_failed = 0;
-	} else {
-		mac->autoneg_failed = 0;
-		DEBUGOUT("Valid Link Found\n");
-	}
-
-out:
-	return ret_val;
-}
-
-/**
- *  e1000_commit_fc_settings_generic - Configure flow control
- *  @hw: pointer to the HW structure
- *
- *  Write the flow control settings to the Transmit Config Word Register (TXCW)
- *  base on the flow control settings in e1000_mac_info.
- **/
-s32 e1000_commit_fc_settings_generic(struct e1000_hw *hw)
-{
-	struct e1000_mac_info *mac = &hw->mac;
-	u32 txcw;
-	s32 ret_val = E1000_SUCCESS;
-
-	DEBUGFUNC("e1000_commit_fc_settings_generic");
-
-	/*
-	 * Check for a software override of the flow control settings, and
-	 * setup the device accordingly.  If auto-negotiation is enabled, then
-	 * software will have to set the "PAUSE" bits to the correct value in
-	 * the Transmit Config Word Register (TXCW) and re-start auto-
-	 * negotiation.  However, if auto-negotiation is disabled, then
-	 * software will have to manually configure the two flow control enable
-	 * bits in the CTRL register.
-	 *
-	 * The possible values of the "fc" parameter are:
-	 *      0:  Flow control is completely disabled
-	 *      1:  Rx flow control is enabled (we can receive pause frames,
-	 *          but not send pause frames).
-	 *      2:  Tx flow control is enabled (we can send pause frames but we
-	 *          do not support receiving pause frames).
-	 *      3:  Both Rx and Tx flow control (symmetric) are enabled.
-	 */
-	switch (hw->fc.current_mode) {
-	case e1000_fc_none:
-		/* Flow control completely disabled by a software over-ride. */
-		txcw = (E1000_TXCW_ANE | E1000_TXCW_FD);
-		break;
-	case e1000_fc_rx_pause:
-		/*
-		 * Rx Flow control is enabled and Tx Flow control is disabled
-		 * by a software over-ride. Since there really isn't a way to
-		 * advertise that we are capable of Rx Pause ONLY, we will
-		 * advertise that we support both symmetric and asymmetric Rx
-		 * PAUSE.  Later, we will disable the adapter's ability to send
-		 * PAUSE frames.
-		 */
-		txcw = (E1000_TXCW_ANE | E1000_TXCW_FD | E1000_TXCW_PAUSE_MASK);
-		break;
-	case e1000_fc_tx_pause:
-		/*
-		 * Tx Flow control is enabled, and Rx Flow control is disabled,
-		 * by a software over-ride.
-		 */
-		txcw = (E1000_TXCW_ANE | E1000_TXCW_FD | E1000_TXCW_ASM_DIR);
-		break;
-	case e1000_fc_full:
-		/*
-		 * Flow control (both Rx and Tx) is enabled by a software
-		 * over-ride.
-		 */
-		txcw = (E1000_TXCW_ANE | E1000_TXCW_FD | E1000_TXCW_PAUSE_MASK);
-		break;
-	default:
-		DEBUGOUT("Flow control param set incorrectly\n");
-		ret_val = -E1000_ERR_CONFIG;
-		goto out;
-		break;
-	}
-
-	E1000_WRITE_REG(hw, E1000_TXCW, txcw);
-	mac->txcw = txcw;
-
-out:
-	return ret_val;
-}
-
-/**
- *  e1000_set_fc_watermarks_generic - Set flow control high/low watermarks
- *  @hw: pointer to the HW structure
- *
- *  Sets the flow control high/low threshold (watermark) registers.  If
- *  flow control XON frame transmission is enabled, then set XON frame
- *  transmission as well.
- **/
-s32 e1000_set_fc_watermarks_generic(struct e1000_hw *hw)
+s32 e1000_set_fc_watermarks_generic(struct e1000_hw *hw)
 {
 	u32 fcrtl = 0, fcrth = 0;
 
 	DEBUGFUNC("e1000_set_fc_watermarks_generic");
 
-	/*
-	 * Set the flow control receive threshold registers.  Normally,
+	/* Set the flow control receive threshold registers.  Normally,
 	 * these registers will be set to a default threshold that may be
 	 * adjusted later by the driver's runtime code.  However, if the
 	 * ability to transmit pause frames is not enabled, then these
 	 * registers will be set to 0.
 	 */
 	if (hw->fc.current_mode & e1000_fc_tx_pause) {
-		/*
-		 * We need to set up the Receive Threshold high and low water
+		/* We need to set up the Receive Threshold high and low water
 		 * marks as well as (optionally) enabling the transmission of
 		 * XON frames.
 		 */
@@ -1258,48 +1257,6 @@ s32 e1000_set_fc_watermarks_generic(struct e1000_hw *hw)
 }
 
 /**
- *  e1000_set_default_fc_generic - Set flow control default values
- *  @hw: pointer to the HW structure
- *
- *  Read the EEPROM for the default values for flow control and store the
- *  values.
- **/
-s32 e1000_set_default_fc_generic(struct e1000_hw *hw)
-{
-	s32 ret_val = E1000_SUCCESS;
-	u16 nvm_data;
-
-	DEBUGFUNC("e1000_set_default_fc_generic");
-
-	/*
-	 * Read and store word 0x0F of the EEPROM. This word contains bits
-	 * that determine the hardware's default PAUSE (flow control) mode,
-	 * a bit that determines whether the HW defaults to enabling or
-	 * disabling auto-negotiation, and the direction of the
-	 * SW defined pins. If there is no SW over-ride of the flow
-	 * control setting, then the variable hw->fc will
-	 * be initialized based on a value in the EEPROM.
-	 */
-	ret_val = hw->nvm.ops.read(hw, NVM_INIT_CONTROL2_REG, 1, &nvm_data);
-
-	if (ret_val) {
-		DEBUGOUT("NVM Read Error\n");
-		goto out;
-	}
-
-	if ((nvm_data & NVM_WORD0F_PAUSE_MASK) == 0)
-		hw->fc.requested_mode = e1000_fc_none;
-	else if ((nvm_data & NVM_WORD0F_PAUSE_MASK) ==
-		 NVM_WORD0F_ASM_DIR)
-		hw->fc.requested_mode = e1000_fc_tx_pause;
-	else
-		hw->fc.requested_mode = e1000_fc_full;
-
-out:
-	return ret_val;
-}
-
-/**
  *  e1000_force_mac_fc_generic - Force the MAC's flow control settings
  *  @hw: pointer to the HW structure
  *
@@ -1312,14 +1269,12 @@ out:
 s32 e1000_force_mac_fc_generic(struct e1000_hw *hw)
 {
 	u32 ctrl;
-	s32 ret_val = E1000_SUCCESS;
 
 	DEBUGFUNC("e1000_force_mac_fc_generic");
 
 	ctrl = E1000_READ_REG(hw, E1000_CTRL);
 
-	/*
-	 * Because we didn't get link via the internal auto-negotiation
+	/* Because we didn't get link via the internal auto-negotiation
 	 * mechanism (we either forced link or we got link via PHY
 	 * auto-neg), we have to manually enable/disable transmit an
 	 * receive flow control.
@@ -1355,14 +1310,12 @@ s32 e1000_force_mac_fc_generic(struct e1000_hw *hw)
 		break;
 	default:
 		DEBUGOUT("Flow control param set incorrectly\n");
-		ret_val = -E1000_ERR_CONFIG;
-		goto out;
+		return -E1000_ERR_CONFIG;
 	}
 
 	E1000_WRITE_REG(hw, E1000_CTRL, ctrl);
 
-out:
-	return ret_val;
+	return E1000_SUCCESS;
 }
 
 /**
@@ -1379,13 +1332,13 @@ s32 e1000_config_fc_after_link_up_generic(struct e1000_hw *hw)
 {
 	struct e1000_mac_info *mac = &hw->mac;
 	s32 ret_val = E1000_SUCCESS;
+	u32 pcs_status_reg, pcs_adv_reg, pcs_lp_ability_reg, pcs_ctrl_reg;
 	u16 mii_status_reg, mii_nway_adv_reg, mii_nway_lp_ability_reg;
 	u16 speed, duplex;
 
 	DEBUGFUNC("e1000_config_fc_after_link_up_generic");
 
-	/*
-	 * Check for the case where we have fiber media and auto-neg failed
+	/* Check for the case where we have fiber media and auto-neg failed
 	 * so we had to force link.  In this case, we need to force the
 	 * configuration of the MAC to match the "fc" parameter.
 	 */
@@ -1400,35 +1353,32 @@ s32 e1000_config_fc_after_link_up_generic(struct e1000_hw *hw)
 
 	if (ret_val) {
 		DEBUGOUT("Error forcing flow control settings\n");
-		goto out;
+		return ret_val;
 	}
 
-	/*
-	 * Check for the case where we have copper media and auto-neg is
+	/* Check for the case where we have copper media and auto-neg is
 	 * enabled.  In this case, we need to check and see if Auto-Neg
 	 * has completed, and if so, how the PHY and link partner has
 	 * flow control configured.
 	 */
 	if ((hw->phy.media_type == e1000_media_type_copper) && mac->autoneg) {
-		/*
-		 * Read the MII Status Register and check to see if AutoNeg
+		/* Read the MII Status Register and check to see if AutoNeg
 		 * has completed.  We read this twice because this reg has
 		 * some "sticky" (latched) bits.
 		 */
 		ret_val = hw->phy.ops.read_reg(hw, PHY_STATUS, &mii_status_reg);
 		if (ret_val)
-			goto out;
+			return ret_val;
 		ret_val = hw->phy.ops.read_reg(hw, PHY_STATUS, &mii_status_reg);
 		if (ret_val)
-			goto out;
+			return ret_val;
 
 		if (!(mii_status_reg & MII_SR_AUTONEG_COMPLETE)) {
 			DEBUGOUT("Copper PHY and Auto Neg has not completed.\n");
-			goto out;
+			return ret_val;
 		}
 
-		/*
-		 * The AutoNeg process has completed, so we now need to
+		/* The AutoNeg process has completed, so we now need to
 		 * read both the Auto Negotiation Advertisement
 		 * Register (Address 4) and the Auto_Negotiation Base
 		 * Page Ability Register (Address 5) to determine how
@@ -1437,14 +1387,13 @@ s32 e1000_config_fc_after_link_up_generic(struct e1000_hw *hw)
 		ret_val = hw->phy.ops.read_reg(hw, PHY_AUTONEG_ADV,
 					       &mii_nway_adv_reg);
 		if (ret_val)
-			goto out;
+			return ret_val;
 		ret_val = hw->phy.ops.read_reg(hw, PHY_LP_ABILITY,
 					       &mii_nway_lp_ability_reg);
 		if (ret_val)
-			goto out;
+			return ret_val;
 
-		/*
-		 * Two bits in the Auto Negotiation Advertisement Register
+		/* Two bits in the Auto Negotiation Advertisement Register
 		 * (Address 4) and two bits in the Auto Negotiation Base
 		 * Page Ability Register (Address 5) determine flow control
 		 * for both the PHY and the link partner.  The following
@@ -1479,8 +1428,7 @@ s32 e1000_config_fc_after_link_up_generic(struct e1000_hw *hw)
 		 */
 		if ((mii_nway_adv_reg & NWAY_AR_PAUSE) &&
 		    (mii_nway_lp_ability_reg & NWAY_LPAR_PAUSE)) {
-			/*
-			 * Now we need to check if the user selected Rx ONLY
+			/* Now we need to check if the user selected Rx ONLY
 			 * of pause frames.  In this case, we had to advertise
 			 * FULL flow control because we could not advertise Rx
 			 * ONLY. Hence, we must now check to see if we need to
@@ -1494,8 +1442,7 @@ s32 e1000_config_fc_after_link_up_generic(struct e1000_hw *hw)
 				DEBUGOUT("Flow Control = Rx PAUSE frames only.\n");
 			}
 		}
-		/*
-		 * For receiving PAUSE frames ONLY.
+		/* For receiving PAUSE frames ONLY.
 		 *
 		 *   LOCAL DEVICE  |   LINK PARTNER
 		 * PAUSE | ASM_DIR | PAUSE | ASM_DIR | Result
@@ -1509,8 +1456,7 @@ s32 e1000_config_fc_after_link_up_generic(struct e1000_hw *hw)
 			hw->fc.current_mode = e1000_fc_tx_pause;
 			DEBUGOUT("Flow Control = Tx PAUSE frames only.\n");
 		}
-		/*
-		 * For transmitting PAUSE frames ONLY.
+		/* For transmitting PAUSE frames ONLY.
 		 *
 		 *   LOCAL DEVICE  |   LINK PARTNER
 		 * PAUSE | ASM_DIR | PAUSE | ASM_DIR | Result
@@ -1524,41 +1470,161 @@ s32 e1000_config_fc_after_link_up_generic(struct e1000_hw *hw)
 			hw->fc.current_mode = e1000_fc_rx_pause;
 			DEBUGOUT("Flow Control = Rx PAUSE frames only.\n");
 		} else {
-			/*
-			 * Per the IEEE spec, at this point flow control
+			/* Per the IEEE spec, at this point flow control
 			 * should be disabled.
 			 */
 			hw->fc.current_mode = e1000_fc_none;
 			DEBUGOUT("Flow Control = NONE.\n");
 		}
 
-		/*
-		 * Now we need to do one last check...  If we auto-
+		/* Now we need to do one last check...  If we auto-
 		 * negotiated to HALF DUPLEX, flow control should not be
 		 * enabled per IEEE 802.3 spec.
 		 */
 		ret_val = mac->ops.get_link_up_info(hw, &speed, &duplex);
 		if (ret_val) {
 			DEBUGOUT("Error getting link speed and duplex\n");
-			goto out;
+			return ret_val;
 		}
 
 		if (duplex == HALF_DUPLEX)
 			hw->fc.current_mode = e1000_fc_none;
 
-		/*
-		 * Now we call a subroutine to actually force the MAC
+		/* Now we call a subroutine to actually force the MAC
 		 * controller to use the correct flow control settings.
 		 */
 		ret_val = e1000_force_mac_fc_generic(hw);
 		if (ret_val) {
 			DEBUGOUT("Error forcing flow control settings\n");
-			goto out;
+			return ret_val;
 		}
 	}
 
-out:
-	return ret_val;
+	/* Check for the case where we have SerDes media and auto-neg is
+	 * enabled.  In this case, we need to check and see if Auto-Neg
+	 * has completed, and if so, how the PHY and link partner has
+	 * flow control configured.
+	 */
+	if ((hw->phy.media_type == e1000_media_type_internal_serdes) &&
+	    mac->autoneg) {
+		/* Read the PCS_LSTS and check to see if AutoNeg
+		 * has completed.
+		 */
+		pcs_status_reg = E1000_READ_REG(hw, E1000_PCS_LSTAT);
+
+		if (!(pcs_status_reg & E1000_PCS_LSTS_AN_COMPLETE)) {
+			DEBUGOUT("PCS Auto Neg has not completed.\n");
+			return ret_val;
+		}
+
+		/* The AutoNeg process has completed, so we now need to
+		 * read both the Auto Negotiation Advertisement
+		 * Register (PCS_ANADV) and the Auto_Negotiation Base
+		 * Page Ability Register (PCS_LPAB) to determine how
+		 * flow control was negotiated.
+		 */
+		pcs_adv_reg = E1000_READ_REG(hw, E1000_PCS_ANADV);
+		pcs_lp_ability_reg = E1000_READ_REG(hw, E1000_PCS_LPAB);
+
+		/* Two bits in the Auto Negotiation Advertisement Register
+		 * (PCS_ANADV) and two bits in the Auto Negotiation Base
+		 * Page Ability Register (PCS_LPAB) determine flow control
+		 * for both the PHY and the link partner.  The following
+		 * table, taken out of the IEEE 802.3ab/D6.0 dated March 25,
+		 * 1999, describes these PAUSE resolution bits and how flow
+		 * control is determined based upon these settings.
+		 * NOTE:  DC = Don't Care
+		 *
+		 *   LOCAL DEVICE  |   LINK PARTNER
+		 * PAUSE | ASM_DIR | PAUSE | ASM_DIR | NIC Resolution
+		 *-------|---------|-------|---------|--------------------
+		 *   0   |    0    |  DC   |   DC    | e1000_fc_none
+		 *   0   |    1    |   0   |   DC    | e1000_fc_none
+		 *   0   |    1    |   1   |    0    | e1000_fc_none
+		 *   0   |    1    |   1   |    1    | e1000_fc_tx_pause
+		 *   1   |    0    |   0   |   DC    | e1000_fc_none
+		 *   1   |   DC    |   1   |   DC    | e1000_fc_full
+		 *   1   |    1    |   0   |    0    | e1000_fc_none
+		 *   1   |    1    |   0   |    1    | e1000_fc_rx_pause
+		 *
+		 * Are both PAUSE bits set to 1?  If so, this implies
+		 * Symmetric Flow Control is enabled at both ends.  The
+		 * ASM_DIR bits are irrelevant per the spec.
+		 *
+		 * For Symmetric Flow Control:
+		 *
+		 *   LOCAL DEVICE  |   LINK PARTNER
+		 * PAUSE | ASM_DIR | PAUSE | ASM_DIR | Result
+		 *-------|---------|-------|---------|--------------------
+		 *   1   |   DC    |   1   |   DC    | e1000_fc_full
+		 *
+		 */
+		if ((pcs_adv_reg & E1000_TXCW_PAUSE) &&
+		    (pcs_lp_ability_reg & E1000_TXCW_PAUSE)) {
+			/* Now we need to check if the user selected Rx ONLY
+			 * of pause frames.  In this case, we had to advertise
+			 * FULL flow control because we could not advertise Rx
+			 * ONLY. Hence, we must now check to see if we need to
+			 * turn OFF the TRANSMISSION of PAUSE frames.
+			 */
+			if (hw->fc.requested_mode == e1000_fc_full) {
+				hw->fc.current_mode = e1000_fc_full;
+				DEBUGOUT("Flow Control = FULL.\n");
+			} else {
+				hw->fc.current_mode = e1000_fc_rx_pause;
+				DEBUGOUT("Flow Control = Rx PAUSE frames only.\n");
+			}
+		}
+		/* For receiving PAUSE frames ONLY.
+		 *
+		 *   LOCAL DEVICE  |   LINK PARTNER
+		 * PAUSE | ASM_DIR | PAUSE | ASM_DIR | Result
+		 *-------|---------|-------|---------|--------------------
+		 *   0   |    1    |   1   |    1    | e1000_fc_tx_pause
+		 */
+		else if (!(pcs_adv_reg & E1000_TXCW_PAUSE) &&
+			  (pcs_adv_reg & E1000_TXCW_ASM_DIR) &&
+			  (pcs_lp_ability_reg & E1000_TXCW_PAUSE) &&
+			  (pcs_lp_ability_reg & E1000_TXCW_ASM_DIR)) {
+			hw->fc.current_mode = e1000_fc_tx_pause;
+			DEBUGOUT("Flow Control = Tx PAUSE frames only.\n");
+		}
+		/* For transmitting PAUSE frames ONLY.
+		 *
+		 *   LOCAL DEVICE  |   LINK PARTNER
+		 * PAUSE | ASM_DIR | PAUSE | ASM_DIR | Result
+		 *-------|---------|-------|---------|--------------------
+		 *   1   |    1    |   0   |    1    | e1000_fc_rx_pause
+		 */
+		else if ((pcs_adv_reg & E1000_TXCW_PAUSE) &&
+			 (pcs_adv_reg & E1000_TXCW_ASM_DIR) &&
+			 !(pcs_lp_ability_reg & E1000_TXCW_PAUSE) &&
+			 (pcs_lp_ability_reg & E1000_TXCW_ASM_DIR)) {
+			hw->fc.current_mode = e1000_fc_rx_pause;
+			DEBUGOUT("Flow Control = Rx PAUSE frames only.\n");
+		} else {
+			/* Per the IEEE spec, at this point flow control
+			 * should be disabled.
+			 */
+			hw->fc.current_mode = e1000_fc_none;
+			DEBUGOUT("Flow Control = NONE.\n");
+		}
+
+		/* Now we call a subroutine to actually force the MAC
+		 * controller to use the correct flow control settings.
+		 */
+		pcs_ctrl_reg = E1000_READ_REG(hw, E1000_PCS_LCTL);
+		pcs_ctrl_reg |= E1000_PCS_LCTL_FORCE_FCTRL;
+		E1000_WRITE_REG(hw, E1000_PCS_LCTL, pcs_ctrl_reg);
+
+		ret_val = e1000_force_mac_fc_generic(hw);
+		if (ret_val) {
+			DEBUGOUT("Error forcing flow control settings\n");
+			return ret_val;
+		}
+	}
+
+	return E1000_SUCCESS;
 }
 
 /**
@@ -1629,7 +1695,6 @@ s32 e1000_get_speed_and_duplex_fiber_serdes_generic(struct e1000_hw *hw,
 s32 e1000_get_hw_semaphore_generic(struct e1000_hw *hw)
 {
 	u32 swsm;
-	s32 ret_val = E1000_SUCCESS;
 	s32 timeout = hw->nvm.word_size + 1;
 	s32 i = 0;
 
@@ -1647,8 +1712,7 @@ s32 e1000_get_hw_semaphore_generic(struct e1000_hw *hw)
 
 	if (i == timeout) {
 		DEBUGOUT("Driver can't access device - SMBI bit is set.\n");
-		ret_val = -E1000_ERR_NVM;
-		goto out;
+		return -E1000_ERR_NVM;
 	}
 
 	/* Get the FW semaphore. */
@@ -1667,12 +1731,10 @@ s32 e1000_get_hw_semaphore_generic(struct e1000_hw *hw)
 		/* Release semaphores */
 		e1000_put_hw_semaphore_generic(hw);
 		DEBUGOUT("Driver can't access the NVM\n");
-		ret_val = -E1000_ERR_NVM;
-		goto out;
+		return -E1000_ERR_NVM;
 	}
 
-out:
-	return ret_val;
+	return E1000_SUCCESS;
 }
 
 /**
@@ -1703,7 +1765,6 @@ void e1000_put_hw_semaphore_generic(struct e1000_hw *hw)
 s32 e1000_get_auto_rd_done_generic(struct e1000_hw *hw)
 {
 	s32 i = 0;
-	s32 ret_val = E1000_SUCCESS;
 
 	DEBUGFUNC("e1000_get_auto_rd_done_generic");
 
@@ -1716,12 +1777,10 @@ s32 e1000_get_auto_rd_done_generic(struct e1000_hw *hw)
 
 	if (i == AUTO_READ_DONE_TIMEOUT) {
 		DEBUGOUT("Auto read by HW from NVM has not completed.\n");
-		ret_val = -E1000_ERR_RESET;
-		goto out;
+		return -E1000_ERR_RESET;
 	}
 
-out:
-	return ret_val;
+	return E1000_SUCCESS;
 }
 
 /**
@@ -1741,14 +1800,13 @@ s32 e1000_valid_led_default_generic(struct e1000_hw *hw, u16 *data)
 	ret_val = hw->nvm.ops.read(hw, NVM_ID_LED_SETTINGS, 1, data);
 	if (ret_val) {
 		DEBUGOUT("NVM Read Error\n");
-		goto out;
+		return ret_val;
 	}
 
 	if (*data == ID_LED_RESERVED_0000 || *data == ID_LED_RESERVED_FFFF)
 		*data = ID_LED_DEFAULT;
 
-out:
-	return ret_val;
+	return E1000_SUCCESS;
 }
 
 /**
@@ -1770,7 +1828,7 @@ s32 e1000_id_led_init_generic(struct e1000_hw *hw)
 
 	ret_val = hw->nvm.ops.valid_led_default(hw, &data);
 	if (ret_val)
-		goto out;
+		return ret_val;
 
 	mac->ledctl_default = E1000_READ_REG(hw, E1000_LEDCTL);
 	mac->ledctl_mode1 = mac->ledctl_default;
@@ -1814,8 +1872,7 @@ s32 e1000_id_led_init_generic(struct e1000_hw *hw)
 		}
 	}
 
-out:
-	return ret_val;
+	return E1000_SUCCESS;
 }
 
 /**
@@ -1828,14 +1885,11 @@ out:
 s32 e1000_setup_led_generic(struct e1000_hw *hw)
 {
 	u32 ledctl;
-	s32 ret_val = E1000_SUCCESS;
 
 	DEBUGFUNC("e1000_setup_led_generic");
 
-	if (hw->mac.ops.setup_led != e1000_setup_led_generic) {
-		ret_val = -E1000_ERR_CONFIG;
-		goto out;
-	}
+	if (hw->mac.ops.setup_led != e1000_setup_led_generic)
+		return -E1000_ERR_CONFIG;
 
 	if (hw->phy.media_type == e1000_media_type_fiber) {
 		ledctl = E1000_READ_REG(hw, E1000_LEDCTL);
@@ -1850,8 +1904,7 @@ s32 e1000_setup_led_generic(struct e1000_hw *hw)
 		E1000_WRITE_REG(hw, E1000_LEDCTL, hw->mac.ledctl_mode1);
 	}
 
-out:
-	return ret_val;
+	return E1000_SUCCESS;
 }
 
 /**
@@ -1887,16 +1940,28 @@ s32 e1000_blink_led_generic(struct e1000_hw *hw)
 		ledctl_blink = E1000_LEDCTL_LED0_BLINK |
 		     (E1000_LEDCTL_MODE_LED_ON << E1000_LEDCTL_LED0_MODE_SHIFT);
 	} else {
-		/*
-		 * set the blink bit for each LED that's "on" (0x0E)
-		 * in ledctl_mode2
+		/* Set the blink bit for each LED that's "on" (0x0E)
+		 * (or "off" if inverted) in ledctl_mode2.  The blink
+		 * logic in hardware only works when mode is set to "on"
+		 * so it must be changed accordingly when the mode is
+		 * "off" and inverted.
 		 */
 		ledctl_blink = hw->mac.ledctl_mode2;
-		for (i = 0; i < 4; i++)
-			if (((hw->mac.ledctl_mode2 >> (i * 8)) & 0xFF) ==
-			    E1000_LEDCTL_MODE_LED_ON)
-				ledctl_blink |= (E1000_LEDCTL_LED0_BLINK <<
-						 (i * 8));
+		for (i = 0; i < 32; i += 8) {
+			u32 mode = (hw->mac.ledctl_mode2 >> i) &
+			    E1000_LEDCTL_LED0_MODE_MASK;
+			u32 led_default = hw->mac.ledctl_default >> i;
+
+			if ((!(led_default & E1000_LEDCTL_LED0_IVRT) &&
+			     (mode == E1000_LEDCTL_MODE_LED_ON)) ||
+			    ((led_default & E1000_LEDCTL_LED0_IVRT) &&
+			     (mode == E1000_LEDCTL_MODE_LED_OFF))) {
+				ledctl_blink &=
+				    ~(E1000_LEDCTL_LED0_MODE_MASK << i);
+				ledctl_blink |= (E1000_LEDCTL_LED0_BLINK |
+						 E1000_LEDCTL_MODE_LED_ON) << i;
+			}
+		}
 	}
 
 	E1000_WRITE_REG(hw, E1000_LEDCTL, ledctl_blink);
@@ -1976,7 +2041,7 @@ void e1000_set_pcie_no_snoop_generic(struct e1000_hw *hw, u32 no_snoop)
 	DEBUGFUNC("e1000_set_pcie_no_snoop_generic");
 
 	if (hw->bus.type != e1000_bus_type_pci_express)
-		goto out;
+		return;
 
 	if (no_snoop) {
 		gcr = E1000_READ_REG(hw, E1000_GCR);
@@ -1984,8 +2049,6 @@ void e1000_set_pcie_no_snoop_generic(struct e1000_hw *hw, u32 no_snoop)
 		gcr |= no_snoop;
 		E1000_WRITE_REG(hw, E1000_GCR, gcr);
 	}
-out:
-	return;
 }
 
 /**
@@ -2003,12 +2066,11 @@ s32 e1000_disable_pcie_master_generic(struct e1000_hw *hw)
 {
 	u32 ctrl;
 	s32 timeout = MASTER_DISABLE_TIMEOUT;
-	s32 ret_val = E1000_SUCCESS;
 
 	DEBUGFUNC("e1000_disable_pcie_master_generic");
 
 	if (hw->bus.type != e1000_bus_type_pci_express)
-		goto out;
+		return E1000_SUCCESS;
 
 	ctrl = E1000_READ_REG(hw, E1000_CTRL);
 	ctrl |= E1000_CTRL_GIO_MASTER_DISABLE;
@@ -2024,11 +2086,10 @@ s32 e1000_disable_pcie_master_generic(struct e1000_hw *hw)
 
 	if (!timeout) {
 		DEBUGOUT("Master requests are pending.\n");
-		ret_val = -E1000_ERR_MASTER_REQUESTS_PENDING;
+		return -E1000_ERR_MASTER_REQUESTS_PENDING;
 	}
 
-out:
-	return ret_val;
+	return E1000_SUCCESS;
 }
 
 /**
@@ -2045,7 +2106,7 @@ void e1000_reset_adaptive_generic(struct e1000_hw *hw)
 
 	if (!mac->adaptive_ifs) {
 		DEBUGOUT("Not in Adaptive IFS mode!\n");
-		goto out;
+		return;
 	}
 
 	mac->current_ifs_val = 0;
@@ -2056,8 +2117,6 @@ void e1000_reset_adaptive_generic(struct e1000_hw *hw)
 
 	mac->in_ifs_mode = FALSE;
 	E1000_WRITE_REG(hw, E1000_AIT, 0);
-out:
-	return;
 }
 
 /**
@@ -2075,7 +2134,7 @@ void e1000_update_adaptive_generic(struct e1000_hw *hw)
 
 	if (!mac->adaptive_ifs) {
 		DEBUGOUT("Not in Adaptive IFS mode!\n");
-		goto out;
+		return;
 	}
 
 	if ((mac->collision_delta * mac->ifs_ratio) > mac->tx_packet_delta) {
@@ -2099,8 +2158,6 @@ void e1000_update_adaptive_generic(struct e1000_hw *hw)
 			E1000_WRITE_REG(hw, E1000_AIT, 0);
 		}
 	}
-out:
-	return;
 }
 
 /**
@@ -2112,19 +2169,29 @@ out:
  **/
 static s32 e1000_validate_mdi_setting_generic(struct e1000_hw *hw)
 {
-	s32 ret_val = E1000_SUCCESS;
-
 	DEBUGFUNC("e1000_validate_mdi_setting_generic");
 
 	if (!hw->mac.autoneg && (hw->phy.mdix == 0 || hw->phy.mdix == 3)) {
 		DEBUGOUT("Invalid MDI setting detected\n");
 		hw->phy.mdix = 1;
-		ret_val = -E1000_ERR_CONFIG;
-		goto out;
+		return -E1000_ERR_CONFIG;
 	}
 
-out:
-	return ret_val;
+	return E1000_SUCCESS;
+}
+
+/**
+ *  e1000_validate_mdi_setting_crossover_generic - Verify MDI/MDIx settings
+ *  @hw: pointer to the HW structure
+ *
+ *  Validate the MDI/MDIx setting, allowing for auto-crossover during forced
+ *  operation.
+ **/
+s32 e1000_validate_mdi_setting_crossover_generic(struct e1000_hw *hw)
+{
+	DEBUGFUNC("e1000_validate_mdi_setting_crossover_generic");
+
+	return E1000_SUCCESS;
 }
 
 /**
@@ -2142,7 +2209,6 @@ s32 e1000_write_8bit_ctrl_reg_generic(struct e1000_hw *hw, u32 reg,
 				      u32 offset, u8 data)
 {
 	u32 i, regvalue = 0;
-	s32 ret_val = E1000_SUCCESS;
 
 	DEBUGFUNC("e1000_write_8bit_ctrl_reg_generic");
 
@@ -2159,10 +2225,8 @@ s32 e1000_write_8bit_ctrl_reg_generic(struct e1000_hw *hw, u32 reg,
 	}
 	if (!(regvalue & E1000_GEN_CTL_READY)) {
 		DEBUGOUT1("Reg %08x did not indicate ready\n", reg);
-		ret_val = -E1000_ERR_PHY;
-		goto out;
+		return -E1000_ERR_PHY;
 	}
 
-out:
-	return ret_val;
+	return E1000_SUCCESS;
 }
diff --git a/sys/dev/e1000/e1000_mac.h b/sys/dev/e1000/e1000_mac.h
index 11ffab7..3e2ccde 100644
--- a/sys/dev/e1000/e1000_mac.h
+++ b/sys/dev/e1000/e1000_mac.h
@@ -1,6 +1,6 @@
 /******************************************************************************
 
-  Copyright (c) 2001-2010, Intel Corporation 
+  Copyright (c) 2001-2013, Intel Corporation 
   All rights reserved.
   
   Redistribution and use in source and binary forms, with or without 
@@ -35,10 +35,6 @@
 #ifndef _E1000_MAC_H_
 #define _E1000_MAC_H_
 
-/*
- * Functions that should not be called directly from drivers but can be used
- * by other files in this 'shared code'
- */
 void e1000_init_mac_ops_generic(struct e1000_hw *hw);
 void e1000_null_mac_generic(struct e1000_hw *hw);
 s32  e1000_null_ops_generic(struct e1000_hw *hw);
@@ -47,6 +43,7 @@ bool e1000_null_mng_mode(struct e1000_hw *hw);
 void e1000_null_update_mc(struct e1000_hw *hw, u8 *h, u32 a);
 void e1000_null_write_vfta(struct e1000_hw *hw, u32 a, u32 b);
 void e1000_null_rar_set(struct e1000_hw *hw, u8 *h, u32 a);
+s32  e1000_null_set_obff_timer(struct e1000_hw *hw, u32 a);
 s32  e1000_blink_led_generic(struct e1000_hw *hw);
 s32  e1000_check_for_copper_link_generic(struct e1000_hw *hw);
 s32  e1000_check_for_fiber_link_generic(struct e1000_hw *hw);
@@ -64,31 +61,30 @@ void e1000_set_lan_id_single_port(struct e1000_hw *hw);
 void e1000_set_lan_id_multi_port_pci(struct e1000_hw *hw);
 s32  e1000_get_hw_semaphore_generic(struct e1000_hw *hw);
 s32  e1000_get_speed_and_duplex_copper_generic(struct e1000_hw *hw, u16 *speed,
-                                               u16 *duplex);
+					       u16 *duplex);
 s32  e1000_get_speed_and_duplex_fiber_serdes_generic(struct e1000_hw *hw,
-                                                     u16 *speed, u16 *duplex);
+						     u16 *speed, u16 *duplex);
 s32  e1000_id_led_init_generic(struct e1000_hw *hw);
 s32  e1000_led_on_generic(struct e1000_hw *hw);
 s32  e1000_led_off_generic(struct e1000_hw *hw);
 void e1000_update_mc_addr_list_generic(struct e1000_hw *hw,
-                                       u8 *mc_addr_list, u32 mc_addr_count);
+				       u8 *mc_addr_list, u32 mc_addr_count);
 s32  e1000_set_default_fc_generic(struct e1000_hw *hw);
 s32  e1000_set_fc_watermarks_generic(struct e1000_hw *hw);
 s32  e1000_setup_fiber_serdes_link_generic(struct e1000_hw *hw);
 s32  e1000_setup_led_generic(struct e1000_hw *hw);
 s32  e1000_setup_link_generic(struct e1000_hw *hw);
+s32  e1000_validate_mdi_setting_crossover_generic(struct e1000_hw *hw);
 s32  e1000_write_8bit_ctrl_reg_generic(struct e1000_hw *hw, u32 reg,
-                                       u32 offset, u8 data);
+				       u32 offset, u8 data);
 
 u32  e1000_hash_mc_addr_generic(struct e1000_hw *hw, u8 *mc_addr);
 
 void e1000_clear_hw_cntrs_base_generic(struct e1000_hw *hw);
 void e1000_clear_vfta_generic(struct e1000_hw *hw);
-void e1000_config_collision_dist_generic(struct e1000_hw *hw);
 void e1000_init_rx_addrs_generic(struct e1000_hw *hw, u16 rar_count);
 void e1000_pcix_mmrbc_workaround_generic(struct e1000_hw *hw);
 void e1000_put_hw_semaphore_generic(struct e1000_hw *hw);
-void e1000_rar_set_generic(struct e1000_hw *hw, u8 *addr, u32 index);
 s32  e1000_check_alt_mac_addr_generic(struct e1000_hw *hw);
 void e1000_reset_adaptive_generic(struct e1000_hw *hw);
 void e1000_set_pcie_no_snoop_generic(struct e1000_hw *hw, u32 no_snoop);
diff --git a/sys/dev/e1000/e1000_manage.c b/sys/dev/e1000/e1000_manage.c
index 7782739..c58d32d 100644
--- a/sys/dev/e1000/e1000_manage.c
+++ b/sys/dev/e1000/e1000_manage.c
@@ -1,6 +1,6 @@
 /******************************************************************************
 
-  Copyright (c) 2001-2010, Intel Corporation 
+  Copyright (c) 2001-2013, Intel Corporation 
   All rights reserved.
   
   Redistribution and use in source and binary forms, with or without 
@@ -71,23 +71,20 @@ u8 e1000_calculate_checksum(u8 *buffer, u32 length)
 s32 e1000_mng_enable_host_if_generic(struct e1000_hw *hw)
 {
 	u32 hicr;
-	s32 ret_val = E1000_SUCCESS;
 	u8 i;
 
 	DEBUGFUNC("e1000_mng_enable_host_if_generic");
 
-	if (!(hw->mac.arc_subsystem_valid)) {
+	if (!hw->mac.arc_subsystem_valid) {
 		DEBUGOUT("ARC subsystem not valid.\n");
-		ret_val = -E1000_ERR_HOST_INTERFACE_COMMAND;
-		goto out;
+		return -E1000_ERR_HOST_INTERFACE_COMMAND;
 	}
 
 	/* Check that the host interface is enabled. */
 	hicr = E1000_READ_REG(hw, E1000_HICR);
-	if ((hicr & E1000_HICR_EN) == 0) {
+	if (!(hicr & E1000_HICR_EN)) {
 		DEBUGOUT("E1000_HOST_EN bit disabled.\n");
-		ret_val = -E1000_ERR_HOST_INTERFACE_COMMAND;
-		goto out;
+		return -E1000_ERR_HOST_INTERFACE_COMMAND;
 	}
 	/* check the previous command is completed */
 	for (i = 0; i < E1000_MNG_DHCP_COMMAND_TIMEOUT; i++) {
@@ -99,12 +96,10 @@ s32 e1000_mng_enable_host_if_generic(struct e1000_hw *hw)
 
 	if (i == E1000_MNG_DHCP_COMMAND_TIMEOUT) {
 		DEBUGOUT("Previous command timeout failed .\n");
-		ret_val = -E1000_ERR_HOST_INTERFACE_COMMAND;
-		goto out;
+		return -E1000_ERR_HOST_INTERFACE_COMMAND;
 	}
 
-out:
-	return ret_val;
+	return E1000_SUCCESS;
 }
 
 /**
@@ -122,7 +117,7 @@ bool e1000_check_mng_mode_generic(struct e1000_hw *hw)
 
 
 	return (fwsm & E1000_FWSM_MODE_MASK) ==
-	        (E1000_MNG_IAMT_MODE << E1000_FWSM_MODE_SHIFT);
+		(E1000_MNG_IAMT_MODE << E1000_FWSM_MODE_SHIFT);
 }
 
 /**
@@ -147,17 +142,16 @@ bool e1000_enable_tx_pkt_filtering_generic(struct e1000_hw *hw)
 	/* No manageability, no filtering */
 	if (!hw->mac.ops.check_mng_mode(hw)) {
 		hw->mac.tx_pkt_filtering = FALSE;
-		goto out;
+		return hw->mac.tx_pkt_filtering;
 	}
 
-	/*
-	 * If we can't read from the host interface for whatever
+	/* If we can't read from the host interface for whatever
 	 * reason, disable filtering.
 	 */
-	ret_val = hw->mac.ops.mng_enable_host_if(hw);
+	ret_val = e1000_mng_enable_host_if_generic(hw);
 	if (ret_val != E1000_SUCCESS) {
 		hw->mac.tx_pkt_filtering = FALSE;
-		goto out;
+		return hw->mac.tx_pkt_filtering;
 	}
 
 	/* Read in the header.  Length and offset are in dwords. */
@@ -165,79 +159,28 @@ bool e1000_enable_tx_pkt_filtering_generic(struct e1000_hw *hw)
 	offset = E1000_MNG_DHCP_COOKIE_OFFSET >> 2;
 	for (i = 0; i < len; i++)
 		*(buffer + i) = E1000_READ_REG_ARRAY_DWORD(hw, E1000_HOST_IF,
-		                                           offset + i);
+							   offset + i);
 	hdr_csum = hdr->checksum;
 	hdr->checksum = 0;
 	csum = e1000_calculate_checksum((u8 *)hdr,
-	                                E1000_MNG_DHCP_COOKIE_LENGTH);
-	/*
-	 * If either the checksums or signature don't match, then
+					E1000_MNG_DHCP_COOKIE_LENGTH);
+	/* If either the checksums or signature don't match, then
 	 * the cookie area isn't considered valid, in which case we
 	 * take the safe route of assuming Tx filtering is enabled.
 	 */
 	if ((hdr_csum != csum) || (hdr->signature != E1000_IAMT_SIGNATURE)) {
 		hw->mac.tx_pkt_filtering = TRUE;
-		goto out;
+		return hw->mac.tx_pkt_filtering;
 	}
 
 	/* Cookie area is valid, make the final check for filtering. */
-	if (!(hdr->status & E1000_MNG_DHCP_COOKIE_STATUS_PARSING)) {
+	if (!(hdr->status & E1000_MNG_DHCP_COOKIE_STATUS_PARSING))
 		hw->mac.tx_pkt_filtering = FALSE;
-		goto out;
-	}
 
-out:
 	return hw->mac.tx_pkt_filtering;
 }
 
 /**
- *  e1000_mng_write_dhcp_info_generic - Writes DHCP info to host interface
- *  @hw: pointer to the HW structure
- *  @buffer: pointer to the host interface
- *  @length: size of the buffer
- *
- *  Writes the DHCP information to the host interface.
- **/
-s32 e1000_mng_write_dhcp_info_generic(struct e1000_hw *hw, u8 *buffer,
-                                      u16 length)
-{
-	struct e1000_host_mng_command_header hdr;
-	s32 ret_val;
-	u32 hicr;
-
-	DEBUGFUNC("e1000_mng_write_dhcp_info_generic");
-
-	hdr.command_id = E1000_MNG_DHCP_TX_PAYLOAD_CMD;
-	hdr.command_length = length;
-	hdr.reserved1 = 0;
-	hdr.reserved2 = 0;
-	hdr.checksum = 0;
-
-	/* Enable the host interface */
-	ret_val = hw->mac.ops.mng_enable_host_if(hw);
-	if (ret_val)
-		goto out;
-
-	/* Populate the host interface with the contents of "buffer". */
-	ret_val = hw->mac.ops.mng_host_if_write(hw, buffer, length,
-	                                  sizeof(hdr), &(hdr.checksum));
-	if (ret_val)
-		goto out;
-
-	/* Write the manageability command header */
-	ret_val = hw->mac.ops.mng_write_cmd_header(hw, &hdr);
-	if (ret_val)
-		goto out;
-
-	/* Tell the ARC a new command is pending. */
-	hicr = E1000_READ_REG(hw, E1000_HICR);
-	E1000_WRITE_REG(hw, E1000_HICR, hicr | E1000_HICR_C);
-
-out:
-	return ret_val;
-}
-
-/**
  *  e1000_mng_write_cmd_header_generic - Writes manageability command header
  *  @hw: pointer to the HW structure
  *  @hdr: pointer to the host interface command header
@@ -245,7 +188,7 @@ out:
  *  Writes the command header after does the checksum calculation.
  **/
 s32 e1000_mng_write_cmd_header_generic(struct e1000_hw *hw,
-                                    struct e1000_host_mng_command_header *hdr)
+				      struct e1000_host_mng_command_header *hdr)
 {
 	u16 i, length = sizeof(struct e1000_host_mng_command_header);
 
@@ -259,7 +202,7 @@ s32 e1000_mng_write_cmd_header_generic(struct e1000_hw *hw,
 	/* Write the relevant command block into the ram area. */
 	for (i = 0; i < length; i++) {
 		E1000_WRITE_REG_ARRAY_DWORD(hw, E1000_HOST_IF, i,
-		                            *((u32 *) hdr + i));
+					    *((u32 *) hdr + i));
 		E1000_WRITE_FLUSH(hw);
 	}
 
@@ -279,22 +222,19 @@ s32 e1000_mng_write_cmd_header_generic(struct e1000_hw *hw,
  *  way.  Also fills up the sum of the buffer in *buffer parameter.
  **/
 s32 e1000_mng_host_if_write_generic(struct e1000_hw *hw, u8 *buffer,
-                                    u16 length, u16 offset, u8 *sum)
+				    u16 length, u16 offset, u8 *sum)
 {
 	u8 *tmp;
 	u8 *bufptr = buffer;
 	u32 data = 0;
-	s32 ret_val = E1000_SUCCESS;
 	u16 remaining, i, j, prev_bytes;
 
 	DEBUGFUNC("e1000_mng_host_if_write_generic");
 
 	/* sum = only sum of the data and it is not checksum */
 
-	if (length == 0 || offset + length > E1000_HI_MAX_MNG_DATA_LENGTH) {
-		ret_val = -E1000_ERR_PARAM;
-		goto out;
-	}
+	if (length == 0 || offset + length > E1000_HI_MAX_MNG_DATA_LENGTH)
+		return -E1000_ERR_PARAM;
 
 	tmp = (u8 *)&data;
 	prev_bytes = offset & 0x3;
@@ -317,8 +257,7 @@ s32 e1000_mng_host_if_write_generic(struct e1000_hw *hw, u8 *buffer,
 	/* Calculate length in DWORDs */
 	length >>= 2;
 
-	/*
-	 * The device driver writes the relevant command block into the
+	/* The device driver writes the relevant command block into the
 	 * ram area.
 	 */
 	for (i = 0; i < length; i++) {
@@ -328,7 +267,7 @@ s32 e1000_mng_host_if_write_generic(struct e1000_hw *hw, u8 *buffer,
 		}
 
 		E1000_WRITE_REG_ARRAY_DWORD(hw, E1000_HOST_IF, offset + i,
-		                            data);
+					    data);
 	}
 	if (remaining) {
 		for (j = 0; j < sizeof(u32); j++) {
@@ -339,11 +278,57 @@ s32 e1000_mng_host_if_write_generic(struct e1000_hw *hw, u8 *buffer,
 
 			*sum += *(tmp + j);
 		}
-		E1000_WRITE_REG_ARRAY_DWORD(hw, E1000_HOST_IF, offset + i, data);
+		E1000_WRITE_REG_ARRAY_DWORD(hw, E1000_HOST_IF, offset + i,
+					    data);
 	}
 
-out:
-	return ret_val;
+	return E1000_SUCCESS;
+}
+
+/**
+ *  e1000_mng_write_dhcp_info_generic - Writes DHCP info to host interface
+ *  @hw: pointer to the HW structure
+ *  @buffer: pointer to the host interface
+ *  @length: size of the buffer
+ *
+ *  Writes the DHCP information to the host interface.
+ **/
+s32 e1000_mng_write_dhcp_info_generic(struct e1000_hw *hw, u8 *buffer,
+				      u16 length)
+{
+	struct e1000_host_mng_command_header hdr;
+	s32 ret_val;
+	u32 hicr;
+
+	DEBUGFUNC("e1000_mng_write_dhcp_info_generic");
+
+	hdr.command_id = E1000_MNG_DHCP_TX_PAYLOAD_CMD;
+	hdr.command_length = length;
+	hdr.reserved1 = 0;
+	hdr.reserved2 = 0;
+	hdr.checksum = 0;
+
+	/* Enable the host interface */
+	ret_val = e1000_mng_enable_host_if_generic(hw);
+	if (ret_val)
+		return ret_val;
+
+	/* Populate the host interface with the contents of "buffer". */
+	ret_val = e1000_mng_host_if_write_generic(hw, buffer, length,
+						  sizeof(hdr), &(hdr.checksum));
+	if (ret_val)
+		return ret_val;
+
+	/* Write the manageability command header */
+	ret_val = e1000_mng_write_cmd_header_generic(hw, &hdr);
+	if (ret_val)
+		return ret_val;
+
+	/* Tell the ARC a new command is pending. */
+	hicr = E1000_READ_REG(hw, E1000_HICR);
+	E1000_WRITE_REG(hw, E1000_HICR, hicr | E1000_HICR_C);
+
+	return E1000_SUCCESS;
 }
 
 /**
@@ -357,17 +342,16 @@ bool e1000_enable_mng_pass_thru(struct e1000_hw *hw)
 {
 	u32 manc;
 	u32 fwsm, factps;
-	bool ret_val = FALSE;
 
 	DEBUGFUNC("e1000_enable_mng_pass_thru");
 
 	if (!hw->mac.asf_firmware_present)
-		goto out;
+		return FALSE;
 
 	manc = E1000_READ_REG(hw, E1000_MANC);
 
 	if (!(manc & E1000_MANC_RCV_TCO_EN))
-		goto out;
+		return FALSE;
 
 	if (hw->mac.has_fwsm) {
 		fwsm = E1000_READ_REG(hw, E1000_FWSM);
@@ -375,10 +359,8 @@ bool e1000_enable_mng_pass_thru(struct e1000_hw *hw)
 
 		if (!(factps & E1000_FACTPS_MNGCG) &&
 		    ((fwsm & E1000_FWSM_MODE_MASK) ==
-		     (e1000_mng_mode_pt << E1000_FWSM_MODE_SHIFT))) {
-			ret_val = TRUE;
-			goto out;
-		}
+		     (e1000_mng_mode_pt << E1000_FWSM_MODE_SHIFT)))
+			return TRUE;
 	} else if ((hw->mac.type == e1000_82574) ||
 		   (hw->mac.type == e1000_82583)) {
 		u16 data;
@@ -388,18 +370,14 @@ bool e1000_enable_mng_pass_thru(struct e1000_hw *hw)
 
 		if (!(factps & E1000_FACTPS_MNGCG) &&
 		    ((data & E1000_NVM_INIT_CTRL2_MNGM) ==
-		     (e1000_mng_mode_pt << 13))) {
-			ret_val = TRUE;
-			goto out;
-		}
+		     (e1000_mng_mode_pt << 13)))
+			return TRUE;
 	} else if ((manc & E1000_MANC_SMBUS_EN) &&
-		    !(manc & E1000_MANC_ASF_EN)) {
-			ret_val = TRUE;
-			goto out;
+		   !(manc & E1000_MANC_ASF_EN)) {
+			return TRUE;
 	}
 
-out:
-	return ret_val;
+	return FALSE;
 }
 
 /**
@@ -414,47 +392,41 @@ out:
 s32 e1000_host_interface_command(struct e1000_hw *hw, u8 *buffer, u32 length)
 {
 	u32 hicr, i;
-	s32 ret_val = E1000_SUCCESS;
 
 	DEBUGFUNC("e1000_host_interface_command");
 
 	if (!(hw->mac.arc_subsystem_valid)) {
 		DEBUGOUT("Hardware doesn't support host interface command.\n");
-		goto out;
+		return E1000_SUCCESS;
 	}
 
 	if (!hw->mac.asf_firmware_present) {
 		DEBUGOUT("Firmware is not present.\n");
-		goto out;
+		return E1000_SUCCESS;
 	}
 
 	if (length == 0 || length & 0x3 ||
 	    length > E1000_HI_MAX_BLOCK_BYTE_LENGTH) {
 		DEBUGOUT("Buffer length failure.\n");
-		ret_val = -E1000_ERR_HOST_INTERFACE_COMMAND;
-		goto out;
+		return -E1000_ERR_HOST_INTERFACE_COMMAND;
 	}
 
 	/* Check that the host interface is enabled. */
 	hicr = E1000_READ_REG(hw, E1000_HICR);
-	if ((hicr & E1000_HICR_EN) == 0) {
+	if (!(hicr & E1000_HICR_EN)) {
 		DEBUGOUT("E1000_HOST_EN bit disabled.\n");
-		ret_val = -E1000_ERR_HOST_INTERFACE_COMMAND;
-		goto out;
+		return -E1000_ERR_HOST_INTERFACE_COMMAND;
 	}
 
 	/* Calculate length in DWORDs */
 	length >>= 2;
 
-	/*
-	 * The device driver writes the relevant command block
+	/* The device driver writes the relevant command block
 	 * into the ram area.
 	 */
 	for (i = 0; i < length; i++)
-		E1000_WRITE_REG_ARRAY_DWORD(hw,
-		                            E1000_HOST_IF,
-		                            i,
-		                            *((u32 *)buffer + i));
+		E1000_WRITE_REG_ARRAY_DWORD(hw, E1000_HOST_IF, i,
+					    *((u32 *)buffer + i));
 
 	/* Setting this bit tells the ARC that a new command is pending. */
 	E1000_WRITE_REG(hw, E1000_HICR, hicr | E1000_HICR_C);
@@ -470,16 +442,133 @@ s32 e1000_host_interface_command(struct e1000_hw *hw, u8 *buffer, u32 length)
 	if (i == E1000_HI_COMMAND_TIMEOUT ||
 	    (!(E1000_READ_REG(hw, E1000_HICR) & E1000_HICR_SV))) {
 		DEBUGOUT("Command has failed with no status valid.\n");
-		ret_val = -E1000_ERR_HOST_INTERFACE_COMMAND;
-		goto out;
+		return -E1000_ERR_HOST_INTERFACE_COMMAND;
 	}
 
 	for (i = 0; i < length; i++)
 		*((u32 *)buffer + i) = E1000_READ_REG_ARRAY_DWORD(hw,
-		                                                  E1000_HOST_IF,
-		                                                  i);
+								  E1000_HOST_IF,
+								  i);
+
+	return E1000_SUCCESS;
+}
+/**
+ *  e1000_load_firmware - Writes proxy FW code buffer to host interface
+ *                        and execute.
+ *  @hw: pointer to the HW structure
+ *  @buffer: contains a firmware to write
+ *  @length: the byte length of the buffer, must be multiple of 4 bytes
+ *
+ *  Upon success returns E1000_SUCCESS, returns E1000_ERR_CONFIG if not enabled
+ *  in HW else returns E1000_ERR_HOST_INTERFACE_COMMAND.
+ **/
+s32 e1000_load_firmware(struct e1000_hw *hw, u8 *buffer, u32 length)
+{
+	u32 hicr, hibba, fwsm, icr, i;
+
+	DEBUGFUNC("e1000_load_firmware");
+
+	if (hw->mac.type < e1000_i210) {
+		DEBUGOUT("Hardware doesn't support loading FW by the driver\n");
+		return -E1000_ERR_CONFIG;
+	}
+
+	/* Check that the host interface is enabled. */
+	hicr = E1000_READ_REG(hw, E1000_HICR);
+	if (!(hicr & E1000_HICR_EN)) {
+		DEBUGOUT("E1000_HOST_EN bit disabled.\n");
+		return -E1000_ERR_CONFIG;
+	}
+	if (!(hicr & E1000_HICR_MEMORY_BASE_EN)) {
+		DEBUGOUT("E1000_HICR_MEMORY_BASE_EN bit disabled.\n");
+		return -E1000_ERR_CONFIG;
+	}
+
+	if (length == 0 || length & 0x3 || length > E1000_HI_FW_MAX_LENGTH) {
+		DEBUGOUT("Buffer length failure.\n");
+		return -E1000_ERR_INVALID_ARGUMENT;
+	}
+
+	/* Clear notification from ROM-FW by reading ICR register */
+	icr = E1000_READ_REG(hw, E1000_ICR_V2);
+
+	/* Reset ROM-FW */
+	hicr = E1000_READ_REG(hw, E1000_HICR);
+	hicr |= E1000_HICR_FW_RESET_ENABLE;
+	E1000_WRITE_REG(hw, E1000_HICR, hicr);
+	hicr |= E1000_HICR_FW_RESET;
+	E1000_WRITE_REG(hw, E1000_HICR, hicr);
+	E1000_WRITE_FLUSH(hw);
+
+	/* Wait till MAC notifies about its readiness after ROM-FW reset */
+	for (i = 0; i < (E1000_HI_COMMAND_TIMEOUT * 2); i++) {
+		icr = E1000_READ_REG(hw, E1000_ICR_V2);
+		if (icr & E1000_ICR_MNG)
+			break;
+		msec_delay(1);
+	}
+
+	/* Check for timeout */
+	if (i == E1000_HI_COMMAND_TIMEOUT) {
+		DEBUGOUT("FW reset failed.\n");
+		return -E1000_ERR_HOST_INTERFACE_COMMAND;
+	}
+
+	/* Wait till MAC is ready to accept new FW code */
+	for (i = 0; i < E1000_HI_COMMAND_TIMEOUT; i++) {
+		fwsm = E1000_READ_REG(hw, E1000_FWSM);
+		if ((fwsm & E1000_FWSM_FW_VALID) &&
+		    ((fwsm & E1000_FWSM_MODE_MASK) >> E1000_FWSM_MODE_SHIFT ==
+		    E1000_FWSM_HI_EN_ONLY_MODE))
+			break;
+		msec_delay(1);
+	}
+
+	/* Check for timeout */
+	if (i == E1000_HI_COMMAND_TIMEOUT) {
+		DEBUGOUT("FW reset failed.\n");
+		return -E1000_ERR_HOST_INTERFACE_COMMAND;
+	}
+
+	/* Calculate length in DWORDs */
+	length >>= 2;
+
+	/* The device driver writes the relevant FW code block
+	 * into the ram area in DWORDs via 1kB ram addressing window.
+	 */
+	for (i = 0; i < length; i++) {
+		if (!(i % E1000_HI_FW_BLOCK_DWORD_LENGTH)) {
+			/* Point to correct 1kB ram window */
+			hibba = E1000_HI_FW_BASE_ADDRESS +
+				((E1000_HI_FW_BLOCK_DWORD_LENGTH << 2) *
+				(i / E1000_HI_FW_BLOCK_DWORD_LENGTH));
 
-out:
-	return ret_val;
+			E1000_WRITE_REG(hw, E1000_HIBBA, hibba);
+		}
+
+		E1000_WRITE_REG_ARRAY_DWORD(hw, E1000_HOST_IF,
+					    i % E1000_HI_FW_BLOCK_DWORD_LENGTH,
+					    *((u32 *)buffer + i));
+	}
+
+	/* Setting this bit tells the ARC that a new FW is ready to execute. */
+	hicr = E1000_READ_REG(hw, E1000_HICR);
+	E1000_WRITE_REG(hw, E1000_HICR, hicr | E1000_HICR_C);
+
+	for (i = 0; i < E1000_HI_COMMAND_TIMEOUT; i++) {
+		hicr = E1000_READ_REG(hw, E1000_HICR);
+		if (!(hicr & E1000_HICR_C))
+			break;
+		msec_delay(1);
+	}
+
+	/* Check for successful FW start. */
+	if (i == E1000_HI_COMMAND_TIMEOUT) {
+		DEBUGOUT("New FW did not start within timeout period.\n");
+		return -E1000_ERR_HOST_INTERFACE_COMMAND;
+	}
+
+	return E1000_SUCCESS;
 }
 
+
diff --git a/sys/dev/e1000/e1000_manage.h b/sys/dev/e1000/e1000_manage.h
index 6a0c2a0..51f17671 100644
--- a/sys/dev/e1000/e1000_manage.h
+++ b/sys/dev/e1000/e1000_manage.h
@@ -1,6 +1,6 @@
 /******************************************************************************
 
-  Copyright (c) 2001-2010, Intel Corporation 
+  Copyright (c) 2001-2012, Intel Corporation 
   All rights reserved.
   
   Redistribution and use in source and binary forms, with or without 
@@ -39,14 +39,15 @@ bool e1000_check_mng_mode_generic(struct e1000_hw *hw);
 bool e1000_enable_tx_pkt_filtering_generic(struct e1000_hw *hw);
 s32  e1000_mng_enable_host_if_generic(struct e1000_hw *hw);
 s32  e1000_mng_host_if_write_generic(struct e1000_hw *hw, u8 *buffer,
-                                     u16 length, u16 offset, u8 *sum);
+				     u16 length, u16 offset, u8 *sum);
 s32  e1000_mng_write_cmd_header_generic(struct e1000_hw *hw,
-                                    struct e1000_host_mng_command_header *hdr);
+				     struct e1000_host_mng_command_header *hdr);
 s32  e1000_mng_write_dhcp_info_generic(struct e1000_hw *hw,
-                                       u8 *buffer, u16 length);
+				       u8 *buffer, u16 length);
 bool e1000_enable_mng_pass_thru(struct e1000_hw *hw);
 u8 e1000_calculate_checksum(u8 *buffer, u32 length);
 s32 e1000_host_interface_command(struct e1000_hw *hw, u8 *buffer, u32 length);
+s32 e1000_load_firmware(struct e1000_hw *hw, u8 *buffer, u32 length);
 
 enum e1000_mng_mode {
 	e1000_mng_mode_none = 0,
@@ -56,35 +57,40 @@ enum e1000_mng_mode {
 	e1000_mng_mode_host_if_only
 };
 
-#define E1000_FACTPS_MNGCG    0x20000000
+#define E1000_FACTPS_MNGCG			0x20000000
 
-#define E1000_FWSM_MODE_MASK  0xE
-#define E1000_FWSM_MODE_SHIFT 1
+#define E1000_FWSM_MODE_MASK			0xE
+#define E1000_FWSM_MODE_SHIFT			1
+#define E1000_FWSM_FW_VALID			0x00008000
+#define E1000_FWSM_HI_EN_ONLY_MODE		0x4
 
-#define E1000_MNG_IAMT_MODE                  0x3
-#define E1000_MNG_DHCP_COOKIE_LENGTH         0x10
-#define E1000_MNG_DHCP_COOKIE_OFFSET         0x6F0
-#define E1000_MNG_DHCP_COMMAND_TIMEOUT       10
-#define E1000_MNG_DHCP_TX_PAYLOAD_CMD        64
-#define E1000_MNG_DHCP_COOKIE_STATUS_PARSING 0x1
-#define E1000_MNG_DHCP_COOKIE_STATUS_VLAN    0x2
+#define E1000_MNG_IAMT_MODE			0x3
+#define E1000_MNG_DHCP_COOKIE_LENGTH		0x10
+#define E1000_MNG_DHCP_COOKIE_OFFSET		0x6F0
+#define E1000_MNG_DHCP_COMMAND_TIMEOUT		10
+#define E1000_MNG_DHCP_TX_PAYLOAD_CMD		64
+#define E1000_MNG_DHCP_COOKIE_STATUS_PARSING	0x1
+#define E1000_MNG_DHCP_COOKIE_STATUS_VLAN	0x2
 
-#define E1000_VFTA_ENTRY_SHIFT               5
-#define E1000_VFTA_ENTRY_MASK                0x7F
-#define E1000_VFTA_ENTRY_BIT_SHIFT_MASK      0x1F
+#define E1000_VFTA_ENTRY_SHIFT			5
+#define E1000_VFTA_ENTRY_MASK			0x7F
+#define E1000_VFTA_ENTRY_BIT_SHIFT_MASK		0x1F
 
-#define E1000_HI_MAX_BLOCK_BYTE_LENGTH       1792 /* Num of bytes in range */
-#define E1000_HI_MAX_BLOCK_DWORD_LENGTH      448 /* Num of dwords in range */
-#define E1000_HI_COMMAND_TIMEOUT             500 /* Process HI command limit */
-
-#define E1000_HICR_EN              0x01  /* Enable bit - RO */
+#define E1000_HI_MAX_BLOCK_BYTE_LENGTH		1792 /* Num of bytes in range */
+#define E1000_HI_MAX_BLOCK_DWORD_LENGTH		448 /* Num of dwords in range */
+#define E1000_HI_COMMAND_TIMEOUT		500 /* Process HI cmd limit */
+#define E1000_HI_FW_BASE_ADDRESS		0x10000
+#define E1000_HI_FW_MAX_LENGTH			(64 * 1024) /* Num of bytes */
+#define E1000_HI_FW_BLOCK_DWORD_LENGTH		256 /* Num of DWORDs per page */
+#define E1000_HICR_MEMORY_BASE_EN		0x200 /* MB Enable bit - RO */
+#define E1000_HICR_EN			0x01  /* Enable bit - RO */
 /* Driver sets this bit when done to put command in RAM */
-#define E1000_HICR_C               0x02
-#define E1000_HICR_SV              0x04  /* Status Validity */
-#define E1000_HICR_FW_RESET_ENABLE 0x40
-#define E1000_HICR_FW_RESET        0x80
+#define E1000_HICR_C			0x02
+#define E1000_HICR_SV			0x04  /* Status Validity */
+#define E1000_HICR_FW_RESET_ENABLE	0x40
+#define E1000_HICR_FW_RESET		0x80
 
 /* Intel(R) Active Management Technology signature */
-#define E1000_IAMT_SIGNATURE  0x544D4149
+#define E1000_IAMT_SIGNATURE		0x544D4149
 
 #endif
diff --git a/sys/dev/e1000/e1000_nvm.c b/sys/dev/e1000/e1000_nvm.c
index d8df089..a39b847 100644
--- a/sys/dev/e1000/e1000_nvm.c
+++ b/sys/dev/e1000/e1000_nvm.c
@@ -1,6 +1,6 @@
 /******************************************************************************
 
-  Copyright (c) 2001-2011, Intel Corporation 
+  Copyright (c) 2001-2013, Intel Corporation 
   All rights reserved.
   
   Redistribution and use in source and binary forms, with or without 
@@ -227,7 +227,6 @@ s32 e1000_poll_eerd_eewr_done(struct e1000_hw *hw, int ee_reg)
 {
 	u32 attempts = 100000;
 	u32 i, reg = 0;
-	s32 ret_val = -E1000_ERR_NVM;
 
 	DEBUGFUNC("e1000_poll_eerd_eewr_done");
 
@@ -237,15 +236,13 @@ s32 e1000_poll_eerd_eewr_done(struct e1000_hw *hw, int ee_reg)
 		else
 			reg = E1000_READ_REG(hw, E1000_EEWR);
 
-		if (reg & E1000_NVM_RW_REG_DONE) {
-			ret_val = E1000_SUCCESS;
-			break;
-		}
+		if (reg & E1000_NVM_RW_REG_DONE)
+			return E1000_SUCCESS;
 
 		usec_delay(5);
 	}
 
-	return ret_val;
+	return -E1000_ERR_NVM;
 }
 
 /**
@@ -260,7 +257,6 @@ s32 e1000_acquire_nvm_generic(struct e1000_hw *hw)
 {
 	u32 eecd = E1000_READ_REG(hw, E1000_EECD);
 	s32 timeout = E1000_NVM_GRANT_ATTEMPTS;
-	s32 ret_val = E1000_SUCCESS;
 
 	DEBUGFUNC("e1000_acquire_nvm_generic");
 
@@ -279,10 +275,10 @@ s32 e1000_acquire_nvm_generic(struct e1000_hw *hw)
 		eecd &= ~E1000_EECD_REQ;
 		E1000_WRITE_REG(hw, E1000_EECD, eecd);
 		DEBUGOUT("Could not acquire NVM grant\n");
-		ret_val = -E1000_ERR_NVM;
+		return -E1000_ERR_NVM;
 	}
 
-	return ret_val;
+	return E1000_SUCCESS;
 }
 
 /**
@@ -381,7 +377,6 @@ static s32 e1000_ready_nvm_eeprom(struct e1000_hw *hw)
 {
 	struct e1000_nvm_info *nvm = &hw->nvm;
 	u32 eecd = E1000_READ_REG(hw, E1000_EECD);
-	s32 ret_val = E1000_SUCCESS;
 	u8 spi_stat_reg;
 
 	DEBUGFUNC("e1000_ready_nvm_eeprom");
@@ -402,8 +397,7 @@ static s32 e1000_ready_nvm_eeprom(struct e1000_hw *hw)
 		E1000_WRITE_FLUSH(hw);
 		usec_delay(1);
 
-		/*
-		 * Read "Status Register" repeatedly until the LSB is cleared.
+		/* Read "Status Register" repeatedly until the LSB is cleared.
 		 * The EEPROM will signal that the command has been completed
 		 * by clearing bit 0 of the internal status register.  If it's
 		 * not cleared within 'timeout', then error out.
@@ -422,13 +416,11 @@ static s32 e1000_ready_nvm_eeprom(struct e1000_hw *hw)
 
 		if (!timeout) {
 			DEBUGOUT("SPI NVM Status error\n");
-			ret_val = -E1000_ERR_NVM;
-			goto out;
+			return -E1000_ERR_NVM;
 		}
 	}
 
-out:
-	return ret_val;
+	return E1000_SUCCESS;
 }
 
 /**
@@ -450,20 +442,18 @@ s32 e1000_read_nvm_spi(struct e1000_hw *hw, u16 offset, u16 words, u16 *data)
 
 	DEBUGFUNC("e1000_read_nvm_spi");
 
-	/*
-	 * A check for invalid values:  offset too large, too many words,
+	/* A check for invalid values:  offset too large, too many words,
 	 * and not enough words.
 	 */
 	if ((offset >= nvm->word_size) || (words > (nvm->word_size - offset)) ||
 	    (words == 0)) {
 		DEBUGOUT("nvm parameter(s) out of bounds\n");
-		ret_val = -E1000_ERR_NVM;
-		goto out;
+		return -E1000_ERR_NVM;
 	}
 
 	ret_val = nvm->ops.acquire(hw);
 	if (ret_val)
-		goto out;
+		return ret_val;
 
 	ret_val = e1000_ready_nvm_eeprom(hw);
 	if (ret_val)
@@ -478,8 +468,7 @@ s32 e1000_read_nvm_spi(struct e1000_hw *hw, u16 offset, u16 words, u16 *data)
 	e1000_shift_out_eec_bits(hw, read_opcode, nvm->opcode_bits);
 	e1000_shift_out_eec_bits(hw, (u16)(offset*2), nvm->address_bits);
 
-	/*
-	 * Read the data.  SPI NVMs increment the address with each byte
+	/* Read the data.  SPI NVMs increment the address with each byte
 	 * read and will roll over if reading beyond the end.  This allows
 	 * us to read the whole NVM from any offset
 	 */
@@ -491,7 +480,6 @@ s32 e1000_read_nvm_spi(struct e1000_hw *hw, u16 offset, u16 words, u16 *data)
 release:
 	nvm->ops.release(hw);
 
-out:
 	return ret_val;
 }
 
@@ -514,20 +502,18 @@ s32 e1000_read_nvm_microwire(struct e1000_hw *hw, u16 offset, u16 words,
 
 	DEBUGFUNC("e1000_read_nvm_microwire");
 
-	/*
-	 * A check for invalid values:  offset too large, too many words,
+	/* A check for invalid values:  offset too large, too many words,
 	 * and not enough words.
 	 */
 	if ((offset >= nvm->word_size) || (words > (nvm->word_size - offset)) ||
 	    (words == 0)) {
 		DEBUGOUT("nvm parameter(s) out of bounds\n");
-		ret_val = -E1000_ERR_NVM;
-		goto out;
+		return -E1000_ERR_NVM;
 	}
 
 	ret_val = nvm->ops.acquire(hw);
 	if (ret_val)
-		goto out;
+		return ret_val;
 
 	ret_val = e1000_ready_nvm_eeprom(hw);
 	if (ret_val)
@@ -539,8 +525,7 @@ s32 e1000_read_nvm_microwire(struct e1000_hw *hw, u16 offset, u16 words,
 		e1000_shift_out_eec_bits(hw, (u16)(offset + i),
 					nvm->address_bits);
 
-		/*
-		 * Read the data.  For microwire, each word requires the
+		/* Read the data.  For microwire, each word requires the
 		 * overhead of setup and tear-down.
 		 */
 		data[i] = e1000_shift_in_eec_bits(hw, 16);
@@ -550,7 +535,6 @@ s32 e1000_read_nvm_microwire(struct e1000_hw *hw, u16 offset, u16 words,
 release:
 	nvm->ops.release(hw);
 
-out:
 	return ret_val;
 }
 
@@ -571,15 +555,13 @@ s32 e1000_read_nvm_eerd(struct e1000_hw *hw, u16 offset, u16 words, u16 *data)
 
 	DEBUGFUNC("e1000_read_nvm_eerd");
 
-	/*
-	 * A check for invalid values:  offset too large, too many words,
+	/* A check for invalid values:  offset too large, too many words,
 	 * too many words for the offset, and not enough words.
 	 */
 	if ((offset >= nvm->word_size) || (words > (nvm->word_size - offset)) ||
 	    (words == 0)) {
 		DEBUGOUT("nvm parameter(s) out of bounds\n");
-		ret_val = -E1000_ERR_NVM;
-		goto out;
+		return -E1000_ERR_NVM;
 	}
 
 	for (i = 0; i < words; i++) {
@@ -595,7 +577,6 @@ s32 e1000_read_nvm_eerd(struct e1000_hw *hw, u16 offset, u16 words, u16 *data)
 			   E1000_NVM_RW_REG_DATA);
 	}
 
-out:
 	return ret_val;
 }
 
@@ -614,32 +595,32 @@ out:
 s32 e1000_write_nvm_spi(struct e1000_hw *hw, u16 offset, u16 words, u16 *data)
 {
 	struct e1000_nvm_info *nvm = &hw->nvm;
-	s32 ret_val;
+	s32 ret_val = -E1000_ERR_NVM;
 	u16 widx = 0;
 
 	DEBUGFUNC("e1000_write_nvm_spi");
 
-	/*
-	 * A check for invalid values:  offset too large, too many words,
+	/* A check for invalid values:  offset too large, too many words,
 	 * and not enough words.
 	 */
 	if ((offset >= nvm->word_size) || (words > (nvm->word_size - offset)) ||
 	    (words == 0)) {
 		DEBUGOUT("nvm parameter(s) out of bounds\n");
-		ret_val = -E1000_ERR_NVM;
-		goto out;
+		return -E1000_ERR_NVM;
 	}
 
-	ret_val = nvm->ops.acquire(hw);
-	if (ret_val)
-		goto out;
-
 	while (widx < words) {
 		u8 write_opcode = NVM_WRITE_OPCODE_SPI;
 
-		ret_val = e1000_ready_nvm_eeprom(hw);
+		ret_val = nvm->ops.acquire(hw);
 		if (ret_val)
-			goto release;
+			return ret_val;
+
+		ret_val = e1000_ready_nvm_eeprom(hw);
+		if (ret_val) {
+			nvm->ops.release(hw);
+			return ret_val;
+		}
 
 		e1000_standby_nvm(hw);
 
@@ -649,8 +630,7 @@ s32 e1000_write_nvm_spi(struct e1000_hw *hw, u16 offset, u16 words, u16 *data)
 
 		e1000_standby_nvm(hw);
 
-		/*
-		 * Some SPI eeproms use the 8th address bit embedded in the
+		/* Some SPI eeproms use the 8th address bit embedded in the
 		 * opcode
 		 */
 		if ((nvm->address_bits == 8) && (offset >= 128))
@@ -673,13 +653,10 @@ s32 e1000_write_nvm_spi(struct e1000_hw *hw, u16 offset, u16 words, u16 *data)
 				break;
 			}
 		}
+		msec_delay(10);
+		nvm->ops.release(hw);
 	}
 
-	msec_delay(10);
-release:
-	nvm->ops.release(hw);
-
-out:
 	return ret_val;
 }
 
@@ -706,20 +683,18 @@ s32 e1000_write_nvm_microwire(struct e1000_hw *hw, u16 offset, u16 words,
 
 	DEBUGFUNC("e1000_write_nvm_microwire");
 
-	/*
-	 * A check for invalid values:  offset too large, too many words,
+	/* A check for invalid values:  offset too large, too many words,
 	 * and not enough words.
 	 */
 	if ((offset >= nvm->word_size) || (words > (nvm->word_size - offset)) ||
 	    (words == 0)) {
 		DEBUGOUT("nvm parameter(s) out of bounds\n");
-		ret_val = -E1000_ERR_NVM;
-		goto out;
+		return -E1000_ERR_NVM;
 	}
 
 	ret_val = nvm->ops.acquire(hw);
 	if (ret_val)
-		goto out;
+		return ret_val;
 
 	ret_val = e1000_ready_nvm_eeprom(hw);
 	if (ret_val)
@@ -769,7 +744,6 @@ s32 e1000_write_nvm_microwire(struct e1000_hw *hw, u16 offset, u16 words,
 release:
 	nvm->ops.release(hw);
 
-out:
 	return ret_val;
 }
 
@@ -795,32 +769,30 @@ s32 e1000_read_pba_string_generic(struct e1000_hw *hw, u8 *pba_num,
 
 	if (pba_num == NULL) {
 		DEBUGOUT("PBA string buffer was null\n");
-		ret_val = E1000_ERR_INVALID_ARGUMENT;
-		goto out;
+		return -E1000_ERR_INVALID_ARGUMENT;
 	}
 
 	ret_val = hw->nvm.ops.read(hw, NVM_PBA_OFFSET_0, 1, &nvm_data);
 	if (ret_val) {
 		DEBUGOUT("NVM Read Error\n");
-		goto out;
+		return ret_val;
 	}
 
 	ret_val = hw->nvm.ops.read(hw, NVM_PBA_OFFSET_1, 1, &pba_ptr);
 	if (ret_val) {
 		DEBUGOUT("NVM Read Error\n");
-		goto out;
+		return ret_val;
 	}
 
-	/*
-	 * if nvm_data is not ptr guard the PBA must be in legacy format which
+	/* if nvm_data is not ptr guard the PBA must be in legacy format which
 	 * means pba_ptr is actually our second data word for the PBA number
 	 * and we can decode it into an ascii string
 	 */
 	if (nvm_data != NVM_PBA_PTR_GUARD) {
 		DEBUGOUT("NVM PBA number is not stored as string\n");
 
-		/* we will need 11 characters to store the PBA */
-		if (pba_num_size < 11) {
+		/* make sure callers buffer is big enough to store the PBA */
+		if (pba_num_size < E1000_PBANUM_LENGTH) {
 			DEBUGOUT("PBA string buffer too small\n");
 			return E1000_ERR_NO_SPACE;
 		}
@@ -848,25 +820,23 @@ s32 e1000_read_pba_string_generic(struct e1000_hw *hw, u8 *pba_num,
 				pba_num[offset] += 'A' - 0xA;
 		}
 
-		goto out;
+		return E1000_SUCCESS;
 	}
 
 	ret_val = hw->nvm.ops.read(hw, pba_ptr, 1, &length);
 	if (ret_val) {
 		DEBUGOUT("NVM Read Error\n");
-		goto out;
+		return ret_val;
 	}
 
 	if (length == 0xFFFF || length == 0) {
 		DEBUGOUT("NVM PBA number section invalid length\n");
-		ret_val = E1000_ERR_NVM_PBA_SECTION;
-		goto out;
+		return -E1000_ERR_NVM_PBA_SECTION;
 	}
 	/* check if pba_num buffer is big enough */
 	if (pba_num_size < (((u32)length * 2) - 1)) {
 		DEBUGOUT("PBA string buffer too small\n");
-		ret_val = E1000_ERR_NO_SPACE;
-		goto out;
+		return -E1000_ERR_NO_SPACE;
 	}
 
 	/* trim pba length from start of string */
@@ -877,15 +847,14 @@ s32 e1000_read_pba_string_generic(struct e1000_hw *hw, u8 *pba_num,
 		ret_val = hw->nvm.ops.read(hw, pba_ptr + offset, 1, &nvm_data);
 		if (ret_val) {
 			DEBUGOUT("NVM Read Error\n");
-			goto out;
+			return ret_val;
 		}
 		pba_num[offset * 2] = (u8)(nvm_data >> 8);
 		pba_num[(offset * 2) + 1] = (u8)(nvm_data & 0xFF);
 	}
 	pba_num[offset * 2] = '\0';
 
-out:
-	return ret_val;
+	return E1000_SUCCESS;
 }
 
 /**
@@ -907,48 +876,233 @@ s32 e1000_read_pba_length_generic(struct e1000_hw *hw, u32 *pba_num_size)
 
 	if (pba_num_size == NULL) {
 		DEBUGOUT("PBA buffer size was null\n");
-		ret_val = E1000_ERR_INVALID_ARGUMENT;
-		goto out;
+		return -E1000_ERR_INVALID_ARGUMENT;
 	}
 
 	ret_val = hw->nvm.ops.read(hw, NVM_PBA_OFFSET_0, 1, &nvm_data);
 	if (ret_val) {
 		DEBUGOUT("NVM Read Error\n");
-		goto out;
+		return ret_val;
 	}
 
 	ret_val = hw->nvm.ops.read(hw, NVM_PBA_OFFSET_1, 1, &pba_ptr);
 	if (ret_val) {
 		DEBUGOUT("NVM Read Error\n");
-		goto out;
+		return ret_val;
 	}
 
 	 /* if data is not ptr guard the PBA must be in legacy format */
 	if (nvm_data != NVM_PBA_PTR_GUARD) {
-		*pba_num_size = 11;
-		goto out;
+		*pba_num_size = E1000_PBANUM_LENGTH;
+		return E1000_SUCCESS;
 	}
 
 	ret_val = hw->nvm.ops.read(hw, pba_ptr, 1, &length);
 	if (ret_val) {
 		DEBUGOUT("NVM Read Error\n");
-		goto out;
+		return ret_val;
 	}
 
 	if (length == 0xFFFF || length == 0) {
 		DEBUGOUT("NVM PBA number section invalid length\n");
-		ret_val = E1000_ERR_NVM_PBA_SECTION;
-		goto out;
+		return -E1000_ERR_NVM_PBA_SECTION;
 	}
 
-	/*
-	 * Convert from length in u16 values to u8 chars, add 1 for NULL,
+	/* Convert from length in u16 values to u8 chars, add 1 for NULL,
 	 * and subtract 2 because length field is included in length.
 	 */
 	*pba_num_size = ((u32)length * 2) - 1;
 
-out:
-	return ret_val;
+	return E1000_SUCCESS;
+}
+
+
+/**
+ *  e1000_read_pba_raw
+ *  @hw: pointer to the HW structure
+ *  @eeprom_buf: optional pointer to EEPROM image
+ *  @eeprom_buf_size: size of EEPROM image in words
+ *  @max_pba_block_size: PBA block size limit
+ *  @pba: pointer to output PBA structure
+ *
+ *  Reads PBA from EEPROM image when eeprom_buf is not NULL.
+ *  Reads PBA from physical EEPROM device when eeprom_buf is NULL.
+ *
+ **/
+s32 e1000_read_pba_raw(struct e1000_hw *hw, u16 *eeprom_buf,
+		       u32 eeprom_buf_size, u16 max_pba_block_size,
+		       struct e1000_pba *pba)
+{
+	s32 ret_val;
+	u16 pba_block_size;
+
+	if (pba == NULL)
+		return -E1000_ERR_PARAM;
+
+	if (eeprom_buf == NULL) {
+		ret_val = e1000_read_nvm(hw, NVM_PBA_OFFSET_0, 2,
+					 &pba->word[0]);
+		if (ret_val)
+			return ret_val;
+	} else {
+		if (eeprom_buf_size > NVM_PBA_OFFSET_1) {
+			pba->word[0] = eeprom_buf[NVM_PBA_OFFSET_0];
+			pba->word[1] = eeprom_buf[NVM_PBA_OFFSET_1];
+		} else {
+			return -E1000_ERR_PARAM;
+		}
+	}
+
+	if (pba->word[0] == NVM_PBA_PTR_GUARD) {
+		if (pba->pba_block == NULL)
+			return -E1000_ERR_PARAM;
+
+		ret_val = e1000_get_pba_block_size(hw, eeprom_buf,
+						   eeprom_buf_size,
+						   &pba_block_size);
+		if (ret_val)
+			return ret_val;
+
+		if (pba_block_size > max_pba_block_size)
+			return -E1000_ERR_PARAM;
+
+		if (eeprom_buf == NULL) {
+			ret_val = e1000_read_nvm(hw, pba->word[1],
+						 pba_block_size,
+						 pba->pba_block);
+			if (ret_val)
+				return ret_val;
+		} else {
+			if (eeprom_buf_size > (u32)(pba->word[1] +
+					      pba->pba_block[0])) {
+				memcpy(pba->pba_block,
+				       &eeprom_buf[pba->word[1]],
+				       pba_block_size * sizeof(u16));
+			} else {
+				return -E1000_ERR_PARAM;
+			}
+		}
+	}
+
+	return E1000_SUCCESS;
+}
+
+/**
+ *  e1000_write_pba_raw
+ *  @hw: pointer to the HW structure
+ *  @eeprom_buf: optional pointer to EEPROM image
+ *  @eeprom_buf_size: size of EEPROM image in words
+ *  @pba: pointer to PBA structure
+ *
+ *  Writes PBA to EEPROM image when eeprom_buf is not NULL.
+ *  Writes PBA to physical EEPROM device when eeprom_buf is NULL.
+ *
+ **/
+s32 e1000_write_pba_raw(struct e1000_hw *hw, u16 *eeprom_buf,
+			u32 eeprom_buf_size, struct e1000_pba *pba)
+{
+	s32 ret_val;
+
+	if (pba == NULL)
+		return -E1000_ERR_PARAM;
+
+	if (eeprom_buf == NULL) {
+		ret_val = e1000_write_nvm(hw, NVM_PBA_OFFSET_0, 2,
+					  &pba->word[0]);
+		if (ret_val)
+			return ret_val;
+	} else {
+		if (eeprom_buf_size > NVM_PBA_OFFSET_1) {
+			eeprom_buf[NVM_PBA_OFFSET_0] = pba->word[0];
+			eeprom_buf[NVM_PBA_OFFSET_1] = pba->word[1];
+		} else {
+			return -E1000_ERR_PARAM;
+		}
+	}
+
+	if (pba->word[0] == NVM_PBA_PTR_GUARD) {
+		if (pba->pba_block == NULL)
+			return -E1000_ERR_PARAM;
+
+		if (eeprom_buf == NULL) {
+			ret_val = e1000_write_nvm(hw, pba->word[1],
+						  pba->pba_block[0],
+						  pba->pba_block);
+			if (ret_val)
+				return ret_val;
+		} else {
+			if (eeprom_buf_size > (u32)(pba->word[1] +
+					      pba->pba_block[0])) {
+				memcpy(&eeprom_buf[pba->word[1]],
+				       pba->pba_block,
+				       pba->pba_block[0] * sizeof(u16));
+			} else {
+				return -E1000_ERR_PARAM;
+			}
+		}
+	}
+
+	return E1000_SUCCESS;
+}
+
+/**
+ *  e1000_get_pba_block_size
+ *  @hw: pointer to the HW structure
+ *  @eeprom_buf: optional pointer to EEPROM image
+ *  @eeprom_buf_size: size of EEPROM image in words
+ *  @pba_data_size: pointer to output variable
+ *
+ *  Returns the size of the PBA block in words. Function operates on EEPROM
+ *  image if the eeprom_buf pointer is not NULL otherwise it accesses physical
+ *  EEPROM device.
+ *
+ **/
+s32 e1000_get_pba_block_size(struct e1000_hw *hw, u16 *eeprom_buf,
+			     u32 eeprom_buf_size, u16 *pba_block_size)
+{
+	s32 ret_val;
+	u16 pba_word[2];
+	u16 length;
+
+	DEBUGFUNC("e1000_get_pba_block_size");
+
+	if (eeprom_buf == NULL) {
+		ret_val = e1000_read_nvm(hw, NVM_PBA_OFFSET_0, 2, &pba_word[0]);
+		if (ret_val)
+			return ret_val;
+	} else {
+		if (eeprom_buf_size > NVM_PBA_OFFSET_1) {
+			pba_word[0] = eeprom_buf[NVM_PBA_OFFSET_0];
+			pba_word[1] = eeprom_buf[NVM_PBA_OFFSET_1];
+		} else {
+			return -E1000_ERR_PARAM;
+		}
+	}
+
+	if (pba_word[0] == NVM_PBA_PTR_GUARD) {
+		if (eeprom_buf == NULL) {
+			ret_val = e1000_read_nvm(hw, pba_word[1] + 0, 1,
+						 &length);
+			if (ret_val)
+				return ret_val;
+		} else {
+			if (eeprom_buf_size > pba_word[1])
+				length = eeprom_buf[pba_word[1] + 0];
+			else
+				return -E1000_ERR_PARAM;
+		}
+
+		if (length == 0xFFFF || length == 0)
+			return -E1000_ERR_NVM_PBA_SECTION;
+	} else {
+		/* PBA number in legacy format, there is no PBA Block. */
+		length = 0;
+	}
+
+	if (pba_block_size != NULL)
+		*pba_block_size = length;
+
+	return E1000_SUCCESS;
 }
 
 /**
@@ -989,7 +1143,7 @@ s32 e1000_read_mac_addr_generic(struct e1000_hw *hw)
  **/
 s32 e1000_validate_nvm_checksum_generic(struct e1000_hw *hw)
 {
-	s32 ret_val = E1000_SUCCESS;
+	s32 ret_val;
 	u16 checksum = 0;
 	u16 i, nvm_data;
 
@@ -999,19 +1153,17 @@ s32 e1000_validate_nvm_checksum_generic(struct e1000_hw *hw)
 		ret_val = hw->nvm.ops.read(hw, i, 1, &nvm_data);
 		if (ret_val) {
 			DEBUGOUT("NVM Read Error\n");
-			goto out;
+			return ret_val;
 		}
 		checksum += nvm_data;
 	}
 
 	if (checksum != (u16) NVM_SUM) {
 		DEBUGOUT("NVM Checksum Invalid\n");
-		ret_val = -E1000_ERR_NVM;
-		goto out;
+		return -E1000_ERR_NVM;
 	}
 
-out:
-	return ret_val;
+	return E1000_SUCCESS;
 }
 
 /**
@@ -1034,7 +1186,7 @@ s32 e1000_update_nvm_checksum_generic(struct e1000_hw *hw)
 		ret_val = hw->nvm.ops.read(hw, i, 1, &nvm_data);
 		if (ret_val) {
 			DEBUGOUT("NVM Read Error while updating checksum.\n");
-			goto out;
+			return ret_val;
 		}
 		checksum += nvm_data;
 	}
@@ -1043,7 +1195,6 @@ s32 e1000_update_nvm_checksum_generic(struct e1000_hw *hw)
 	if (ret_val)
 		DEBUGOUT("NVM Write Error while updating checksum.\n");
 
-out:
 	return ret_val;
 }
 
@@ -1067,3 +1218,4 @@ static void e1000_reload_nvm_generic(struct e1000_hw *hw)
 	E1000_WRITE_FLUSH(hw);
 }
 
+
diff --git a/sys/dev/e1000/e1000_nvm.h b/sys/dev/e1000/e1000_nvm.h
index ed23eb3..34077b2 100644
--- a/sys/dev/e1000/e1000_nvm.h
+++ b/sys/dev/e1000/e1000_nvm.h
@@ -1,6 +1,6 @@
 /******************************************************************************
 
-  Copyright (c) 2001-2011, Intel Corporation 
+  Copyright (c) 2001-2013, Intel Corporation 
   All rights reserved.
   
   Redistribution and use in source and binary forms, with or without 
@@ -35,6 +35,14 @@
 #ifndef _E1000_NVM_H_
 #define _E1000_NVM_H_
 
+#if !defined(NO_READ_PBA_RAW) || !defined(NO_WRITE_PBA_RAW)
+struct e1000_pba {
+	u16 word[2];
+	u16 *pba_block;
+};
+#endif
+
+
 void e1000_init_nvm_ops_generic(struct e1000_hw *hw);
 s32  e1000_null_read_nvm(struct e1000_hw *hw, u16 a, u16 b, u16 *c);
 void e1000_null_nvm_generic(struct e1000_hw *hw);
@@ -47,6 +55,13 @@ s32  e1000_read_mac_addr_generic(struct e1000_hw *hw);
 s32  e1000_read_pba_string_generic(struct e1000_hw *hw, u8 *pba_num,
 				   u32 pba_num_size);
 s32  e1000_read_pba_length_generic(struct e1000_hw *hw, u32 *pba_num_size);
+s32 e1000_read_pba_raw(struct e1000_hw *hw, u16 *eeprom_buf,
+		       u32 eeprom_buf_size, u16 max_pba_block_size,
+		       struct e1000_pba *pba);
+s32 e1000_write_pba_raw(struct e1000_hw *hw, u16 *eeprom_buf,
+			u32 eeprom_buf_size, struct e1000_pba *pba);
+s32 e1000_get_pba_block_size(struct e1000_hw *hw, u16 *eeprom_buf,
+			     u32 eeprom_buf_size, u16 *pba_block_size);
 s32  e1000_read_nvm_spi(struct e1000_hw *hw, u16 offset, u16 words, u16 *data);
 s32  e1000_read_nvm_microwire(struct e1000_hw *hw, u16 offset,
 			      u16 words, u16 *data);
diff --git a/sys/dev/e1000/e1000_osdep.h b/sys/dev/e1000/e1000_osdep.h
index e6d131a..dd19613 100644
--- a/sys/dev/e1000/e1000_osdep.h
+++ b/sys/dev/e1000/e1000_osdep.h
@@ -1,6 +1,6 @@
 /******************************************************************************
 
-  Copyright (c) 2001-2010, Intel Corporation 
+  Copyright (c) 2001-2013, Intel Corporation 
   All rights reserved.
   
   Redistribution and use in source and binary forms, with or without 
@@ -66,7 +66,8 @@
 #define MSGOUT(S, A, B)     printf(S "\n", A, B)
 #define DEBUGFUNC(F)        DEBUGOUT(F);
 #define DEBUGOUT(S)			do {} while (0)
-#define DEBUGOUT1(S,A)			do {} while (0)
+/* This define is needed or shared code will not build */
+#define DEBUGOUT1(S,A)			if (0) printf(S,A);
 #define DEBUGOUT2(S,A,B)		do {} while (0)
 #define DEBUGOUT3(S,A,B,C)		do {} while (0)
 #define DEBUGOUT7(S,A,B,C,D,E,F,G)	do {} while (0)
diff --git a/sys/dev/e1000/e1000_phy.c b/sys/dev/e1000/e1000_phy.c
index ead72690..241c1d5 100644
--- a/sys/dev/e1000/e1000_phy.c
+++ b/sys/dev/e1000/e1000_phy.c
@@ -1,6 +1,6 @@
 /******************************************************************************
 
-  Copyright (c) 2001-2011, Intel Corporation 
+  Copyright (c) 2001-2013, Intel Corporation 
   All rights reserved.
   
   Redistribution and use in source and binary forms, with or without 
@@ -34,7 +34,7 @@
 
 #include "e1000_api.h"
 
-static u32 e1000_get_phy_addr_for_bm_page(u32 page, u32 reg);
+static s32 e1000_wait_autoneg(struct e1000_hw *hw);
 static s32 e1000_access_phy_wakeup_reg_bm(struct e1000_hw *hw, u32 offset,
 					  u16 *data, bool read, bool page_set);
 static u32 e1000_get_phy_addr_for_hv_page(u32 page);
@@ -95,8 +95,8 @@ void e1000_init_phy_ops_generic(struct e1000_hw *hw)
 	phy->ops.write_reg_page = e1000_null_write_reg;
 	phy->ops.power_up = e1000_null_phy_generic;
 	phy->ops.power_down = e1000_null_phy_generic;
-	phy->ops.read_i2c_byte = e1000_read_i2c_byte_generic;
-	phy->ops.write_i2c_byte = e1000_write_i2c_byte_generic;
+	phy->ops.read_i2c_byte = e1000_read_i2c_byte_null;
+	phy->ops.write_i2c_byte = e1000_write_i2c_byte_null;
 	phy->ops.cfg_on_link_up = e1000_null_ops_generic;
 }
 
@@ -151,6 +151,38 @@ s32 e1000_null_write_reg(struct e1000_hw *hw, u32 offset, u16 data)
 }
 
 /**
+ *  e1000_read_i2c_byte_null - No-op function, return 0
+ *  @hw: pointer to hardware structure
+ *  @byte_offset: byte offset to write
+ *  @dev_addr: device address
+ *  @data: data value read
+ *
+ **/
+s32 e1000_read_i2c_byte_null(struct e1000_hw *hw, u8 byte_offset,
+			     u8 dev_addr, u8 *data)
+{
+	DEBUGFUNC("e1000_read_i2c_byte_null");
+	return E1000_SUCCESS;
+}
+
+/**
+ *  e1000_write_i2c_byte_null - No-op function, return 0
+ *  @hw: pointer to hardware structure
+ *  @byte_offset: byte offset to write
+ *  @dev_addr: device address
+ *  @data: data value to write
+ *
+ **/
+s32 e1000_write_i2c_byte_null(struct e1000_hw *hw,
+			      u8 byte_offset,
+			      u8 dev_addr,
+			      u8 data)
+{
+	DEBUGFUNC("e1000_write_i2c_byte_null");
+	return E1000_SUCCESS;
+}
+
+/**
  *  e1000_check_reset_block_generic - Check if PHY reset is blocked
  *  @hw: pointer to the HW structure
  *
@@ -186,30 +218,30 @@ s32 e1000_get_phy_id(struct e1000_hw *hw)
 
 	DEBUGFUNC("e1000_get_phy_id");
 
-	if (!(phy->ops.read_reg))
-		goto out;
+	if (!phy->ops.read_reg)
+		return E1000_SUCCESS;
 
 	while (retry_count < 2) {
 		ret_val = phy->ops.read_reg(hw, PHY_ID1, &phy_id);
 		if (ret_val)
-			goto out;
+			return ret_val;
 
 		phy->id = (u32)(phy_id << 16);
 		usec_delay(20);
 		ret_val = phy->ops.read_reg(hw, PHY_ID2, &phy_id);
 		if (ret_val)
-			goto out;
+			return ret_val;
 
 		phy->id |= (u32)(phy_id & PHY_REVISION_MASK);
 		phy->revision = (u32)(phy_id & ~PHY_REVISION_MASK);
 
 		if (phy->id != 0 && phy->id != PHY_REVISION_MASK)
-			goto out;
+			return E1000_SUCCESS;
 
 		retry_count++;
 	}
-out:
-	return ret_val;
+
+	return E1000_SUCCESS;
 }
 
 /**
@@ -220,21 +252,18 @@ out:
  **/
 s32 e1000_phy_reset_dsp_generic(struct e1000_hw *hw)
 {
-	s32 ret_val = E1000_SUCCESS;
+	s32 ret_val;
 
 	DEBUGFUNC("e1000_phy_reset_dsp_generic");
 
-	if (!(hw->phy.ops.write_reg))
-		goto out;
+	if (!hw->phy.ops.write_reg)
+		return E1000_SUCCESS;
 
 	ret_val = hw->phy.ops.write_reg(hw, M88E1000_PHY_GEN_CONTROL, 0xC1);
 	if (ret_val)
-		goto out;
-
-	ret_val = hw->phy.ops.write_reg(hw, M88E1000_PHY_GEN_CONTROL, 0);
+		return ret_val;
 
-out:
-	return ret_val;
+	return hw->phy.ops.write_reg(hw, M88E1000_PHY_GEN_CONTROL, 0);
 }
 
 /**
@@ -250,7 +279,6 @@ s32 e1000_read_phy_reg_mdic(struct e1000_hw *hw, u32 offset, u16 *data)
 {
 	struct e1000_phy_info *phy = &hw->phy;
 	u32 i, mdic = 0;
-	s32 ret_val = E1000_SUCCESS;
 
 	DEBUGFUNC("e1000_read_phy_reg_mdic");
 
@@ -259,8 +287,7 @@ s32 e1000_read_phy_reg_mdic(struct e1000_hw *hw, u32 offset, u16 *data)
 		return -E1000_ERR_PARAM;
 	}
 
-	/*
-	 * Set up Op-code, Phy Address, and register offset in the MDI
+	/* Set up Op-code, Phy Address, and register offset in the MDI
 	 * Control register.  The MAC will take care of interfacing with the
 	 * PHY to retrieve the desired data.
 	 */
@@ -270,8 +297,7 @@ s32 e1000_read_phy_reg_mdic(struct e1000_hw *hw, u32 offset, u16 *data)
 
 	E1000_WRITE_REG(hw, E1000_MDIC, mdic);
 
-	/*
-	 * Poll the ready bit to see if the MDI read completed
+	/* Poll the ready bit to see if the MDI read completed
 	 * Increasing the time out as testing showed failures with
 	 * the lower time out
 	 */
@@ -283,25 +309,27 @@ s32 e1000_read_phy_reg_mdic(struct e1000_hw *hw, u32 offset, u16 *data)
 	}
 	if (!(mdic & E1000_MDIC_READY)) {
 		DEBUGOUT("MDI Read did not complete\n");
-		ret_val = -E1000_ERR_PHY;
-		goto out;
+		return -E1000_ERR_PHY;
 	}
 	if (mdic & E1000_MDIC_ERROR) {
 		DEBUGOUT("MDI Error\n");
-		ret_val = -E1000_ERR_PHY;
-		goto out;
+		return -E1000_ERR_PHY;
+	}
+	if (((mdic & E1000_MDIC_REG_MASK) >> E1000_MDIC_REG_SHIFT) != offset) {
+		DEBUGOUT2("MDI Read offset error - requested %d, returned %d\n",
+			  offset,
+			  (mdic & E1000_MDIC_REG_MASK) >> E1000_MDIC_REG_SHIFT);
+		return -E1000_ERR_PHY;
 	}
 	*data = (u16) mdic;
 
-	/*
-	 * Allow some time after each MDIC transaction to avoid
+	/* Allow some time after each MDIC transaction to avoid
 	 * reading duplicate data in the next MDIC transaction.
 	 */
 	if (hw->mac.type == e1000_pch2lan)
 		usec_delay(100);
 
-out:
-	return ret_val;
+	return E1000_SUCCESS;
 }
 
 /**
@@ -316,7 +344,6 @@ s32 e1000_write_phy_reg_mdic(struct e1000_hw *hw, u32 offset, u16 data)
 {
 	struct e1000_phy_info *phy = &hw->phy;
 	u32 i, mdic = 0;
-	s32 ret_val = E1000_SUCCESS;
 
 	DEBUGFUNC("e1000_write_phy_reg_mdic");
 
@@ -325,8 +352,7 @@ s32 e1000_write_phy_reg_mdic(struct e1000_hw *hw, u32 offset, u16 data)
 		return -E1000_ERR_PARAM;
 	}
 
-	/*
-	 * Set up Op-code, Phy Address, and register offset in the MDI
+	/* Set up Op-code, Phy Address, and register offset in the MDI
 	 * Control register.  The MAC will take care of interfacing with the
 	 * PHY to retrieve the desired data.
 	 */
@@ -337,8 +363,7 @@ s32 e1000_write_phy_reg_mdic(struct e1000_hw *hw, u32 offset, u16 data)
 
 	E1000_WRITE_REG(hw, E1000_MDIC, mdic);
 
-	/*
-	 * Poll the ready bit to see if the MDI read completed
+	/* Poll the ready bit to see if the MDI read completed
 	 * Increasing the time out as testing showed failures with
 	 * the lower time out
 	 */
@@ -350,24 +375,26 @@ s32 e1000_write_phy_reg_mdic(struct e1000_hw *hw, u32 offset, u16 data)
 	}
 	if (!(mdic & E1000_MDIC_READY)) {
 		DEBUGOUT("MDI Write did not complete\n");
-		ret_val = -E1000_ERR_PHY;
-		goto out;
+		return -E1000_ERR_PHY;
 	}
 	if (mdic & E1000_MDIC_ERROR) {
 		DEBUGOUT("MDI Error\n");
-		ret_val = -E1000_ERR_PHY;
-		goto out;
+		return -E1000_ERR_PHY;
+	}
+	if (((mdic & E1000_MDIC_REG_MASK) >> E1000_MDIC_REG_SHIFT) != offset) {
+		DEBUGOUT2("MDI Write offset error - requested %d, returned %d\n",
+			  offset,
+			  (mdic & E1000_MDIC_REG_MASK) >> E1000_MDIC_REG_SHIFT);
+		return -E1000_ERR_PHY;
 	}
 
-	/*
-	 * Allow some time after each MDIC transaction to avoid
+	/* Allow some time after each MDIC transaction to avoid
 	 * reading duplicate data in the next MDIC transaction.
 	 */
 	if (hw->mac.type == e1000_pch2lan)
 		usec_delay(100);
 
-out:
-	return ret_val;
+	return E1000_SUCCESS;
 }
 
 /**
@@ -386,8 +413,7 @@ s32 e1000_read_phy_reg_i2c(struct e1000_hw *hw, u32 offset, u16 *data)
 
 	DEBUGFUNC("e1000_read_phy_reg_i2c");
 
-	/*
-	 * Set up Op-code, Phy Address, and register address in the I2CCMD
+	/* Set up Op-code, Phy Address, and register address in the I2CCMD
 	 * register.  The MAC will take care of interfacing with the
 	 * PHY to retrieve the desired data.
 	 */
@@ -445,8 +471,7 @@ s32 e1000_write_phy_reg_i2c(struct e1000_hw *hw, u32 offset, u16 data)
 	/* Swap the data bytes for the I2C interface */
 	phy_data_swapped = ((data >> 8) & 0x00FF) | ((data << 8) & 0xFF00);
 
-	/*
-	 * Set up Op-code, Phy Address, and register address in the I2CCMD
+	/* Set up Op-code, Phy Address, and register address in the I2CCMD
 	 * register.  The MAC will take care of interfacing with the
 	 * PHY to retrieve the desired data.
 	 */
@@ -502,8 +527,7 @@ s32 e1000_read_sfp_data_byte(struct e1000_hw *hw, u16 offset, u8 *data)
 		return -E1000_ERR_PHY;
 	}
 
-	/*
-	 * Set up Op-code, EEPROM Address,in the I2CCMD
+	/* Set up Op-code, EEPROM Address,in the I2CCMD
 	 * register. The MAC will take care of interfacing with the
 	 * EEPROM to retrieve the desired data.
 	 */
@@ -557,14 +581,12 @@ s32 e1000_write_sfp_data_byte(struct e1000_hw *hw, u16 offset, u8 data)
 		DEBUGOUT("I2CCMD command address exceeds upper limit\n");
 		return -E1000_ERR_PHY;
 	}
-	/*
-	 * The programming interface is 16 bits wide
+	/* The programming interface is 16 bits wide
 	 * so we need to read the whole word first
 	 * then update appropriate byte lane and write
 	 * the updated word back.
 	 */
-	/*
-	 * Set up Op-code, EEPROM Address,in the I2CCMD
+	/* Set up Op-code, EEPROM Address,in the I2CCMD
 	 * register. The MAC will take care of interfacing
 	 * with an EEPROM to write the data given.
 	 */
@@ -574,8 +596,7 @@ s32 e1000_write_sfp_data_byte(struct e1000_hw *hw, u16 offset, u8 data)
 	E1000_WRITE_REG(hw, E1000_I2CCMD, i2ccmd);
 	for (i = 0; i < E1000_I2CCMD_PHY_TIMEOUT; i++) {
 		usec_delay(50);
-		/*
-		 * Poll the ready bit to see if lastly
+		/* Poll the ready bit to see if lastly
 		 * launched I2C operation completed
 		 */
 		i2ccmd = E1000_READ_REG(hw, E1000_I2CCMD);
@@ -583,8 +604,7 @@ s32 e1000_write_sfp_data_byte(struct e1000_hw *hw, u16 offset, u8 data)
 			/* Check if this is READ or WRITE phase */
 			if ((i2ccmd & E1000_I2CCMD_OPCODE_READ) ==
 			    E1000_I2CCMD_OPCODE_READ) {
-				/*
-				 * Write the selected byte
+				/* Write the selected byte
 				 * lane and update whole word
 				 */
 				data_local = i2ccmd & 0xFF00;
@@ -621,23 +641,22 @@ s32 e1000_write_sfp_data_byte(struct e1000_hw *hw, u16 offset, u8 data)
  **/
 s32 e1000_read_phy_reg_m88(struct e1000_hw *hw, u32 offset, u16 *data)
 {
-	s32 ret_val = E1000_SUCCESS;
+	s32 ret_val;
 
 	DEBUGFUNC("e1000_read_phy_reg_m88");
 
-	if (!(hw->phy.ops.acquire))
-		goto out;
+	if (!hw->phy.ops.acquire)
+		return E1000_SUCCESS;
 
 	ret_val = hw->phy.ops.acquire(hw);
 	if (ret_val)
-		goto out;
+		return ret_val;
 
 	ret_val = e1000_read_phy_reg_mdic(hw, MAX_PHY_REG_ADDRESS & offset,
 					  data);
 
 	hw->phy.ops.release(hw);
 
-out:
 	return ret_val;
 }
 
@@ -652,23 +671,22 @@ out:
  **/
 s32 e1000_write_phy_reg_m88(struct e1000_hw *hw, u32 offset, u16 data)
 {
-	s32 ret_val = E1000_SUCCESS;
+	s32 ret_val;
 
 	DEBUGFUNC("e1000_write_phy_reg_m88");
 
-	if (!(hw->phy.ops.acquire))
-		goto out;
+	if (!hw->phy.ops.acquire)
+		return E1000_SUCCESS;
 
 	ret_val = hw->phy.ops.acquire(hw);
 	if (ret_val)
-		goto out;
+		return ret_val;
 
 	ret_val = e1000_write_phy_reg_mdic(hw, MAX_PHY_REG_ADDRESS & offset,
 					   data);
 
 	hw->phy.ops.release(hw);
 
-out:
 	return ret_val;
 }
 
@@ -711,29 +729,25 @@ static s32 __e1000_read_phy_reg_igp(struct e1000_hw *hw, u32 offset, u16 *data,
 	DEBUGFUNC("__e1000_read_phy_reg_igp");
 
 	if (!locked) {
-		if (!(hw->phy.ops.acquire))
-			goto out;
+		if (!hw->phy.ops.acquire)
+			return E1000_SUCCESS;
 
 		ret_val = hw->phy.ops.acquire(hw);
 		if (ret_val)
-			goto out;
+			return ret_val;
 	}
 
-	if (offset > MAX_PHY_MULTI_PAGE_REG) {
+	if (offset > MAX_PHY_MULTI_PAGE_REG)
 		ret_val = e1000_write_phy_reg_mdic(hw,
 						   IGP01E1000_PHY_PAGE_SELECT,
 						   (u16)offset);
-		if (ret_val)
-			goto release;
-	}
-
-	ret_val = e1000_read_phy_reg_mdic(hw, MAX_PHY_REG_ADDRESS & offset,
-					  data);
-
-release:
+	if (!ret_val)
+		ret_val = e1000_read_phy_reg_mdic(hw,
+						  MAX_PHY_REG_ADDRESS & offset,
+						  data);
 	if (!locked)
 		hw->phy.ops.release(hw);
-out:
+
 	return ret_val;
 }
 
@@ -784,30 +798,25 @@ static s32 __e1000_write_phy_reg_igp(struct e1000_hw *hw, u32 offset, u16 data,
 	DEBUGFUNC("e1000_write_phy_reg_igp");
 
 	if (!locked) {
-		if (!(hw->phy.ops.acquire))
-			goto out;
+		if (!hw->phy.ops.acquire)
+			return E1000_SUCCESS;
 
 		ret_val = hw->phy.ops.acquire(hw);
 		if (ret_val)
-			goto out;
+			return ret_val;
 	}
 
-	if (offset > MAX_PHY_MULTI_PAGE_REG) {
+	if (offset > MAX_PHY_MULTI_PAGE_REG)
 		ret_val = e1000_write_phy_reg_mdic(hw,
 						   IGP01E1000_PHY_PAGE_SELECT,
 						   (u16)offset);
-		if (ret_val)
-			goto release;
-	}
-
-	ret_val = e1000_write_phy_reg_mdic(hw, MAX_PHY_REG_ADDRESS & offset,
-					   data);
-
-release:
+	if (!ret_val)
+		ret_val = e1000_write_phy_reg_mdic(hw, MAX_PHY_REG_ADDRESS &
+						       offset,
+						   data);
 	if (!locked)
 		hw->phy.ops.release(hw);
 
-out:
 	return ret_val;
 }
 
@@ -854,17 +863,18 @@ static s32 __e1000_read_kmrn_reg(struct e1000_hw *hw, u32 offset, u16 *data,
 				 bool locked)
 {
 	u32 kmrnctrlsta;
-	s32 ret_val = E1000_SUCCESS;
 
 	DEBUGFUNC("__e1000_read_kmrn_reg");
 
 	if (!locked) {
-		if (!(hw->phy.ops.acquire))
-			goto out;
+		s32 ret_val = E1000_SUCCESS;
+
+		if (!hw->phy.ops.acquire)
+			return E1000_SUCCESS;
 
 		ret_val = hw->phy.ops.acquire(hw);
 		if (ret_val)
-			goto out;
+			return ret_val;
 	}
 
 	kmrnctrlsta = ((offset << E1000_KMRNCTRLSTA_OFFSET_SHIFT) &
@@ -880,8 +890,7 @@ static s32 __e1000_read_kmrn_reg(struct e1000_hw *hw, u32 offset, u16 *data,
 	if (!locked)
 		hw->phy.ops.release(hw);
 
-out:
-	return ret_val;
+	return E1000_SUCCESS;
 }
 
 /**
@@ -929,17 +938,18 @@ static s32 __e1000_write_kmrn_reg(struct e1000_hw *hw, u32 offset, u16 data,
 				  bool locked)
 {
 	u32 kmrnctrlsta;
-	s32 ret_val = E1000_SUCCESS;
 
 	DEBUGFUNC("e1000_write_kmrn_reg_generic");
 
 	if (!locked) {
-		if (!(hw->phy.ops.acquire))
-			goto out;
+		s32 ret_val = E1000_SUCCESS;
+
+		if (!hw->phy.ops.acquire)
+			return E1000_SUCCESS;
 
 		ret_val = hw->phy.ops.acquire(hw);
 		if (ret_val)
-			goto out;
+			return ret_val;
 	}
 
 	kmrnctrlsta = ((offset << E1000_KMRNCTRLSTA_OFFSET_SHIFT) &
@@ -952,8 +962,7 @@ static s32 __e1000_write_kmrn_reg(struct e1000_hw *hw, u32 offset, u16 data,
 	if (!locked)
 		hw->phy.ops.release(hw);
 
-out:
-	return ret_val;
+	return E1000_SUCCESS;
 }
 
 /**
@@ -985,6 +994,46 @@ s32 e1000_write_kmrn_reg_locked(struct e1000_hw *hw, u32 offset, u16 data)
 }
 
 /**
+ *  e1000_set_master_slave_mode - Setup PHY for Master/slave mode
+ *  @hw: pointer to the HW structure
+ *
+ *  Sets up Master/slave mode
+ **/
+static s32 e1000_set_master_slave_mode(struct e1000_hw *hw)
+{
+	s32 ret_val;
+	u16 phy_data;
+
+	/* Resolve Master/Slave mode */
+	ret_val = hw->phy.ops.read_reg(hw, PHY_1000T_CTRL, &phy_data);
+	if (ret_val)
+		return ret_val;
+
+	/* load defaults for future use */
+	hw->phy.original_ms_type = (phy_data & CR_1000T_MS_ENABLE) ?
+				   ((phy_data & CR_1000T_MS_VALUE) ?
+				    e1000_ms_force_master :
+				    e1000_ms_force_slave) : e1000_ms_auto;
+
+	switch (hw->phy.ms_type) {
+	case e1000_ms_force_master:
+		phy_data |= (CR_1000T_MS_ENABLE | CR_1000T_MS_VALUE);
+		break;
+	case e1000_ms_force_slave:
+		phy_data |= CR_1000T_MS_ENABLE;
+		phy_data &= ~(CR_1000T_MS_VALUE);
+		break;
+	case e1000_ms_auto:
+		phy_data &= ~CR_1000T_MS_ENABLE;
+		/* fall-through */
+	default:
+		break;
+	}
+
+	return hw->phy.ops.write_reg(hw, PHY_1000T_CTRL, phy_data);
+}
+
+/**
  *  e1000_copper_link_setup_82577 - Setup 82577 PHY for copper link
  *  @hw: pointer to the HW structure
  *
@@ -1001,55 +1050,54 @@ s32 e1000_copper_link_setup_82577(struct e1000_hw *hw)
 		ret_val = hw->phy.ops.reset(hw);
 		if (ret_val) {
 			DEBUGOUT("Error resetting the PHY.\n");
-			goto out;
+			return ret_val;
 		}
 	}
 
-	/* Enable CRS on Tx. This must be set for half-duplex operation. */
+	/* Enable CRS on Tx. This must be set for half-duplex operation.
+	 * Not required on some PHYs.
+	 */
 	ret_val = hw->phy.ops.read_reg(hw, I82577_CFG_REG, &phy_data);
 	if (ret_val)
-		goto out;
+		return ret_val;
 
-	phy_data |= I82577_CFG_ASSERT_CRS_ON_TX;
+	if ((hw->phy.type != e1000_phy_82579) &&
+	    (hw->phy.type != e1000_phy_i217))
+		phy_data |= I82577_CFG_ASSERT_CRS_ON_TX;
 
 	/* Enable downshift */
 	phy_data |= I82577_CFG_ENABLE_DOWNSHIFT;
 
 	ret_val = hw->phy.ops.write_reg(hw, I82577_CFG_REG, phy_data);
 	if (ret_val)
-		goto out;
+		return ret_val;
 
-	/* Resolve Master/Slave mode */
-	ret_val = hw->phy.ops.read_reg(hw, PHY_1000T_CTRL, &phy_data);
+	/* Set MDI/MDIX mode */
+	ret_val = hw->phy.ops.read_reg(hw, I82577_PHY_CTRL_2, &phy_data);
 	if (ret_val)
-		goto out;
-
-	/* load defaults for future use */
-	hw->phy.original_ms_type = (phy_data & CR_1000T_MS_ENABLE) ?
-				   ((phy_data & CR_1000T_MS_VALUE) ?
-				   e1000_ms_force_master :
-				   e1000_ms_force_slave) : e1000_ms_auto;
-
-	switch (hw->phy.ms_type) {
-	case e1000_ms_force_master:
-		phy_data |= (CR_1000T_MS_ENABLE | CR_1000T_MS_VALUE);
+		return ret_val;
+	phy_data &= ~I82577_PHY_CTRL2_MDIX_CFG_MASK;
+	/* Options:
+	 *   0 - Auto (default)
+	 *   1 - MDI mode
+	 *   2 - MDI-X mode
+	 */
+	switch (hw->phy.mdix) {
+	case 1:
 		break;
-	case e1000_ms_force_slave:
-		phy_data |= CR_1000T_MS_ENABLE;
-		phy_data &= ~(CR_1000T_MS_VALUE);
+	case 2:
+		phy_data |= I82577_PHY_CTRL2_MANUAL_MDIX;
 		break;
-	case e1000_ms_auto:
-		phy_data &= ~CR_1000T_MS_ENABLE;
+	case 0:
 	default:
+		phy_data |= I82577_PHY_CTRL2_AUTO_MDI_MDIX;
 		break;
 	}
-
-	ret_val = hw->phy.ops.write_reg(hw, PHY_1000T_CTRL, phy_data);
+	ret_val = hw->phy.ops.write_reg(hw, I82577_PHY_CTRL_2, phy_data);
 	if (ret_val)
-		goto out;
+		return ret_val;
 
-out:
-	return ret_val;
+	return e1000_set_master_slave_mode(hw);
 }
 
 /**
@@ -1071,14 +1119,13 @@ s32 e1000_copper_link_setup_m88(struct e1000_hw *hw)
 	/* Enable CRS on Tx. This must be set for half-duplex operation. */
 	ret_val = phy->ops.read_reg(hw, M88E1000_PHY_SPEC_CTRL, &phy_data);
 	if (ret_val)
-		goto out;
+		return ret_val;
 
 	/* For BM PHY this bit is downshift enable */
 	if (phy->type != e1000_phy_bm)
 		phy_data |= M88E1000_PSCR_ASSERT_CRS_ON_TX;
 
-	/*
-	 * Options:
+	/* Options:
 	 *   MDI/MDI-X = 0 (default)
 	 *   0 - Auto for all speeds
 	 *   1 - MDI mode
@@ -1103,36 +1150,50 @@ s32 e1000_copper_link_setup_m88(struct e1000_hw *hw)
 		break;
 	}
 
-	/*
-	 * Options:
+	/* Options:
 	 *   disable_polarity_correction = 0 (default)
 	 *       Automatic Correction for Reversed Cable Polarity
 	 *   0 - Disabled
 	 *   1 - Enabled
 	 */
 	phy_data &= ~M88E1000_PSCR_POLARITY_REVERSAL;
-	if (phy->disable_polarity_correction == 1)
+	if (phy->disable_polarity_correction)
 		phy_data |= M88E1000_PSCR_POLARITY_REVERSAL;
 
 	/* Enable downshift on BM (disabled by default) */
-	if (phy->type == e1000_phy_bm)
+	if (phy->type == e1000_phy_bm) {
+		/* For 82574/82583, first disable then enable downshift */
+		if (phy->id == BME1000_E_PHY_ID_R2) {
+			phy_data &= ~BME1000_PSCR_ENABLE_DOWNSHIFT;
+			ret_val = phy->ops.write_reg(hw, M88E1000_PHY_SPEC_CTRL,
+						     phy_data);
+			if (ret_val)
+				return ret_val;
+			/* Commit the changes. */
+			ret_val = phy->ops.commit(hw);
+			if (ret_val) {
+				DEBUGOUT("Error committing the PHY changes\n");
+				return ret_val;
+			}
+		}
+
 		phy_data |= BME1000_PSCR_ENABLE_DOWNSHIFT;
+	}
 
 	ret_val = phy->ops.write_reg(hw, M88E1000_PHY_SPEC_CTRL, phy_data);
 	if (ret_val)
-		goto out;
+		return ret_val;
 
 	if ((phy->type == e1000_phy_m88) &&
 	    (phy->revision < E1000_REVISION_4) &&
 	    (phy->id != BME1000_E_PHY_ID_R2)) {
-		/*
-		 * Force TX_CLK in the Extended PHY Specific Control Register
+		/* Force TX_CLK in the Extended PHY Specific Control Register
 		 * to 25MHz clock.
 		 */
 		ret_val = phy->ops.read_reg(hw, M88E1000_EXT_PHY_SPEC_CTRL,
 					    &phy_data);
 		if (ret_val)
-			goto out;
+			return ret_val;
 
 		phy_data |= M88E1000_EPSCR_TX_CLK_25;
 
@@ -1151,33 +1212,33 @@ s32 e1000_copper_link_setup_m88(struct e1000_hw *hw)
 		ret_val = phy->ops.write_reg(hw, M88E1000_EXT_PHY_SPEC_CTRL,
 					     phy_data);
 		if (ret_val)
-			goto out;
+			return ret_val;
 	}
 
 	if ((phy->type == e1000_phy_bm) && (phy->id == BME1000_E_PHY_ID_R2)) {
 		/* Set PHY page 0, register 29 to 0x0003 */
 		ret_val = phy->ops.write_reg(hw, 29, 0x0003);
 		if (ret_val)
-			goto out;
+			return ret_val;
 
 		/* Set PHY page 0, register 30 to 0x0000 */
 		ret_val = phy->ops.write_reg(hw, 30, 0x0000);
 		if (ret_val)
-			goto out;
+			return ret_val;
 	}
 
 	/* Commit the changes. */
 	ret_val = phy->ops.commit(hw);
 	if (ret_val) {
 		DEBUGOUT("Error committing the PHY changes\n");
-		goto out;
+		return ret_val;
 	}
 
 	if (phy->type == e1000_phy_82578) {
 		ret_val = phy->ops.read_reg(hw, M88E1000_EXT_PHY_SPEC_CTRL,
 					    &phy_data);
 		if (ret_val)
-			goto out;
+			return ret_val;
 
 		/* 82578 PHY - set the downshift count to 1x. */
 		phy_data |= I82578_EPSCR_DOWNSHIFT_ENABLE;
@@ -1185,11 +1246,16 @@ s32 e1000_copper_link_setup_m88(struct e1000_hw *hw)
 		ret_val = phy->ops.write_reg(hw, M88E1000_EXT_PHY_SPEC_CTRL,
 					     phy_data);
 		if (ret_val)
-			goto out;
+			return ret_val;
 	}
 
-out:
-	return ret_val;
+	if (phy->type == e1000_phy_i210) {
+		ret_val = e1000_set_master_slave_mode(hw);
+		if (ret_val)
+			return ret_val;
+	}
+
+	return E1000_SUCCESS;
 }
 
 /**
@@ -1211,10 +1277,9 @@ s32 e1000_copper_link_setup_m88_gen2(struct e1000_hw *hw)
 	/* Enable CRS on Tx. This must be set for half-duplex operation. */
 	ret_val = phy->ops.read_reg(hw, M88E1000_PHY_SPEC_CTRL, &phy_data);
 	if (ret_val)
-		goto out;
+		return ret_val;
 
-	/*
-	 * Options:
+	/* Options:
 	 *   MDI/MDI-X = 0 (default)
 	 *   0 - Auto for all speeds
 	 *   1 - MDI mode
@@ -1242,15 +1307,14 @@ s32 e1000_copper_link_setup_m88_gen2(struct e1000_hw *hw)
 		break;
 	}
 
-	/*
-	 * Options:
+	/* Options:
 	 *   disable_polarity_correction = 0 (default)
 	 *       Automatic Correction for Reversed Cable Polarity
 	 *   0 - Disabled
 	 *   1 - Enabled
 	 */
 	phy_data &= ~M88E1000_PSCR_POLARITY_REVERSAL;
-	if (phy->disable_polarity_correction == 1)
+	if (phy->disable_polarity_correction)
 		phy_data |= M88E1000_PSCR_POLARITY_REVERSAL;
 
 	/* Enable downshift and setting it to X6 */
@@ -1260,17 +1324,16 @@ s32 e1000_copper_link_setup_m88_gen2(struct e1000_hw *hw)
 
 	ret_val = phy->ops.write_reg(hw, M88E1000_PHY_SPEC_CTRL, phy_data);
 	if (ret_val)
-		goto out;
+		return ret_val;
 
 	/* Commit the changes. */
 	ret_val = phy->ops.commit(hw);
 	if (ret_val) {
 		DEBUGOUT("Error committing the PHY changes\n");
-		goto out;
+		return ret_val;
 	}
 
-out:
-	return ret_val;
+	return E1000_SUCCESS;
 }
 
 /**
@@ -1292,17 +1355,15 @@ s32 e1000_copper_link_setup_igp(struct e1000_hw *hw)
 	ret_val = hw->phy.ops.reset(hw);
 	if (ret_val) {
 		DEBUGOUT("Error resetting the PHY.\n");
-		goto out;
+		return ret_val;
 	}
 
-	/*
-	 * Wait 100ms for MAC to configure PHY from NVM settings, to avoid
+	/* Wait 100ms for MAC to configure PHY from NVM settings, to avoid
 	 * timeout issues when LFS is enabled.
 	 */
 	msec_delay(100);
 
-	/*
-	 * The NVM settings will configure LPLU in D3 for
+	/* The NVM settings will configure LPLU in D3 for
 	 * non-IGP1 PHYs.
 	 */
 	if (phy->type == e1000_phy_igp) {
@@ -1310,7 +1371,7 @@ s32 e1000_copper_link_setup_igp(struct e1000_hw *hw)
 		ret_val = hw->phy.ops.set_d3_lplu_state(hw, FALSE);
 		if (ret_val) {
 			DEBUGOUT("Error Disabling LPLU D3\n");
-			goto out;
+			return ret_val;
 		}
 	}
 
@@ -1319,13 +1380,13 @@ s32 e1000_copper_link_setup_igp(struct e1000_hw *hw)
 		ret_val = hw->phy.ops.set_d0_lplu_state(hw, FALSE);
 		if (ret_val) {
 			DEBUGOUT("Error Disabling LPLU D0\n");
-			goto out;
+			return ret_val;
 		}
 	}
 	/* Configure mdi-mdix settings */
 	ret_val = phy->ops.read_reg(hw, IGP01E1000_PHY_PORT_CTRL, &data);
 	if (ret_val)
-		goto out;
+		return ret_val;
 
 	data &= ~IGP01E1000_PSCR_AUTO_MDIX;
 
@@ -1343,12 +1404,11 @@ s32 e1000_copper_link_setup_igp(struct e1000_hw *hw)
 	}
 	ret_val = phy->ops.write_reg(hw, IGP01E1000_PHY_PORT_CTRL, data);
 	if (ret_val)
-		goto out;
+		return ret_val;
 
 	/* set auto-master slave resolution settings */
 	if (hw->mac.autoneg) {
-		/*
-		 * when autonegotiation advertisement is only 1000Mbps then we
+		/* when autonegotiation advertisement is only 1000Mbps then we
 		 * should disable SmartSpeed and enable Auto MasterSlave
 		 * resolution as hardware default.
 		 */
@@ -1358,125 +1418,29 @@ s32 e1000_copper_link_setup_igp(struct e1000_hw *hw)
 						    IGP01E1000_PHY_PORT_CONFIG,
 						    &data);
 			if (ret_val)
-				goto out;
+				return ret_val;
 
 			data &= ~IGP01E1000_PSCFR_SMART_SPEED;
 			ret_val = phy->ops.write_reg(hw,
 						     IGP01E1000_PHY_PORT_CONFIG,
 						     data);
 			if (ret_val)
-				goto out;
+				return ret_val;
 
 			/* Set auto Master/Slave resolution process */
 			ret_val = phy->ops.read_reg(hw, PHY_1000T_CTRL, &data);
 			if (ret_val)
-				goto out;
+				return ret_val;
 
 			data &= ~CR_1000T_MS_ENABLE;
 			ret_val = phy->ops.write_reg(hw, PHY_1000T_CTRL, data);
 			if (ret_val)
-				goto out;
+				return ret_val;
 		}
 
-		ret_val = phy->ops.read_reg(hw, PHY_1000T_CTRL, &data);
-		if (ret_val)
-			goto out;
-
-		/* load defaults for future use */
-		phy->original_ms_type = (data & CR_1000T_MS_ENABLE) ?
-			((data & CR_1000T_MS_VALUE) ?
-			e1000_ms_force_master :
-			e1000_ms_force_slave) :
-			e1000_ms_auto;
-
-		switch (phy->ms_type) {
-		case e1000_ms_force_master:
-			data |= (CR_1000T_MS_ENABLE | CR_1000T_MS_VALUE);
-			break;
-		case e1000_ms_force_slave:
-			data |= CR_1000T_MS_ENABLE;
-			data &= ~(CR_1000T_MS_VALUE);
-			break;
-		case e1000_ms_auto:
-			data &= ~CR_1000T_MS_ENABLE;
-		default:
-			break;
-		}
-		ret_val = phy->ops.write_reg(hw, PHY_1000T_CTRL, data);
-		if (ret_val)
-			goto out;
+		ret_val = e1000_set_master_slave_mode(hw);
 	}
 
-out:
-	return ret_val;
-}
-
-/**
- *  e1000_copper_link_autoneg - Setup/Enable autoneg for copper link
- *  @hw: pointer to the HW structure
- *
- *  Performs initial bounds checking on autoneg advertisement parameter, then
- *  configure to advertise the full capability.  Setup the PHY to autoneg
- *  and restart the negotiation process between the link partner.  If
- *  autoneg_wait_to_complete, then wait for autoneg to complete before exiting.
- **/
-s32 e1000_copper_link_autoneg(struct e1000_hw *hw)
-{
-	struct e1000_phy_info *phy = &hw->phy;
-	s32 ret_val;
-	u16 phy_ctrl;
-
-	DEBUGFUNC("e1000_copper_link_autoneg");
-
-	/*
-	 * Perform some bounds checking on the autoneg advertisement
-	 * parameter.
-	 */
-	phy->autoneg_advertised &= phy->autoneg_mask;
-
-	/*
-	 * If autoneg_advertised is zero, we assume it was not defaulted
-	 * by the calling code so we set to advertise full capability.
-	 */
-	if (phy->autoneg_advertised == 0)
-		phy->autoneg_advertised = phy->autoneg_mask;
-
-	DEBUGOUT("Reconfiguring auto-neg advertisement params\n");
-	ret_val = e1000_phy_setup_autoneg(hw);
-	if (ret_val) {
-		DEBUGOUT("Error Setting up Auto-Negotiation\n");
-		goto out;
-	}
-	DEBUGOUT("Restarting Auto-Neg\n");
-
-	/*
-	 * Restart auto-negotiation by setting the Auto Neg Enable bit and
-	 * the Auto Neg Restart bit in the PHY control register.
-	 */
-	ret_val = phy->ops.read_reg(hw, PHY_CONTROL, &phy_ctrl);
-	if (ret_val)
-		goto out;
-
-	phy_ctrl |= (MII_CR_AUTO_NEG_EN | MII_CR_RESTART_AUTO_NEG);
-	ret_val = phy->ops.write_reg(hw, PHY_CONTROL, phy_ctrl);
-	if (ret_val)
-		goto out;
-
-	/*
-	 * Does the user want to wait for Auto-Neg to complete here, or
-	 * check at a later time (for example, callback routine).
-	 */
-	if (phy->autoneg_wait_to_complete) {
-		ret_val = hw->mac.ops.wait_autoneg(hw);
-		if (ret_val) {
-			DEBUGOUT("Error while waiting for autoneg to complete\n");
-			goto out;
-		}
-	}
-
-	hw->mac.get_link_status = TRUE;
-
-out:
 	return ret_val;
 }
 
@@ -1503,26 +1467,24 @@ s32 e1000_phy_setup_autoneg(struct e1000_hw *hw)
 	/* Read the MII Auto-Neg Advertisement Register (Address 4). */
 	ret_val = phy->ops.read_reg(hw, PHY_AUTONEG_ADV, &mii_autoneg_adv_reg);
 	if (ret_val)
-		goto out;
+		return ret_val;
 
 	if (phy->autoneg_mask & ADVERTISE_1000_FULL) {
 		/* Read the MII 1000Base-T Control Register (Address 9). */
 		ret_val = phy->ops.read_reg(hw, PHY_1000T_CTRL,
 					    &mii_1000t_ctrl_reg);
 		if (ret_val)
-			goto out;
+			return ret_val;
 	}
 
-	/*
-	 * Need to parse both autoneg_advertised and fc and set up
+	/* Need to parse both autoneg_advertised and fc and set up
 	 * the appropriate PHY registers.  First we will parse for
 	 * autoneg_advertised software override.  Since we can advertise
 	 * a plethora of combinations, we need to check each bit
 	 * individually.
 	 */
 
-	/*
-	 * First we clear all the 10/100 mb speed bits in the Auto-Neg
+	/* First we clear all the 10/100 mb speed bits in the Auto-Neg
 	 * Advertisement Register (Address 4) and the 1000 mb speed bits in
 	 * the  1000Base-T Control Register (Address 9).
 	 */
@@ -1568,8 +1530,7 @@ s32 e1000_phy_setup_autoneg(struct e1000_hw *hw)
 		mii_1000t_ctrl_reg |= CR_1000T_FD_CAPS;
 	}
 
-	/*
-	 * Check for a software override of the flow control settings, and
+	/* Check for a software override of the flow control settings, and
 	 * setup the PHY advertisement registers accordingly.  If
 	 * auto-negotiation is enabled, then software will have to set the
 	 * "PAUSE" bits to the correct value in the Auto-Negotiation
@@ -1588,15 +1549,13 @@ s32 e1000_phy_setup_autoneg(struct e1000_hw *hw)
 	 */
 	switch (hw->fc.current_mode) {
 	case e1000_fc_none:
-		/*
-		 * Flow control (Rx & Tx) is completely disabled by a
+		/* Flow control (Rx & Tx) is completely disabled by a
 		 * software over-ride.
 		 */
 		mii_autoneg_adv_reg &= ~(NWAY_AR_ASM_DIR | NWAY_AR_PAUSE);
 		break;
 	case e1000_fc_rx_pause:
-		/*
-		 * Rx Flow control is enabled, and Tx Flow control is
+		/* Rx Flow control is enabled, and Tx Flow control is
 		 * disabled, by a software over-ride.
 		 *
 		 * Since there really isn't a way to advertise that we are
@@ -1608,40 +1567,97 @@ s32 e1000_phy_setup_autoneg(struct e1000_hw *hw)
 		mii_autoneg_adv_reg |= (NWAY_AR_ASM_DIR | NWAY_AR_PAUSE);
 		break;
 	case e1000_fc_tx_pause:
-		/*
-		 * Tx Flow control is enabled, and Rx Flow control is
+		/* Tx Flow control is enabled, and Rx Flow control is
 		 * disabled, by a software over-ride.
 		 */
 		mii_autoneg_adv_reg |= NWAY_AR_ASM_DIR;
 		mii_autoneg_adv_reg &= ~NWAY_AR_PAUSE;
 		break;
 	case e1000_fc_full:
-		/*
-		 * Flow control (both Rx and Tx) is enabled by a software
+		/* Flow control (both Rx and Tx) is enabled by a software
 		 * over-ride.
 		 */
 		mii_autoneg_adv_reg |= (NWAY_AR_ASM_DIR | NWAY_AR_PAUSE);
 		break;
 	default:
 		DEBUGOUT("Flow control param set incorrectly\n");
-		ret_val = -E1000_ERR_CONFIG;
-		goto out;
+		return -E1000_ERR_CONFIG;
 	}
 
 	ret_val = phy->ops.write_reg(hw, PHY_AUTONEG_ADV, mii_autoneg_adv_reg);
 	if (ret_val)
-		goto out;
+		return ret_val;
 
 	DEBUGOUT1("Auto-Neg Advertising %x\n", mii_autoneg_adv_reg);
 
-	if (phy->autoneg_mask & ADVERTISE_1000_FULL) {
+	if (phy->autoneg_mask & ADVERTISE_1000_FULL)
 		ret_val = phy->ops.write_reg(hw, PHY_1000T_CTRL,
 					     mii_1000t_ctrl_reg);
-		if (ret_val)
-			goto out;
+
+	return ret_val;
+}
+
+/**
+ *  e1000_copper_link_autoneg - Setup/Enable autoneg for copper link
+ *  @hw: pointer to the HW structure
+ *
+ *  Performs initial bounds checking on autoneg advertisement parameter, then
+ *  configure to advertise the full capability.  Setup the PHY to autoneg
+ *  and restart the negotiation process between the link partner.  If
+ *  autoneg_wait_to_complete, then wait for autoneg to complete before exiting.
+ **/
+s32 e1000_copper_link_autoneg(struct e1000_hw *hw)
+{
+	struct e1000_phy_info *phy = &hw->phy;
+	s32 ret_val;
+	u16 phy_ctrl;
+
+	DEBUGFUNC("e1000_copper_link_autoneg");
+
+	/* Perform some bounds checking on the autoneg advertisement
+	 * parameter.
+	 */
+	phy->autoneg_advertised &= phy->autoneg_mask;
+
+	/* If autoneg_advertised is zero, we assume it was not defaulted
+	 * by the calling code so we set to advertise full capability.
+	 */
+	if (!phy->autoneg_advertised)
+		phy->autoneg_advertised = phy->autoneg_mask;
+
+	DEBUGOUT("Reconfiguring auto-neg advertisement params\n");
+	ret_val = e1000_phy_setup_autoneg(hw);
+	if (ret_val) {
+		DEBUGOUT("Error Setting up Auto-Negotiation\n");
+		return ret_val;
 	}
+	DEBUGOUT("Restarting Auto-Neg\n");
+
+	/* Restart auto-negotiation by setting the Auto Neg Enable bit and
+	 * the Auto Neg Restart bit in the PHY control register.
+	 */
+	ret_val = phy->ops.read_reg(hw, PHY_CONTROL, &phy_ctrl);
+	if (ret_val)
+		return ret_val;
+
+	phy_ctrl |= (MII_CR_AUTO_NEG_EN | MII_CR_RESTART_AUTO_NEG);
+	ret_val = phy->ops.write_reg(hw, PHY_CONTROL, phy_ctrl);
+	if (ret_val)
+		return ret_val;
+
+	/* Does the user want to wait for Auto-Neg to complete here, or
+	 * check at a later time (for example, callback routine).
+	 */
+	if (phy->autoneg_wait_to_complete) {
+		ret_val = e1000_wait_autoneg(hw);
+		if (ret_val) {
+			DEBUGOUT("Error while waiting for autoneg to complete\n");
+			return ret_val;
+		}
+	}
+
+	hw->mac.get_link_status = TRUE;
 
-out:
 	return ret_val;
 }
 
@@ -1662,44 +1678,40 @@ s32 e1000_setup_copper_link_generic(struct e1000_hw *hw)
 	DEBUGFUNC("e1000_setup_copper_link_generic");
 
 	if (hw->mac.autoneg) {
-		/*
-		 * Setup autoneg and flow control advertisement and perform
+		/* Setup autoneg and flow control advertisement and perform
 		 * autonegotiation.
 		 */
 		ret_val = e1000_copper_link_autoneg(hw);
 		if (ret_val)
-			goto out;
+			return ret_val;
 	} else {
-		/*
-		 * PHY will be set to 10H, 10F, 100H or 100F
+		/* PHY will be set to 10H, 10F, 100H or 100F
 		 * depending on user settings.
 		 */
 		DEBUGOUT("Forcing Speed and Duplex\n");
 		ret_val = hw->phy.ops.force_speed_duplex(hw);
 		if (ret_val) {
 			DEBUGOUT("Error Forcing Speed and Duplex\n");
-			goto out;
+			return ret_val;
 		}
 	}
 
-	/*
-	 * Check link status. Wait up to 100 microseconds for link to become
+	/* Check link status. Wait up to 100 microseconds for link to become
 	 * valid.
 	 */
 	ret_val = e1000_phy_has_link_generic(hw, COPPER_LINK_UP_LIMIT, 10,
 					     &link);
 	if (ret_val)
-		goto out;
+		return ret_val;
 
 	if (link) {
 		DEBUGOUT("Valid link established!!!\n");
-		e1000_config_collision_dist_generic(hw);
+		hw->mac.ops.config_collision_dist(hw);
 		ret_val = e1000_config_fc_after_link_up_generic(hw);
 	} else {
 		DEBUGOUT("Unable to establish link!!!\n");
 	}
 
-out:
 	return ret_val;
 }
 
@@ -1722,28 +1734,27 @@ s32 e1000_phy_force_speed_duplex_igp(struct e1000_hw *hw)
 
 	ret_val = phy->ops.read_reg(hw, PHY_CONTROL, &phy_data);
 	if (ret_val)
-		goto out;
+		return ret_val;
 
 	e1000_phy_force_speed_duplex_setup(hw, &phy_data);
 
 	ret_val = phy->ops.write_reg(hw, PHY_CONTROL, phy_data);
 	if (ret_val)
-		goto out;
+		return ret_val;
 
-	/*
-	 * Clear Auto-Crossover to force MDI manually.  IGP requires MDI
+	/* Clear Auto-Crossover to force MDI manually.  IGP requires MDI
 	 * forced whenever speed and duplex are forced.
 	 */
 	ret_val = phy->ops.read_reg(hw, IGP01E1000_PHY_PORT_CTRL, &phy_data);
 	if (ret_val)
-		goto out;
+		return ret_val;
 
 	phy_data &= ~IGP01E1000_PSCR_AUTO_MDIX;
 	phy_data &= ~IGP01E1000_PSCR_FORCE_MDI_MDIX;
 
 	ret_val = phy->ops.write_reg(hw, IGP01E1000_PHY_PORT_CTRL, phy_data);
 	if (ret_val)
-		goto out;
+		return ret_val;
 
 	DEBUGOUT1("IGP PSCR: %X\n", phy_data);
 
@@ -1755,7 +1766,7 @@ s32 e1000_phy_force_speed_duplex_igp(struct e1000_hw *hw)
 		ret_val = e1000_phy_has_link_generic(hw, PHY_FORCE_LIMIT,
 						     100000, &link);
 		if (ret_val)
-			goto out;
+			return ret_val;
 
 		if (!link)
 			DEBUGOUT("Link taking longer than expected.\n");
@@ -1763,11 +1774,8 @@ s32 e1000_phy_force_speed_duplex_igp(struct e1000_hw *hw)
 		/* Try once more */
 		ret_val = e1000_phy_has_link_generic(hw, PHY_FORCE_LIMIT,
 						     100000, &link);
-		if (ret_val)
-			goto out;
 	}
 
-out:
 	return ret_val;
 }
 
@@ -1790,35 +1798,39 @@ s32 e1000_phy_force_speed_duplex_m88(struct e1000_hw *hw)
 
 	DEBUGFUNC("e1000_phy_force_speed_duplex_m88");
 
-	/*
-	 * Clear Auto-Crossover to force MDI manually.  M88E1000 requires MDI
-	 * forced whenever speed and duplex are forced.
-	 */
-	ret_val = phy->ops.read_reg(hw, M88E1000_PHY_SPEC_CTRL, &phy_data);
-	if (ret_val)
-		goto out;
+	/* I210 and I211 devices support Auto-Crossover in forced operation. */
+	if (phy->type != e1000_phy_i210) {
+		/* Clear Auto-Crossover to force MDI manually.  M88E1000
+		 * requires MDI forced whenever speed and duplex are forced.
+		 */
+		ret_val = phy->ops.read_reg(hw, M88E1000_PHY_SPEC_CTRL,
+					    &phy_data);
+		if (ret_val)
+			return ret_val;
 
-	phy_data &= ~M88E1000_PSCR_AUTO_X_MODE;
-	ret_val = phy->ops.write_reg(hw, M88E1000_PHY_SPEC_CTRL, phy_data);
-	if (ret_val)
-		goto out;
+		phy_data &= ~M88E1000_PSCR_AUTO_X_MODE;
+		ret_val = phy->ops.write_reg(hw, M88E1000_PHY_SPEC_CTRL,
+					     phy_data);
+		if (ret_val)
+			return ret_val;
+	}
 
 	DEBUGOUT1("M88E1000 PSCR: %X\n", phy_data);
 
 	ret_val = phy->ops.read_reg(hw, PHY_CONTROL, &phy_data);
 	if (ret_val)
-		goto out;
+		return ret_val;
 
 	e1000_phy_force_speed_duplex_setup(hw, &phy_data);
 
 	ret_val = phy->ops.write_reg(hw, PHY_CONTROL, phy_data);
 	if (ret_val)
-		goto out;
+		return ret_val;
 
 	/* Reset the phy to commit changes. */
 	ret_val = hw->phy.ops.commit(hw);
 	if (ret_val)
-		goto out;
+		return ret_val;
 
 	if (phy->autoneg_wait_to_complete) {
 		DEBUGOUT("Waiting for forced speed/duplex link on M88 phy.\n");
@@ -1826,27 +1838,38 @@ s32 e1000_phy_force_speed_duplex_m88(struct e1000_hw *hw)
 		ret_val = e1000_phy_has_link_generic(hw, PHY_FORCE_LIMIT,
 						     100000, &link);
 		if (ret_val)
-			goto out;
+			return ret_val;
 
 		if (!link) {
-			if (hw->phy.type != e1000_phy_m88 ||
-			    hw->phy.id == I347AT4_E_PHY_ID ||
-			    hw->phy.id == M88E1340M_E_PHY_ID ||
-			    hw->phy.id == M88E1112_E_PHY_ID) {
+			bool reset_dsp = TRUE;
+
+			switch (hw->phy.id) {
+			case I347AT4_E_PHY_ID:
+			case M88E1340M_E_PHY_ID:
+			case M88E1112_E_PHY_ID:
+			case I210_I_PHY_ID:
+				reset_dsp = FALSE;
+				break;
+			default:
+				if (hw->phy.type != e1000_phy_m88)
+					reset_dsp = FALSE;
+				break;
+			}
+
+			if (!reset_dsp) {
 				DEBUGOUT("Link taking longer than expected.\n");
 			} else {
-				/*
-				 * We didn't get link.
+				/* We didn't get link.
 				 * Reset the DSP and cross our fingers.
 				 */
 				ret_val = phy->ops.write_reg(hw,
 						M88E1000_PHY_PAGE_SELECT,
 						0x001d);
 				if (ret_val)
-					goto out;
+					return ret_val;
 				ret_val = e1000_phy_reset_dsp_generic(hw);
 				if (ret_val)
-					goto out;
+					return ret_val;
 			}
 		}
 
@@ -1854,41 +1877,41 @@ s32 e1000_phy_force_speed_duplex_m88(struct e1000_hw *hw)
 		ret_val = e1000_phy_has_link_generic(hw, PHY_FORCE_LIMIT,
 						     100000, &link);
 		if (ret_val)
-			goto out;
+			return ret_val;
 	}
 
-	if (hw->phy.type != e1000_phy_m88 ||
-	    hw->phy.id == I347AT4_E_PHY_ID ||
-	    hw->phy.id == M88E1340M_E_PHY_ID ||
-	    hw->phy.id == M88E1112_E_PHY_ID)
-		goto out;
+	if (hw->phy.type != e1000_phy_m88)
+		return E1000_SUCCESS;
 
+	if (hw->phy.id == I347AT4_E_PHY_ID ||
+		hw->phy.id == M88E1340M_E_PHY_ID ||
+		hw->phy.id == M88E1112_E_PHY_ID)
+		return E1000_SUCCESS;
+	if (hw->phy.id == I210_I_PHY_ID)
+		return E1000_SUCCESS;
 	ret_val = phy->ops.read_reg(hw, M88E1000_EXT_PHY_SPEC_CTRL, &phy_data);
 	if (ret_val)
-		goto out;
+		return ret_val;
 
-	/*
-	 * Resetting the phy means we need to re-force TX_CLK in the
+	/* Resetting the phy means we need to re-force TX_CLK in the
 	 * Extended PHY Specific Control Register to 25MHz clock from
 	 * the reset value of 2.5MHz.
 	 */
 	phy_data |= M88E1000_EPSCR_TX_CLK_25;
 	ret_val = phy->ops.write_reg(hw, M88E1000_EXT_PHY_SPEC_CTRL, phy_data);
 	if (ret_val)
-		goto out;
+		return ret_val;
 
-	/*
-	 * In addition, we must re-enable CRS on Tx for both half and full
+	/* In addition, we must re-enable CRS on Tx for both half and full
 	 * duplex.
 	 */
 	ret_val = phy->ops.read_reg(hw, M88E1000_PHY_SPEC_CTRL, &phy_data);
 	if (ret_val)
-		goto out;
+		return ret_val;
 
 	phy_data |= M88E1000_PSCR_ASSERT_CRS_ON_TX;
 	ret_val = phy->ops.write_reg(hw, M88E1000_PHY_SPEC_CTRL, phy_data);
 
-out:
 	return ret_val;
 }
 
@@ -1911,25 +1934,25 @@ s32 e1000_phy_force_speed_duplex_ife(struct e1000_hw *hw)
 
 	ret_val = phy->ops.read_reg(hw, PHY_CONTROL, &data);
 	if (ret_val)
-		goto out;
+		return ret_val;
 
 	e1000_phy_force_speed_duplex_setup(hw, &data);
 
 	ret_val = phy->ops.write_reg(hw, PHY_CONTROL, data);
 	if (ret_val)
-		goto out;
+		return ret_val;
 
 	/* Disable MDI-X support for 10/100 */
 	ret_val = phy->ops.read_reg(hw, IFE_PHY_MDIX_CONTROL, &data);
 	if (ret_val)
-		goto out;
+		return ret_val;
 
 	data &= ~IFE_PMC_AUTO_MDIX;
 	data &= ~IFE_PMC_FORCE_MDIX;
 
 	ret_val = phy->ops.write_reg(hw, IFE_PHY_MDIX_CONTROL, data);
 	if (ret_val)
-		goto out;
+		return ret_val;
 
 	DEBUGOUT1("IFE PMC: %X\n", data);
 
@@ -1941,7 +1964,7 @@ s32 e1000_phy_force_speed_duplex_ife(struct e1000_hw *hw)
 		ret_val = e1000_phy_has_link_generic(hw, PHY_FORCE_LIMIT,
 						     100000, &link);
 		if (ret_val)
-			goto out;
+			return ret_val;
 
 		if (!link)
 			DEBUGOUT("Link taking longer than expected.\n");
@@ -1950,11 +1973,10 @@ s32 e1000_phy_force_speed_duplex_ife(struct e1000_hw *hw)
 		ret_val = e1000_phy_has_link_generic(hw, PHY_FORCE_LIMIT,
 						     100000, &link);
 		if (ret_val)
-			goto out;
+			return ret_val;
 	}
 
-out:
-	return ret_val;
+	return E1000_SUCCESS;
 }
 
 /**
@@ -2005,16 +2027,15 @@ void e1000_phy_force_speed_duplex_setup(struct e1000_hw *hw, u16 *phy_ctrl)
 	if (mac->forced_speed_duplex & E1000_ALL_100_SPEED) {
 		ctrl |= E1000_CTRL_SPD_100;
 		*phy_ctrl |= MII_CR_SPEED_100;
-		*phy_ctrl &= ~(MII_CR_SPEED_1000 | MII_CR_SPEED_10);
+		*phy_ctrl &= ~MII_CR_SPEED_1000;
 		DEBUGOUT("Forcing 100mb\n");
 	} else {
 		ctrl &= ~(E1000_CTRL_SPD_1000 | E1000_CTRL_SPD_100);
-		*phy_ctrl |= MII_CR_SPEED_10;
 		*phy_ctrl &= ~(MII_CR_SPEED_1000 | MII_CR_SPEED_100);
 		DEBUGOUT("Forcing 10mb\n");
 	}
 
-	e1000_config_collision_dist_generic(hw);
+	hw->mac.ops.config_collision_dist(hw);
 
 	E1000_WRITE_REG(hw, E1000_CTRL, ctrl);
 }
@@ -2036,26 +2057,25 @@ void e1000_phy_force_speed_duplex_setup(struct e1000_hw *hw, u16 *phy_ctrl)
 s32 e1000_set_d3_lplu_state_generic(struct e1000_hw *hw, bool active)
 {
 	struct e1000_phy_info *phy = &hw->phy;
-	s32 ret_val = E1000_SUCCESS;
+	s32 ret_val;
 	u16 data;
 
 	DEBUGFUNC("e1000_set_d3_lplu_state_generic");
 
-	if (!(hw->phy.ops.read_reg))
-		goto out;
+	if (!hw->phy.ops.read_reg)
+		return E1000_SUCCESS;
 
 	ret_val = phy->ops.read_reg(hw, IGP02E1000_PHY_POWER_MGMT, &data);
 	if (ret_val)
-		goto out;
+		return ret_val;
 
 	if (!active) {
 		data &= ~IGP02E1000_PM_D3_LPLU;
 		ret_val = phy->ops.write_reg(hw, IGP02E1000_PHY_POWER_MGMT,
 					     data);
 		if (ret_val)
-			goto out;
-		/*
-		 * LPLU and SmartSpeed are mutually exclusive.  LPLU is used
+			return ret_val;
+		/* LPLU and SmartSpeed are mutually exclusive.  LPLU is used
 		 * during Dx states where the power conservation is most
 		 * important.  During driver activity we should enable
 		 * SmartSpeed, so performance is maintained.
@@ -2065,27 +2085,27 @@ s32 e1000_set_d3_lplu_state_generic(struct e1000_hw *hw, bool active)
 						    IGP01E1000_PHY_PORT_CONFIG,
 						    &data);
 			if (ret_val)
-				goto out;
+				return ret_val;
 
 			data |= IGP01E1000_PSCFR_SMART_SPEED;
 			ret_val = phy->ops.write_reg(hw,
 						     IGP01E1000_PHY_PORT_CONFIG,
 						     data);
 			if (ret_val)
-				goto out;
+				return ret_val;
 		} else if (phy->smart_speed == e1000_smart_speed_off) {
 			ret_val = phy->ops.read_reg(hw,
 						    IGP01E1000_PHY_PORT_CONFIG,
 						    &data);
 			if (ret_val)
-				goto out;
+				return ret_val;
 
 			data &= ~IGP01E1000_PSCFR_SMART_SPEED;
 			ret_val = phy->ops.write_reg(hw,
 						     IGP01E1000_PHY_PORT_CONFIG,
 						     data);
 			if (ret_val)
-				goto out;
+				return ret_val;
 		}
 	} else if ((phy->autoneg_advertised == E1000_ALL_SPEED_DUPLEX) ||
 		   (phy->autoneg_advertised == E1000_ALL_NOT_GIG) ||
@@ -2094,20 +2114,19 @@ s32 e1000_set_d3_lplu_state_generic(struct e1000_hw *hw, bool active)
 		ret_val = phy->ops.write_reg(hw, IGP02E1000_PHY_POWER_MGMT,
 					     data);
 		if (ret_val)
-			goto out;
+			return ret_val;
 
 		/* When LPLU is enabled, we should disable SmartSpeed */
 		ret_val = phy->ops.read_reg(hw, IGP01E1000_PHY_PORT_CONFIG,
 					    &data);
 		if (ret_val)
-			goto out;
+			return ret_val;
 
 		data &= ~IGP01E1000_PSCFR_SMART_SPEED;
 		ret_val = phy->ops.write_reg(hw, IGP01E1000_PHY_PORT_CONFIG,
 					     data);
 	}
 
-out:
 	return ret_val;
 }
 
@@ -2128,6 +2147,7 @@ s32 e1000_check_downshift_generic(struct e1000_hw *hw)
 	DEBUGFUNC("e1000_check_downshift_generic");
 
 	switch (phy->type) {
+	case e1000_phy_i210:
 	case e1000_phy_m88:
 	case e1000_phy_gg82563:
 	case e1000_phy_bm:
@@ -2144,16 +2164,14 @@ s32 e1000_check_downshift_generic(struct e1000_hw *hw)
 	default:
 		/* speed downshift not supported */
 		phy->speed_downgraded = FALSE;
-		ret_val = E1000_SUCCESS;
-		goto out;
+		return E1000_SUCCESS;
 	}
 
 	ret_val = phy->ops.read_reg(hw, offset, &phy_data);
 
 	if (!ret_val)
-		phy->speed_downgraded = (phy_data & mask) ? TRUE : FALSE;
+		phy->speed_downgraded = !!(phy_data & mask);
 
-out:
 	return ret_val;
 }
 
@@ -2200,21 +2218,19 @@ s32 e1000_check_polarity_igp(struct e1000_hw *hw)
 
 	DEBUGFUNC("e1000_check_polarity_igp");
 
-	/*
-	 * Polarity is determined based on the speed of
+	/* Polarity is determined based on the speed of
 	 * our connection.
 	 */
 	ret_val = phy->ops.read_reg(hw, IGP01E1000_PHY_PORT_STATUS, &data);
 	if (ret_val)
-		goto out;
+		return ret_val;
 
 	if ((data & IGP01E1000_PSSR_SPEED_MASK) ==
 	    IGP01E1000_PSSR_SPEED_1000MBPS) {
 		offset = IGP01E1000_PHY_PCS_INIT_REG;
 		mask = IGP01E1000_PHY_POLARITY_MASK;
 	} else {
-		/*
-		 * This really only applies to 10Mbps since
+		/* This really only applies to 10Mbps since
 		 * there is no polarity for 100Mbps (always 0).
 		 */
 		offset = IGP01E1000_PHY_PORT_STATUS;
@@ -2228,7 +2244,6 @@ s32 e1000_check_polarity_igp(struct e1000_hw *hw)
 				      ? e1000_rev_polarity_reversed
 				      : e1000_rev_polarity_normal;
 
-out:
 	return ret_val;
 }
 
@@ -2246,8 +2261,7 @@ s32 e1000_check_polarity_ife(struct e1000_hw *hw)
 
 	DEBUGFUNC("e1000_check_polarity_ife");
 
-	/*
-	 * Polarity is determined based on the reversal feature being enabled.
+	/* Polarity is determined based on the reversal feature being enabled.
 	 */
 	if (phy->polarity_correction) {
 		offset = IFE_PHY_EXTENDED_STATUS_CONTROL;
@@ -2268,20 +2282,20 @@ s32 e1000_check_polarity_ife(struct e1000_hw *hw)
 }
 
 /**
- *  e1000_wait_autoneg_generic - Wait for auto-neg completion
+ *  e1000_wait_autoneg - Wait for auto-neg completion
  *  @hw: pointer to the HW structure
  *
  *  Waits for auto-negotiation to complete or for the auto-negotiation time
  *  limit to expire, which ever happens first.
  **/
-s32 e1000_wait_autoneg_generic(struct e1000_hw *hw)
+static s32 e1000_wait_autoneg(struct e1000_hw *hw)
 {
 	s32 ret_val = E1000_SUCCESS;
 	u16 i, phy_status;
 
-	DEBUGFUNC("e1000_wait_autoneg_generic");
+	DEBUGFUNC("e1000_wait_autoneg");
 
-	if (!(hw->phy.ops.read_reg))
+	if (!hw->phy.ops.read_reg)
 		return E1000_SUCCESS;
 
 	/* Break after autoneg completes or PHY_AUTO_NEG_LIMIT expires. */
@@ -2297,8 +2311,7 @@ s32 e1000_wait_autoneg_generic(struct e1000_hw *hw)
 		msec_delay(100);
 	}
 
-	/*
-	 * PHY_AUTO_NEG_TIME expiration doesn't guarantee auto-negotiation
+	/* PHY_AUTO_NEG_TIME expiration doesn't guarantee auto-negotiation
 	 * has completed.
 	 */
 	return ret_val;
@@ -2321,19 +2334,17 @@ s32 e1000_phy_has_link_generic(struct e1000_hw *hw, u32 iterations,
 
 	DEBUGFUNC("e1000_phy_has_link_generic");
 
-	if (!(hw->phy.ops.read_reg))
+	if (!hw->phy.ops.read_reg)
 		return E1000_SUCCESS;
 
 	for (i = 0; i < iterations; i++) {
-		/*
-		 * Some PHYs require the PHY_STATUS register to be read
+		/* Some PHYs require the PHY_STATUS register to be read
 		 * twice due to the link bit being sticky.  No harm doing
 		 * it across the board.
 		 */
 		ret_val = hw->phy.ops.read_reg(hw, PHY_STATUS, &phy_status);
 		if (ret_val)
-			/*
-			 * If the first read fails, another entity may have
+			/* If the first read fails, another entity may have
 			 * ownership of the resources, wait and try again to
 			 * see if they have relinquished the resources yet.
 			 */
@@ -2349,7 +2360,7 @@ s32 e1000_phy_has_link_generic(struct e1000_hw *hw, u32 iterations,
 			usec_delay(usec_interval);
 	}
 
-	*success = (i < iterations) ? TRUE : FALSE;
+	*success = (i < iterations);
 
 	return ret_val;
 }
@@ -2379,55 +2390,75 @@ s32 e1000_get_cable_length_m88(struct e1000_hw *hw)
 
 	ret_val = phy->ops.read_reg(hw, M88E1000_PHY_SPEC_STATUS, &phy_data);
 	if (ret_val)
-		goto out;
+		return ret_val;
 
 	index = (phy_data & M88E1000_PSSR_CABLE_LENGTH) >>
 		M88E1000_PSSR_CABLE_LENGTH_SHIFT;
-	if (index >= M88E1000_CABLE_LENGTH_TABLE_SIZE - 1) {
-		ret_val = -E1000_ERR_PHY;
-		goto out;
-	}
+
+	if (index >= M88E1000_CABLE_LENGTH_TABLE_SIZE - 1)
+		return -E1000_ERR_PHY;
 
 	phy->min_cable_length = e1000_m88_cable_length_table[index];
 	phy->max_cable_length = e1000_m88_cable_length_table[index + 1];
 
 	phy->cable_length = (phy->min_cable_length + phy->max_cable_length) / 2;
 
-out:
-	return ret_val;
+	return E1000_SUCCESS;
 }
 
 s32 e1000_get_cable_length_m88_gen2(struct e1000_hw *hw)
 {
 	struct e1000_phy_info *phy = &hw->phy;
 	s32 ret_val;
-	u16 phy_data, phy_data2, index, default_page, is_cm;
+	u16 phy_data, phy_data2, is_cm;
+	u16 index, default_page;
 
 	DEBUGFUNC("e1000_get_cable_length_m88_gen2");
 
 	switch (hw->phy.id) {
+	case I210_I_PHY_ID:
+		/* Get cable length from PHY Cable Diagnostics Control Reg */
+		ret_val = phy->ops.read_reg(hw, (0x7 << GS40G_PAGE_SHIFT) +
+					    (I347AT4_PCDL + phy->addr),
+					    &phy_data);
+		if (ret_val)
+			return ret_val;
+
+		/* Check if the unit of cable length is meters or cm */
+		ret_val = phy->ops.read_reg(hw, (0x7 << GS40G_PAGE_SHIFT) +
+					    I347AT4_PCDC, &phy_data2);
+		if (ret_val)
+			return ret_val;
+
+		is_cm = !(phy_data2 & I347AT4_PCDC_CABLE_LENGTH_UNIT);
+
+		/* Populate the phy structure with cable length in meters */
+		phy->min_cable_length = phy_data / (is_cm ? 100 : 1);
+		phy->max_cable_length = phy_data / (is_cm ? 100 : 1);
+		phy->cable_length = phy_data / (is_cm ? 100 : 1);
+		break;
 	case M88E1340M_E_PHY_ID:
 	case I347AT4_E_PHY_ID:
 		/* Remember the original page select and set it to 7 */
 		ret_val = phy->ops.read_reg(hw, I347AT4_PAGE_SELECT,
 					    &default_page);
 		if (ret_val)
-			goto out;
+			return ret_val;
 
 		ret_val = phy->ops.write_reg(hw, I347AT4_PAGE_SELECT, 0x07);
 		if (ret_val)
-			goto out;
+			return ret_val;
 
 		/* Get cable length from PHY Cable Diagnostics Control Reg */
 		ret_val = phy->ops.read_reg(hw, (I347AT4_PCDL + phy->addr),
 					    &phy_data);
 		if (ret_val)
-			goto out;
+			return ret_val;
 
 		/* Check if the unit of cable length is meters or cm */
 		ret_val = phy->ops.read_reg(hw, I347AT4_PCDC, &phy_data2);
 		if (ret_val)
-			goto out;
+			return ret_val;
 
 		is_cm = !(phy_data2 & I347AT4_PCDC_CABLE_LENGTH_UNIT);
 
@@ -2440,30 +2471,30 @@ s32 e1000_get_cable_length_m88_gen2(struct e1000_hw *hw)
 		ret_val = phy->ops.write_reg(hw, I347AT4_PAGE_SELECT,
 					     default_page);
 		if (ret_val)
-			goto out;
+			return ret_val;
 		break;
+
 	case M88E1112_E_PHY_ID:
 		/* Remember the original page select and set it to 5 */
 		ret_val = phy->ops.read_reg(hw, I347AT4_PAGE_SELECT,
 					    &default_page);
 		if (ret_val)
-			goto out;
+			return ret_val;
 
 		ret_val = phy->ops.write_reg(hw, I347AT4_PAGE_SELECT, 0x05);
 		if (ret_val)
-			goto out;
+			return ret_val;
 
 		ret_val = phy->ops.read_reg(hw, M88E1112_VCT_DSP_DISTANCE,
 					    &phy_data);
 		if (ret_val)
-			goto out;
+			return ret_val;
 
 		index = (phy_data & M88E1000_PSSR_CABLE_LENGTH) >>
 			M88E1000_PSSR_CABLE_LENGTH_SHIFT;
-		if (index >= M88E1000_CABLE_LENGTH_TABLE_SIZE - 1) {
-			ret_val = -E1000_ERR_PHY;
-			goto out;
-		}
+
+		if (index >= M88E1000_CABLE_LENGTH_TABLE_SIZE - 1)
+			return -E1000_ERR_PHY;
 
 		phy->min_cable_length = e1000_m88_cable_length_table[index];
 		phy->max_cable_length = e1000_m88_cable_length_table[index + 1];
@@ -2475,15 +2506,13 @@ s32 e1000_get_cable_length_m88_gen2(struct e1000_hw *hw)
 		ret_val = phy->ops.write_reg(hw, I347AT4_PAGE_SELECT,
 					     default_page);
 		if (ret_val)
-			goto out;
+			return ret_val;
 
 		break;
 	default:
-		ret_val = -E1000_ERR_PHY;
-		goto out;
+		return -E1000_ERR_PHY;
 	}
 
-out:
 	return ret_val;
 }
 
@@ -2501,7 +2530,7 @@ out:
 s32 e1000_get_cable_length_igp_2(struct e1000_hw *hw)
 {
 	struct e1000_phy_info *phy = &hw->phy;
-	s32 ret_val = E1000_SUCCESS;
+	s32 ret_val;
 	u16 phy_data, i, agc_value = 0;
 	u16 cur_agc_index, max_agc_index = 0;
 	u16 min_agc_index = IGP02E1000_CABLE_LENGTH_TABLE_SIZE - 1;
@@ -2518,10 +2547,9 @@ s32 e1000_get_cable_length_igp_2(struct e1000_hw *hw)
 	for (i = 0; i < IGP02E1000_PHY_CHANNEL_NUM; i++) {
 		ret_val = phy->ops.read_reg(hw, agc_reg_array[i], &phy_data);
 		if (ret_val)
-			goto out;
+			return ret_val;
 
-		/*
-		 * Getting bits 15:9, which represent the combination of
+		/* Getting bits 15:9, which represent the combination of
 		 * coarse and fine gain values.  The result is a number
 		 * that can be put into the lookup table to obtain the
 		 * approximate cable length.
@@ -2531,10 +2559,8 @@ s32 e1000_get_cable_length_igp_2(struct e1000_hw *hw)
 
 		/* Array index bound check. */
 		if ((cur_agc_index >= IGP02E1000_CABLE_LENGTH_TABLE_SIZE) ||
-		    (cur_agc_index == 0)) {
-			ret_val = -E1000_ERR_PHY;
-			goto out;
-		}
+		    (cur_agc_index == 0))
+			return -E1000_ERR_PHY;
 
 		/* Remove min & max AGC values from calculation. */
 		if (e1000_igp_2_cable_length_table[min_agc_index] >
@@ -2558,8 +2584,7 @@ s32 e1000_get_cable_length_igp_2(struct e1000_hw *hw)
 
 	phy->cable_length = (phy->min_cable_length + phy->max_cable_length) / 2;
 
-out:
-	return ret_val;
+	return E1000_SUCCESS;
 }
 
 /**
@@ -2583,45 +2608,43 @@ s32 e1000_get_phy_info_m88(struct e1000_hw *hw)
 
 	if (phy->media_type != e1000_media_type_copper) {
 		DEBUGOUT("Phy info is only valid for copper media\n");
-		ret_val = -E1000_ERR_CONFIG;
-		goto out;
+		return -E1000_ERR_CONFIG;
 	}
 
 	ret_val = e1000_phy_has_link_generic(hw, 1, 0, &link);
 	if (ret_val)
-		goto out;
+		return ret_val;
 
 	if (!link) {
 		DEBUGOUT("Phy info is only valid if link is up\n");
-		ret_val = -E1000_ERR_CONFIG;
-		goto out;
+		return -E1000_ERR_CONFIG;
 	}
 
 	ret_val = phy->ops.read_reg(hw, M88E1000_PHY_SPEC_CTRL, &phy_data);
 	if (ret_val)
-		goto out;
+		return ret_val;
 
-	phy->polarity_correction = (phy_data & M88E1000_PSCR_POLARITY_REVERSAL)
-				   ? TRUE : FALSE;
+	phy->polarity_correction = !!(phy_data &
+				      M88E1000_PSCR_POLARITY_REVERSAL);
 
 	ret_val = e1000_check_polarity_m88(hw);
 	if (ret_val)
-		goto out;
+		return ret_val;
 
 	ret_val = phy->ops.read_reg(hw, M88E1000_PHY_SPEC_STATUS, &phy_data);
 	if (ret_val)
-		goto out;
+		return ret_val;
 
-	phy->is_mdix = (phy_data & M88E1000_PSSR_MDIX) ? TRUE : FALSE;
+	phy->is_mdix = !!(phy_data & M88E1000_PSSR_MDIX);
 
 	if ((phy_data & M88E1000_PSSR_SPEED) == M88E1000_PSSR_1000MBS) {
 		ret_val = hw->phy.ops.get_cable_length(hw);
 		if (ret_val)
-			goto out;
+			return ret_val;
 
 		ret_val = phy->ops.read_reg(hw, PHY_1000T_STATUS, &phy_data);
 		if (ret_val)
-			goto out;
+			return ret_val;
 
 		phy->local_rx = (phy_data & SR_1000T_LOCAL_RX_STATUS)
 				? e1000_1000t_rx_status_ok
@@ -2637,7 +2660,6 @@ s32 e1000_get_phy_info_m88(struct e1000_hw *hw)
 		phy->remote_rx = e1000_1000t_rx_status_undefined;
 	}
 
-out:
 	return ret_val;
 }
 
@@ -2661,35 +2683,34 @@ s32 e1000_get_phy_info_igp(struct e1000_hw *hw)
 
 	ret_val = e1000_phy_has_link_generic(hw, 1, 0, &link);
 	if (ret_val)
-		goto out;
+		return ret_val;
 
 	if (!link) {
 		DEBUGOUT("Phy info is only valid if link is up\n");
-		ret_val = -E1000_ERR_CONFIG;
-		goto out;
+		return -E1000_ERR_CONFIG;
 	}
 
 	phy->polarity_correction = TRUE;
 
 	ret_val = e1000_check_polarity_igp(hw);
 	if (ret_val)
-		goto out;
+		return ret_val;
 
 	ret_val = phy->ops.read_reg(hw, IGP01E1000_PHY_PORT_STATUS, &data);
 	if (ret_val)
-		goto out;
+		return ret_val;
 
-	phy->is_mdix = (data & IGP01E1000_PSSR_MDIX) ? TRUE : FALSE;
+	phy->is_mdix = !!(data & IGP01E1000_PSSR_MDIX);
 
 	if ((data & IGP01E1000_PSSR_SPEED_MASK) ==
 	    IGP01E1000_PSSR_SPEED_1000MBPS) {
 		ret_val = phy->ops.get_cable_length(hw);
 		if (ret_val)
-			goto out;
+			return ret_val;
 
 		ret_val = phy->ops.read_reg(hw, PHY_1000T_STATUS, &data);
 		if (ret_val)
-			goto out;
+			return ret_val;
 
 		phy->local_rx = (data & SR_1000T_LOCAL_RX_STATUS)
 				? e1000_1000t_rx_status_ok
@@ -2704,7 +2725,6 @@ s32 e1000_get_phy_info_igp(struct e1000_hw *hw)
 		phy->remote_rx = e1000_1000t_rx_status_undefined;
 	}
 
-out:
 	return ret_val;
 }
 
@@ -2725,24 +2745,22 @@ s32 e1000_get_phy_info_ife(struct e1000_hw *hw)
 
 	ret_val = e1000_phy_has_link_generic(hw, 1, 0, &link);
 	if (ret_val)
-		goto out;
+		return ret_val;
 
 	if (!link) {
 		DEBUGOUT("Phy info is only valid if link is up\n");
-		ret_val = -E1000_ERR_CONFIG;
-		goto out;
+		return -E1000_ERR_CONFIG;
 	}
 
 	ret_val = phy->ops.read_reg(hw, IFE_PHY_SPECIAL_CONTROL, &data);
 	if (ret_val)
-		goto out;
-	phy->polarity_correction = (data & IFE_PSC_AUTO_POLARITY_DISABLE)
-				   ? FALSE : TRUE;
+		return ret_val;
+	phy->polarity_correction = !(data & IFE_PSC_AUTO_POLARITY_DISABLE);
 
 	if (phy->polarity_correction) {
 		ret_val = e1000_check_polarity_ife(hw);
 		if (ret_val)
-			goto out;
+			return ret_val;
 	} else {
 		/* Polarity is forced */
 		phy->cable_polarity = (data & IFE_PSC_FORCE_POLARITY)
@@ -2752,17 +2770,16 @@ s32 e1000_get_phy_info_ife(struct e1000_hw *hw)
 
 	ret_val = phy->ops.read_reg(hw, IFE_PHY_MDIX_CONTROL, &data);
 	if (ret_val)
-		goto out;
+		return ret_val;
 
-	phy->is_mdix = (data & IFE_PMC_MDIX_STATUS) ? TRUE : FALSE;
+	phy->is_mdix = !!(data & IFE_PMC_MDIX_STATUS);
 
 	/* The following parameters are undefined for 10/100 operation. */
 	phy->cable_length = E1000_CABLE_LENGTH_UNDEFINED;
 	phy->local_rx = e1000_1000t_rx_status_undefined;
 	phy->remote_rx = e1000_1000t_rx_status_undefined;
 
-out:
-	return ret_val;
+	return E1000_SUCCESS;
 }
 
 /**
@@ -2774,26 +2791,25 @@ out:
  **/
 s32 e1000_phy_sw_reset_generic(struct e1000_hw *hw)
 {
-	s32 ret_val = E1000_SUCCESS;
+	s32 ret_val;
 	u16 phy_ctrl;
 
 	DEBUGFUNC("e1000_phy_sw_reset_generic");
 
-	if (!(hw->phy.ops.read_reg))
-		goto out;
+	if (!hw->phy.ops.read_reg)
+		return E1000_SUCCESS;
 
 	ret_val = hw->phy.ops.read_reg(hw, PHY_CONTROL, &phy_ctrl);
 	if (ret_val)
-		goto out;
+		return ret_val;
 
 	phy_ctrl |= MII_CR_RESET;
 	ret_val = hw->phy.ops.write_reg(hw, PHY_CONTROL, phy_ctrl);
 	if (ret_val)
-		goto out;
+		return ret_val;
 
 	usec_delay(1);
 
-out:
 	return ret_val;
 }
 
@@ -2809,20 +2825,20 @@ out:
 s32 e1000_phy_hw_reset_generic(struct e1000_hw *hw)
 {
 	struct e1000_phy_info *phy = &hw->phy;
-	s32 ret_val = E1000_SUCCESS;
+	s32 ret_val;
 	u32 ctrl;
 
 	DEBUGFUNC("e1000_phy_hw_reset_generic");
 
-	ret_val = phy->ops.check_reset_block(hw);
-	if (ret_val) {
-		ret_val = E1000_SUCCESS;
-		goto out;
+	if (phy->ops.check_reset_block) {
+		ret_val = phy->ops.check_reset_block(hw);
+		if (ret_val)
+			return E1000_SUCCESS;
 	}
 
 	ret_val = phy->ops.acquire(hw);
 	if (ret_val)
-		goto out;
+		return ret_val;
 
 	ctrl = E1000_READ_REG(hw, E1000_CTRL);
 	E1000_WRITE_REG(hw, E1000_CTRL, ctrl | E1000_CTRL_PHY_RST);
@@ -2837,10 +2853,7 @@ s32 e1000_phy_hw_reset_generic(struct e1000_hw *hw)
 
 	phy->ops.release(hw);
 
-	ret_val = phy->ops.get_cfg_done(hw);
-
-out:
-	return ret_val;
+	return phy->ops.get_cfg_done(hw);
 }
 
 /**
@@ -2922,15 +2935,13 @@ s32 e1000_phy_init_script_igp3(struct e1000_hw *hw)
 	hw->phy.ops.write_reg(hw, 0x1796, 0x0008);
 	/* Change cg_icount + enable integbp for channels BCD */
 	hw->phy.ops.write_reg(hw, 0x1798, 0xD008);
-	/*
-	 * Change cg_icount + enable integbp + change prop_factor_master
+	/* Change cg_icount + enable integbp + change prop_factor_master
 	 * to 8 for channel A
 	 */
 	hw->phy.ops.write_reg(hw, 0x1898, 0xD918);
 	/* Disable AHT in Slave mode on channel A */
 	hw->phy.ops.write_reg(hw, 0x187A, 0x0800);
-	/*
-	 * Enable LPLU and disable AN to 1000 in non-D0a states,
+	/* Enable LPLU and disable AN to 1000 in non-D0a states,
 	 * Enable SPD+B2B
 	 */
 	hw->phy.ops.write_reg(hw, 0x0019, 0x008D);
@@ -2991,9 +3002,15 @@ enum e1000_phy_type e1000_get_phy_type_from_id(u32 phy_id)
 	case I82579_E_PHY_ID:
 		phy_type = e1000_phy_82579;
 		break;
+	case I217_E_PHY_ID:
+		phy_type = e1000_phy_i217;
+		break;
 	case I82580_I_PHY_ID:
 		phy_type = e1000_phy_82580;
 		break;
+	case I210_I_PHY_ID:
+		phy_type = e1000_phy_i210;
+		break;
 	default:
 		phy_type = e1000_phy_unknown;
 		break;
@@ -3011,7 +3028,6 @@ enum e1000_phy_type e1000_get_phy_type_from_id(u32 phy_id)
  **/
 s32 e1000_determine_phy_address(struct e1000_hw *hw)
 {
-	s32 ret_val = -E1000_ERR_PHY_TYPE;
 	u32 phy_addr = 0;
 	u32 i;
 	enum e1000_phy_type phy_type = e1000_phy_unknown;
@@ -3026,21 +3042,18 @@ s32 e1000_determine_phy_address(struct e1000_hw *hw)
 			e1000_get_phy_id(hw);
 			phy_type = e1000_get_phy_type_from_id(hw->phy.id);
 
-			/*
-			 * If phy_type is valid, break - we found our
+			/* If phy_type is valid, break - we found our
 			 * PHY address
 			 */
-			if (phy_type != e1000_phy_unknown) {
-				ret_val = E1000_SUCCESS;
-				goto out;
-			}
+			if (phy_type != e1000_phy_unknown)
+				return E1000_SUCCESS;
+
 			msec_delay(1);
 			i++;
 		} while (i < 10);
 	}
 
-out:
-	return ret_val;
+	return -E1000_ERR_PHY_TYPE;
 }
 
 /**
@@ -3083,7 +3096,7 @@ s32 e1000_write_phy_reg_bm(struct e1000_hw *hw, u32 offset, u16 data)
 	if (page == BM_WUC_PAGE) {
 		ret_val = e1000_access_phy_wakeup_reg_bm(hw, offset, &data,
 							 FALSE, FALSE);
-		goto out;
+		goto release;
 	}
 
 	hw->phy.addr = e1000_get_phy_addr_for_bm_page(page, offset);
@@ -3091,8 +3104,7 @@ s32 e1000_write_phy_reg_bm(struct e1000_hw *hw, u32 offset, u16 data)
 	if (offset > MAX_PHY_MULTI_PAGE_REG) {
 		u32 page_shift, page_select;
 
-		/*
-		 * Page select is register 31 for phy address 1 and 22 for
+		/* Page select is register 31 for phy address 1 and 22 for
 		 * phy address 2 and 3. Page select is shifted only for
 		 * phy address 1.
 		 */
@@ -3108,13 +3120,13 @@ s32 e1000_write_phy_reg_bm(struct e1000_hw *hw, u32 offset, u16 data)
 		ret_val = e1000_write_phy_reg_mdic(hw, page_select,
 						   (page << page_shift));
 		if (ret_val)
-			goto out;
+			goto release;
 	}
 
 	ret_val = e1000_write_phy_reg_mdic(hw, MAX_PHY_REG_ADDRESS & offset,
 					   data);
 
-out:
+release:
 	hw->phy.ops.release(hw);
 	return ret_val;
 }
@@ -3144,7 +3156,7 @@ s32 e1000_read_phy_reg_bm(struct e1000_hw *hw, u32 offset, u16 *data)
 	if (page == BM_WUC_PAGE) {
 		ret_val = e1000_access_phy_wakeup_reg_bm(hw, offset, data,
 							 TRUE, FALSE);
-		goto out;
+		goto release;
 	}
 
 	hw->phy.addr = e1000_get_phy_addr_for_bm_page(page, offset);
@@ -3152,8 +3164,7 @@ s32 e1000_read_phy_reg_bm(struct e1000_hw *hw, u32 offset, u16 *data)
 	if (offset > MAX_PHY_MULTI_PAGE_REG) {
 		u32 page_shift, page_select;
 
-		/*
-		 * Page select is register 31 for phy address 1 and 22 for
+		/* Page select is register 31 for phy address 1 and 22 for
 		 * phy address 2 and 3. Page select is shifted only for
 		 * phy address 1.
 		 */
@@ -3169,12 +3180,12 @@ s32 e1000_read_phy_reg_bm(struct e1000_hw *hw, u32 offset, u16 *data)
 		ret_val = e1000_write_phy_reg_mdic(hw, page_select,
 						   (page << page_shift));
 		if (ret_val)
-			goto out;
+			goto release;
 	}
 
 	ret_val = e1000_read_phy_reg_mdic(hw, MAX_PHY_REG_ADDRESS & offset,
 					  data);
-out:
+release:
 	hw->phy.ops.release(hw);
 	return ret_val;
 }
@@ -3204,24 +3215,23 @@ s32 e1000_read_phy_reg_bm2(struct e1000_hw *hw, u32 offset, u16 *data)
 	if (page == BM_WUC_PAGE) {
 		ret_val = e1000_access_phy_wakeup_reg_bm(hw, offset, data,
 							 TRUE, FALSE);
-		goto out;
+		goto release;
 	}
 
 	hw->phy.addr = 1;
 
 	if (offset > MAX_PHY_MULTI_PAGE_REG) {
-
 		/* Page is shifted left, PHY expects (page x 32) */
 		ret_val = e1000_write_phy_reg_mdic(hw, BM_PHY_PAGE_SELECT,
 						   page);
 
 		if (ret_val)
-			goto out;
+			goto release;
 	}
 
 	ret_val = e1000_read_phy_reg_mdic(hw, MAX_PHY_REG_ADDRESS & offset,
 					  data);
-out:
+release:
 	hw->phy.ops.release(hw);
 	return ret_val;
 }
@@ -3250,7 +3260,7 @@ s32 e1000_write_phy_reg_bm2(struct e1000_hw *hw, u32 offset, u16 data)
 	if (page == BM_WUC_PAGE) {
 		ret_val = e1000_access_phy_wakeup_reg_bm(hw, offset, &data,
 							 FALSE, FALSE);
-		goto out;
+		goto release;
 	}
 
 	hw->phy.addr = 1;
@@ -3261,13 +3271,13 @@ s32 e1000_write_phy_reg_bm2(struct e1000_hw *hw, u32 offset, u16 data)
 						   page);
 
 		if (ret_val)
-			goto out;
+			goto release;
 	}
 
 	ret_val = e1000_write_phy_reg_mdic(hw, MAX_PHY_REG_ADDRESS & offset,
 					   data);
 
-out:
+release:
 	hw->phy.ops.release(hw);
 	return ret_val;
 }
@@ -3287,10 +3297,8 @@ s32 e1000_enable_phy_wakeup_reg_access_bm(struct e1000_hw *hw, u16 *phy_reg)
 
 	DEBUGFUNC("e1000_enable_phy_wakeup_reg_access_bm");
 
-	if (!phy_reg) {
-		ret_val = -E1000_ERR_PARAM;
-		goto out;
-	}
+	if (!phy_reg)
+		return -E1000_ERR_PARAM;
 
 	/* All page select, port ctrl and wakeup registers use phy address 1 */
 	hw->phy.addr = 1;
@@ -3299,18 +3307,17 @@ s32 e1000_enable_phy_wakeup_reg_access_bm(struct e1000_hw *hw, u16 *phy_reg)
 	ret_val = e1000_set_page_igp(hw, (BM_PORT_CTRL_PAGE << IGP_PAGE_SHIFT));
 	if (ret_val) {
 		DEBUGOUT("Could not set Port Control page\n");
-		goto out;
+		return ret_val;
 	}
 
 	ret_val = e1000_read_phy_reg_mdic(hw, BM_WUC_ENABLE_REG, phy_reg);
 	if (ret_val) {
 		DEBUGOUT2("Could not read PHY register %d.%d\n",
 			  BM_PORT_CTRL_PAGE, BM_WUC_ENABLE_REG);
-		goto out;
+		return ret_val;
 	}
 
-	/*
-	 * Enable both PHY wakeup mode and Wakeup register page writes.
+	/* Enable both PHY wakeup mode and Wakeup register page writes.
 	 * Prevent a power state change by disabling ME and Host PHY wakeup.
 	 */
 	temp = *phy_reg;
@@ -3321,15 +3328,13 @@ s32 e1000_enable_phy_wakeup_reg_access_bm(struct e1000_hw *hw, u16 *phy_reg)
 	if (ret_val) {
 		DEBUGOUT2("Could not write PHY register %d.%d\n",
 			  BM_PORT_CTRL_PAGE, BM_WUC_ENABLE_REG);
-		goto out;
+		return ret_val;
 	}
 
-	/* Select Host Wakeup Registers page */
-	ret_val = e1000_set_page_igp(hw, (BM_WUC_PAGE << IGP_PAGE_SHIFT));
-
-	/* caller now able to write registers on the Wakeup registers page */
-out:
-	return ret_val;
+	/* Select Host Wakeup Registers page - caller now able to write
+	 * registers on the Wakeup registers page
+	 */
+	return e1000_set_page_igp(hw, (BM_WUC_PAGE << IGP_PAGE_SHIFT));
 }
 
 /**
@@ -3345,7 +3350,7 @@ out:
  **/
 s32 e1000_disable_phy_wakeup_reg_access_bm(struct e1000_hw *hw, u16 *phy_reg)
 {
-	s32 ret_val = E1000_SUCCESS;
+	s32 ret_val;
 
 	DEBUGFUNC("e1000_disable_phy_wakeup_reg_access_bm");
 
@@ -3356,7 +3361,7 @@ s32 e1000_disable_phy_wakeup_reg_access_bm(struct e1000_hw *hw, u16 *phy_reg)
 	ret_val = e1000_set_page_igp(hw, (BM_PORT_CTRL_PAGE << IGP_PAGE_SHIFT));
 	if (ret_val) {
 		DEBUGOUT("Could not set Port Control page\n");
-		goto out;
+		return ret_val;
 	}
 
 	/* Restore 769.17 to its original value */
@@ -3364,7 +3369,7 @@ s32 e1000_disable_phy_wakeup_reg_access_bm(struct e1000_hw *hw, u16 *phy_reg)
 	if (ret_val)
 		DEBUGOUT2("Could not restore PHY register %d.%d\n",
 			  BM_PORT_CTRL_PAGE, BM_WUC_ENABLE_REG);
-out:
+
 	return ret_val;
 }
 
@@ -3398,6 +3403,7 @@ static s32 e1000_access_phy_wakeup_reg_bm(struct e1000_hw *hw, u32 offset,
 {
 	s32 ret_val;
 	u16 reg = BM_PHY_REG_NUM(offset);
+	u16 page = BM_PHY_REG_PAGE(offset);
 	u16 phy_reg = 0;
 
 	DEBUGFUNC("e1000_access_phy_wakeup_reg_bm");
@@ -3413,7 +3419,7 @@ static s32 e1000_access_phy_wakeup_reg_bm(struct e1000_hw *hw, u32 offset,
 		ret_val = e1000_enable_phy_wakeup_reg_access_bm(hw, &phy_reg);
 		if (ret_val) {
 			DEBUGOUT("Could not enable PHY wakeup reg access\n");
-			goto out;
+			return ret_val;
 		}
 	}
 
@@ -3423,7 +3429,7 @@ static s32 e1000_access_phy_wakeup_reg_bm(struct e1000_hw *hw, u32 offset,
 	ret_val = e1000_write_phy_reg_mdic(hw, BM_WUC_ADDRESS_OPCODE, reg);
 	if (ret_val) {
 		DEBUGOUT1("Could not write address opcode to page %d\n", page);
-		goto out;
+		return ret_val;
 	}
 
 	if (read) {
@@ -3438,13 +3444,12 @@ static s32 e1000_access_phy_wakeup_reg_bm(struct e1000_hw *hw, u32 offset,
 
 	if (ret_val) {
 		DEBUGOUT2("Could not access PHY reg %d.%d\n", page, reg);
-		goto out;
+		return ret_val;
 	}
 
 	if (!page_set)
 		ret_val = e1000_disable_phy_wakeup_reg_access_bm(hw, &phy_reg);
 
-out:
 	return ret_val;
 }
 
@@ -3459,10 +3464,16 @@ out:
 void e1000_power_up_phy_copper(struct e1000_hw *hw)
 {
 	u16 mii_reg = 0;
+	u16 power_reg = 0;
 
 	/* The PHY will retain its settings across a power down/up cycle */
 	hw->phy.ops.read_reg(hw, PHY_CONTROL, &mii_reg);
 	mii_reg &= ~MII_CR_POWER_DOWN;
+	if (hw->phy.type == e1000_phy_i210) {
+		hw->phy.ops.read_reg(hw, GS40G_COPPER_SPEC, &power_reg);
+		power_reg &= ~GS40G_CS_POWER_DOWN;
+		hw->phy.ops.write_reg(hw, GS40G_COPPER_SPEC, power_reg);
+	}
 	hw->phy.ops.write_reg(hw, PHY_CONTROL, mii_reg);
 }
 
@@ -3477,10 +3488,17 @@ void e1000_power_up_phy_copper(struct e1000_hw *hw)
 void e1000_power_down_phy_copper(struct e1000_hw *hw)
 {
 	u16 mii_reg = 0;
+	u16 power_reg = 0;
 
 	/* The PHY will retain its settings across a power down/up cycle */
 	hw->phy.ops.read_reg(hw, PHY_CONTROL, &mii_reg);
 	mii_reg |= MII_CR_POWER_DOWN;
+	/* i210 Phy requires an additional bit for power up/down */
+	if (hw->phy.type == e1000_phy_i210) {
+		hw->phy.ops.read_reg(hw, GS40G_COPPER_SPEC, &power_reg);
+		power_reg |= GS40G_CS_POWER_DOWN;
+		hw->phy.ops.write_reg(hw, GS40G_COPPER_SPEC, power_reg);
+	}
 	hw->phy.ops.write_reg(hw, PHY_CONTROL, mii_reg);
 	msec_delay(1);
 }
@@ -3639,14 +3657,13 @@ static s32 __e1000_write_phy_reg_hv(struct e1000_hw *hw, u32 offset, u16 data,
 		if (page == HV_INTC_FC_PAGE_START)
 			page = 0;
 
-		/*
-		 * Workaround MDIO accesses being disabled after entering IEEE
+		/* Workaround MDIO accesses being disabled after entering IEEE
 		 * Power Down (when bit 11 of the PHY Control register is set)
 		 */
 		if ((hw->phy.type == e1000_phy_82578) &&
 		    (hw->phy.revision >= 1) &&
 		    (hw->phy.addr == 2) &&
-		    ((MAX_PHY_REG_ADDRESS & reg) == 0) &&
+		    !(MAX_PHY_REG_ADDRESS & reg) &&
 		    (data & (1 << 11))) {
 			u16 data2 = 0x7EFF;
 			ret_val = e1000_access_phy_debug_regs_hv(hw,
@@ -3753,8 +3770,8 @@ static s32 e1000_access_phy_debug_regs_hv(struct e1000_hw *hw, u32 offset,
 					  u16 *data, bool read)
 {
 	s32 ret_val;
-	u32 addr_reg = 0;
-	u32 data_reg = 0;
+	u32 addr_reg;
+	u32 data_reg;
 
 	DEBUGFUNC("e1000_access_phy_debug_regs_hv");
 
@@ -3770,7 +3787,7 @@ static s32 e1000_access_phy_debug_regs_hv(struct e1000_hw *hw, u32 offset,
 	ret_val = e1000_write_phy_reg_mdic(hw, addr_reg, (u16)offset & 0x3F);
 	if (ret_val) {
 		DEBUGOUT("Could not write the Address Offset port register\n");
-		goto out;
+		return ret_val;
 	}
 
 	/* Read or write the data value next */
@@ -3779,12 +3796,9 @@ static s32 e1000_access_phy_debug_regs_hv(struct e1000_hw *hw, u32 offset,
 	else
 		ret_val = e1000_write_phy_reg_mdic(hw, data_reg, *data);
 
-	if (ret_val) {
+	if (ret_val)
 		DEBUGOUT("Could not access the Data port register\n");
-		goto out;
-	}
 
-out:
 	return ret_val;
 }
 
@@ -3807,39 +3821,36 @@ s32 e1000_link_stall_workaround_hv(struct e1000_hw *hw)
 	DEBUGFUNC("e1000_link_stall_workaround_hv");
 
 	if (hw->phy.type != e1000_phy_82578)
-		goto out;
+		return E1000_SUCCESS;
 
 	/* Do not apply workaround if in PHY loopback bit 14 set */
 	hw->phy.ops.read_reg(hw, PHY_CONTROL, &data);
 	if (data & PHY_CONTROL_LB)
-		goto out;
+		return E1000_SUCCESS;
 
 	/* check if link is up and at 1Gbps */
 	ret_val = hw->phy.ops.read_reg(hw, BM_CS_STATUS, &data);
 	if (ret_val)
-		goto out;
+		return ret_val;
 
 	data &= BM_CS_STATUS_LINK_UP | BM_CS_STATUS_RESOLVED |
 		BM_CS_STATUS_SPEED_MASK;
 
 	if (data != (BM_CS_STATUS_LINK_UP | BM_CS_STATUS_RESOLVED |
 		     BM_CS_STATUS_SPEED_1000))
-		goto out;
+		return E1000_SUCCESS;
 
 	msec_delay(200);
 
 	/* flush the packets in the fifo buffer */
 	ret_val = hw->phy.ops.write_reg(hw, HV_MUX_DATA_CTRL,
-					HV_MUX_DATA_CTRL_GEN_TO_MAC |
-					HV_MUX_DATA_CTRL_FORCE_SPEED);
+					(HV_MUX_DATA_CTRL_GEN_TO_MAC |
+					 HV_MUX_DATA_CTRL_FORCE_SPEED));
 	if (ret_val)
-		goto out;
-
-	ret_val = hw->phy.ops.write_reg(hw, HV_MUX_DATA_CTRL,
-					HV_MUX_DATA_CTRL_GEN_TO_MAC);
+		return ret_val;
 
-out:
-	return ret_val;
+	return hw->phy.ops.write_reg(hw, HV_MUX_DATA_CTRL,
+				     HV_MUX_DATA_CTRL_GEN_TO_MAC);
 }
 
 /**
@@ -3885,13 +3896,13 @@ s32 e1000_phy_force_speed_duplex_82577(struct e1000_hw *hw)
 
 	ret_val = phy->ops.read_reg(hw, PHY_CONTROL, &phy_data);
 	if (ret_val)
-		goto out;
+		return ret_val;
 
 	e1000_phy_force_speed_duplex_setup(hw, &phy_data);
 
 	ret_val = phy->ops.write_reg(hw, PHY_CONTROL, phy_data);
 	if (ret_val)
-		goto out;
+		return ret_val;
 
 	usec_delay(1);
 
@@ -3901,7 +3912,7 @@ s32 e1000_phy_force_speed_duplex_82577(struct e1000_hw *hw)
 		ret_val = e1000_phy_has_link_generic(hw, PHY_FORCE_LIMIT,
 						     100000, &link);
 		if (ret_val)
-			goto out;
+			return ret_val;
 
 		if (!link)
 			DEBUGOUT("Link taking longer than expected.\n");
@@ -3909,11 +3920,8 @@ s32 e1000_phy_force_speed_duplex_82577(struct e1000_hw *hw)
 		/* Try once more */
 		ret_val = e1000_phy_has_link_generic(hw, PHY_FORCE_LIMIT,
 						     100000, &link);
-		if (ret_val)
-			goto out;
 	}
 
-out:
 	return ret_val;
 }
 
@@ -3937,35 +3945,34 @@ s32 e1000_get_phy_info_82577(struct e1000_hw *hw)
 
 	ret_val = e1000_phy_has_link_generic(hw, 1, 0, &link);
 	if (ret_val)
-		goto out;
+		return ret_val;
 
 	if (!link) {
 		DEBUGOUT("Phy info is only valid if link is up\n");
-		ret_val = -E1000_ERR_CONFIG;
-		goto out;
+		return -E1000_ERR_CONFIG;
 	}
 
 	phy->polarity_correction = TRUE;
 
 	ret_val = e1000_check_polarity_82577(hw);
 	if (ret_val)
-		goto out;
+		return ret_val;
 
 	ret_val = phy->ops.read_reg(hw, I82577_PHY_STATUS_2, &data);
 	if (ret_val)
-		goto out;
+		return ret_val;
 
-	phy->is_mdix = (data & I82577_PHY_STATUS2_MDIX) ? TRUE : FALSE;
+	phy->is_mdix = !!(data & I82577_PHY_STATUS2_MDIX);
 
 	if ((data & I82577_PHY_STATUS2_SPEED_MASK) ==
 	    I82577_PHY_STATUS2_SPEED_1000MBPS) {
 		ret_val = hw->phy.ops.get_cable_length(hw);
 		if (ret_val)
-			goto out;
+			return ret_val;
 
 		ret_val = phy->ops.read_reg(hw, PHY_1000T_STATUS, &data);
 		if (ret_val)
-			goto out;
+			return ret_val;
 
 		phy->local_rx = (data & SR_1000T_LOCAL_RX_STATUS)
 				? e1000_1000t_rx_status_ok
@@ -3980,8 +3987,7 @@ s32 e1000_get_phy_info_82577(struct e1000_hw *hw)
 		phy->remote_rx = e1000_1000t_rx_status_undefined;
 	}
 
-out:
-	return ret_val;
+	return E1000_SUCCESS;
 }
 
 /**
@@ -4001,16 +4007,79 @@ s32 e1000_get_cable_length_82577(struct e1000_hw *hw)
 
 	ret_val = phy->ops.read_reg(hw, I82577_PHY_DIAG_STATUS, &phy_data);
 	if (ret_val)
-		goto out;
+		return ret_val;
 
 	length = (phy_data & I82577_DSTATUS_CABLE_LENGTH) >>
 		 I82577_DSTATUS_CABLE_LENGTH_SHIFT;
 
 	if (length == E1000_CABLE_LENGTH_UNDEFINED)
-		ret_val = -E1000_ERR_PHY;
+		return -E1000_ERR_PHY;
 
 	phy->cable_length = length;
 
-out:
+	return E1000_SUCCESS;
+}
+
+/**
+ *  e1000_write_phy_reg_gs40g - Write GS40G  PHY register
+ *  @hw: pointer to the HW structure
+ *  @offset: register offset to write to
+ *  @data: data to write at register offset
+ *
+ *  Acquires semaphore, if necessary, then writes the data to PHY register
+ *  at the offset.  Release any acquired semaphores before exiting.
+ **/
+s32 e1000_write_phy_reg_gs40g(struct e1000_hw *hw, u32 offset, u16 data)
+{
+	s32 ret_val;
+	u16 page = offset >> GS40G_PAGE_SHIFT;
+
+	DEBUGFUNC("e1000_write_phy_reg_gs40g");
+
+	offset = offset & GS40G_OFFSET_MASK;
+	ret_val = hw->phy.ops.acquire(hw);
+	if (ret_val)
+		return ret_val;
+
+	ret_val = e1000_write_phy_reg_mdic(hw, GS40G_PAGE_SELECT, page);
+	if (ret_val)
+		goto release;
+	ret_val = e1000_write_phy_reg_mdic(hw, offset, data);
+
+release:
+	hw->phy.ops.release(hw);
+	return ret_val;
+}
+
+/**
+ *  e1000_read_phy_reg_gs40g - Read GS40G  PHY register
+ *  @hw: pointer to the HW structure
+ *  @offset: lower half is register offset to read to
+ *     upper half is page to use.
+ *  @data: data to read at register offset
+ *
+ *  Acquires semaphore, if necessary, then reads the data in the PHY register
+ *  at the offset.  Release any acquired semaphores before exiting.
+ **/
+s32 e1000_read_phy_reg_gs40g(struct e1000_hw *hw, u32 offset, u16 *data)
+{
+	s32 ret_val;
+	u16 page = offset >> GS40G_PAGE_SHIFT;
+
+	DEBUGFUNC("e1000_read_phy_reg_gs40g");
+
+	offset = offset & GS40G_OFFSET_MASK;
+	ret_val = hw->phy.ops.acquire(hw);
+	if (ret_val)
+		return ret_val;
+
+	ret_val = e1000_write_phy_reg_mdic(hw, GS40G_PAGE_SELECT, page);
+	if (ret_val)
+		goto release;
+	ret_val = e1000_read_phy_reg_mdic(hw, offset, data);
+
+release:
+	hw->phy.ops.release(hw);
 	return ret_val;
 }
+
diff --git a/sys/dev/e1000/e1000_phy.h b/sys/dev/e1000/e1000_phy.h
index 93d0afc..9911df7 100644
--- a/sys/dev/e1000/e1000_phy.h
+++ b/sys/dev/e1000/e1000_phy.h
@@ -1,6 +1,6 @@
 /******************************************************************************
 
-  Copyright (c) 2001-2011, Intel Corporation 
+  Copyright (c) 2001-2013, Intel Corporation 
   All rights reserved.
   
   Redistribution and use in source and binary forms, with or without 
@@ -41,6 +41,10 @@ void e1000_null_phy_generic(struct e1000_hw *hw);
 s32  e1000_null_lplu_state(struct e1000_hw *hw, bool active);
 s32  e1000_null_write_reg(struct e1000_hw *hw, u32 offset, u16 data);
 s32  e1000_null_set_page(struct e1000_hw *hw, u16 data);
+s32 e1000_read_i2c_byte_null(struct e1000_hw *hw, u8 byte_offset,
+			     u8 dev_addr, u8 *data);
+s32 e1000_write_i2c_byte_null(struct e1000_hw *hw, u8 byte_offset,
+			      u8 dev_addr, u8 data);
 s32  e1000_check_downshift_generic(struct e1000_hw *hw);
 s32  e1000_check_polarity_m88(struct e1000_hw *hw);
 s32  e1000_check_polarity_igp(struct e1000_hw *hw);
@@ -74,13 +78,11 @@ s32  e1000_read_phy_reg_igp_locked(struct e1000_hw *hw, u32 offset, u16 *data);
 s32  e1000_read_phy_reg_m88(struct e1000_hw *hw, u32 offset, u16 *data);
 s32  e1000_set_d3_lplu_state_generic(struct e1000_hw *hw, bool active);
 s32  e1000_setup_copper_link_generic(struct e1000_hw *hw);
-s32  e1000_wait_autoneg_generic(struct e1000_hw *hw);
 s32  e1000_write_kmrn_reg_generic(struct e1000_hw *hw, u32 offset, u16 data);
 s32  e1000_write_kmrn_reg_locked(struct e1000_hw *hw, u32 offset, u16 data);
 s32  e1000_write_phy_reg_igp(struct e1000_hw *hw, u32 offset, u16 data);
 s32  e1000_write_phy_reg_igp_locked(struct e1000_hw *hw, u32 offset, u16 data);
 s32  e1000_write_phy_reg_m88(struct e1000_hw *hw, u32 offset, u16 data);
-s32  e1000_phy_reset_dsp(struct e1000_hw *hw);
 s32  e1000_phy_has_link_generic(struct e1000_hw *hw, u32 iterations,
 				u32 usec_interval, bool *success);
 s32  e1000_phy_init_script_igp3(struct e1000_hw *hw);
@@ -112,6 +114,8 @@ s32  e1000_check_polarity_82577(struct e1000_hw *hw);
 s32  e1000_get_phy_info_82577(struct e1000_hw *hw);
 s32  e1000_phy_force_speed_duplex_82577(struct e1000_hw *hw);
 s32  e1000_get_cable_length_82577(struct e1000_hw *hw);
+s32  e1000_write_phy_reg_gs40g(struct e1000_hw *hw, u32 offset, u16 data);
+s32  e1000_read_phy_reg_gs40g(struct e1000_hw *hw, u32 offset, u16 *data);
 
 #define E1000_MAX_PHY_ADDR		8
 
@@ -121,16 +125,25 @@ s32  e1000_get_cable_length_82577(struct e1000_hw *hw);
 #define IGP01E1000_PHY_PORT_CTRL	0x12 /* Control */
 #define IGP01E1000_PHY_LINK_HEALTH	0x13 /* PHY Link Health */
 #define IGP01E1000_GMII_FIFO		0x14 /* GMII FIFO */
-#define IGP01E1000_PHY_CHANNEL_QUALITY	0x15 /* PHY Channel Quality */
 #define IGP02E1000_PHY_POWER_MGMT	0x19 /* Power Management */
 #define IGP01E1000_PHY_PAGE_SELECT	0x1F /* Page Select */
 #define BM_PHY_PAGE_SELECT		22   /* Page Select for BM */
 #define IGP_PAGE_SHIFT			5
 #define PHY_REG_MASK			0x1F
 
+/* GS40G - I210 PHY defines */
+#define GS40G_PAGE_SELECT		0x16
+#define GS40G_PAGE_SHIFT		16
+#define GS40G_OFFSET_MASK		0xFFFF
+#define GS40G_PAGE_2			0x20000
+#define GS40G_MAC_REG2			0x15
+#define GS40G_MAC_LB			0x4140
+#define GS40G_MAC_SPEED_1G		0X0006
+#define GS40G_COPPER_SPEC		0x0010
+#define GS40G_CS_POWER_DOWN		0x0002
+
 /* BM/HV Specific Registers */
 #define BM_PORT_CTRL_PAGE		769
-#define BM_PCIE_PAGE			770
 #define BM_WUC_PAGE			800
 #define BM_WUC_ADDRESS_OPCODE		0x11
 #define BM_WUC_DATA_OPCODE		0x12
@@ -171,11 +184,11 @@ s32  e1000_get_cable_length_82577(struct e1000_hw *hw);
 #define I82577_PHY_STATUS2_MDIX			0x0800
 #define I82577_PHY_STATUS2_SPEED_MASK		0x0300
 #define I82577_PHY_STATUS2_SPEED_1000MBPS	0x0200
-#define I82577_PHY_STATUS2_SPEED_100MBPS	0x0100
 
 /* I82577 PHY Control 2 */
-#define I82577_PHY_CTRL2_AUTO_MDIX		0x0400
-#define I82577_PHY_CTRL2_FORCE_MDI_MDIX		0x0200
+#define I82577_PHY_CTRL2_MANUAL_MDIX		0x0200
+#define I82577_PHY_CTRL2_AUTO_MDI_MDIX		0x0400
+#define I82577_PHY_CTRL2_MDIX_CFG_MASK		0x0600
 
 /* I82577 PHY Diagnostics Status */
 #define I82577_DSTATUS_CABLE_LENGTH		0x03FC
@@ -186,14 +199,13 @@ s32  e1000_get_cable_length_82577(struct e1000_hw *hw);
 #define E1000_82580_PM_SPD		0x0001 /* Smart Power Down */
 #define E1000_82580_PM_D0_LPLU		0x0002 /* For D0a states */
 #define E1000_82580_PM_D3_LPLU		0x0004 /* For all other states */
+#define E1000_82580_PM_GO_LINKD		0x0020 /* Go Link Disconnect */
 
 /* BM PHY Copper Specific Control 1 */
 #define BM_CS_CTRL1			16
-#define BM_CS_CTRL1_ENERGY_DETECT	0x0300 /* Enable Energy Detect */
 
 /* BM PHY Copper Specific Status */
 #define BM_CS_STATUS			17
-#define BM_CS_STATUS_ENERGY_DETECT	0x0010 /* Energy Detect Status */
 #define BM_CS_STATUS_LINK_UP		0x0400
 #define BM_CS_STATUS_RESOLVED		0x0800
 #define BM_CS_STATUS_SPEED_MASK		0xC000
@@ -239,9 +251,6 @@ s32  e1000_get_cable_length_82577(struct e1000_hw *hw);
 #define IGP02E1000_AGC_LENGTH_MASK	0x7F
 #define IGP02E1000_AGC_RANGE		15
 
-#define IGP03E1000_PHY_MISC_CTRL	0x1B
-#define IGP03E1000_PHY_MISC_DUPLEX_MANUAL_SET	0x1000 /* Manually Set Duplex */
-
 #define E1000_CABLE_LENGTH_UNDEFINED	0xFF
 
 #define E1000_KMRNCTRLSTA_OFFSET	0x001F0000
@@ -254,7 +263,7 @@ s32  e1000_get_cable_length_82577(struct e1000_hw *hw);
 #define E1000_KMRNCTRLSTA_IBIST_DISABLE	0x0200 /* Kumeran IBIST Disable */
 #define E1000_KMRNCTRLSTA_DIAG_NELPBK	0x1000 /* Nearend Loopback mode */
 #define E1000_KMRNCTRLSTA_K1_CONFIG	0x7
-#define E1000_KMRNCTRLSTA_K1_ENABLE	0x0002
+#define E1000_KMRNCTRLSTA_K1_ENABLE	0x0002 /* enable K1 */
 #define E1000_KMRNCTRLSTA_HD_CTRL	0x10   /* Kumeran HD Control */
 
 #define IFE_PHY_EXTENDED_STATUS_CONTROL	0x10
@@ -268,7 +277,6 @@ s32  e1000_get_cable_length_82577(struct e1000_hw *hw);
 /* IFE PHY Special Control */
 #define IFE_PSC_AUTO_POLARITY_DISABLE	0x0010
 #define IFE_PSC_FORCE_POLARITY		0x0020
-#define IFE_PSC_DISABLE_DYNAMIC_POWER_DOWN	0x0100
 
 /* IFE PHY Special Control and LED Control */
 #define IFE_PSCL_PROBE_MODE		0x0020
diff --git a/sys/dev/e1000/e1000_regs.h b/sys/dev/e1000/e1000_regs.h
index 2cc89d5..516d377 100644
--- a/sys/dev/e1000/e1000_regs.h
+++ b/sys/dev/e1000/e1000_regs.h
@@ -1,6 +1,6 @@
 /******************************************************************************
 
-  Copyright (c) 2001-2011, Intel Corporation 
+  Copyright (c) 2001-2013, Intel Corporation 
   All rights reserved.
   
   Redistribution and use in source and binary forms, with or without 
@@ -51,12 +51,15 @@
 #define E1000_BARCTRL_FLSIZE		0x0700 /* BAR ctrl Flsize */
 #define E1000_BARCTRL_CSRSIZE		0x2000 /* BAR ctrl CSR size */
 #define E1000_I350_BARCTRL		0x5BFC /* BAR ctrl reg */
+#define E1000_I350_DTXMXPKTSZ		0x355C /* Maximum sent packet size reg*/
 #define E1000_SCTL	0x00024  /* SerDes Control - RW */
 #define E1000_FCAL	0x00028  /* Flow Control Address Low - RW */
 #define E1000_FCAH	0x0002C  /* Flow Control Address High -RW */
-#define E1000_FEXT	0x0002C  /* Future Extended - RW */
-#define E1000_FEXTNVM4	0x00024  /* Future Extended NVM 4 - RW */
 #define E1000_FEXTNVM	0x00028  /* Future Extended NVM - RW */
+#define E1000_FEXTNVM3	0x0003C  /* Future Extended NVM 3 - RW */
+#define E1000_FEXTNVM4	0x00024  /* Future Extended NVM 4 - RW */
+#define E1000_FEXTNVM6	0x00010  /* Future Extended NVM 6 - RW */
+#define E1000_FEXTNVM7	0x000E4  /* Future Extended NVM 7 - RW */
 #define E1000_FCT	0x00030  /* Flow Control Type - RW */
 #define E1000_CONNSW	0x00034  /* Copper/Fiber switch control - RW */
 #define E1000_VET	0x00038  /* VLAN Ether Type - RW */
@@ -69,6 +72,7 @@
 #define E1000_IVAR	0x000E4  /* Interrupt Vector Allocation Register - RW */
 #define E1000_SVCR	0x000F0
 #define E1000_SVT	0x000F4
+#define E1000_LPIC	0x000FC  /* Low Power IDLE control */
 #define E1000_RCTL	0x00100  /* Rx Control - RW */
 #define E1000_FCTTV	0x00170  /* Flow Control Transmit Timer Value - RW */
 #define E1000_TXCW	0x00178  /* Tx Configuration Word - RW */
@@ -96,6 +100,7 @@
 #define E1000_POEMB	E1000_PHY_CTRL /* PHY OEM Bits */
 #define E1000_PBA	0x01000  /* Packet Buffer Allocation - RW */
 #define E1000_PBS	0x01008  /* Packet Buffer Size */
+#define E1000_PBECCSTS	0x0100C  /* Packet Buffer ECC Status - RW */
 #define E1000_EEMNGCTL	0x01010  /* MNG EEprom Control */
 #define E1000_EEARBC	0x01024  /* EEPROM Auto Read Bus Control */
 #define E1000_FLASHT	0x01028  /* FLASH Timer Register */
@@ -128,7 +133,11 @@
 #define E1000_FCRTL	0x02160  /* Flow Control Receive Threshold Low - RW */
 #define E1000_FCRTH	0x02168  /* Flow Control Receive Threshold High - RW */
 #define E1000_PSRCTL	0x02170  /* Packet Split Receive Control - RW */
-#define E1000_RDFPCQ(_n)	(0x02430 + (0x4 * (_n)))
+#define E1000_RDFH	0x02410  /* Rx Data FIFO Head - RW */
+#define E1000_RDFT	0x02418  /* Rx Data FIFO Tail - RW */
+#define E1000_RDFHS	0x02420  /* Rx Data FIFO Head Saved - RW */
+#define E1000_RDFTS	0x02428  /* Rx Data FIFO Tail Saved - RW */
+#define E1000_RDFPC	0x02430  /* Rx Data FIFO Packet Count - RW */
 #define E1000_PBRTH	0x02458  /* PB Rx Arbitration Threshold - RW */
 #define E1000_FCRTV	0x02460  /* Flow Control Refresh Timer Value - RW */
 /* Split and Replication Rx Control - RW */
@@ -143,8 +152,63 @@
 #define E1000_PBRWAC	0x024E8 /* Rx packet buffer wrap around counter - RO */
 #define E1000_RDTR	0x02820  /* Rx Delay Timer - RW */
 #define E1000_RADV	0x0282C  /* Rx Interrupt Absolute Delay Timer - RW */
-/*
- * Convenience macros
+#define E1000_SRWR		0x12018  /* Shadow Ram Write Register - RW */
+#define E1000_I210_FLMNGCTL	0x12038
+#define E1000_I210_FLMNGDATA	0x1203C
+#define E1000_I210_FLMNGCNT	0x12040
+
+#define E1000_I210_FLSWCTL	0x12048
+#define E1000_I210_FLSWDATA	0x1204C
+#define E1000_I210_FLSWCNT	0x12050
+
+#define E1000_I210_FLA		0x1201C
+
+#define E1000_INVM_DATA_REG(_n)	(0x12120 + 4*(_n))
+#define E1000_INVM_SIZE		64 /* Number of INVM Data Registers */
+
+/* QAV Tx mode control register */
+#define E1000_I210_TQAVCTRL	0x3570
+
+/* QAV Tx mode control register bitfields masks */
+/* QAV enable */
+#define E1000_TQAVCTRL_MODE			(1 << 0)
+/* Fetching arbitration type */
+#define E1000_TQAVCTRL_FETCH_ARB		(1 << 4)
+/* Fetching timer enable */
+#define E1000_TQAVCTRL_FETCH_TIMER_ENABLE	(1 << 5)
+/* Launch arbitration type */
+#define E1000_TQAVCTRL_LAUNCH_ARB		(1 << 8)
+/* Launch timer enable */
+#define E1000_TQAVCTRL_LAUNCH_TIMER_ENABLE	(1 << 9)
+/* SP waits for SR enable */
+#define E1000_TQAVCTRL_SP_WAIT_SR		(1 << 10)
+/* Fetching timer correction */
+#define E1000_TQAVCTRL_FETCH_TIMER_DELTA_OFFSET	16
+#define E1000_TQAVCTRL_FETCH_TIMER_DELTA	\
+			(0xFFFF << E1000_TQAVCTRL_FETCH_TIMER_DELTA_OFFSET)
+
+/* High credit registers where _n can be 0 or 1. */
+#define E1000_I210_TQAVHC(_n)			(0x300C + 0x40 * (_n))
+
+/* Queues fetch arbitration priority control register */
+#define E1000_I210_TQAVARBCTRL			0x3574
+/* Queues priority masks where _n and _p can be 0-3. */
+#define E1000_TQAVARBCTRL_QUEUE_PRI(_n, _p)	((_p) << (2 * _n))
+/* QAV Tx mode control registers where _n can be 0 or 1. */
+#define E1000_I210_TQAVCC(_n)			(0x3004 + 0x40 * (_n))
+
+/* QAV Tx mode control register bitfields masks */
+#define E1000_TQAVCC_IDLE_SLOPE		0xFFFF /* Idle slope */
+#define E1000_TQAVCC_KEEP_CREDITS	(1 << 30) /* Keep credits opt enable */
+#define E1000_TQAVCC_QUEUE_MODE		(1 << 31) /* SP vs. SR Tx mode */
+
+/* Good transmitted packets counter registers */
+#define E1000_PQGPTC(_n)		(0x010014 + (0x100 * (_n)))
+
+/* Queues packet buffer size masks where _n can be 0-3 and _s 0-63 [kB] */
+#define E1000_I210_TXPBS_SIZE(_n, _s)	((_s) << (6 * _n))
+
+/* Convenience macros
  *
  * Note: "_n" is the queue number of the register to be written to.
  *
@@ -356,8 +420,7 @@
 #define E1000_LSECTXKEY1(_n)	(0x0B030 + (0x04 * (_n)))
 #define E1000_LSECRXSA(_n)	(0x0B310 + (0x04 * (_n))) /* Rx SAs - RW */
 #define E1000_LSECRXPN(_n)	(0x0B330 + (0x04 * (_n))) /* Rx SAs - RW */
-/*
- * LinkSec Rx Keys  - where _n is the SA no. and _m the 4 dwords of the 128 bit
+/* LinkSec Rx Keys  - where _n is the SA no. and _m the 4 dwords of the 128 bit
  * key - RW.
  */
 #define E1000_LSECRXKEY(_n, _m)	(0x0B350 + (0x10 * (_n)) + (0x04 * (_m)))
@@ -397,7 +460,6 @@
 #define E1000_PCS_LPAB	0x0421C  /* Link Partner Ability - RW */
 #define E1000_PCS_NPTX	0x04220  /* AN Next Page Transmit - RW */
 #define E1000_PCS_LPABNP	0x04224 /* Link Partner Ability Next Pg - RW */
-#define E1000_1GSTAT_RCV	0x04228 /* 1GSTAT Code Violation Pkt Cnt - RW */
 #define E1000_RXCSUM	0x05000  /* Rx Checksum Control - RW */
 #define E1000_RLPML	0x05004  /* Rx Long Packet Max Length */
 #define E1000_RFCTL	0x05008  /* Receive Filter Control*/
@@ -424,14 +486,14 @@
 #define E1000_HOST_IF	0x08800  /* Host Interface */
 #define E1000_FFMT	0x09000  /* Flexible Filter Mask Table - RW Array */
 #define E1000_FFVT	0x09800  /* Flexible Filter Value Table - RW Array */
+#define E1000_HIBBA	0x8F40   /* Host Interface Buffer Base Address */
 /* Flexible Host Filter Table */
-#define E1000_FHFT(_n)	(0x09000 + (_n * 0x100))
+#define E1000_FHFT(_n)	(0x09000 + ((_n) * 0x100))
 /* Ext Flexible Host Filter Table */
-#define E1000_FHFT_EXT(_n)	(0x09A00 + (_n * 0x100))
+#define E1000_FHFT_EXT(_n)	(0x09A00 + ((_n) * 0x100))
 
 
 #define E1000_KMRNCTRLSTA	0x00034 /* MAC-PHY interface - RW */
-#define E1000_MDPHYA		0x0003C /* PHY address - RW */
 #define E1000_MANC2H		0x05860 /* Management Control To Host - RW */
 /* Management Decision Filters */
 #define E1000_MDEF(_n)		(0x05890 + (4 * (_n)))
@@ -464,15 +526,6 @@
 #define E1000_IMIREXT(_i)	(0x05AA0 + ((_i) * 4)) /* Immediate INTR Ext*/
 #define E1000_IMIRVP		0x05AC0 /* Immediate INT Rx VLAN Priority -RW */
 #define E1000_MSIXBM(_i)	(0x01600 + ((_i) * 4)) /* MSI-X Alloc Reg -RW */
-/* MSI-X Table entry addr low reg - RW */
-#define E1000_MSIXTADD(_i)	(0x0C000 + ((_i) * 0x10))
-/* MSI-X Table entry addr upper reg - RW */
-#define E1000_MSIXTUADD(_i)	(0x0C004 + ((_i) * 0x10))
-/* MSI-X Table entry message reg - RW */
-#define E1000_MSIXTMSG(_i)	(0x0C008 + ((_i) * 0x10))
-/* MSI-X Table entry vector ctrl reg - RW */
-#define E1000_MSIXVCTRL(_i)	(0x0C00C + ((_i) * 0x10))
-#define E1000_MSIXPBA	0x0E000 /* MSI-X Pending bit array */
 #define E1000_RETA(_i)	(0x05C00 + ((_i) * 4)) /* Redirection Table - RW */
 #define E1000_RSSRK(_i)	(0x05C80 + ((_i) * 4)) /* RSS Random Key - RW */
 #define E1000_RSSIM	0x05864 /* RSS Interrupt Mask */
@@ -522,8 +575,12 @@
 #define E1000_SYSTIML	0x0B600 /* System time register Low - RO */
 #define E1000_SYSTIMH	0x0B604 /* System time register High - RO */
 #define E1000_TIMINCA	0x0B608 /* Increment attributes register - RW */
+#define E1000_TIMADJL	0x0B60C /* Time sync time adjustment offset Low - RW */
+#define E1000_TIMADJH	0x0B610 /* Time sync time adjustment offset High - RW */
 #define E1000_TSAUXC	0x0B640 /* Timesync Auxiliary Control register */
 #define E1000_SYSTIMR	0x0B6F8 /* System time register Residue */
+#define E1000_TSICR	0x0B66C /* Interrupt Cause Register */
+#define E1000_TSIM	0x0B674 /* Interrupt Mask Register */
 #define E1000_RXMTRL	0x0B634 /* Time sync Rx EtherType and Msg Type - RW */
 #define E1000_RXUDP	0x0B638 /* Time Sync Rx UDP Port - RW */
 
@@ -590,10 +647,6 @@
 /* PCIe Parity Status Register */
 #define E1000_PCIEERRSTS	0x05BA8
 
-#define E1000_LTRMINV	0x5BB0 /* LTR Minimum Value */
-#define E1000_LTRMAXV	0x5BB4 /* LTR Maximum Value */
-#define E1000_DOBFFCTL	0x3F24 /* DMA OBFF Control Register */
-
 #define E1000_PROXYS	0x5F64 /* Proxying Status */
 #define E1000_PROXYFC	0x5F60 /* Proxying Filter Control */
 /* Thermal sensor configuration and status registers */
@@ -603,7 +656,7 @@
 #define E1000_THHIGHTC	0x0810C /* High Threshold Control */
 #define E1000_THSTAT	0x08110 /* Thermal Sensor Status */
 
-/*Energy Efficient Ethernet "EEE" registers */
+/* Energy Efficient Ethernet "EEE" registers */
 #define E1000_IPCNFG	0x0E38 /* Internal PHY Configuration */
 #define E1000_LTRC	0x01A0 /* Latency Tolerance Reporting Control */
 #define E1000_EEER	0x0E30 /* Energy Efficient Ethernet "EEE"*/
@@ -617,4 +670,7 @@
 #define E1000_O2BGPTC	0x08FE4 /* OS2BMC packets received by BMC */
 #define E1000_O2BSPC	0x0415C /* OS2BMC packets transmitted by host */
 
+#define E1000_DOBFFCTL	0x3F24 /* DMA OBFF Control Register */
+
+
 #endif
diff --git a/sys/dev/e1000/if_em.c b/sys/dev/e1000/if_em.c
index f942942..64be42d 100644
--- a/sys/dev/e1000/if_em.c
+++ b/sys/dev/e1000/if_em.c
@@ -1,6 +1,6 @@
 /******************************************************************************
 
-  Copyright (c) 2001-2011, Intel Corporation 
+  Copyright (c) 2001-2013, Intel Corporation 
   All rights reserved.
   
   Redistribution and use in source and binary forms, with or without 
@@ -94,7 +94,7 @@ int	em_display_debug_stats = 0;
 /*********************************************************************
  *  Driver version:
  *********************************************************************/
-char em_driver_version[] = "7.3.2";
+char em_driver_version[] = "7.3.7";
 
 /*********************************************************************
  *  PCI Device ID Table
@@ -172,6 +172,12 @@ static em_vendor_info_t em_vendor_info_array[] =
 	{ 0x8086, E1000_DEV_ID_PCH_D_HV_DC,	PCI_ANY_ID, PCI_ANY_ID, 0},
 	{ 0x8086, E1000_DEV_ID_PCH2_LV_LM,	PCI_ANY_ID, PCI_ANY_ID, 0},
 	{ 0x8086, E1000_DEV_ID_PCH2_LV_V,	PCI_ANY_ID, PCI_ANY_ID, 0},
+	{ 0x8086, E1000_DEV_ID_PCH_LPT_I217_LM,	PCI_ANY_ID, PCI_ANY_ID, 0},
+	{ 0x8086, E1000_DEV_ID_PCH_LPT_I217_V,	PCI_ANY_ID, PCI_ANY_ID, 0},
+	{ 0x8086, E1000_DEV_ID_PCH_LPTLP_I218_LM,
+						PCI_ANY_ID, PCI_ANY_ID, 0},
+	{ 0x8086, E1000_DEV_ID_PCH_LPTLP_I218_V,
+						PCI_ANY_ID, PCI_ANY_ID, 0},
 	/* required last entry */
 	{ 0, 0, 0, 0, 0}
 };
@@ -289,6 +295,7 @@ static void	em_handle_link(void *context, int pending);
 static void	em_set_sysctl_value(struct adapter *, const char *,
 		    const char *, int *, int);
 static int	em_set_flowcntl(SYSCTL_HANDLER_ARGS);
+static int	em_sysctl_eee(SYSCTL_HANDLER_ARGS);
 
 static __inline void em_rx_discard(struct rx_ring *, int);
 
@@ -308,7 +315,7 @@ static device_method_t em_methods[] = {
 	DEVMETHOD(device_shutdown, em_shutdown),
 	DEVMETHOD(device_suspend, em_suspend),
 	DEVMETHOD(device_resume, em_resume),
-	{0, 0}
+	DEVMETHOD_END
 };
 
 static driver_t em_driver = {
@@ -389,7 +396,7 @@ SYSCTL_INT(_hw_em, OID_AUTO, rx_process_limit, CTLFLAG_RDTUN,
     "at a time, -1 means unlimited");
 
 /* Energy efficient ethernet - default to OFF */
-static int eee_setting = 0;
+static int eee_setting = 1;
 TUNABLE_INT("hw.em.eee_setting", &eee_setting);
 SYSCTL_INT(_hw_em, OID_AUTO, eee_setting, CTLFLAG_RDTUN, &eee_setting, 0,
     "Enable Energy Efficient Ethernet");
@@ -397,6 +404,10 @@ SYSCTL_INT(_hw_em, OID_AUTO, eee_setting, CTLFLAG_RDTUN, &eee_setting, 0,
 /* Global used in WOL setup with multiport cards */
 static int global_quad_port_a = 0;
 
+#ifdef DEV_NETMAP	/* see ixgbe.c for details */
+#include <dev/netmap/if_em_netmap.h>
+#endif /* DEV_NETMAP */
+
 /*********************************************************************
  *  Device identification routine
  *
@@ -515,7 +526,8 @@ em_attach(device_t dev)
 	    (hw->mac.type == e1000_ich9lan) ||
 	    (hw->mac.type == e1000_ich10lan) ||
 	    (hw->mac.type == e1000_pchlan) ||
-	    (hw->mac.type == e1000_pch2lan)) {
+	    (hw->mac.type == e1000_pch2lan) ||
+	    (hw->mac.type == e1000_pch_lpt)) {
 		int rid = EM_BAR_TYPE_FLASH;
 		adapter->flash = bus_alloc_resource_any(dev,
 		    SYS_RES_MEMORY, &rid, RF_ACTIVE);
@@ -600,8 +612,8 @@ em_attach(device_t dev)
 	 * Set the frame limits assuming
 	 * standard ethernet sized frames.
 	 */
-	adapter->max_frame_size = ETHERMTU + ETHER_HDR_LEN + ETHERNET_FCS_SIZE;
-	adapter->min_frame_size = ETH_ZLEN + ETHERNET_FCS_SIZE;
+	adapter->hw.mac.max_frame_size =
+	    ETHERMTU + ETHER_HDR_LEN + ETHERNET_FCS_SIZE;
 
 	/*
 	 * This controls when hardware reports transmit completion
@@ -632,9 +644,12 @@ em_attach(device_t dev)
 		    " due to SOL/IDER session.\n");
 
 	/* Sysctl for setting Energy Efficient Ethernet */
-	em_set_sysctl_value(adapter, "eee_control",
-	    "enable Energy Efficient Ethernet",
-	    &hw->dev_spec.ich8lan.eee_disable, eee_setting);
+	hw->dev_spec.ich8lan.eee_disable = eee_setting;
+	SYSCTL_ADD_PROC(device_get_sysctl_ctx(dev),
+	    SYSCTL_CHILDREN(device_get_sysctl_tree(dev)),
+	    OID_AUTO, "eee_control", CTLTYPE_INT|CTLFLAG_RW,
+	    adapter, 0, em_sysctl_eee, "I",
+	    "Disable Energy Efficient Ethernet");
 
 	/*
 	** Start from a known state, this is
@@ -718,6 +733,9 @@ em_attach(device_t dev)
 
 	adapter->led_dev = led_create(em_led_func, adapter,
 	    device_get_nameunit(dev));
+#ifdef DEV_NETMAP
+	em_netmap_attach(adapter);
+#endif /* DEV_NETMAP */
 
 	INIT_DEBUGOUT("em_attach: end");
 
@@ -789,6 +807,10 @@ em_detach(device_t dev)
 	ether_ifdetach(adapter->ifp);
 	callout_drain(&adapter->timer);
 
+#ifdef DEV_NETMAP
+	netmap_detach(ifp);
+#endif /* DEV_NETMAP */
+
 	em_free_pci_resources(adapter);
 	bus_generic_detach(dev);
 	if_free(ifp);
@@ -890,28 +912,29 @@ em_mq_start_locked(struct ifnet *ifp, struct tx_ring *txr, struct mbuf *m)
 	}
 
 	enq = 0;
-	if (m == NULL) {
-		next = drbr_dequeue(ifp, txr->br);
-	} else if (drbr_needs_enqueue(ifp, txr->br)) {
-		if ((err = drbr_enqueue(ifp, txr->br, m)) != 0)
+	if (m != NULL) {
+		err = drbr_enqueue(ifp, txr->br, m);
+		if (err)
 			return (err);
-		next = drbr_dequeue(ifp, txr->br);
-	} else
-		next = m;
+	} 
 
 	/* Process the queue */
-	while (next != NULL) {
+	while ((next = drbr_peek(ifp, txr->br)) != NULL) {
 		if ((err = em_xmit(txr, &next)) != 0) {
-                        if (next != NULL)
-                                err = drbr_enqueue(ifp, txr->br, next);
-                        break;
+			if (next == NULL)
+				drbr_advance(ifp, txr->br);
+			else 
+				drbr_putback(ifp, txr->br, next);
+			break;
 		}
+		drbr_advance(ifp, txr->br);
 		enq++;
-		drbr_stats_update(ifp, next->m_pkthdr.len, next->m_flags);
+		ifp->if_obytes += next->m_pkthdr.len;
+		if (next->m_flags & M_MCAST)
+			ifp->if_omcasts++;
 		ETHER_BPF_MTAP(ifp, next);
 		if ((ifp->if_drv_flags & IFF_DRV_RUNNING) == 0)
                         break;
-		next = drbr_dequeue(ifp, txr->br);
 	}
 
 	if (enq > 0) {
@@ -1090,6 +1113,7 @@ em_ioctl(struct ifnet *ifp, u_long command, caddr_t data)
 		case e1000_ich9lan:
 		case e1000_ich10lan:
 		case e1000_pch2lan:
+		case e1000_pch_lpt:
 		case e1000_82574:
 		case e1000_82583:
 		case e1000_80003es2lan:	/* 9K Jumbo Frame size */
@@ -1113,7 +1137,7 @@ em_ioctl(struct ifnet *ifp, u_long command, caddr_t data)
 		}
 
 		ifp->if_mtu = ifr->ifr_mtu;
-		adapter->max_frame_size =
+		adapter->hw.mac.max_frame_size =
 		    ifp->if_mtu + ETHER_HDR_LEN + ETHER_CRC_LEN;
 		em_init_locked(adapter);
 		EM_CORE_UNLOCK(adapter);
@@ -1308,9 +1332,9 @@ em_init_locked(struct adapter *adapter)
 	** Figure out the desired mbuf
 	** pool for doing jumbos
 	*/
-	if (adapter->max_frame_size <= 2048)
+	if (adapter->hw.mac.max_frame_size <= 2048)
 		adapter->rx_mbuf_sz = MCLBYTES;
-	else if (adapter->max_frame_size <= 4096)
+	else if (adapter->hw.mac.max_frame_size <= 4096)
 		adapter->rx_mbuf_sz = MJUMPAGESIZE;
 	else
 		adapter->rx_mbuf_sz = MJUM9BYTES;
@@ -1555,6 +1579,8 @@ em_msix_rx(void *arg)
 	bool		more;
 
 	++rxr->rx_irq;
+	if (!(adapter->ifp->if_drv_flags & IFF_DRV_RUNNING))
+		return;
 	more = em_rxeof(rxr, adapter->rx_process_limit, NULL);
 	if (more)
 		taskqueue_enqueue(rxr->tq, &rxr->rx_task);
@@ -1812,7 +1838,7 @@ retry:
 		if (do_tso || (m_head->m_next != NULL && 
 		    m_head->m_pkthdr.csum_flags & CSUM_OFFLOAD)) {
 			if (M_WRITABLE(*m_headp) == 0) {
-				m_head = m_dup(*m_headp, M_DONTWAIT);
+				m_head = m_dup(*m_headp, M_NOWAIT);
 				m_freem(*m_headp);
 				if (m_head == NULL) {
 					*m_headp = NULL;
@@ -1929,7 +1955,7 @@ retry:
 	if (error == EFBIG && remap) {
 		struct mbuf *m;
 
-		m = m_defrag(*m_headp, M_DONTWAIT);
+		m = m_defrag(*m_headp, M_NOWAIT);
 		if (m == NULL) {
 			adapter->mbuf_alloc_failed++;
 			m_freem(*m_headp);
@@ -2797,17 +2823,18 @@ em_reset(struct adapter *adapter)
 	case e1000_ich9lan:
 	case e1000_ich10lan:
 		/* Boost Receive side for jumbo frames */
-		if (adapter->max_frame_size > 4096)
+		if (adapter->hw.mac.max_frame_size > 4096)
 			pba = E1000_PBA_14K;
 		else
 			pba = E1000_PBA_10K;
 		break;
 	case e1000_pchlan:
 	case e1000_pch2lan:
+	case e1000_pch_lpt:
 		pba = E1000_PBA_26K;
 		break;
 	default:
-		if (adapter->max_frame_size > 8192)
+		if (adapter->hw.mac.max_frame_size > 8192)
 			pba = E1000_PBA_40K; /* 40K for Rx, 24K for Tx */
 		else
 			pba = E1000_PBA_48K; /* 48K for Rx, 16K for Tx */
@@ -2830,7 +2857,7 @@ em_reset(struct adapter *adapter)
 	 */
 	rx_buffer_size = ((E1000_READ_REG(hw, E1000_PBA) & 0xffff) << 10 );
 	hw->fc.high_water = rx_buffer_size -
-	    roundup2(adapter->max_frame_size, 1024);
+	    roundup2(adapter->hw.mac.max_frame_size, 1024);
 	hw->fc.low_water = hw->fc.high_water - 1500;
 
 	if (adapter->fc) /* locally set flow control value? */
@@ -2861,6 +2888,7 @@ em_reset(struct adapter *adapter)
 		hw->fc.refresh_time = 0x1000;
 		break;
 	case e1000_pch2lan:
+	case e1000_pch_lpt:
 		hw->fc.high_water = 0x5C20;
 		hw->fc.low_water = 0x5048;
 		hw->fc.pause_time = 0x0650;
@@ -3289,9 +3317,17 @@ em_setup_transmit_ring(struct tx_ring *txr)
 	struct adapter *adapter = txr->adapter;
 	struct em_buffer *txbuf;
 	int i;
+#ifdef DEV_NETMAP
+	struct netmap_adapter *na = NA(adapter->ifp);
+	struct netmap_slot *slot;
+#endif /* DEV_NETMAP */
 
 	/* Clear the old descriptor contents */
 	EM_TX_LOCK(txr);
+#ifdef DEV_NETMAP
+	slot = netmap_reset(na, NR_TX, txr->me, 0);
+#endif /* DEV_NETMAP */
+
 	bzero((void *)txr->tx_base,
 	      (sizeof(struct e1000_tx_desc)) * adapter->num_tx_desc);
 	/* Reset indices */
@@ -3308,6 +3344,19 @@ em_setup_transmit_ring(struct tx_ring *txr)
 			m_freem(txbuf->m_head);
 			txbuf->m_head = NULL;
 		}
+#ifdef DEV_NETMAP
+		if (slot) {
+			int si = netmap_idx_n2k(&na->tx_rings[txr->me], i);
+			uint64_t paddr;
+			void *addr;
+
+			addr = PNMB(slot + si, &paddr);
+			txr->tx_base[i].buffer_addr = htole64(paddr);
+			/* reload the map for netmap mode */
+			netmap_load_map(txr->txtag, txbuf->map, addr);
+		}
+#endif /* DEV_NETMAP */
+
 		/* clear the watch index */
 		txbuf->next_eop = -1;
         }
@@ -3753,6 +3802,19 @@ em_txeof(struct tx_ring *txr)
 	struct ifnet   *ifp = adapter->ifp;
 
 	EM_TX_LOCK_ASSERT(txr);
+#ifdef DEV_NETMAP
+	if (ifp->if_capenable & IFCAP_NETMAP) {
+		struct netmap_adapter *na = NA(ifp);
+
+		selwakeuppri(&na->tx_rings[txr->me].si, PI_NET);
+		EM_TX_UNLOCK(txr);
+		EM_CORE_LOCK(adapter);
+		selwakeuppri(&na->tx_si, PI_NET);
+		EM_CORE_UNLOCK(adapter);
+		EM_TX_LOCK(txr);
+		return;
+	}
+#endif /* DEV_NETMAP */
 
 	/* No work, make sure watchdog is off */
         if (txr->tx_avail == adapter->num_tx_desc) {
@@ -3877,7 +3939,7 @@ em_refresh_mbufs(struct rx_ring *rxr, int limit)
 	while (j != limit) {
 		rxbuf = &rxr->rx_buffers[i];
 		if (rxbuf->m_head == NULL) {
-			m = m_getjcl(M_DONTWAIT, MT_DATA,
+			m = m_getjcl(M_NOWAIT, MT_DATA,
 			    M_PKTHDR, adapter->rx_mbuf_sz);
 			/*
 			** If we have a temporary resource shortage
@@ -4001,7 +4063,11 @@ em_setup_receive_ring(struct rx_ring *rxr)
 	struct	adapter 	*adapter = rxr->adapter;
 	struct em_buffer	*rxbuf;
 	bus_dma_segment_t	seg[1];
-	int			rsize, nsegs, error;
+	int			rsize, nsegs, error = 0;
+#ifdef DEV_NETMAP
+	struct netmap_adapter *na = NA(adapter->ifp);
+	struct netmap_slot *slot;
+#endif
 
 
 	/* Clear the ring contents */
@@ -4009,6 +4075,9 @@ em_setup_receive_ring(struct rx_ring *rxr)
 	rsize = roundup2(adapter->num_rx_desc *
 	    sizeof(struct e1000_rx_desc), EM_DBA_ALIGN);
 	bzero((void *)rxr->rx_base, rsize);
+#ifdef DEV_NETMAP
+	slot = netmap_reset(na, NR_RX, 0, 0);
+#endif
 
 	/*
 	** Free current RX buffer structs and their mbufs
@@ -4027,7 +4096,20 @@ em_setup_receive_ring(struct rx_ring *rxr)
 	/* Now replenish the mbufs */
         for (int j = 0; j != adapter->num_rx_desc; ++j) {
 		rxbuf = &rxr->rx_buffers[j];
-		rxbuf->m_head = m_getjcl(M_DONTWAIT, MT_DATA,
+#ifdef DEV_NETMAP
+		if (slot) {
+			int si = netmap_idx_n2k(&na->rx_rings[rxr->me], j);
+			uint64_t paddr;
+			void *addr;
+
+			addr = PNMB(slot + si, &paddr);
+			netmap_load_map(rxr->rxtag, rxbuf->map, addr);
+			/* Update descriptor */
+			rxr->rx_base[j].buffer_addr = htole64(paddr);
+			continue;
+		}
+#endif /* DEV_NETMAP */
+		rxbuf->m_head = m_getjcl(M_NOWAIT, MT_DATA,
 		    M_PKTHDR, adapter->rx_mbuf_sz);
 		if (rxbuf->m_head == NULL) {
 			error = ENOBUFS;
@@ -4240,6 +4322,21 @@ em_initialize_receive_unit(struct adapter *adapter)
 		E1000_WRITE_REG(hw, E1000_RDBAL(i), (u32)bus_addr);
 		/* Setup the Head and Tail Descriptor Pointers */
 		E1000_WRITE_REG(hw, E1000_RDH(i), 0);
+#ifdef DEV_NETMAP
+		/*
+		 * an init() while a netmap client is active must
+		 * preserve the rx buffers passed to userspace.
+		 * In this driver it means we adjust RDT to
+		 * something different from na->num_rx_desc - 1.
+		 */
+		if (ifp->if_capenable & IFCAP_NETMAP) {
+			struct netmap_adapter *na = NA(adapter->ifp);
+			struct netmap_kring *kring = &na->rx_rings[i];
+			int t = na->num_rx_desc - 1 - kring->nr_hwavail;
+
+			E1000_WRITE_REG(hw, E1000_RDT(i), t);
+		} else
+#endif /* DEV_NETMAP */
 		E1000_WRITE_REG(hw, E1000_RDT(i), adapter->num_rx_desc - 1);
 	}
 
@@ -4252,7 +4349,7 @@ em_initialize_receive_unit(struct adapter *adapter)
 		E1000_WRITE_REG(hw, E1000_RXDCTL(0), rxdctl | 3);
 	}
 		
-	if (adapter->hw.mac.type == e1000_pch2lan) {
+	if (adapter->hw.mac.type >= e1000_pch2lan) {
 		if (ifp->if_mtu > ETHERMTU)
 			e1000_lv_jumbo_workaround_ich8lan(hw, TRUE);
 		else
@@ -4316,6 +4413,20 @@ em_rxeof(struct rx_ring *rxr, int count, int *done)
 
 	EM_RX_LOCK(rxr);
 
+#ifdef DEV_NETMAP
+	if (ifp->if_capenable & IFCAP_NETMAP) {
+		struct netmap_adapter *na = NA(ifp);
+
+		na->rx_rings[rxr->me].nr_kflags |= NKR_PENDINTR;
+		selwakeuppri(&na->rx_rings[rxr->me].si, PI_NET);
+		EM_RX_UNLOCK(rxr);
+		EM_CORE_LOCK(adapter);
+		selwakeuppri(&na->rx_si, PI_NET);
+		EM_CORE_UNLOCK(adapter);
+		return (0);
+	}
+#endif /* DEV_NETMAP */
+
 	for (i = rxr->next_to_check, processed = 0; count != 0;) {
 
 		if ((ifp->if_drv_flags & IFF_DRV_RUNNING) == 0)
@@ -4372,7 +4483,7 @@ em_rxeof(struct rx_ring *rxr, int count, int *done)
 			ifp->if_ipackets++;
 			em_receive_checksum(cur, sendmp);
 #ifndef __NO_STRICT_ALIGNMENT
-			if (adapter->max_frame_size >
+			if (adapter->hw.mac.max_frame_size >
 			    (MCLBYTES - ETHER_ALIGN) &&
 			    em_fixup_rx(rxr) != 0)
 				goto skip;
@@ -4477,7 +4588,7 @@ em_fixup_rx(struct rx_ring *rxr)
 		bcopy(m->m_data, m->m_data + ETHER_HDR_LEN, m->m_len);
 		m->m_data += ETHER_HDR_LEN;
 	} else {
-		MGETHDR(n, M_DONTWAIT, MT_DATA);
+		MGETHDR(n, M_NOWAIT, MT_DATA);
 		if (n != NULL) {
 			bcopy(m->m_data, n->m_data, ETHER_HDR_LEN);
 			m->m_data += ETHER_HDR_LEN;
@@ -5019,7 +5130,7 @@ em_disable_aspm(struct adapter *adapter)
 		return;
 	reg = base + PCIER_LINK_CTL;
 	link_ctrl = pci_read_config(dev, reg, 2);
-	link_ctrl &= 0xFFFC; /* turn off bit 1 and 2 */
+	link_ctrl &= ~PCIEM_LINK_CTL_ASPMC;
 	pci_write_config(dev, reg, link_ctrl, 2);
 	return;
 }
@@ -5601,6 +5712,27 @@ em_set_flowcntl(SYSCTL_HANDLER_ARGS)
         return (error);
 }
 
+/*
+** Manage Energy Efficient Ethernet:
+** Control values:
+**     0/1 - enabled/disabled
+*/
+static int
+em_sysctl_eee(SYSCTL_HANDLER_ARGS)
+{
+       struct adapter *adapter = (struct adapter *) arg1;
+       int             error, value;
+
+       value = adapter->hw.dev_spec.ich8lan.eee_disable;
+       error = sysctl_handle_int(oidp, &value, 0, req);
+       if (error || req->newptr == NULL)
+               return (error);
+       EM_CORE_LOCK(adapter);
+       adapter->hw.dev_spec.ich8lan.eee_disable = (value != 0);
+       em_init_locked(adapter);
+       EM_CORE_UNLOCK(adapter);
+       return (0);
+}
 
 static int
 em_sysctl_debug_info(SYSCTL_HANDLER_ARGS)
diff --git a/sys/dev/e1000/if_igb.c b/sys/dev/e1000/if_igb.c
index 721e88b..fd88ed2 100644
--- a/sys/dev/e1000/if_igb.c
+++ b/sys/dev/e1000/if_igb.c
@@ -1,6 +1,6 @@
 /******************************************************************************
 
-  Copyright (c) 2001-2011, Intel Corporation 
+  Copyright (c) 2001-2013, Intel Corporation 
   All rights reserved.
   
   Redistribution and use in source and binary forms, with or without 
@@ -100,7 +100,7 @@ int	igb_display_debug_stats = 0;
 /*********************************************************************
  *  Driver version:
  *********************************************************************/
-char igb_driver_version[] = "version - 2.3.1";
+char igb_driver_version[] = "version - 2.3.9 - 8";
 
 
 /*********************************************************************
@@ -150,6 +150,14 @@ static igb_vendor_info_t igb_vendor_info_array[] =
 	{ 0x8086, E1000_DEV_ID_I350_SERDES,	PCI_ANY_ID, PCI_ANY_ID, 0},
 	{ 0x8086, E1000_DEV_ID_I350_SGMII,	PCI_ANY_ID, PCI_ANY_ID, 0},
 	{ 0x8086, E1000_DEV_ID_I350_VF,		PCI_ANY_ID, PCI_ANY_ID, 0},
+	{ 0x8086, E1000_DEV_ID_I210_COPPER,	PCI_ANY_ID, PCI_ANY_ID, 0},
+	{ 0x8086, E1000_DEV_ID_I210_COPPER_IT,	PCI_ANY_ID, PCI_ANY_ID, 0},
+	{ 0x8086, E1000_DEV_ID_I210_COPPER_OEM1,
+						PCI_ANY_ID, PCI_ANY_ID, 0},
+	{ 0x8086, E1000_DEV_ID_I210_FIBER,	PCI_ANY_ID, PCI_ANY_ID, 0},
+	{ 0x8086, E1000_DEV_ID_I210_SERDES,	PCI_ANY_ID, PCI_ANY_ID, 0},
+	{ 0x8086, E1000_DEV_ID_I210_SGMII,	PCI_ANY_ID, PCI_ANY_ID, 0},
+	{ 0x8086, E1000_DEV_ID_I211_COPPER,	PCI_ANY_ID, PCI_ANY_ID, 0},
 	/* required last entry */
 	{ 0, 0, 0, 0, 0}
 };
@@ -173,8 +181,7 @@ static int	igb_suspend(device_t);
 static int	igb_resume(device_t);
 #if __FreeBSD_version >= 800000
 static int	igb_mq_start(struct ifnet *, struct mbuf *);
-static int	igb_mq_start_locked(struct ifnet *,
-		    struct tx_ring *, struct mbuf *);
+static int	igb_mq_start_locked(struct ifnet *, struct tx_ring *);
 static void	igb_qflush(struct ifnet *);
 static void	igb_deferred_mq_start(void *, int);
 #else
@@ -269,6 +276,7 @@ static void	igb_set_sysctl_value(struct adapter *, const char *,
 		    const char *, int *, int);
 static int	igb_set_flowcntl(SYSCTL_HANDLER_ARGS);
 static int	igb_sysctl_dmac(SYSCTL_HANDLER_ARGS);
+static int	igb_sysctl_eee(SYSCTL_HANDLER_ARGS);
 
 #ifdef DEVICE_POLLING
 static poll_handler_t igb_poll;
@@ -286,7 +294,7 @@ static device_method_t igb_methods[] = {
 	DEVMETHOD(device_shutdown, igb_shutdown),
 	DEVMETHOD(device_suspend, igb_suspend),
 	DEVMETHOD(device_resume, igb_resume),
-	{0, 0}
+	DEVMETHOD_END
 };
 
 static driver_t igb_driver = {
@@ -342,6 +350,16 @@ TUNABLE_INT("hw.igb.max_interrupt_rate", &igb_max_interrupt_rate);
 SYSCTL_INT(_hw_igb, OID_AUTO, max_interrupt_rate, CTLFLAG_RDTUN,
     &igb_max_interrupt_rate, 0, "Maximum interrupts per second");
 
+#if __FreeBSD_version >= 800000
+/*
+** Tuneable number of buffers in the buf-ring (drbr_xxx)
+*/
+static int igb_buf_ring_size = IGB_BR_SIZE;
+TUNABLE_INT("hw.igb.buf_ring_size", &igb_buf_ring_size);
+SYSCTL_INT(_hw_igb, OID_AUTO, buf_ring_size, CTLFLAG_RDTUN,
+    &igb_buf_ring_size, 0, "Size of the bufring");
+#endif
+
 /*
 ** Header split causes the packet header to
 ** be dma'd to a seperate mbuf from the payload.
@@ -378,6 +396,9 @@ SYSCTL_INT(_hw_igb, OID_AUTO, rx_process_limit, CTLFLAG_RDTUN,
     &igb_rx_process_limit, 0,
     "Maximum number of received packets to process at a time, -1 means unlimited");
 
+#ifdef DEV_NETMAP	/* see ixgbe.c for details */
+#include <dev/netmap/if_igb_netmap.h>
+#endif /* DEV_NETMAP */
 /*********************************************************************
  *  Device identification routine
  *
@@ -575,11 +596,13 @@ igb_attach(device_t dev)
 		    SYSCTL_CHILDREN(device_get_sysctl_tree(dev)),
 		    OID_AUTO, "dmac", CTLTYPE_INT|CTLFLAG_RW,
 		    adapter, 0, igb_sysctl_dmac, "I", "DMA Coalesce");
-		igb_set_sysctl_value(adapter, "eee_disabled",
-		    "enable Energy Efficient Ethernet",
-		    &adapter->hw.dev_spec._82575.eee_disable,
-		    TRUE);
-		e1000_set_eee_i350(&adapter->hw);
+		SYSCTL_ADD_PROC(device_get_sysctl_ctx(dev),
+		    SYSCTL_CHILDREN(device_get_sysctl_tree(dev)),
+		    OID_AUTO, "eee_disabled", CTLTYPE_INT|CTLFLAG_RW,
+		    adapter, 0, igb_sysctl_eee, "I",
+		    "Disable Energy Efficient Ethernet");
+		if (adapter->hw.phy.media_type == e1000_media_type_copper)
+			e1000_set_eee_i350(&adapter->hw);
 	}
 
 	/*
@@ -590,7 +613,9 @@ igb_attach(device_t dev)
 	e1000_reset_hw(&adapter->hw);
 
 	/* Make sure we have a good EEPROM before we read from it */
-	if (e1000_validate_nvm_checksum(&adapter->hw) < 0) {
+	if (((adapter->hw.mac.type != e1000_i210) &&
+	    (adapter->hw.mac.type != e1000_i211)) &&
+	    (e1000_validate_nvm_checksum(&adapter->hw) < 0)) {
 		/*
 		** Some PCI-E parts fail the first check due to
 		** the link being in sleep state, call it again,
@@ -674,6 +699,9 @@ igb_attach(device_t dev)
 	if (error)
 		goto err_late;
 
+#ifdef DEV_NETMAP
+	igb_netmap_attach(adapter);
+#endif /* DEV_NETMAP */
 	INIT_DEBUGOUT("igb_attach: end");
 
 	return (0);
@@ -752,6 +780,9 @@ igb_detach(device_t dev)
 
 	callout_drain(&adapter->timer);
 
+#ifdef DEV_NETMAP
+	netmap_detach(adapter->ifp);
+#endif /* DEV_NETMAP */
 	igb_free_pci_resources(adapter);
 	bus_generic_detach(dev);
 	if_free(ifp);
@@ -823,7 +854,7 @@ igb_resume(device_t dev)
 			/* Process the stack queue only if not depleted */
 			if (((txr->queue_status & IGB_QUEUE_DEPLETED) == 0) &&
 			    !drbr_empty(ifp, txr->br))
-				igb_mq_start_locked(ifp, txr, NULL);
+				igb_mq_start_locked(ifp, txr);
 #else
 			if (!IFQ_DRV_IS_EMPTY(&ifp->if_snd))
 				igb_start_locked(txr, ifp);
@@ -837,6 +868,8 @@ igb_resume(device_t dev)
 }
 
 
+#if __FreeBSD_version < 800000
+
 /*********************************************************************
  *  Transmit entry point
  *
@@ -913,9 +946,11 @@ igb_start(struct ifnet *ifp)
 	return;
 }
 
-#if __FreeBSD_version >= 800000
+#else /* __FreeBSD_version >= 800000 */
+
 /*
-** Multiqueue Transmit driver
+** Multiqueue Transmit Entry:
+**  quick turnaround to the stack
 **
 */
 static int
@@ -925,69 +960,50 @@ igb_mq_start(struct ifnet *ifp, struct mbuf *m)
 	struct igb_queue	*que;
 	struct tx_ring		*txr;
 	int 			i, err = 0;
-	bool			moveable = TRUE;
 
 	/* Which queue to use */
-	if ((m->m_flags & M_FLOWID) != 0) {
+	if ((m->m_flags & M_FLOWID) != 0)
 		i = m->m_pkthdr.flowid % adapter->num_queues;
-		moveable = FALSE;
-	} else
+	else
 		i = curcpu % adapter->num_queues;
-
 	txr = &adapter->tx_rings[i];
 	que = &adapter->queues[i];
-	if (((txr->queue_status & IGB_QUEUE_DEPLETED) == 0) &&
-	    IGB_TX_TRYLOCK(txr)) {
-		err = igb_mq_start_locked(ifp, txr, m);
-		IGB_TX_UNLOCK(txr);
-	} else {
-		err = drbr_enqueue(ifp, txr->br, m);
-		taskqueue_enqueue(que->tq, &txr->txq_task);
-	}
+
+	err = drbr_enqueue(ifp, txr->br, m);
+	taskqueue_enqueue(que->tq, &txr->txq_task);
 
 	return (err);
 }
 
 static int
-igb_mq_start_locked(struct ifnet *ifp, struct tx_ring *txr, struct mbuf *m)
+igb_mq_start_locked(struct ifnet *ifp, struct tx_ring *txr)
 {
 	struct adapter  *adapter = txr->adapter;
-        struct mbuf     *next;
-        int             err = 0, enq;
+        struct mbuf     *buf;
+        int             err = 0, enq = 0;
 
 	IGB_TX_LOCK_ASSERT(txr);
 
 	if (((ifp->if_drv_flags & IFF_DRV_RUNNING) == 0) ||
-	    (txr->queue_status == IGB_QUEUE_DEPLETED) ||
-	    adapter->link_active == 0) {
-		if (m != NULL)
-			err = drbr_enqueue(ifp, txr->br, m);
-		return (err);
-	}
-
-	enq = 0;
-	if (m == NULL) {
-		next = drbr_dequeue(ifp, txr->br);
-	} else if (drbr_needs_enqueue(ifp, txr->br)) {
-		if ((err = drbr_enqueue(ifp, txr->br, m)) != 0)
-			return (err);
-		next = drbr_dequeue(ifp, txr->br);
-	} else
-		next = m;
+	    adapter->link_active == 0)
+		return (ENETDOWN);
 
 	/* Process the queue */
-	while (next != NULL) {
-		if ((err = igb_xmit(txr, &next)) != 0) {
-			if (next != NULL)
-				err = drbr_enqueue(ifp, txr->br, next);
+	buf = drbr_dequeue(ifp, txr->br);
+	while (buf != NULL) {
+		if ((err = igb_xmit(txr, &buf)) != 0) {
+			if (buf != NULL)
+				err = drbr_enqueue(ifp, txr->br, buf);
 			break;
 		}
 		enq++;
-		drbr_stats_update(ifp, next->m_pkthdr.len, next->m_flags);
-		ETHER_BPF_MTAP(ifp, next);
+		ifp->if_obytes += buf->m_pkthdr.len;
+		if (buf->m_flags & M_MCAST)
+			ifp->if_omcasts++;
+		ETHER_BPF_MTAP(ifp, buf);
 		if ((ifp->if_drv_flags & IFF_DRV_RUNNING) == 0)
 			break;
-		next = drbr_dequeue(ifp, txr->br);
+		buf = drbr_dequeue(ifp, txr->br);
 	}
 	if (enq > 0) {
 		/* Set the watchdog */
@@ -1013,7 +1029,7 @@ igb_deferred_mq_start(void *arg, int pending)
 
 	IGB_TX_LOCK(txr);
 	if (!drbr_empty(ifp, txr->br))
-		igb_mq_start_locked(ifp, txr, NULL);
+		igb_mq_start_locked(ifp, txr);
 	IGB_TX_UNLOCK(txr);
 }
 
@@ -1331,8 +1347,8 @@ igb_init_locked(struct adapter *adapter)
 	}
 
 	/* Set Energy Efficient Ethernet */
-
-	e1000_set_eee_i350(&adapter->hw);
+	if (adapter->hw.phy.media_type == e1000_media_type_copper)
+		e1000_set_eee_i350(&adapter->hw);
 }
 
 static void
@@ -1365,7 +1381,7 @@ igb_handle_que(void *context, int pending)
 		/* Process the stack queue only if not depleted */
 		if (((txr->queue_status & IGB_QUEUE_DEPLETED) == 0) &&
 		    !drbr_empty(ifp, txr->br))
-			igb_mq_start_locked(ifp, txr, NULL);
+			igb_mq_start_locked(ifp, txr);
 #else
 		if (!IFQ_DRV_IS_EMPTY(&ifp->if_snd))
 			igb_start_locked(txr, ifp);
@@ -1416,7 +1432,7 @@ igb_handle_link_locked(struct adapter *adapter)
 			/* Process the stack queue only if not depleted */
 			if (((txr->queue_status & IGB_QUEUE_DEPLETED) == 0) &&
 			    !drbr_empty(ifp, txr->br))
-				igb_mq_start_locked(ifp, txr, NULL);
+				igb_mq_start_locked(ifp, txr);
 #else
 			if (!IFQ_DRV_IS_EMPTY(&ifp->if_snd))
 				igb_start_locked(txr, ifp);
@@ -1471,12 +1487,6 @@ igb_irq_fast(void *arg)
 }
 
 #ifdef DEVICE_POLLING
-/*********************************************************************
- *
- *  Legacy polling routine : if using this code you MUST be sure that
- *  multiqueue is not defined, ie, set igb_num_queues to 1.
- *
- *********************************************************************/
 #if __FreeBSD_version >= 800000
 #define POLL_RETURN_COUNT(a) (a)
 static int
@@ -1487,8 +1497,8 @@ static void
 igb_poll(struct ifnet *ifp, enum poll_cmd cmd, int count)
 {
 	struct adapter		*adapter = ifp->if_softc;
-	struct igb_queue	*que = adapter->queues;
-	struct tx_ring		*txr = adapter->tx_rings;
+	struct igb_queue	*que;
+	struct tx_ring		*txr;
 	u32			reg_icr, rx_done = 0;
 	u32			loop = IGB_MAX_LOOP;
 	bool			more;
@@ -1510,20 +1520,26 @@ igb_poll(struct ifnet *ifp, enum poll_cmd cmd, int count)
 	}
 	IGB_CORE_UNLOCK(adapter);
 
-	igb_rxeof(que, count, &rx_done);
+	for (int i = 0; i < adapter->num_queues; i++) {
+		que = &adapter->queues[i];
+		txr = que->txr;
 
-	IGB_TX_LOCK(txr);
-	do {
-		more = igb_txeof(txr);
-	} while (loop-- && more);
+		igb_rxeof(que, count, &rx_done);
+
+		IGB_TX_LOCK(txr);
+		do {
+			more = igb_txeof(txr);
+		} while (loop-- && more);
 #if __FreeBSD_version >= 800000
-	if (!drbr_empty(ifp, txr->br))
-		igb_mq_start_locked(ifp, txr, NULL);
+		if (!drbr_empty(ifp, txr->br))
+			igb_mq_start_locked(ifp, txr);
 #else
-	if (!IFQ_DRV_IS_EMPTY(&ifp->if_snd))
-		igb_start_locked(txr, ifp);
+		if (!IFQ_DRV_IS_EMPTY(&ifp->if_snd))
+			igb_start_locked(txr, ifp);
 #endif
-	IGB_TX_UNLOCK(txr);
+		IGB_TX_UNLOCK(txr);
+	}
+
 	return POLL_RETURN_COUNT(rx_done);
 }
 #endif /* DEVICE_POLLING */
@@ -1553,7 +1569,7 @@ igb_msix_que(void *arg)
 	/* Process the stack queue only if not depleted */
 	if (((txr->queue_status & IGB_QUEUE_DEPLETED) == 0) &&
 	    !drbr_empty(ifp, txr->br))
-		igb_mq_start_locked(ifp, txr, NULL);
+		igb_mq_start_locked(ifp, txr);
 #else
 	if (!IFQ_DRV_IS_EMPTY(&ifp->if_snd))
 		igb_start_locked(txr, ifp);
@@ -1662,7 +1678,6 @@ static void
 igb_media_status(struct ifnet *ifp, struct ifmediareq *ifmr)
 {
 	struct adapter *adapter = ifp->if_softc;
-	u_char fiber_type = IFM_1000_SX;
 
 	INIT_DEBUGOUT("igb_media_status: begin");
 
@@ -1679,26 +1694,31 @@ igb_media_status(struct ifnet *ifp, struct ifmediareq *ifmr)
 
 	ifmr->ifm_status |= IFM_ACTIVE;
 
-	if ((adapter->hw.phy.media_type == e1000_media_type_fiber) ||
-	    (adapter->hw.phy.media_type == e1000_media_type_internal_serdes))
-		ifmr->ifm_active |= fiber_type | IFM_FDX;
-	else {
-		switch (adapter->link_speed) {
-		case 10:
-			ifmr->ifm_active |= IFM_10_T;
-			break;
-		case 100:
-			ifmr->ifm_active |= IFM_100_TX;
-			break;
-		case 1000:
-			ifmr->ifm_active |= IFM_1000_T;
-			break;
-		}
-		if (adapter->link_duplex == FULL_DUPLEX)
-			ifmr->ifm_active |= IFM_FDX;
+	switch (adapter->link_speed) {
+	case 10:
+		ifmr->ifm_active |= IFM_10_T;
+		break;
+	case 100:
+		/*
+		** Support for 100Mb SFP - these are Fiber 
+		** but the media type appears as serdes
+		*/
+		if (adapter->hw.phy.media_type ==
+		    e1000_media_type_internal_serdes)
+			ifmr->ifm_active |= IFM_100_FX;
 		else
-			ifmr->ifm_active |= IFM_HDX;
+			ifmr->ifm_active |= IFM_100_TX;
+		break;
+	case 1000:
+		ifmr->ifm_active |= IFM_1000_T;
+		break;
 	}
+
+	if (adapter->link_duplex == FULL_DUPLEX)
+		ifmr->ifm_active |= IFM_FDX;
+	else
+		ifmr->ifm_active |= IFM_HDX;
+
 	IGB_CORE_UNLOCK(adapter);
 }
 
@@ -1811,7 +1831,7 @@ retry:
 		if (do_tso || (m_head->m_next != NULL && 
 		    m_head->m_pkthdr.csum_flags & CSUM_OFFLOAD)) {
 			if (M_WRITABLE(*m_headp) == 0) {
-				m_head = m_dup(*m_headp, M_DONTWAIT);
+				m_head = m_dup(*m_headp, M_NOWAIT);
 				m_freem(*m_headp);
 				if (m_head == NULL) {
 					*m_headp = NULL;
@@ -1916,7 +1936,7 @@ retry:
 	if (error == EFBIG && remap) {
 		struct mbuf *m;
 
-		m = m_defrag(*m_headp, M_DONTWAIT);
+		m = m_defrag(*m_headp, M_NOWAIT);
 		if (m == NULL) {
 			adapter->mbuf_defrag_failed++;
 			m_freem(*m_headp);
@@ -2201,11 +2221,13 @@ timeout:
 static void
 igb_update_link_status(struct adapter *adapter)
 {
-	struct e1000_hw *hw = &adapter->hw;
-	struct ifnet *ifp = adapter->ifp;
-	device_t dev = adapter->dev;
-	struct tx_ring *txr = adapter->tx_rings;
-	u32 link_check, thstat, ctrl;
+	struct e1000_hw		*hw = &adapter->hw;
+	struct e1000_fc_info	*fc = &hw->fc;
+	struct ifnet		*ifp = adapter->ifp;
+	device_t		dev = adapter->dev;
+	struct tx_ring		*txr = adapter->tx_rings;
+	u32			link_check, thstat, ctrl;
+	char			*flowctl = NULL;
 
 	link_check = thstat = ctrl = 0;
 
@@ -2243,15 +2265,33 @@ igb_update_link_status(struct adapter *adapter)
 		ctrl = E1000_READ_REG(hw, E1000_CTRL_EXT);
 	}
 
+	/* Get the flow control for display */
+	switch (fc->current_mode) {
+	case e1000_fc_rx_pause:
+		flowctl = "RX";
+		break;	
+	case e1000_fc_tx_pause:
+		flowctl = "TX";
+		break;	
+	case e1000_fc_full:
+		flowctl = "Full";
+		break;	
+	case e1000_fc_none:
+	default:
+		flowctl = "None";
+		break;	
+	}
+
 	/* Now we check if a transition has happened */
 	if (link_check && (adapter->link_active == 0)) {
 		e1000_get_speed_and_duplex(&adapter->hw, 
 		    &adapter->link_speed, &adapter->link_duplex);
 		if (bootverbose)
-			device_printf(dev, "Link is up %d Mbps %s\n",
+			device_printf(dev, "Link is up %d Mbps %s,"
+			    " Flow Control: %s\n",
 			    adapter->link_speed,
 			    ((adapter->link_duplex == FULL_DUPLEX) ?
-			    "Full Duplex" : "Half Duplex"));
+			    "Full Duplex" : "Half Duplex"), flowctl);
 		adapter->link_active = 1;
 		ifp->if_baudrate = adapter->link_speed * 1000000;
 		if ((ctrl & E1000_CTRL_EXT_LINK_MODE_GMII) &&
@@ -2499,7 +2539,6 @@ igb_allocate_msix(struct adapter *adapter)
 				"Bound queue %d to cpu %d\n",
 				i,igb_last_bind_cpu);
 			igb_last_bind_cpu = CPU_NEXT(igb_last_bind_cpu);
-			igb_last_bind_cpu = igb_last_bind_cpu % mp_ncpus;
 		}
 #if __FreeBSD_version >= 800000
 		TASK_INIT(&que->txr->txq_task, 0, igb_deferred_mq_start,
@@ -2555,6 +2594,8 @@ igb_configure_queues(struct adapter *adapter)
 	switch (adapter->hw.mac.type) {
 	case e1000_82580:
 	case e1000_i350:
+	case e1000_i210:
+	case e1000_i211:
 	case e1000_vfadapt:
 	case e1000_vfadapt_i350:
 		/* RX entries */
@@ -2753,7 +2794,7 @@ static int
 igb_setup_msix(struct adapter *adapter)
 {
 	device_t dev = adapter->dev;
-	int rid, want, queues, msgs;
+	int rid, want, queues, msgs, maxqueues;
 
 	/* tuneable override */
 	if (igb_enable_msix == 0)
@@ -2784,16 +2825,29 @@ igb_setup_msix(struct adapter *adapter)
 	/* Manual override */
 	if (igb_num_queues != 0)
 		queues = igb_num_queues;
-	if (queues > 8)  /* max queues */
-		queues = 8;
-
-	/* Can have max of 4 queues on 82575 */
-	if ((adapter->hw.mac.type == e1000_82575) && (queues > 4))
-		queues = 4;
 
-	/* Limit the VF devices to one queue */
-	if (adapter->vf_ifp)
-		queues = 1;
+	/* Sanity check based on HW */
+	switch (adapter->hw.mac.type) {
+		case e1000_82575:
+			maxqueues = 4;
+			break;
+		case e1000_82576:
+		case e1000_82580:
+		case e1000_i350:
+			maxqueues = 8;
+			break;
+		case e1000_i210:
+			maxqueues = 4;
+			break;
+		case e1000_i211:
+			maxqueues = 2;
+			break;
+		default:  /* VF interfaces */
+			maxqueues = 1;
+			break;
+	}
+	if (queues > maxqueues)
+		queues = maxqueues;
 
 	/*
 	** One vector (RX/TX pair) per queue
@@ -2864,6 +2918,9 @@ igb_reset(struct adapter *adapter)
 		pba = E1000_READ_REG(hw, E1000_RXPBS);
 		pba = e1000_rxpbs_adjust_82580(pba);
 		break;
+	case e1000_i210:
+	case e1000_i211:
+		pba = E1000_PBA_34K;
 	default:
 		break;
 	}
@@ -2931,7 +2988,9 @@ igb_reset(struct adapter *adapter)
 		device_printf(dev, "Hardware Initialization Failed\n");
 
 	/* Setup DMA Coalescing */
-	if (hw->mac.type == e1000_i350) {
+	if ((hw->mac.type > e1000_82580) &&
+	    (hw->mac.type != e1000_i211)) {
+		u32 dmac;
 		u32 reg = ~E1000_DMACR_DMAC_EN;
 
 		if (adapter->dmac == 0) { /* Disabling it */
@@ -2939,26 +2998,36 @@ igb_reset(struct adapter *adapter)
 			goto reset_out;
 		}
 
-		hwm = (pba - 4) << 10;
-		reg = (((pba-6) << E1000_DMACR_DMACTHR_SHIFT)
-		    & E1000_DMACR_DMACTHR_MASK);
+		/* Set starting thresholds */
+		E1000_WRITE_REG(hw, E1000_DMCTXTH, 0);
+		E1000_WRITE_REG(hw, E1000_DMCRTRH, 0);
 
+		hwm = 64 * pba - adapter->max_frame_size / 16;
+		if (hwm < 64 * (pba - 6))
+			hwm = 64 * (pba - 6);
+		reg = E1000_READ_REG(hw, E1000_FCRTC);
+		reg &= ~E1000_FCRTC_RTH_COAL_MASK;
+		reg |= ((hwm << E1000_FCRTC_RTH_COAL_SHIFT)
+		    & E1000_FCRTC_RTH_COAL_MASK);
+		E1000_WRITE_REG(hw, E1000_FCRTC, reg);
+
+
+		dmac = pba - adapter->max_frame_size / 512;
+		if (dmac < pba - 10)
+			dmac = pba - 10;
+		reg = E1000_READ_REG(hw, E1000_DMACR);
+		reg &= ~E1000_DMACR_DMACTHR_MASK;
+		reg = ((dmac << E1000_DMACR_DMACTHR_SHIFT)
+		    & E1000_DMACR_DMACTHR_MASK);
 		/* transition to L0x or L1 if available..*/
 		reg |= (E1000_DMACR_DMAC_EN | E1000_DMACR_DMAC_LX_MASK);
-
 		/* timer = value in adapter->dmac in 32usec intervals */
 		reg |= (adapter->dmac >> 5);
 		E1000_WRITE_REG(hw, E1000_DMACR, reg);
 
-		/* No lower threshold */
-		E1000_WRITE_REG(hw, E1000_DMCRTRH, 0);
-
-		/* set hwm to PBA -  2 * max frame size */
-		E1000_WRITE_REG(hw, E1000_FCRTC, hwm);
-
 		/* Set the interval before transition */
 		reg = E1000_READ_REG(hw, E1000_DMCTLX);
-		reg |= 0x800000FF; /* 255 usec */
+		reg |= 0x80000004;
 		E1000_WRITE_REG(hw, E1000_DMCTLX, reg);
 
 		/* free space in tx packet buffer to wake from DMA coal */
@@ -2967,9 +3036,15 @@ igb_reset(struct adapter *adapter)
 
 		/* make low power state decision controlled by DMA coal */
 		reg = E1000_READ_REG(hw, E1000_PCIEMISC);
-		E1000_WRITE_REG(hw, E1000_PCIEMISC,
-		    reg | E1000_PCIEMISC_LX_DECISION);
+		reg &= ~E1000_PCIEMISC_LX_DECISION;
+		E1000_WRITE_REG(hw, E1000_PCIEMISC, reg);
 		device_printf(dev, "DMA Coalescing enabled\n");
+
+	} else if (hw->mac.type == e1000_82580) {
+		u32 reg = E1000_READ_REG(hw, E1000_PCIEMISC);
+		E1000_WRITE_REG(hw, E1000_DMACR, 0);
+		E1000_WRITE_REG(hw, E1000_PCIEMISC,
+		    reg & ~E1000_PCIEMISC_LX_DECISION);
 	}
 
 reset_out:
@@ -3001,14 +3076,15 @@ igb_setup_interface(device_t dev, struct adapter *adapter)
 	ifp->if_softc = adapter;
 	ifp->if_flags = IFF_BROADCAST | IFF_SIMPLEX | IFF_MULTICAST;
 	ifp->if_ioctl = igb_ioctl;
-	ifp->if_start = igb_start;
 #if __FreeBSD_version >= 800000
 	ifp->if_transmit = igb_mq_start;
 	ifp->if_qflush = igb_qflush;
-#endif
+#else
+	ifp->if_start = igb_start;
 	IFQ_SET_MAXLEN(&ifp->if_snd, adapter->num_tx_desc - 1);
 	ifp->if_snd.ifq_drv_maxlen = adapter->num_tx_desc - 1;
 	IFQ_SET_READY(&ifp->if_snd);
+#endif
 
 	ether_ifattach(ifp, adapter->hw.mac.addr);
 
@@ -3246,7 +3322,7 @@ igb_allocate_queues(struct adapter *adapter)
         	}
 #if __FreeBSD_version >= 800000
 		/* Allocate a buf ring */
-		txr->br = buf_ring_alloc(IGB_BR_SIZE, M_DEVBUF,
+		txr->br = buf_ring_alloc(igb_buf_ring_size, M_DEVBUF,
 		    M_WAITOK, &txr->tx_mtx);
 #endif
 	}
@@ -3385,9 +3461,16 @@ igb_setup_transmit_ring(struct tx_ring *txr)
 	struct adapter *adapter = txr->adapter;
 	struct igb_tx_buffer *txbuf;
 	int i;
+#ifdef DEV_NETMAP
+	struct netmap_adapter *na = NA(adapter->ifp);
+	struct netmap_slot *slot;
+#endif /* DEV_NETMAP */
 
 	/* Clear the old descriptor contents */
 	IGB_TX_LOCK(txr);
+#ifdef DEV_NETMAP
+	slot = netmap_reset(na, NR_TX, txr->me, 0);
+#endif /* DEV_NETMAP */
 	bzero((void *)txr->tx_base,
 	      (sizeof(union e1000_adv_tx_desc)) * adapter->num_tx_desc);
 	/* Reset indices */
@@ -3404,6 +3487,13 @@ igb_setup_transmit_ring(struct tx_ring *txr)
 			m_freem(txbuf->m_head);
 			txbuf->m_head = NULL;
 		}
+#ifdef DEV_NETMAP
+		if (slot) {
+			int si = netmap_idx_n2k(&na->tx_rings[txr->me], i);
+			/* no need to set the address */
+			netmap_load_map(txr->txtag, txbuf->map, NMB(slot + si));
+		}
+#endif /* DEV_NETMAP */
 		/* clear the watch index */
 		txbuf->next_eop = -1;
         }
@@ -3770,6 +3860,19 @@ igb_txeof(struct tx_ring *txr)
 
 	IGB_TX_LOCK_ASSERT(txr);
 
+#ifdef DEV_NETMAP
+	if (ifp->if_capenable & IFCAP_NETMAP) {
+		struct netmap_adapter *na = NA(ifp);
+
+		selwakeuppri(&na->tx_rings[txr->me].si, PI_NET);
+		IGB_TX_UNLOCK(txr);
+		IGB_CORE_LOCK(adapter);
+		selwakeuppri(&na->tx_si, PI_NET);
+		IGB_CORE_UNLOCK(adapter);
+		IGB_TX_LOCK(txr);
+		return FALSE;
+	}
+#endif /* DEV_NETMAP */
         if (txr->tx_avail == adapter->num_tx_desc) {
 		txr->queue_status = IGB_QUEUE_IDLE;
                 return FALSE;
@@ -3901,7 +4004,7 @@ igb_refresh_mbufs(struct rx_ring *rxr, int limit)
 		if (rxr->hdr_split == FALSE)
 			goto no_split;
 		if (rxbuf->m_head == NULL) {
-			mh = m_gethdr(M_DONTWAIT, MT_DATA);
+			mh = m_gethdr(M_NOWAIT, MT_DATA);
 			if (mh == NULL)
 				goto update;
 		} else
@@ -3927,7 +4030,7 @@ igb_refresh_mbufs(struct rx_ring *rxr, int limit)
 		    htole64(hseg[0].ds_addr);
 no_split:
 		if (rxbuf->m_pack == NULL) {
-			mp = m_getjcl(M_DONTWAIT, MT_DATA,
+			mp = m_getjcl(M_NOWAIT, MT_DATA,
 			    M_PKTHDR, adapter->rx_mbuf_sz);
 			if (mp == NULL)
 				goto update;
@@ -4093,6 +4196,10 @@ igb_setup_receive_ring(struct rx_ring *rxr)
 	bus_dma_segment_t	pseg[1], hseg[1];
 	struct lro_ctrl		*lro = &rxr->lro;
 	int			rsize, nsegs, error = 0;
+#ifdef DEV_NETMAP
+	struct netmap_adapter *na = NA(rxr->adapter->ifp);
+	struct netmap_slot *slot;
+#endif /* DEV_NETMAP */
 
 	adapter = rxr->adapter;
 	dev = adapter->dev;
@@ -4100,6 +4207,9 @@ igb_setup_receive_ring(struct rx_ring *rxr)
 
 	/* Clear the ring contents */
 	IGB_RX_LOCK(rxr);
+#ifdef DEV_NETMAP
+	slot = netmap_reset(na, NR_RX, rxr->me, 0);
+#endif /* DEV_NETMAP */
 	rsize = roundup2(adapter->num_rx_desc *
 	    sizeof(union e1000_adv_rx_desc), IGB_DBA_ALIGN);
 	bzero((void *)rxr->rx_base, rsize);
@@ -4118,11 +4228,25 @@ igb_setup_receive_ring(struct rx_ring *rxr)
 		struct mbuf	*mh, *mp;
 
 		rxbuf = &rxr->rx_buffers[j];
+#ifdef DEV_NETMAP
+		if (slot) {
+			/* slot sj is mapped to the i-th NIC-ring entry */
+			int sj = netmap_idx_n2k(&na->rx_rings[rxr->me], j);
+			uint64_t paddr;
+			void *addr;
+
+			addr = PNMB(slot + sj, &paddr);
+			netmap_load_map(rxr->ptag, rxbuf->pmap, addr);
+			/* Update descriptor */
+			rxr->rx_base[j].read.pkt_addr = htole64(paddr);
+			continue;
+		}
+#endif /* DEV_NETMAP */
 		if (rxr->hdr_split == FALSE)
 			goto skip_head;
 
 		/* First the header */
-		rxbuf->m_head = m_gethdr(M_DONTWAIT, MT_DATA);
+		rxbuf->m_head = m_gethdr(M_NOWAIT, MT_DATA);
 		if (rxbuf->m_head == NULL) {
 			error = ENOBUFS;
                         goto fail;
@@ -4144,7 +4268,7 @@ igb_setup_receive_ring(struct rx_ring *rxr)
 
 skip_head:
 		/* Now the payload cluster */
-		rxbuf->m_pack = m_getjcl(M_DONTWAIT, MT_DATA,
+		rxbuf->m_pack = m_getjcl(M_NOWAIT, MT_DATA,
 		    M_PKTHDR, adapter->rx_mbuf_sz);
 		if (rxbuf->m_pack == NULL) {
 			error = ENOBUFS;
@@ -4227,8 +4351,8 @@ fail:
 	 * the rings that completed, the failing case will have
 	 * cleaned up for itself. 'i' is the endpoint.
 	 */
-	for (int j = 0; j > i; ++j) {
-		rxr = &adapter->rx_rings[i];
+	for (int j = 0; j < i; ++j) {
+		rxr = &adapter->rx_rings[j];
 		IGB_RX_LOCK(rxr);
 		igb_free_receive_ring(rxr);
 		IGB_RX_UNLOCK(rxr);
@@ -4402,6 +4526,26 @@ igb_initialize_receive_units(struct adapter *adapter)
 	for (int i = 0; i < adapter->num_queues; i++) {
 		rxr = &adapter->rx_rings[i];
 		E1000_WRITE_REG(hw, E1000_RDH(i), rxr->next_to_check);
+#ifdef DEV_NETMAP
+		/*
+		 * an init() while a netmap client is active must
+		 * preserve the rx buffers passed to userspace.
+		 * In this driver it means we adjust RDT to
+		 * somthing different from next_to_refresh
+		 * (which is not used in netmap mode).
+		 */
+		if (ifp->if_capenable & IFCAP_NETMAP) {
+			struct netmap_adapter *na = NA(adapter->ifp);
+			struct netmap_kring *kring = &na->rx_rings[i];
+			int t = rxr->next_to_refresh - kring->nr_hwavail;
+
+			if (t >= adapter->num_rx_desc)
+				t -= adapter->num_rx_desc;
+			else if (t < 0)
+				t += adapter->num_rx_desc;
+			E1000_WRITE_REG(hw, E1000_RDT(i), t);
+		} else
+#endif /* DEV_NETMAP */
 		E1000_WRITE_REG(hw, E1000_RDT(i), rxr->next_to_refresh);
 	}
 	return;
@@ -4580,6 +4724,20 @@ igb_rxeof(struct igb_queue *que, int count, int *done)
 	bus_dmamap_sync(rxr->rxdma.dma_tag, rxr->rxdma.dma_map,
 	    BUS_DMASYNC_POSTREAD | BUS_DMASYNC_POSTWRITE);
 
+#ifdef DEV_NETMAP
+	if (ifp->if_capenable & IFCAP_NETMAP) {
+		struct netmap_adapter *na = NA(ifp);
+
+		na->rx_rings[rxr->me].nr_kflags |= NKR_PENDINTR;
+		selwakeuppri(&na->rx_rings[rxr->me].si, PI_NET);
+		IGB_RX_UNLOCK(rxr);
+		IGB_CORE_LOCK(adapter);
+		selwakeuppri(&na->rx_si, PI_NET);
+		IGB_CORE_UNLOCK(adapter);
+		return (0);
+	}
+#endif /* DEV_NETMAP */
+
 	/* Main clean loop */
 	for (i = rxr->next_to_check; count != 0;) {
 		struct mbuf		*sendmp, *mh, *mp;
@@ -4752,7 +4910,7 @@ next_desc:
 	}
 
 	if (done != NULL)
-		*done = rxdone;
+		*done += rxdone;
 
 	IGB_RX_UNLOCK(rxr);
 	return ((staterr & E1000_RXD_STAT_DD) ? TRUE : FALSE);
@@ -5848,3 +6006,25 @@ igb_sysctl_dmac(SYSCTL_HANDLER_ARGS)
 	igb_init(adapter);
 	return (error);
 }
+
+/*
+** Manage Energy Efficient Ethernet:
+** Control values:
+**     0/1 - enabled/disabled
+*/
+static int
+igb_sysctl_eee(SYSCTL_HANDLER_ARGS)
+{
+	struct adapter	*adapter = (struct adapter *) arg1;
+	int		error, value;
+
+	value = adapter->hw.dev_spec._82575.eee_disable;
+	error = sysctl_handle_int(oidp, &value, 0, req);
+	if (error || req->newptr == NULL)
+		return (error);
+	IGB_CORE_LOCK(adapter);
+	adapter->hw.dev_spec._82575.eee_disable = (value != 0);
+	igb_init_locked(adapter);
+	IGB_CORE_UNLOCK(adapter);
+	return (0);
+}
diff --git a/sys/dev/e1000/if_igb.h b/sys/dev/e1000/if_igb.h
index 8ff1b44..f286e67 100644
--- a/sys/dev/e1000/if_igb.h
+++ b/sys/dev/e1000/if_igb.h
@@ -52,7 +52,7 @@
 #define IGB_MAX_TXD		4096
 
 /*
- * IGB_RXD: Maximum number of Transmit Descriptors
+ * IGB_RXD: Maximum number of Receive Descriptors
  *
  *   This value is the number of receive descriptors allocated by the driver.
  *   Increasing this value allows the driver to buffer more incoming packets.
@@ -299,9 +299,9 @@ struct tx_ring {
 	struct igb_tx_buffer	*tx_buffers;
 #if __FreeBSD_version >= 800000
 	struct buf_ring		*br;
+	struct task		txq_task;
 #endif
 	bus_dma_tag_t		txtag;
-	struct task		txq_task;
 
 	u32			bytes;
 	u32			packets;
diff --git a/sys/dev/e1000/if_lem.c b/sys/dev/e1000/if_lem.c
index 4690249..655504d 100644
--- a/sys/dev/e1000/if_lem.c
+++ b/sys/dev/e1000/if_lem.c
@@ -1,6 +1,6 @@
 /******************************************************************************
 
-  Copyright (c) 2001-2011, Intel Corporation 
+  Copyright (c) 2001-2012, Intel Corporation 
   All rights reserved.
   
   Redistribution and use in source and binary forms, with or without 
@@ -85,7 +85,7 @@
 /*********************************************************************
  *  Legacy Em Driver version:
  *********************************************************************/
-char lem_driver_version[] = "1.0.4";
+char lem_driver_version[] = "1.0.5";
 
 /*********************************************************************
  *  PCI Device ID Table
@@ -239,15 +239,12 @@ static void     lem_enable_wakeup(device_t);
 static int	lem_enable_phy_wakeup(struct adapter *);
 static void	lem_led_func(void *, int);
 
-#ifdef EM_LEGACY_IRQ
 static void	lem_intr(void *);
-#else /* FAST IRQ */
 static int	lem_irq_fast(void *);
 static void	lem_handle_rxtx(void *context, int pending);
 static void	lem_handle_link(void *context, int pending);
 static void	lem_add_rx_process_limit(struct adapter *, const char *,
 		    const char *, int *, int);
-#endif /* ~EM_LEGACY_IRQ */
 
 #ifdef DEVICE_POLLING
 static poll_handler_t lem_poll;
@@ -265,7 +262,7 @@ static device_method_t lem_methods[] = {
 	DEVMETHOD(device_shutdown, lem_shutdown),
 	DEVMETHOD(device_suspend, lem_suspend),
 	DEVMETHOD(device_resume, lem_resume),
-	{0, 0}
+	DEVMETHOD_END
 };
 
 static driver_t lem_driver = {
@@ -304,11 +301,13 @@ TUNABLE_INT("hw.em.txd", &lem_txd);
 TUNABLE_INT("hw.em.smart_pwr_down", &lem_smart_pwr_down);
 TUNABLE_INT("hw.em.sbp", &lem_debug_sbp);
 
-#ifndef EM_LEGACY_IRQ
+/* Interrupt style - default to fast */
+static int lem_use_legacy_irq = 0;
+TUNABLE_INT("hw.em.use_legacy_irq", &lem_use_legacy_irq);
+
 /* How many packets rxeof tries to clean at a time */
 static int lem_rx_process_limit = 100;
 TUNABLE_INT("hw.em.rx_process_limit", &lem_rx_process_limit);
-#endif
 
 /* Flow control setting - default to FULL */
 static int lem_fc_setting = e1000_fc_full;
@@ -317,6 +316,10 @@ TUNABLE_INT("hw.em.fc_setting", &lem_fc_setting);
 /* Global used in WOL setup with multiport cards */
 static int global_quad_port_a = 0;
 
+#ifdef DEV_NETMAP	/* see ixgbe.c for details */
+#include <dev/netmap/if_lem_netmap.h>
+#endif /* DEV_NETMAP */
+
 /*********************************************************************
  *  Device identification routine
  *
@@ -446,12 +449,10 @@ lem_attach(device_t dev)
 		    lem_tx_abs_int_delay_dflt);
 	}
 
-#ifndef EM_LEGACY_IRQ
 	/* Sysctls for limiting the amount of work done in the taskqueue */
 	lem_add_rx_process_limit(adapter, "rx_processing_limit",
 	    "max number of rx packets to process", &adapter->rx_process_limit,
 	    lem_rx_process_limit);
-#endif
 
         /* Sysctl for setting the interface flow control */
 	lem_set_flow_cntrl(adapter, "flow_control",
@@ -652,6 +653,9 @@ lem_attach(device_t dev)
 	adapter->led_dev = led_create(lem_led_func, adapter,
 	    device_get_nameunit(dev));
 
+#ifdef DEV_NETMAP
+	lem_netmap_attach(adapter);
+#endif /* DEV_NETMAP */
 	INIT_DEBUGOUT("lem_attach: end");
 
 	return (0);
@@ -730,6 +734,9 @@ lem_detach(device_t dev)
 	callout_drain(&adapter->timer);
 	callout_drain(&adapter->tx_fifo_timer);
 
+#ifdef DEV_NETMAP
+	netmap_detach(ifp);
+#endif /* DEV_NETMAP */
 	lem_free_pci_resources(adapter);
 	bus_generic_detach(dev);
 	if_free(ifp);
@@ -1187,22 +1194,6 @@ lem_init_locked(struct adapter *adapter)
 	callout_reset(&adapter->timer, hz, lem_local_timer, adapter);
 	e1000_clear_hw_cntrs_base_generic(&adapter->hw);
 
-	/* MSI/X configuration for 82574 */
-	if (adapter->hw.mac.type == e1000_82574) {
-		int tmp;
-		tmp = E1000_READ_REG(&adapter->hw, E1000_CTRL_EXT);
-		tmp |= E1000_CTRL_EXT_PBA_CLR;
-		E1000_WRITE_REG(&adapter->hw, E1000_CTRL_EXT, tmp);
-		/*
-		** Set the IVAR - interrupt vector routing.
-		** Each nibble represents a vector, high bit
-		** is enable, other 3 bits are the MSIX table
-		** entry, we map RXQ0 to 0, TXQ0 to 1, and
-		** Link (other) to 2, hence the magic number.
-		*/
-		E1000_WRITE_REG(&adapter->hw, E1000_IVAR, 0x800A0908);
-	}
-
 #ifdef DEVICE_POLLING
 	/*
 	 * Only enable interrupts if we are not polling, make sure
@@ -1271,7 +1262,6 @@ lem_poll(struct ifnet *ifp, enum poll_cmd cmd, int count)
 }
 #endif /* DEVICE_POLLING */
 
-#ifdef EM_LEGACY_IRQ 
 /*********************************************************************
  *
  *  Legacy Interrupt Service routine  
@@ -1285,7 +1275,8 @@ lem_intr(void *arg)
 	u32		reg_icr;
 
 
-	if (ifp->if_capenable & IFCAP_POLLING)
+	if ((ifp->if_capenable & IFCAP_POLLING) ||
+	    ((ifp->if_drv_flags & IFF_DRV_RUNNING) == 0))
 		return;
 
 	EM_CORE_LOCK(adapter);
@@ -1293,11 +1284,10 @@ lem_intr(void *arg)
 	if (reg_icr & E1000_ICR_RXO)
 		adapter->rx_overruns++;
 
-	if ((reg_icr == 0xffffffff) || (reg_icr == 0))
-			goto out;
-
-	if ((ifp->if_drv_flags & IFF_DRV_RUNNING) == 0)
-			goto out;
+	if ((reg_icr == 0xffffffff) || (reg_icr == 0)) {
+		EM_CORE_UNLOCK(adapter);
+		return;
+	}
 
 	if (reg_icr & (E1000_ICR_RXSEQ | E1000_ICR_LSC)) {
 		callout_stop(&adapter->timer);
@@ -1307,23 +1297,22 @@ lem_intr(void *arg)
 		lem_tx_purge(adapter);
 		callout_reset(&adapter->timer, hz,
 		    lem_local_timer, adapter);
-		goto out;
+		EM_CORE_UNLOCK(adapter);
+		return;
 	}
 
-	EM_TX_LOCK(adapter);
+	EM_CORE_UNLOCK(adapter);
 	lem_rxeof(adapter, -1, NULL);
+
+	EM_TX_LOCK(adapter);
 	lem_txeof(adapter);
 	if (ifp->if_drv_flags & IFF_DRV_RUNNING &&
 	    !IFQ_DRV_IS_EMPTY(&ifp->if_snd))
 		lem_start_locked(ifp);
 	EM_TX_UNLOCK(adapter);
-
-out:
-	EM_CORE_UNLOCK(adapter);
 	return;
 }
 
-#else /* EM_FAST_IRQ, then fast interrupt routines only */
 
 static void
 lem_handle_link(void *context, int pending)
@@ -1407,7 +1396,6 @@ lem_irq_fast(void *arg)
 		adapter->rx_overruns++;
 	return FILTER_HANDLED;
 }
-#endif /* ~EM_LEGACY_IRQ */
 
 
 /*********************************************************************
@@ -1583,7 +1571,7 @@ lem_xmit(struct adapter *adapter, struct mbuf **m_headp)
 	if (error == EFBIG) {
 		struct mbuf *m;
 
-		m = m_defrag(*m_headp, M_DONTWAIT);
+		m = m_defrag(*m_headp, M_NOWAIT);
 		if (m == NULL) {
 			adapter->mbuf_alloc_failed++;
 			m_freem(*m_headp);
@@ -2204,19 +2192,21 @@ lem_allocate_irq(struct adapter *adapter)
 		return (ENXIO);
 	}
 
-#ifdef EM_LEGACY_IRQ
-	/* We do Legacy setup */
-	if ((error = bus_setup_intr(dev, adapter->res[0],
-	    INTR_TYPE_NET | INTR_MPSAFE, NULL, lem_intr, adapter,
-	    &adapter->tag[0])) != 0) {
-		device_printf(dev, "Failed to register interrupt handler");
-		return (error);
+	/* Do Legacy setup? */
+	if (lem_use_legacy_irq) {
+		if ((error = bus_setup_intr(dev, adapter->res[0],
+	    	    INTR_TYPE_NET | INTR_MPSAFE, NULL, lem_intr, adapter,
+	    	    &adapter->tag[0])) != 0) {
+			device_printf(dev,
+			    "Failed to register interrupt handler");
+			return (error);
+		}
+		return (0);
 	}
 
-#else /* FAST_IRQ */
 	/*
-	 * Try allocating a fast interrupt and the associated deferred
-	 * processing contexts.
+	 * Use a Fast interrupt and the associated
+	 * deferred processing contexts.
 	 */
 	TASK_INIT(&adapter->rxtx_task, 0, lem_handle_rxtx, adapter);
 	TASK_INIT(&adapter->link_task, 0, lem_handle_link, adapter);
@@ -2233,7 +2223,6 @@ lem_allocate_irq(struct adapter *adapter)
 		adapter->tq = NULL;
 		return (error);
 	}
-#endif  /* EM_LEGACY_IRQ */
 	
 	return (0);
 }
@@ -2638,6 +2627,11 @@ static void
 lem_setup_transmit_structures(struct adapter *adapter)
 {
 	struct em_buffer *tx_buffer;
+#ifdef DEV_NETMAP
+	/* we are already locked */
+	struct netmap_adapter *na = NA(adapter->ifp);
+	struct netmap_slot *slot = netmap_reset(na, NR_TX, 0, 0);
+#endif /* DEV_NETMAP */
 
 	/* Clear the old ring contents */
 	bzero(adapter->tx_desc_base,
@@ -2651,6 +2645,19 @@ lem_setup_transmit_structures(struct adapter *adapter)
 		bus_dmamap_unload(adapter->txtag, tx_buffer->map);
 		m_freem(tx_buffer->m_head);
 		tx_buffer->m_head = NULL;
+#ifdef DEV_NETMAP
+		if (slot) {
+			/* the i-th NIC entry goes to slot si */
+			int si = netmap_idx_n2k(&na->tx_rings[0], i);
+			uint64_t paddr;
+			void *addr;
+
+			addr = PNMB(slot + si, &paddr);
+			adapter->tx_desc_base[si].buffer_addr = htole64(paddr);
+			/* reload the map for netmap mode */
+			netmap_load_map(adapter->txtag, tx_buffer->map, addr);
+		}
+#endif /* DEV_NETMAP */
 		tx_buffer->next_eop = -1;
 	}
 
@@ -2952,6 +2959,12 @@ lem_txeof(struct adapter *adapter)
 
 	EM_TX_LOCK_ASSERT(adapter);
 
+#ifdef DEV_NETMAP
+	if (ifp->if_capenable & IFCAP_NETMAP) {
+		selwakeuppri(&NA(ifp)->tx_rings[0].si, PI_NET);
+		return;
+	}
+#endif /* DEV_NETMAP */
         if (adapter->num_tx_desc_avail == adapter->num_tx_desc)
                 return;
 
@@ -3067,7 +3080,7 @@ lem_get_buf(struct adapter *adapter, int i)
 	struct em_buffer	*rx_buffer;
 	int			error, nsegs;
 
-	m = m_getcl(M_DONTWAIT, MT_DATA, M_PKTHDR);
+	m = m_getcl(M_NOWAIT, MT_DATA, M_PKTHDR);
 	if (m == NULL) {
 		adapter->mbuf_cluster_failed++;
 		return (ENOBUFS);
@@ -3182,6 +3195,11 @@ lem_setup_receive_structures(struct adapter *adapter)
 {
 	struct em_buffer *rx_buffer;
 	int i, error;
+#ifdef DEV_NETMAP
+	/* we are already under lock */
+	struct netmap_adapter *na = NA(adapter->ifp);
+	struct netmap_slot *slot = netmap_reset(na, NR_RX, 0, 0);
+#endif
 
 	/* Reset descriptor ring */
 	bzero(adapter->rx_desc_base,
@@ -3201,6 +3219,20 @@ lem_setup_receive_structures(struct adapter *adapter)
 
 	/* Allocate new ones. */
 	for (i = 0; i < adapter->num_rx_desc; i++) {
+#ifdef DEV_NETMAP
+		if (slot) {
+			/* the i-th NIC entry goes to slot si */
+			int si = netmap_idx_n2k(&na->rx_rings[0], i);
+			uint64_t paddr;
+			void *addr;
+
+			addr = PNMB(slot + si, &paddr);
+			netmap_load_map(adapter->rxtag, rx_buffer->map, addr);
+			/* Update descriptor */
+			adapter->rx_desc_base[i].buffer_addr = htole64(paddr);
+			continue;
+		}
+#endif /* DEV_NETMAP */
 		error = lem_get_buf(adapter, i);
 		if (error)
                         return (error);
@@ -3248,20 +3280,6 @@ lem_initialize_receive_unit(struct adapter *adapter)
 		E1000_WRITE_REG(&adapter->hw, E1000_ITR, DEFAULT_ITR);
 	}
 
-	/*
-	** When using MSIX interrupts we need to throttle
-	** using the EITR register (82574 only)
-	*/
-	if (adapter->msix)
-		for (int i = 0; i < 4; i++)
-			E1000_WRITE_REG(&adapter->hw,
-			    E1000_EITR_82574(i), DEFAULT_ITR);
-
-	/* Disable accelerated ackknowledge */
-	if (adapter->hw.mac.type == e1000_82574)
-		E1000_WRITE_REG(&adapter->hw,
-		    E1000_RFCTL, E1000_RFCTL_ACK_DIS);
-
 	/* Setup the Base and Length of the Rx Descriptor Ring */
 	bus_addr = adapter->rxdma.dma_paddr;
 	E1000_WRITE_REG(&adapter->hw, E1000_RDLEN(0),
@@ -3325,6 +3343,18 @@ lem_initialize_receive_unit(struct adapter *adapter)
 	 * Tail Descriptor Pointers
 	 */
 	E1000_WRITE_REG(&adapter->hw, E1000_RDH(0), 0);
+#ifdef DEV_NETMAP
+	/* preserve buffers already made available to clients */
+	if (ifp->if_capenable & IFCAP_NETMAP) {
+		struct netmap_adapter *na = NA(adapter->ifp);
+		struct netmap_kring *kring = &na->rx_rings[0];
+		int t = na->num_rx_desc - 1 - kring->nr_hwavail;
+
+		if (t >= na->num_rx_desc)
+			t -= na->num_rx_desc;
+		E1000_WRITE_REG(&adapter->hw, E1000_RDT(0), t);
+	} else
+#endif /* DEV_NETMAP */
 	E1000_WRITE_REG(&adapter->hw, E1000_RDT(0), adapter->num_rx_desc - 1);
 
 	return;
@@ -3408,6 +3438,16 @@ lem_rxeof(struct adapter *adapter, int count, int *done)
 	bus_dmamap_sync(adapter->rxdma.dma_tag, adapter->rxdma.dma_map,
 	    BUS_DMASYNC_POSTREAD);
 
+#ifdef DEV_NETMAP
+	if (ifp->if_capenable & IFCAP_NETMAP) {
+		struct netmap_adapter *na = NA(ifp);
+		na->rx_rings[0].nr_kflags |= NKR_PENDINTR;
+		selwakeuppri(&na->rx_rings[0].si, PI_NET);
+		EM_RX_UNLOCK(adapter);
+		return (0);
+	}
+#endif /* DEV_NETMAP */
+
 	if (!((current_desc->status) & E1000_RXD_STAT_DD)) {
 		if (done != NULL)
 			*done = rx_sent;
@@ -3598,7 +3638,7 @@ lem_fixup_rx(struct adapter *adapter)
 		bcopy(m->m_data, m->m_data + ETHER_HDR_LEN, m->m_len);
 		m->m_data += ETHER_HDR_LEN;
 	} else {
-		MGETHDR(n, M_DONTWAIT, MT_DATA);
+		MGETHDR(n, M_NOWAIT, MT_DATA);
 		if (n != NULL) {
 			bcopy(m->m_data, n->m_data, ETHER_HDR_LEN);
 			m->m_data += ETHER_HDR_LEN;
@@ -3747,10 +3787,6 @@ lem_setup_vlan_hw_support(struct adapter *adapter)
 	reg &= ~E1000_RCTL_CFIEN;
 	reg |= E1000_RCTL_VFE;
 	E1000_WRITE_REG(hw, E1000_RCTL, reg);
-
-	/* Update the frame size */
-	E1000_WRITE_REG(&adapter->hw, E1000_RLPML,
-	    adapter->max_frame_size + VLAN_TAG_SIZE);
 }
 
 static void
@@ -3759,10 +3795,6 @@ lem_enable_intr(struct adapter *adapter)
 	struct e1000_hw *hw = &adapter->hw;
 	u32 ims_mask = IMS_ENABLE_MASK;
 
-	if (adapter->msix) {
-		E1000_WRITE_REG(hw, EM_EIAC, EM_MSIX_MASK);
-		ims_mask |= EM_MSIX_MASK;
-	} 
 	E1000_WRITE_REG(hw, E1000_IMS, ims_mask);
 }
 
@@ -3771,9 +3803,7 @@ lem_disable_intr(struct adapter *adapter)
 {
 	struct e1000_hw *hw = &adapter->hw;
 
-	if (adapter->msix)
-		E1000_WRITE_REG(hw, EM_EIAC, 0);
-	E1000_WRITE_REG(&adapter->hw, E1000_IMC, 0xffffffff);
+	E1000_WRITE_REG(hw, E1000_IMC, 0xffffffff);
 }
 
 /*
@@ -4607,7 +4637,6 @@ lem_set_flow_cntrl(struct adapter *adapter, const char *name,
 	    OID_AUTO, name, CTLTYPE_INT|CTLFLAG_RW, limit, value, description);
 }
 
-#ifndef EM_LEGACY_IRQ
 static void
 lem_add_rx_process_limit(struct adapter *adapter, const char *name,
 	const char *description, int *limit, int value)
@@ -4617,4 +4646,3 @@ lem_add_rx_process_limit(struct adapter *adapter, const char *name,
 	    SYSCTL_CHILDREN(device_get_sysctl_tree(adapter->dev)),
 	    OID_AUTO, name, CTLTYPE_INT|CTLFLAG_RW, limit, value, description);
 }
-#endif
diff --git a/sys/modules/em/Makefile b/sys/modules/em/Makefile
index b74ddf1..870d48a 100644
--- a/sys/modules/em/Makefile
+++ b/sys/modules/em/Makefile
@@ -9,7 +9,7 @@ CORE_SRC = if_em.c e1000_osdep.c
 # undefined when using modular driver if not needed
 LEGACY_SRC    += if_lem.c
 COMMON_SHARED = e1000_api.c e1000_phy.c e1000_nvm.c e1000_mac.c \
-		e1000_manage.c e1000_vf.c e1000_mbx.c
+		e1000_manage.c e1000_vf.c e1000_mbx.c e1000_i210.c
 PCIE_SHARED = e1000_80003es2lan.c e1000_ich8lan.c e1000_82571.c e1000_82575.c
 LEGACY_SHARED = e1000_82540.c e1000_82542.c e1000_82541.c e1000_82543.c
 
diff --git a/sys/modules/igb/Makefile b/sys/modules/igb/Makefile
index a66c32a..45b7ec2 100644
--- a/sys/modules/igb/Makefile
+++ b/sys/modules/igb/Makefile
@@ -6,7 +6,7 @@ SRCS    += if_igb.c $(SHARED_SRCS)
 SHARED_SRCS = e1000_api.c e1000_phy.c e1000_nvm.c e1000_mac.c e1000_manage.c
 SHARED_SRCS += e1000_80003es2lan.c e1000_82542.c e1000_82541.c e1000_82543.c
 SHARED_SRCS += e1000_82540.c e1000_ich8lan.c e1000_82571.c e1000_osdep.c
-SHARED_SRCS += e1000_82575.c e1000_vf.c e1000_mbx.c
+SHARED_SRCS += e1000_82575.c e1000_vf.c e1000_mbx.c e1000_i210.c
 
 CFLAGS += -I${.CURDIR}/../../dev/e1000 -DSMP
 
